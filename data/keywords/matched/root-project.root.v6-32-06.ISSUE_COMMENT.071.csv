id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/issues/11624:4319,deployability,API,API,4319," of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset wi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1501,integrability,pipelin,pipeline,1501,"ards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing diff",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2367,integrability,event,event,2367,"ther we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specifi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2519,integrability,event,event,2519,"xecution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3634,integrability,API,API,3634," left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this exampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4319,integrability,API,API,4319," of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset wi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:822,interoperability,format,formats,822,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:986,interoperability,format,format,986,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1085,interoperability,heterogen,heterogenous,1085,"think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1614,interoperability,specif,specification,1614,"estions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/sampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1709,interoperability,specif,specifying,1709,"vel key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1737,interoperability,format,formats,1737," > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would li",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2567,interoperability,heterogen,heterogeneous,2567,"want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2996,interoperability,specif,specified,2996,"ends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3236,interoperability,specif,specified,3236,"opying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3363,interoperability,specif,specific,3363,"event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3389,interoperability,specif,specific,3389,"me number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3549,interoperability,specif,specified,3549,"e idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3634,interoperability,API,API,3634," left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this exampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3722,interoperability,specif,specification,3722,"d I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the var",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3947,interoperability,specif,specification,3947,"ck of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4064,interoperability,specif,specified,4064,"go there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4319,interoperability,API,API,4319," of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset wi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4898,interoperability,specif,specification,4898,"metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset with join relationships. I guess in your example it would mean that some files could be left-joined, some other files could be inner-joined, keeping always the same set of files as the ""main dataset"" for that particular ""dataset/sample"". Let me know if I got it right.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:5293,interoperability,specif,specify,5293,"metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset with join relationships. I guess in your example it would mean that some files could be left-joined, some other files could be inner-joined, keeping always the same set of files as the ""main dataset"" for that particular ""dataset/sample"". Let me know if I got it right.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1361,modifiability,layer,layer,1361,"d of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1428,modifiability,layer,layer,1428," schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that thi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1600,modifiability,concern,concerns,1600,"probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with so",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2466,modifiability,exten,extend,2466,"f reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1357,performance,I/O,I/O,1357,"nstead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3009,performance,execution time,execution time,3009,"Ntuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4040,performance,error,error,4040," the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4609,performance,time,time,4609,"metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset with join relationships. I guess in your example it would mean that some files could be left-joined, some other files could be inner-joined, keeping always the same set of files as the ""main dataset"" for that particular ""dataset/sample"". Let me know if I got it right.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:844,reliability,doe,does,844,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:5045,reliability,pra,practically,5045,"metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset with join relationships. I guess in your example it would mean that some files could be left-joined, some other files could be inner-joined, keeping always the same set of files as the ""main dataset"" for that particular ""dataset/sample"". Let me know if I got it right.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:36,safety,input,input,36,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:212,safety,valid,validation,212,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1792,safety,input,input,1792,"should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2406,safety,compl,completely,2406,"he analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3251,safety,test,testing,3251," operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3462,safety,test,testing,3462,"extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3899,safety,reme,remember,3899,"very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset speci",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4040,safety,error,error,4040," the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:212,security,validat,validation,212,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2406,security,compl,completely,2406,"he analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3622,security,expos,expose,3622,"aving to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:760,testability,plan,plan,760,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1600,testability,concern,concerns,1600,"probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with so",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3251,testability,test,testing,3251," operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3462,testability,test,testing,3462,"extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:36,usability,input,input,36,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:777,usability,support,support,777,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:922,usability,user,user-facing,922,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1316,usability,clear,clear,1316,"tion effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a le",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1423,usability,tool,tool,1423,"se two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1792,usability,input,input,1792,"should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3031,usability,user,user,3031,"ee we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the to",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4031,usability,tool,tool,4031,"er. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" k",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4040,usability,error,error,4040," the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4379,usability,user,user,4379,"ge to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset with join relationships. I guess in your example it would mean",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:5281,usability,user,users,5281,"metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a single dictionary with those keys (treenames, files, joinType), there could be a list of dictionaries with the same keys, right? This is the implementation of your comment from above mentioning that users could specify an entire dataset with join relationships. I guess in your example it would mean that some files could be left-joined, some other files could be inner-joined, keeping always the same set of files as the ""main dataset"" for that particular ""dataset/sample"". Let me know if I got it right.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:385,energy efficiency,current,currently,385,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:51,integrability,translat,translate,51,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:101,integrability,Event,Events,101,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:314,integrability,event,event,314,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:362,integrability,event,events,362,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:31,interoperability,specif,specification,31,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:51,interoperability,translat,translate,51,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:796,reliability,pra,practically,796,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:644,usability,support,supported,644,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:678,usability,support,support,678,"> Dear @hageboeck,. > . > That specification would translate to. > . > ```c++. > TChain c;. > c.Add(""Events"", ""fa*.root"");. > c.Add(""ADifferentName"", ""TheWeirdFileWithTheDifferentName"");. > ```. > . > For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. > . > RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. > . > I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough. This is what I would have expected. I don't think that you need to do anything in addition. Just note that it's `c.Add(""path/to/file#treename"")`; not two arguments.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:70,energy efficiency,current,current,70,"> not two arguments. Indeed, thanks for checking. I modified with the current suggested syntax from [TChain::Add](https://root.cern.ch/doc/master/classTChain.html#a78a896924ac6c7d3691b7e013bcbfb1c).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:52,security,modif,modified,52,"> not two arguments. Indeed, thanks for checking. I modified with the current suggested syntax from [TChain::Add](https://root.cern.ch/doc/master/classTChain.html#a78a896924ac6c7d3691b7e013bcbfb1c).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11626:153,availability,down,downloaded,153,Actually root should be the directory where the starlight source are located. So it could be something like. `cmake /home/physics/starlight` if you have downloaded the sources in your home directory.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11626
https://github.com/root-project/root/issues/11626:63,availability,error,error,63,I tried to run cmake /home/physics/starlight it gives the same error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11626
https://github.com/root-project/root/issues/11626:63,performance,error,error,63,I tried to run cmake /home/physics/starlight it gives the same error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11626
https://github.com/root-project/root/issues/11626:63,safety,error,error,63,I tried to run cmake /home/physics/starlight it gives the same error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11626
https://github.com/root-project/root/issues/11626:63,usability,error,error,63,I tried to run cmake /home/physics/starlight it gives the same error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11626
https://github.com/root-project/root/issues/11626:15,availability,down,downloaded,15,Where have you downloaded Starlight? Or where did you run `svn co http://starlight.hepforge.org/svn/trunk`? In which directory?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11626
https://github.com/root-project/root/pull/11627:115,availability,failur,failure,115,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:115,deployability,fail,failure,115,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:115,performance,failur,failure,115,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:31,reliability,Doe,Does,31,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:115,reliability,fail,failure,115,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:61,safety,review,review,61,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:110,safety,test,test,110,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:61,testability,review,review,61,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:110,testability,test,test,110,"Hi @egpbos, thanks for the PR! Does it makes sense for me to review already now, or you first want to fix the test failure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:89,deployability,fail,failing,89,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:282,deployability,fail,failing,282,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:829,deployability,fail,fail,829,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:516,energy efficiency,schedul,scheduling,516,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:568,energy efficiency,predict,predictable,568,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:655,integrability,queue,queue,655,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:783,integrability,queue,queue,783,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:866,integrability,queue,queue,866,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:20,performance,time,time,20,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:516,performance,schedul,scheduling,516,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:655,performance,queue,queue,655,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:668,performance,time,time,668,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:783,performance,queue,queue,783,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:793,performance,time,time,793,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:866,performance,queue,queue,866,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:89,reliability,fail,failing,89,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:282,reliability,fail,failing,282,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:295,reliability,doe,does,295,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:829,reliability,fail,fail,829,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:904,reliability,doe,doesn,904,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:28,safety,review,review,28,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:97,safety,test,test,97,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:253,safety,test,test,253,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:290,safety,test,test,290,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:568,safety,predict,predictable,568,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:28,testability,review,review,28,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:97,testability,test,test,97,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:253,testability,test,test,253,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:290,testability,test,test,290,"If you already have time to review than it should be fine to start now, yes. I think the failing test is just a matter of too strict assumptions, should be easily fixable by relaxing that. Btw, if you have suggestions there of how to construct a better test, I'm all ears. What the failing test does is: 1. assign task priorities, 2. run the tasks and record the order in which they are executed, 3. check the received order against the suggested one via the priorities. The problem is that due to random OS process scheduling delays, the received order is never 100% predictable. The only thing that is guaranteed is that if it has multiple tasks in the queue at one time that it will execute the one with highest priority first. I could introduce `sleep`s in each task so that the queue has time to fill up, but it could still fail randomly if for some reason the queue filling is delayed, so it still doesn't guarantee anything...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:8,safety,review,review,8,"Ok, all review suggestions handled, thanks! If CI passes, it is good to merge from my side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:8,testability,review,review,8,"Ok, all review suggestions handled, thanks! If CI passes, it is good to merge from my side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:285,safety,compl,completed,285,"Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:36,security,rotat,rotate,36,"Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:285,security,compl,completed,285,"Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:488,deployability,stack,stackoverflow,488,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:614,deployability,log,logical,614,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:389,reliability,doe,does,389,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:287,safety,compl,completed,287,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:614,safety,log,logical,614,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:38,security,rotat,rotate,38,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:287,security,compl,completed,287,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:381,security,rotat,rotate,381,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:614,security,log,logical,614,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:614,testability,log,logical,614,"> Ah, I think I know the issue: `std::rotate` is not exactly what we're looking for. It's typically **only one** out of 0, 1 or 2 (or sometimes 3 (or 4...)) that is put in front. After that, the rest of the tasks will go in intended order. So we should remove the first element from the completed range and insert it in front of `expected_order`. But isn't this exactly what `std::rotate` does? It is even explicitly recommended for deletion and reinsertion because it's faster:. https://stackoverflow.com/questions/29785266/moving-object-to-front-of-vector-c. Maybe I'm missing something, but what exactly is the logical difference between the code I suggested and the code you have now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:679,availability,failur,failures,679,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:713,availability,slo,slow,713,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1001,availability,robust,robust,1001,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:148,deployability,roll,roll,148,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:679,deployability,fail,failures,679,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:781,deployability,fail,fails,781,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:422,integrability,queue,queue,422,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1059,integrability,queue,queue,1059,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1091,integrability,sub,submitted,1091,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:422,performance,queue,queue,422,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:550,performance,time,time,550,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:679,performance,failur,failures,679,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1059,performance,queue,queue,1059,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:679,reliability,fail,failures,679,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:713,reliability,slo,slow,713,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:781,reliability,fail,fails,781,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1001,reliability,robust,robust,1001,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:770,safety,test,test,770,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:988,safety,test,test,988,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1001,safety,robust,robust,1001,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1283,safety,test,testing,1283,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:47,security,rotat,rotate,47,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:55,security,rotat,rotated,55,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:839,security,modif,modify,839,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1370,security,rotat,rotate,1370,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:770,testability,test,test,770,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:988,testability,test,test,988,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:1283,testability,test,testing,1283,"You're right! I misunderstood, I thought `std::rotate` rotated the whole iterable (e.g. like https://numpy.org/doc/stable/reference/generated/numpy.roll.html), but I see now it only puts the selected part in front and shoves the rest aside to make room. But then apparently there are still situations that we are not catching. I think probably sometimes there will be yet another task executed before all tasks are in the queue. This is of course always possible, because the OS can delay processes and IPC in any way it sees fit. I can up the sleep time to compensate for this so it happens less often, but it is by the nature of the algorithm unavoidable that some statistical failures will still happen (given slow enough OS'es). What we can do to make sure that the test never fails is to iteratively go through all received tasks and modify the expected order until it matches, but of course in the extreme case that every step is reordered this would then defeat the purpose of the test. A more robust approach would be to wait with taking work off the queue until all tasks have been submitted, but this is not actually desirable functionality, because that would mean workers would be doing nothing when they could already be working. Introducing such functionality just for testing purposes seems silly. So not sure how to ""fix"" this. I will at least put `std::rotate` back in.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:604,energy efficiency,current,currently,604,"Ok, I have now set up the test in the only way possible, I think. It walks through the received tasks array, placing them in front of the `expected_order` array, until it finds task 9. After task 9, the rest of the received tasks must be in correct priority order. This is the only guarantee that can be given in this asynchronous system. Worst case received order would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Basically, two constraints are guaranteed: in the first part of the received array the task number increases monotonically and the second part (after 9) decreases monotonically. Oh, actually, I'm not currently checking the monotonic increase in the first part, that should be added! Then the test is really as strict as it can be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:318,integrability,asynchron,asynchronous,318,"Ok, I have now set up the test in the only way possible, I think. It walks through the received tasks array, placing them in front of the `expected_order` array, until it finds task 9. After task 9, the rest of the received tasks must be in correct priority order. This is the only guarantee that can be given in this asynchronous system. Worst case received order would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Basically, two constraints are guaranteed: in the first part of the received array the task number increases monotonically and the second part (after 9) decreases monotonically. Oh, actually, I'm not currently checking the monotonic increase in the first part, that should be added! Then the test is really as strict as it can be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:318,performance,asynch,asynchronous,318,"Ok, I have now set up the test in the only way possible, I think. It walks through the received tasks array, placing them in front of the `expected_order` array, until it finds task 9. After task 9, the rest of the received tasks must be in correct priority order. This is the only guarantee that can be given in this asynchronous system. Worst case received order would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Basically, two constraints are guaranteed: in the first part of the received array the task number increases monotonically and the second part (after 9) decreases monotonically. Oh, actually, I'm not currently checking the monotonic increase in the first part, that should be added! Then the test is really as strict as it can be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:26,safety,test,test,26,"Ok, I have now set up the test in the only way possible, I think. It walks through the received tasks array, placing them in front of the `expected_order` array, until it finds task 9. After task 9, the rest of the received tasks must be in correct priority order. This is the only guarantee that can be given in this asynchronous system. Worst case received order would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Basically, two constraints are guaranteed: in the first part of the received array the task number increases monotonically and the second part (after 9) decreases monotonically. Oh, actually, I'm not currently checking the monotonic increase in the first part, that should be added! Then the test is really as strict as it can be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:696,safety,test,test,696,"Ok, I have now set up the test in the only way possible, I think. It walks through the received tasks array, placing them in front of the `expected_order` array, until it finds task 9. After task 9, the rest of the received tasks must be in correct priority order. This is the only guarantee that can be given in this asynchronous system. Worst case received order would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Basically, two constraints are guaranteed: in the first part of the received array the task number increases monotonically and the second part (after 9) decreases monotonically. Oh, actually, I'm not currently checking the monotonic increase in the first part, that should be added! Then the test is really as strict as it can be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:26,testability,test,test,26,"Ok, I have now set up the test in the only way possible, I think. It walks through the received tasks array, placing them in front of the `expected_order` array, until it finds task 9. After task 9, the rest of the received tasks must be in correct priority order. This is the only guarantee that can be given in this asynchronous system. Worst case received order would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Basically, two constraints are guaranteed: in the first part of the received array the task number increases monotonically and the second part (after 9) decreases monotonically. Oh, actually, I'm not currently checking the monotonic increase in the first part, that should be added! Then the test is really as strict as it can be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:696,testability,test,test,696,"Ok, I have now set up the test in the only way possible, I think. It walks through the received tasks array, placing them in front of the `expected_order` array, until it finds task 9. After task 9, the rest of the received tasks must be in correct priority order. This is the only guarantee that can be given in this asynchronous system. Worst case received order would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Basically, two constraints are guaranteed: in the first part of the received array the task number increases monotonically and the second part (after 9) decreases monotonically. Oh, actually, I'm not currently checking the monotonic increase in the first part, that should be added! Then the test is really as strict as it can be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:230,deployability,continu,continues,230,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:380,deployability,updat,update,380,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:107,integrability,queue,queue,107,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:202,integrability,queue,queue,202,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:394,modifiability,refact,refactoring,394,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:107,performance,queue,queue,107,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:202,performance,queue,queue,202,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:394,performance,refactor,refactoring,394,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:347,safety,valid,valid,347,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:380,safety,updat,update,380,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:423,safety,compl,complicated,423,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:380,security,updat,update,380,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:423,security,compl,complicated,423,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:129,usability,paus,pauses,129,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:192,usability,paus,pauses,192,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:. 1 [ reception pauses on queue here ]. 0 [ reception continues now, 2 comes in ]. 2 [ while executing 2, everything else is received ]. 9. 8. 7. 6. ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/pull/11627:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627
https://github.com/root-project/root/issues/11629:20,availability,error,error,20,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:73,availability,error,error,73,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:20,performance,error,error,20,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:73,performance,error,error,73,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:20,safety,error,error,20,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:73,safety,error,error,73,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:20,usability,error,error,20,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:73,usability,error,error,73,How I can reproduce error? `python3 -i df104.py` script runs without any error.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:12,deployability,build,build,12,"You have to build ROOT with AddressSanitizer instrumentation (`-Dasan=ON`, best results when building with Clang) and then ideally run via `ctest` because that will set up some needed environment variables.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:93,deployability,build,building,93,"You have to build ROOT with AddressSanitizer instrumentation (`-Dasan=ON`, best results when building with Clang) and then ideally run via `ctest` because that will set up some needed environment variables.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:196,modifiability,variab,variables,196,"You have to build ROOT with AddressSanitizer instrumentation (`-Dasan=ON`, best results when building with Clang) and then ideally run via `ctest` because that will set up some needed environment variables.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:45,testability,instrument,instrumentation,45,"You have to build ROOT with AddressSanitizer instrumentation (`-Dasan=ON`, best results when building with Clang) and then ideally run via `ctest` because that will set up some needed environment variables.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:13,deployability,stack,stack,13,According to stack trace ROOT crashes when calling `TString::Append()` method of regular member `TBufferJSON::fValue`. . Most probably - due to memory corruption / illegal memory overwrite somewhere before. I do not think that `TString::Append` has problems. But why it happens only when AddressSanitizer enabled and ROOT compiled with clang?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:144,performance,memor,memory,144,According to stack trace ROOT crashes when calling `TString::Append()` method of regular member `TBufferJSON::fValue`. . Most probably - due to memory corruption / illegal memory overwrite somewhere before. I do not think that `TString::Append` has problems. But why it happens only when AddressSanitizer enabled and ROOT compiled with clang?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:172,performance,memor,memory,172,According to stack trace ROOT crashes when calling `TString::Append()` method of regular member `TBufferJSON::fValue`. . Most probably - due to memory corruption / illegal memory overwrite somewhere before. I do not think that `TString::Append` has problems. But why it happens only when AddressSanitizer enabled and ROOT compiled with clang?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:19,testability,trace,trace,19,According to stack trace ROOT crashes when calling `TString::Append()` method of regular member `TBufferJSON::fValue`. . Most probably - due to memory corruption / illegal memory overwrite somewhere before. I do not think that `TString::Append` has problems. But why it happens only when AddressSanitizer enabled and ROOT compiled with clang?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:144,usability,memor,memory,144,According to stack trace ROOT crashes when calling `TString::Append()` method of regular member `TBufferJSON::fValue`. . Most probably - due to memory corruption / illegal memory overwrite somewhere before. I do not think that `TString::Append` has problems. But why it happens only when AddressSanitizer enabled and ROOT compiled with clang?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:172,usability,memor,memory,172,According to stack trace ROOT crashes when calling `TString::Append()` method of regular member `TBufferJSON::fValue`. . Most probably - due to memory corruption / illegal memory overwrite somewhere before. I do not think that `TString::Append` has problems. But why it happens only when AddressSanitizer enabled and ROOT compiled with clang?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:71,deployability,build,build,71,"It always happens (that's why it should be addressed), an instrumented build is just a way of making it visible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:58,testability,instrument,instrumented,58,"It always happens (that's why it should be addressed), an instrumented build is just a way of making it visible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:57,performance,memor,memory,57,> It always happens . You mean it makes silently illegal memory overwrite? But then one should check `TString::Append()` - I guess.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:57,usability,memor,memory,57,> It always happens . You mean it makes silently illegal memory overwrite? But then one should check `TString::Append()` - I guess.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:198,availability,error,error,198,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:668,availability,state,state,668,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:684,availability,consist,consistent,684,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:227,deployability,stack,stack,227,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:270,integrability,buffer,buffer,270,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:668,integrability,state,state,668,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:37,performance,memor,memory,37,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:198,performance,error,error,198,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:344,performance,memor,memory,344,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:401,performance,memor,memory,401,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:115,reliability,doe,does,115,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:198,safety,error,error,198,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:408,security,access,accesses,408,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:233,testability,trace,trace,233,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:37,usability,memor,memory,37,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:198,usability,error,error,198,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:344,usability,memor,memory,344,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:401,usability,memor,memory,401,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:684,usability,consist,consistent,684,"> You mean it makes silently illegal memory overwrite? Yes, likely so. At least if doing exactly what the tutorial does. > But then one should check `TString::Append()` - I guess. I don't know, the error can be anywhere in the stack trace such as providing insufficient buffer etc. `TString::Append` is just the place that executes the illegal memory read. Also, please keep in mind that more illegal memory accesses may happen afterwards - AddressSanitizer only reports the first problem and then terminates the process. I think it is possible to keep going afterwards and see what else is going belly-up, but IIRC that is not guaranteed to work well due to internal state not being consistent...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:58,availability,operat,operations,58,Ideally AddressSanitizer should detect all illegal memory operations? Then this operation is first one? One need to check `TString::Append()`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:80,availability,operat,operation,80,Ideally AddressSanitizer should detect all illegal memory operations? Then this operation is first one? One need to check `TString::Append()`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:51,performance,memor,memory,51,Ideally AddressSanitizer should detect all illegal memory operations? Then this operation is first one? One need to check `TString::Append()`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:32,safety,detect,detect,32,Ideally AddressSanitizer should detect all illegal memory operations? Then this operation is first one? One need to check `TString::Append()`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:32,security,detect,detect,32,Ideally AddressSanitizer should detect all illegal memory operations? Then this operation is first one? One need to check `TString::Append()`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:51,usability,memor,memory,51,Ideally AddressSanitizer should detect all illegal memory operations? Then this operation is first one? One need to check `TString::Append()`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:0,availability,ping,ping,0,"ping, I still see this locally (the `root-asan` build is with C++14 I think, so no v7)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:48,deployability,build,build,48,"ping, I still see this locally (the `root-asan` build is with C++14 I think, so no v7)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:37,availability,error,error,37,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:439,availability,error,error,439,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:778,availability,error,error,778,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:12,deployability,build,build,12,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:202,deployability,build,building,202,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:211,deployability,modul,module,211,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:233,deployability,build,building,233,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:242,deployability,modul,module,242,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:309,deployability,modul,module-includes,309,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:721,deployability,modul,module,721,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:186,energy efficiency,Core,Core,186,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:219,energy efficiency,Core,Core,219,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:211,modifiability,modul,module,211,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:242,modifiability,modul,module,242,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:309,modifiability,modul,module-includes,309,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:721,modifiability,modul,module,721,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:37,performance,error,error,37,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:439,performance,error,error,439,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:675,performance,time,times,675,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:778,performance,error,error,778,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:37,safety,error,error,37,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:211,safety,modul,module,211,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:242,safety,modul,module,242,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:309,safety,modul,module-includes,309,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:439,safety,error,error,439,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:721,safety,modul,module,721,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:778,safety,error,error,778,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:37,usability,error,error,37,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:439,usability,error,error,439,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:778,usability,error,error,778,"With normal build I cannot reproduce error. With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. ```. [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. While building module 'Core':. While building module 'std' imported from input_line_1:1:. In file included from <module-includes>:18:. In file included from /usr/include/c++/13/condition_variable:40:. /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. ^. /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. #include <bits/chrono.h>. ```. Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). I using clang 15.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:415,availability,error,error,415,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:770,availability,error,error,770,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:170,deployability,build,building,170,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:179,deployability,modul,module,179,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:203,deployability,build,building,203,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:212,deployability,modul,module,212,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:281,deployability,modul,module-includes,281,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:703,deployability,modul,module,703,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:967,deployability,releas,released,967,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:152,energy efficiency,Core,Core,152,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:187,energy efficiency,Core,Core,187,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:179,modifiability,modul,module,179,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:212,modifiability,modul,module,212,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:281,modifiability,modul,module-includes,281,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:703,modifiability,modul,module,703,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:415,performance,error,error,415,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:657,performance,time,times,657,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:770,performance,error,error,770,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:179,safety,modul,module,179,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:212,safety,modul,module,212,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:281,safety,modul,module-includes,281,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:415,safety,error,error,415,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:703,safety,modul,module,703,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:770,safety,error,error,770,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:415,usability,error,error,415,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:770,usability,error,error,770,"> With `clang` and `-Dasan=ON` I getting compilation problem when generating G__Core.cxx dictionary. > . > ```. > [ 44%] Generating G__Core.cxx, ../lib/Core.pcm. > While building module 'Core':. > While building module 'std' imported from input_line_1:1:. > In file included from <module-includes>:18:. > In file included from /usr/include/c++/13/condition_variable:40:. > /usr/include/c++/13/bits/chrono.h:251:29: error: redefinition of '__is_duration_v<duration<_Rep, _Period>>'. > inline constexpr bool __is_duration_v<duration<_Rep, _Period>> = true;. > ^. > /usr/include/c++/13/chrono:41:10: note: '/usr/include/c++/13/bits/chrono.h' included multiple times, additional include site in header from module 'std.chrono'. > #include <bits/chrono.h>. > ```. > . > Full error output: [makelog.txt](https://github.com/root-project/root/files/10519180/makelog.txt). > . > I using clang 15. I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with `asan`? But anyway, unrelated to this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:188,availability,failur,failure,188,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:237,availability,ERROR,ERROR,237,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:758,availability,error,error,758,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:9,deployability,build,building,9,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:79,deployability,Releas,Release,79,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:188,deployability,fail,failure,188,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:474,deployability,build,build,474,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:513,deployability,Build,BuildId,513,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:657,deployability,build,build,657,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:696,deployability,Build,BuildId,696,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:449,integrability,configur,configure,449,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:592,interoperability,plug,plugin,592,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:449,modifiability,configur,configure,449,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:188,performance,failur,failure,188,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:237,performance,ERROR,ERROR,237,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:758,performance,error,error,758,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:188,reliability,fail,failure,188,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:237,safety,ERROR,ERROR,237,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:758,safety,error,error,758,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:449,security,configur,configure,449,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:199,testability,simpl,simply,199,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:199,usability,simpl,simply,199,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:237,usability,ERROR,ERROR,237,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:758,usability,error,error,758,"And when building with gcc and only asan like:. ```. cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui . ```. I getting failure by simply starting ROOT: . ```. ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8. READ of size 8 at 0x621000160c68 thread T0. #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300). ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:81,deployability,releas,released,81,"> I guess this is a general issue with Clang + GCC 13 headers (which is not even released yet), not only with asan? But anyway, unrelated to this issue. gcc13 is not default compiler on my system. No idea why clang tries to use them",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:17,availability,error,error,17,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:56,deployability,patch,patch,56,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:17,performance,error,error,17,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:8,reliability,doe,does,8,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:17,safety,error,error,17,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:56,safety,patch,patch,56,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:56,security,patch,patch,56,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:17,usability,error,error,17,"@hahnjo does the error report improve if you apply this patch ? https://github.com/root-project/root/pull/14627. [EDIT: sorry for the noise, never mind, it's WriteFastArray, but from TBufferJSON, not TBufferFile, so unrelated]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:39,integrability,coupl,couple,39,"@hahnjo could you check now? I fixed a couple of things in TBufferJSON as well as in TString, see:. https://github.com/root-project/root/pull/14820/files#diff-1967f5b8a8cd401aefccedbe85552a576bcbaf3b314c5b6edf253cea42fb0729. and. https://github.com/root-project/root/commit/08b024efd03ef4428603256de1e0f51240c526ef. although it's probably not enough, there are many more missing:. https://github.com/root-project/root/issues/14770#issuecomment-1963012314",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:39,modifiability,coupl,couple,39,"@hahnjo could you check now? I fixed a couple of things in TBufferJSON as well as in TString, see:. https://github.com/root-project/root/pull/14820/files#diff-1967f5b8a8cd401aefccedbe85552a576bcbaf3b314c5b6edf253cea42fb0729. and. https://github.com/root-project/root/commit/08b024efd03ef4428603256de1e0f51240c526ef. although it's probably not enough, there are many more missing:. https://github.com/root-project/root/issues/14770#issuecomment-1963012314",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/issues/11629:39,testability,coupl,couple,39,"@hahnjo could you check now? I fixed a couple of things in TBufferJSON as well as in TString, see:. https://github.com/root-project/root/pull/14820/files#diff-1967f5b8a8cd401aefccedbe85552a576bcbaf3b314c5b6edf253cea42fb0729. and. https://github.com/root-project/root/commit/08b024efd03ef4428603256de1e0f51240c526ef. although it's probably not enough, there are many more missing:. https://github.com/root-project/root/issues/14770#issuecomment-1963012314",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629
https://github.com/root-project/root/pull/11630:11,deployability,build,build,11,@phsft-bot build with flags -Dcheck_connectivity=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11630
https://github.com/root-project/root/pull/11631:103,interoperability,share,shared,103,One remaining issue is the use of the gPluginManagerMutex lock in ```TPluginManager::FindHandler```. A shared lock could solve this. Does it need to be recursive? Why is gPluginManagerMutex needed also in ```TPluginHandler::CheckForExecPlugin```?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:58,performance,lock,lock,58,One remaining issue is the use of the gPluginManagerMutex lock in ```TPluginManager::FindHandler```. A shared lock could solve this. Does it need to be recursive? Why is gPluginManagerMutex needed also in ```TPluginHandler::CheckForExecPlugin```?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:110,performance,lock,lock,110,One remaining issue is the use of the gPluginManagerMutex lock in ```TPluginManager::FindHandler```. A shared lock could solve this. Does it need to be recursive? Why is gPluginManagerMutex needed also in ```TPluginHandler::CheckForExecPlugin```?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:133,reliability,Doe,Does,133,One remaining issue is the use of the gPluginManagerMutex lock in ```TPluginManager::FindHandler```. A shared lock could solve this. Does it need to be recursive? Why is gPluginManagerMutex needed also in ```TPluginHandler::CheckForExecPlugin```?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:58,security,lock,lock,58,One remaining issue is the use of the gPluginManagerMutex lock in ```TPluginManager::FindHandler```. A shared lock could solve this. Does it need to be recursive? Why is gPluginManagerMutex needed also in ```TPluginHandler::CheckForExecPlugin```?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:110,security,lock,lock,110,One remaining issue is the use of the gPluginManagerMutex lock in ```TPluginManager::FindHandler```. A shared lock could solve this. Does it need to be recursive? Why is gPluginManagerMutex needed also in ```TPluginHandler::CheckForExecPlugin```?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:678,availability,down,down,678,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:699,availability,operat,operation,699,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:71,deployability,contain,container,71,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:255,energy efficiency,load,load,255,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:63,interoperability,share,shared,63,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:262,interoperability,share,shared,262,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:339,interoperability,Plug,PluginManager,339,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:359,interoperability,share,shared,359,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:255,performance,load,load,255,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:366,performance,lock,lock,366,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:470,performance,perform,performance,470,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:642,performance,lock,locking,642,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:195,safety,reme,remember,195,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:588,safety,safe,safe,588,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:366,security,lock,lock,366,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:642,security,lock,locking,642,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:470,usability,perform,performance,470,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:606,usability,UseR,UseRWLock,606,"`gPluginManagerMutex` is protecting (mainly but not only) the (shared) container `fHandlers`. As used, it is recursive because we can not tell what we be the side effects of `SetupCallEnv` (if I remember correctly, it calls `TClass::GetClass` which might load a shared library which might run arbitrary code including something using the `PluginManager`. > A shared lock could solve this. . I am not sure what you mean (i.e a straight replacement would not have 'large' performance improvement). One of the thing that we might be able to do is to set the `fHandlers's TList` to be thread safe (by calling `UseRWLock` on it). If we do so, the locking will be move from global to down to the internal operation of the `TList`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:31,performance,lock,lock,31,"I mean that using a read/write lock would largely solve the problem, since we could then take only the read lock in ```TPluginManager::FindHandler```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:108,performance,lock,lock,108,"I mean that using a read/write lock would largely solve the problem, since we could then take only the read lock in ```TPluginManager::FindHandler```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:31,security,lock,lock,31,"I mean that using a read/write lock would largely solve the problem, since we could then take only the read lock in ```TPluginManager::FindHandler```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:108,security,lock,lock,108,"I mean that using a read/write lock would largely solve the problem, since we could then take only the read lock in ```TPluginManager::FindHandler```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:115,deployability,automat,automatically,115,"Finally coming back to this one:. -Simplified a little the implementation of ExecPlugin to attempt the ""fast path"" automatically, while also allowing to explicitly provide the types. -replaced gPluginManagerMutex with the internal RWLock of the underlying TList as suggested",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:35,testability,Simpl,Simplified,35,"Finally coming back to this one:. -Simplified a little the implementation of ExecPlugin to attempt the ""fast path"" automatically, while also allowing to explicitly provide the types. -replaced gPluginManagerMutex with the internal RWLock of the underlying TList as suggested",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:115,testability,automat,automatically,115,"Finally coming back to this one:. -Simplified a little the implementation of ExecPlugin to attempt the ""fast path"" automatically, while also allowing to explicitly provide the types. -replaced gPluginManagerMutex with the internal RWLock of the underlying TList as suggested",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:35,usability,Simpl,Simplified,35,"Finally coming back to this one:. -Simplified a little the implementation of ExecPlugin to attempt the ""fast path"" automatically, while also allowing to explicitly provide the types. -replaced gPluginManagerMutex with the internal RWLock of the underlying TList as suggested",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:0,availability,Failur,Failure,0,Failure for ubuntu20 build looks possibly unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:0,deployability,Fail,Failure,0,Failure for ubuntu20 build looks possibly unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:21,deployability,build,build,21,Failure for ubuntu20 build looks possibly unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:0,performance,Failur,Failure,0,Failure for ubuntu20 build looks possibly unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:0,reliability,Fail,Failure,0,Failure for ubuntu20 build looks possibly unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:57,availability,failur,failure,57,Rebased to hopefully avoid the previously remaining test failure.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:57,deployability,fail,failure,57,Rebased to hopefully avoid the previously remaining test failure.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:57,performance,failur,failure,57,Rebased to hopefully avoid the previously remaining test failure.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:57,reliability,fail,failure,57,Rebased to hopefully avoid the previously remaining test failure.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:21,safety,avoid,avoid,21,Rebased to hopefully avoid the previously remaining test failure.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:52,safety,test,test,52,Rebased to hopefully avoid the previously remaining test failure.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:52,testability,test,test,52,Rebased to hopefully avoid the previously remaining test failure.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:27,deployability,fail,failing,27,I THINK that the remaining failing tests are all unrelated to this PR...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:27,reliability,fail,failing,27,I THINK that the remaining failing tests are all unrelated to this PR...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:35,safety,test,tests,35,I THINK that the remaining failing tests are all unrelated to this PR...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11631:35,testability,test,tests,35,I THINK that the remaining failing tests are all unrelated to this PR...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11631
https://github.com/root-project/root/pull/11632:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11632
https://github.com/root-project/root/pull/11635:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11635
https://github.com/root-project/root/issues/11636:139,integrability,messag,message,139,"I think it is better for you to ask help on the ROOT forum instead of on the issues section on Github. Actually, you have already posted a message on the forum [here](https://root-forum.cern.ch/t/permission-denied/52089/2). So I think, this issue and [this one](https://github.com/root-project/root/issues/11626) should be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11636
https://github.com/root-project/root/issues/11636:139,interoperability,messag,message,139,"I think it is better for you to ask help on the ROOT forum instead of on the issues section on Github. Actually, you have already posted a message on the forum [here](https://root-forum.cern.ch/t/permission-denied/52089/2). So I think, this issue and [this one](https://github.com/root-project/root/issues/11626) should be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11636
https://github.com/root-project/root/issues/11636:196,safety,permiss,permission-denied,196,"I think it is better for you to ask help on the ROOT forum instead of on the issues section on Github. Actually, you have already posted a message on the forum [here](https://root-forum.cern.ch/t/permission-denied/52089/2). So I think, this issue and [this one](https://github.com/root-project/root/issues/11626) should be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11636
https://github.com/root-project/root/issues/11636:36,usability,help,help,36,"I think it is better for you to ask help on the ROOT forum instead of on the issues section on Github. Actually, you have already posted a message on the forum [here](https://root-forum.cern.ch/t/permission-denied/52089/2). So I think, this issue and [this one](https://github.com/root-project/root/issues/11626) should be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11636
https://github.com/root-project/root/issues/11636:323,usability,close,closed,323,"I think it is better for you to ask help on the ROOT forum instead of on the issues section on Github. Actually, you have already posted a message on the forum [here](https://root-forum.cern.ch/t/permission-denied/52089/2). So I think, this issue and [this one](https://github.com/root-project/root/issues/11626) should be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11636
https://github.com/root-project/root/issues/11636:140,deployability,continu,continue,140,"Right, and the problem also doesn't appear to be related to ROOT. In any case, if it turns out that the question is related to ROOT, let us continue discussing on the forum :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11636
https://github.com/root-project/root/issues/11636:28,reliability,doe,doesn,28,"Right, and the problem also doesn't appear to be related to ROOT. In any case, if it turns out that the question is related to ROOT, let us continue discussing on the forum :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11636
https://github.com/root-project/root/issues/11637:239,availability,slo,slowness,239,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:180,deployability,integr,integrated,180,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:180,integrability,integr,integrated,180,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:180,interoperability,integr,integrated,180,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:180,modifiability,integr,integrated,180,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:180,reliability,integr,integrated,180,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:239,reliability,slo,slowness,239,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:218,safety,test,test,218,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:180,security,integr,integrated,180,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:180,testability,integr,integrated,180,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:213,testability,unit,unit,213,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:218,testability,test,test,218,I think https://github.com/root-project/root/compare/99093d95f7...78228fee3b were the changes which caused this issue. There were no issues with root commit 99093d95f7 but once we integrated 78228fee3b then cmssw unit test started to show slowness,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:170,deployability,updat,update,170,"Hi, thank you very much for reporting this! It's indeed a bug that I will fix, but for the CMSSW side we can avoid the problem easily so you can proceed quickly with the update of the ROOT master branch. I have created a PR for that:. https://github.com/cms-sw/cmssw/pull/39867. Indeed, it appears I introduced a bug with recent developments where the overhead when using the `RooFit::Range()` argument blew up. But I suggest you remove this argument to begin with, because the range was the same that is used to define the `InvMass` variable to begin with. So in any case it's better for you to not use `Range()`, and then you also don't hit the code path that has the bug (and you will have less overhead once the bug is gone).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:534,modifiability,variab,variable,534,"Hi, thank you very much for reporting this! It's indeed a bug that I will fix, but for the CMSSW side we can avoid the problem easily so you can proceed quickly with the update of the ROOT master branch. I have created a PR for that:. https://github.com/cms-sw/cmssw/pull/39867. Indeed, it appears I introduced a bug with recent developments where the overhead when using the `RooFit::Range()` argument blew up. But I suggest you remove this argument to begin with, because the range was the same that is used to define the `InvMass` variable to begin with. So in any case it's better for you to not use `Range()`, and then you also don't hit the code path that has the bug (and you will have less overhead once the bug is gone).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:352,performance,overhead,overhead,352,"Hi, thank you very much for reporting this! It's indeed a bug that I will fix, but for the CMSSW side we can avoid the problem easily so you can proceed quickly with the update of the ROOT master branch. I have created a PR for that:. https://github.com/cms-sw/cmssw/pull/39867. Indeed, it appears I introduced a bug with recent developments where the overhead when using the `RooFit::Range()` argument blew up. But I suggest you remove this argument to begin with, because the range was the same that is used to define the `InvMass` variable to begin with. So in any case it's better for you to not use `Range()`, and then you also don't hit the code path that has the bug (and you will have less overhead once the bug is gone).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:698,performance,overhead,overhead,698,"Hi, thank you very much for reporting this! It's indeed a bug that I will fix, but for the CMSSW side we can avoid the problem easily so you can proceed quickly with the update of the ROOT master branch. I have created a PR for that:. https://github.com/cms-sw/cmssw/pull/39867. Indeed, it appears I introduced a bug with recent developments where the overhead when using the `RooFit::Range()` argument blew up. But I suggest you remove this argument to begin with, because the range was the same that is used to define the `InvMass` variable to begin with. So in any case it's better for you to not use `Range()`, and then you also don't hit the code path that has the bug (and you will have less overhead once the bug is gone).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:109,safety,avoid,avoid,109,"Hi, thank you very much for reporting this! It's indeed a bug that I will fix, but for the CMSSW side we can avoid the problem easily so you can proceed quickly with the update of the ROOT master branch. I have created a PR for that:. https://github.com/cms-sw/cmssw/pull/39867. Indeed, it appears I introduced a bug with recent developments where the overhead when using the `RooFit::Range()` argument blew up. But I suggest you remove this argument to begin with, because the range was the same that is used to define the `InvMass` variable to begin with. So in any case it's better for you to not use `Range()`, and then you also don't hit the code path that has the bug (and you will have less overhead once the bug is gone).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:170,safety,updat,update,170,"Hi, thank you very much for reporting this! It's indeed a bug that I will fix, but for the CMSSW side we can avoid the problem easily so you can proceed quickly with the update of the ROOT master branch. I have created a PR for that:. https://github.com/cms-sw/cmssw/pull/39867. Indeed, it appears I introduced a bug with recent developments where the overhead when using the `RooFit::Range()` argument blew up. But I suggest you remove this argument to begin with, because the range was the same that is used to define the `InvMass` variable to begin with. So in any case it's better for you to not use `Range()`, and then you also don't hit the code path that has the bug (and you will have less overhead once the bug is gone).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:170,security,updat,update,170,"Hi, thank you very much for reporting this! It's indeed a bug that I will fix, but for the CMSSW side we can avoid the problem easily so you can proceed quickly with the update of the ROOT master branch. I have created a PR for that:. https://github.com/cms-sw/cmssw/pull/39867. Indeed, it appears I introduced a bug with recent developments where the overhead when using the `RooFit::Range()` argument blew up. But I suggest you remove this argument to begin with, because the range was the same that is used to define the `InvMass` variable to begin with. So in any case it's better for you to not use `Range()`, and then you also don't hit the code path that has the bug (and you will have less overhead once the bug is gone).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:1112,deployability,releas,release,1112,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:721,energy efficiency,model,model,721,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:728,energy efficiency,model,model,728,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,energy efficiency,model,model,798,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:819,energy efficiency,model,model,819,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:88,performance,perform,performance,88,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:721,security,model,model,721,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:728,security,model,model,728,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,security,model,model,798,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:819,security,model,model,819,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:100,testability,regress,regression,100,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:146,testability,simpl,simple,146,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:1021,testability,regress,regression,1021,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:88,usability,perform,performance,88,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:146,usability,simpl,simple,146,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:1061,usability,workflow,workflows,1061,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:. ```c++. void script(). {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);. RooRealVar width(""width"", """", 1.0, 0.1, 10);. RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);. RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);. RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);. RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));. }. ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:21,availability,down,down,21,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:747,deployability,integr,integral,747,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,deployability,integr,integral,798,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:257,energy efficiency,model,model,257,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:264,energy efficiency,model,model,264,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:325,energy efficiency,model,model,325,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:388,energy efficiency,model,model,388,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:448,energy efficiency,model,model,448,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:681,integrability,Batch,BatchMode,681,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:747,integrability,integr,integral,747,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,integrability,integr,integral,798,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:831,integrability,event,event,831,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:747,interoperability,integr,integral,747,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,interoperability,integr,integral,798,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:747,modifiability,integr,integral,747,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,modifiability,integr,integral,798,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:681,performance,Batch,BatchMode,681,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:747,reliability,integr,integral,747,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,reliability,integr,integral,798,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:637,safety,test,test,637,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:257,security,model,model,257,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:264,security,model,model,264,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:325,security,model,model,325,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:388,security,model,model,388,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:448,security,model,model,448,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:747,security,integr,integral,747,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,security,integr,integral,798,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:36,testability,simpl,simple,36,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:637,testability,test,test,637,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:747,testability,integr,integral,747,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:798,testability,integr,integral,798,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:36,usability,simpl,simple,36,"I narrowed the issue down to a more simple reproducer:. ```C++. void script(). {. RooRealVar x{""x"", """", -10, 10};. x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};. RooRealVar s{""n_sig"", """", 1000., 0, 10000};. RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again. model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {. s.setVal(s.getVal() + (i % 2 ? +1 : -1));. nll->getVal();. }. }. ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:65,modifiability,refact,refactoring,65,"I realized that the problem didn't come from the multi-range fit refactoring, but from the refactoring of the RooRealIntegral constructor:. https://github.com/root-project/root/pull/11597. I have opened a PR to fix it:. https://github.com/root-project/root/pull/11662",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:91,modifiability,refact,refactoring,91,"I realized that the problem didn't come from the multi-range fit refactoring, but from the refactoring of the RooRealIntegral constructor:. https://github.com/root-project/root/pull/11597. I have opened a PR to fix it:. https://github.com/root-project/root/pull/11662",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:65,performance,refactor,refactoring,65,"I realized that the problem didn't come from the multi-range fit refactoring, but from the refactoring of the RooRealIntegral constructor:. https://github.com/root-project/root/pull/11597. I have opened a PR to fix it:. https://github.com/root-project/root/pull/11662",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/issues/11637:91,performance,refactor,refactoring,91,"I realized that the problem didn't come from the multi-range fit refactoring, but from the refactoring of the RooRealIntegral constructor:. https://github.com/root-project/root/pull/11597. I have opened a PR to fix it:. https://github.com/root-project/root/pull/11662",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637
https://github.com/root-project/root/pull/11639:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11639
https://github.com/root-project/root/pull/11641:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11641
https://github.com/root-project/root/pull/11641:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11641
https://github.com/root-project/root/pull/11642:20,deployability,patch,patch,20,Closing this as the patch was applied in #11459,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11642
https://github.com/root-project/root/pull/11642:20,safety,patch,patch,20,Closing this as the patch was applied in #11459,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11642
https://github.com/root-project/root/pull/11642:20,security,patch,patch,20,Closing this as the patch was applied in #11459,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11642
https://github.com/root-project/root/pull/11644:13,interoperability,format,format,13,Please clang-format as well...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:323,energy efficiency,Load,LoadTree,323,"> Guilherme tells me that it's actually TChain that strips the file:// from the filename. @pcanal could it not do that? smile. The first call to `TFile::Open` happens here:. ```. #0 0x00007ffff580b7c0 in TFile::Open(char const*, char const*, char const*, int, int)@plt (). from libTree.so. #1 0x00007ffff5856d3a in TChain::LoadTree (this=0x1027b50, entry=0) at core/base/inc/TString.h:244. #2 0x00007ffff58545d2 in TChain::GetListOfBranches (this=0x1027b50) at tree/tree/src/TChain.cxx:1116. #3 0x00007ffff3ee03a6 in (anonymous namespace)::GetBranchNamesImpl (t=..., bNamesReg=std::set with 0 elements, . bNames=std::vector of length 0, capacity 0, analysedTrees=std::set with 1 element = {...}, friendName="""", . allowDuplicates=true) at tree/dataframe/src/RLoopManager.cxx:142. #4 0x00007ffff3ee0e7c in ROOT::Internal::RDF::GetBranchNames[abi:cxx11](TTree&, bool) (t=..., . allowDuplicates=<optimized out>) at tree/dataframe/src/RLoopManager.cxx:341. #5 0x00007ffff3ee0f1d in ROOT::Detail::RDF::RLoopManager::GetBranchNames[abi:cxx11]() (this=0x16502a0). at tree/dataframe/src/RLoopManager.cxx:1015. #6 0x000000000046121e in ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>::Filter(std::basic_string_view<char, std::char_traits<char> >, std::basic_string_view<char, std::char_traits<char> >) (). #7 0x000000000045e376 in df102_NanoAODDimuonAnalysis(char const*) (). #8 0x000000000045eb60 in main (). ```. by this time, the `file://` prefix is already stripped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:361,energy efficiency,core,core,361,"> Guilherme tells me that it's actually TChain that strips the file:// from the filename. @pcanal could it not do that? smile. The first call to `TFile::Open` happens here:. ```. #0 0x00007ffff580b7c0 in TFile::Open(char const*, char const*, char const*, int, int)@plt (). from libTree.so. #1 0x00007ffff5856d3a in TChain::LoadTree (this=0x1027b50, entry=0) at core/base/inc/TString.h:244. #2 0x00007ffff58545d2 in TChain::GetListOfBranches (this=0x1027b50) at tree/tree/src/TChain.cxx:1116. #3 0x00007ffff3ee03a6 in (anonymous namespace)::GetBranchNamesImpl (t=..., bNamesReg=std::set with 0 elements, . bNames=std::vector of length 0, capacity 0, analysedTrees=std::set with 1 element = {...}, friendName="""", . allowDuplicates=true) at tree/dataframe/src/RLoopManager.cxx:142. #4 0x00007ffff3ee0e7c in ROOT::Internal::RDF::GetBranchNames[abi:cxx11](TTree&, bool) (t=..., . allowDuplicates=<optimized out>) at tree/dataframe/src/RLoopManager.cxx:341. #5 0x00007ffff3ee0f1d in ROOT::Detail::RDF::RLoopManager::GetBranchNames[abi:cxx11]() (this=0x16502a0). at tree/dataframe/src/RLoopManager.cxx:1015. #6 0x000000000046121e in ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>::Filter(std::basic_string_view<char, std::char_traits<char> >, std::basic_string_view<char, std::char_traits<char> >) (). #7 0x000000000045e376 in df102_NanoAODDimuonAnalysis(char const*) (). #8 0x000000000045eb60 in main (). ```. by this time, the `file://` prefix is already stripped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:892,energy efficiency,optim,optimized,892,"> Guilherme tells me that it's actually TChain that strips the file:// from the filename. @pcanal could it not do that? smile. The first call to `TFile::Open` happens here:. ```. #0 0x00007ffff580b7c0 in TFile::Open(char const*, char const*, char const*, int, int)@plt (). from libTree.so. #1 0x00007ffff5856d3a in TChain::LoadTree (this=0x1027b50, entry=0) at core/base/inc/TString.h:244. #2 0x00007ffff58545d2 in TChain::GetListOfBranches (this=0x1027b50) at tree/tree/src/TChain.cxx:1116. #3 0x00007ffff3ee03a6 in (anonymous namespace)::GetBranchNamesImpl (t=..., bNamesReg=std::set with 0 elements, . bNames=std::vector of length 0, capacity 0, analysedTrees=std::set with 1 element = {...}, friendName="""", . allowDuplicates=true) at tree/dataframe/src/RLoopManager.cxx:142. #4 0x00007ffff3ee0e7c in ROOT::Internal::RDF::GetBranchNames[abi:cxx11](TTree&, bool) (t=..., . allowDuplicates=<optimized out>) at tree/dataframe/src/RLoopManager.cxx:341. #5 0x00007ffff3ee0f1d in ROOT::Detail::RDF::RLoopManager::GetBranchNames[abi:cxx11]() (this=0x16502a0). at tree/dataframe/src/RLoopManager.cxx:1015. #6 0x000000000046121e in ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>::Filter(std::basic_string_view<char, std::char_traits<char> >, std::basic_string_view<char, std::char_traits<char> >) (). #7 0x000000000045e376 in df102_NanoAODDimuonAnalysis(char const*) (). #8 0x000000000045eb60 in main (). ```. by this time, the `file://` prefix is already stripped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1188,integrability,Filter,Filter,1188,"> Guilherme tells me that it's actually TChain that strips the file:// from the filename. @pcanal could it not do that? smile. The first call to `TFile::Open` happens here:. ```. #0 0x00007ffff580b7c0 in TFile::Open(char const*, char const*, char const*, int, int)@plt (). from libTree.so. #1 0x00007ffff5856d3a in TChain::LoadTree (this=0x1027b50, entry=0) at core/base/inc/TString.h:244. #2 0x00007ffff58545d2 in TChain::GetListOfBranches (this=0x1027b50) at tree/tree/src/TChain.cxx:1116. #3 0x00007ffff3ee03a6 in (anonymous namespace)::GetBranchNamesImpl (t=..., bNamesReg=std::set with 0 elements, . bNames=std::vector of length 0, capacity 0, analysedTrees=std::set with 1 element = {...}, friendName="""", . allowDuplicates=true) at tree/dataframe/src/RLoopManager.cxx:142. #4 0x00007ffff3ee0e7c in ROOT::Internal::RDF::GetBranchNames[abi:cxx11](TTree&, bool) (t=..., . allowDuplicates=<optimized out>) at tree/dataframe/src/RLoopManager.cxx:341. #5 0x00007ffff3ee0f1d in ROOT::Detail::RDF::RLoopManager::GetBranchNames[abi:cxx11]() (this=0x16502a0). at tree/dataframe/src/RLoopManager.cxx:1015. #6 0x000000000046121e in ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>::Filter(std::basic_string_view<char, std::char_traits<char> >, std::basic_string_view<char, std::char_traits<char> >) (). #7 0x000000000045e376 in df102_NanoAODDimuonAnalysis(char const*) (). #8 0x000000000045eb60 in main (). ```. by this time, the `file://` prefix is already stripped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:323,performance,Load,LoadTree,323,"> Guilherme tells me that it's actually TChain that strips the file:// from the filename. @pcanal could it not do that? smile. The first call to `TFile::Open` happens here:. ```. #0 0x00007ffff580b7c0 in TFile::Open(char const*, char const*, char const*, int, int)@plt (). from libTree.so. #1 0x00007ffff5856d3a in TChain::LoadTree (this=0x1027b50, entry=0) at core/base/inc/TString.h:244. #2 0x00007ffff58545d2 in TChain::GetListOfBranches (this=0x1027b50) at tree/tree/src/TChain.cxx:1116. #3 0x00007ffff3ee03a6 in (anonymous namespace)::GetBranchNamesImpl (t=..., bNamesReg=std::set with 0 elements, . bNames=std::vector of length 0, capacity 0, analysedTrees=std::set with 1 element = {...}, friendName="""", . allowDuplicates=true) at tree/dataframe/src/RLoopManager.cxx:142. #4 0x00007ffff3ee0e7c in ROOT::Internal::RDF::GetBranchNames[abi:cxx11](TTree&, bool) (t=..., . allowDuplicates=<optimized out>) at tree/dataframe/src/RLoopManager.cxx:341. #5 0x00007ffff3ee0f1d in ROOT::Detail::RDF::RLoopManager::GetBranchNames[abi:cxx11]() (this=0x16502a0). at tree/dataframe/src/RLoopManager.cxx:1015. #6 0x000000000046121e in ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>::Filter(std::basic_string_view<char, std::char_traits<char> >, std::basic_string_view<char, std::char_traits<char> >) (). #7 0x000000000045e376 in df102_NanoAODDimuonAnalysis(char const*) (). #8 0x000000000045eb60 in main (). ```. by this time, the `file://` prefix is already stripped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:892,performance,optimiz,optimized,892,"> Guilherme tells me that it's actually TChain that strips the file:// from the filename. @pcanal could it not do that? smile. The first call to `TFile::Open` happens here:. ```. #0 0x00007ffff580b7c0 in TFile::Open(char const*, char const*, char const*, int, int)@plt (). from libTree.so. #1 0x00007ffff5856d3a in TChain::LoadTree (this=0x1027b50, entry=0) at core/base/inc/TString.h:244. #2 0x00007ffff58545d2 in TChain::GetListOfBranches (this=0x1027b50) at tree/tree/src/TChain.cxx:1116. #3 0x00007ffff3ee03a6 in (anonymous namespace)::GetBranchNamesImpl (t=..., bNamesReg=std::set with 0 elements, . bNames=std::vector of length 0, capacity 0, analysedTrees=std::set with 1 element = {...}, friendName="""", . allowDuplicates=true) at tree/dataframe/src/RLoopManager.cxx:142. #4 0x00007ffff3ee0e7c in ROOT::Internal::RDF::GetBranchNames[abi:cxx11](TTree&, bool) (t=..., . allowDuplicates=<optimized out>) at tree/dataframe/src/RLoopManager.cxx:341. #5 0x00007ffff3ee0f1d in ROOT::Detail::RDF::RLoopManager::GetBranchNames[abi:cxx11]() (this=0x16502a0). at tree/dataframe/src/RLoopManager.cxx:1015. #6 0x000000000046121e in ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>::Filter(std::basic_string_view<char, std::char_traits<char> >, std::basic_string_view<char, std::char_traits<char> >) (). #7 0x000000000045e376 in df102_NanoAODDimuonAnalysis(char const*) (). #8 0x000000000045eb60 in main (). ```. by this time, the `file://` prefix is already stripped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1426,performance,time,time,1426,"> Guilherme tells me that it's actually TChain that strips the file:// from the filename. @pcanal could it not do that? smile. The first call to `TFile::Open` happens here:. ```. #0 0x00007ffff580b7c0 in TFile::Open(char const*, char const*, char const*, int, int)@plt (). from libTree.so. #1 0x00007ffff5856d3a in TChain::LoadTree (this=0x1027b50, entry=0) at core/base/inc/TString.h:244. #2 0x00007ffff58545d2 in TChain::GetListOfBranches (this=0x1027b50) at tree/tree/src/TChain.cxx:1116. #3 0x00007ffff3ee03a6 in (anonymous namespace)::GetBranchNamesImpl (t=..., bNamesReg=std::set with 0 elements, . bNames=std::vector of length 0, capacity 0, analysedTrees=std::set with 1 element = {...}, friendName="""", . allowDuplicates=true) at tree/dataframe/src/RLoopManager.cxx:142. #4 0x00007ffff3ee0e7c in ROOT::Internal::RDF::GetBranchNames[abi:cxx11](TTree&, bool) (t=..., . allowDuplicates=<optimized out>) at tree/dataframe/src/RLoopManager.cxx:341. #5 0x00007ffff3ee0f1d in ROOT::Detail::RDF::RLoopManager::GetBranchNames[abi:cxx11]() (this=0x16502a0). at tree/dataframe/src/RLoopManager.cxx:1015. #6 0x000000000046121e in ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>::Filter(std::basic_string_view<char, std::char_traits<char> >, std::basic_string_view<char, std::char_traits<char> >) (). #7 0x000000000045e376 in df102_NanoAODDimuonAnalysis(char const*) (). #8 0x000000000045eb60 in main (). ```. by this time, the `file://` prefix is already stripped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:427,integrability,sub,sub-tree,427,"The `file://` prefix is lost here:. https://github.com/root-project/root/blob/8cc176c9ee7dde3b72501a2b657534bc6bd10418/tree/tree/src/TChain.cxx#L485. (this is in `TChain::AddFile` but `TChain::Add` also ends up here). `basename` is the file name stripped of the `file://` prefix and it is what's used to form the file name that's passed to the `TChainElement` constructor later (which is what stores the information about each sub-tree in the chain). It looks like special-casing `file://` is a deliberate choice, here's where just for `file://` we take the URL without the protocol:. https://github.com/root-project/root/blob/8cc176c9ee7dde3b72501a2b657534bc6bd10418/tree/tree/src/TChain.cxx#L2159",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:574,integrability,protocol,protocol,574,"The `file://` prefix is lost here:. https://github.com/root-project/root/blob/8cc176c9ee7dde3b72501a2b657534bc6bd10418/tree/tree/src/TChain.cxx#L485. (this is in `TChain::AddFile` but `TChain::Add` also ends up here). `basename` is the file name stripped of the `file://` prefix and it is what's used to form the file name that's passed to the `TChainElement` constructor later (which is what stores the information about each sub-tree in the chain). It looks like special-casing `file://` is a deliberate choice, here's where just for `file://` we take the URL without the protocol:. https://github.com/root-project/root/blob/8cc176c9ee7dde3b72501a2b657534bc6bd10418/tree/tree/src/TChain.cxx#L2159",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:574,interoperability,protocol,protocol,574,"The `file://` prefix is lost here:. https://github.com/root-project/root/blob/8cc176c9ee7dde3b72501a2b657534bc6bd10418/tree/tree/src/TChain.cxx#L485. (this is in `TChain::AddFile` but `TChain::Add` also ends up here). `basename` is the file name stripped of the `file://` prefix and it is what's used to form the file name that's passed to the `TChainElement` constructor later (which is what stores the information about each sub-tree in the chain). It looks like special-casing `file://` is a deliberate choice, here's where just for `file://` we take the URL without the protocol:. https://github.com/root-project/root/blob/8cc176c9ee7dde3b72501a2b657534bc6bd10418/tree/tree/src/TChain.cxx#L2159",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:115,integrability,protocol,protocol,115,"Thanks for the detailed analysis, @eguiraud! I will see what happens when remove the special case to not strip the protocol part. Should be fine, since this goes into `TFile::Open` but better get confirmation from @pcanal as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:115,interoperability,protocol,protocol,115,"Thanks for the detailed analysis, @eguiraud! I will see what happens when remove the special case to not strip the protocol part. Should be fine, since this goes into `TFile::Open` but better get confirmation from @pcanal as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:196,usability,confirm,confirmation,196,"Thanks for the detailed analysis, @eguiraud! I will see what happens when remove the special case to not strip the protocol part. Should be fine, since this goes into `TFile::Open` but better get confirmation from @pcanal as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:268,security,access,access,268,"Removing the special casing leads to this:. ```. execve(""./df"", [""./df"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd482bdf58 /* 49 vars */) = 0. getxattr(""file:Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = -1 ENOENT (No such file or directory). access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. ... ```. So that breaks the redirection, since now `file:` gets added somewhere... :disappointed:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:344,security,access,access,344,"Removing the special casing leads to this:. ```. execve(""./df"", [""./df"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd482bdf58 /* 49 vars */) = 0. getxattr(""file:Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = -1 ENOENT (No such file or directory). access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. ... ```. So that breaks the redirection, since now `file:` gets added somewhere... :disappointed:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:48,safety,safe,safe,48,"Dropped the draft status, as this should be now safe to merge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:18,usability,statu,status,18,"Dropped the draft status, as this should be now safe to merge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:83,performance,Throughput,Throughput,83,"FYI: A 2GB opendata file in eos home, read & processed using 4 threads with RDF. | Throughput vs time | Aggregated Throughput |. | --- | --- |. | <img width=""1022"" alt=""image"" src=""https://user-images.githubusercontent.com/16205615/200814639-3549ae50-64e8-4d15-88d5-8b8dfc72e24f.png""> | ![image](https://user-images.githubusercontent.com/16205615/200810939-c0ed8674-116c-43b1-8266-fb5fe24546a4.png) |. In case somebody wonders:. The very first read through fuse apparently came from a hot OS cache.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:97,performance,time,time,97,"FYI: A 2GB opendata file in eos home, read & processed using 4 threads with RDF. | Throughput vs time | Aggregated Throughput |. | --- | --- |. | <img width=""1022"" alt=""image"" src=""https://user-images.githubusercontent.com/16205615/200814639-3549ae50-64e8-4d15-88d5-8b8dfc72e24f.png""> | ![image](https://user-images.githubusercontent.com/16205615/200810939-c0ed8674-116c-43b1-8266-fb5fe24546a4.png) |. In case somebody wonders:. The very first read through fuse apparently came from a hot OS cache.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:115,performance,Throughput,Throughput,115,"FYI: A 2GB opendata file in eos home, read & processed using 4 threads with RDF. | Throughput vs time | Aggregated Throughput |. | --- | --- |. | <img width=""1022"" alt=""image"" src=""https://user-images.githubusercontent.com/16205615/200814639-3549ae50-64e8-4d15-88d5-8b8dfc72e24f.png""> | ![image](https://user-images.githubusercontent.com/16205615/200810939-c0ed8674-116c-43b1-8266-fb5fe24546a4.png) |. In case somebody wonders:. The very first read through fuse apparently came from a hot OS cache.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:492,performance,cach,cache,492,"FYI: A 2GB opendata file in eos home, read & processed using 4 threads with RDF. | Throughput vs time | Aggregated Throughput |. | --- | --- |. | <img width=""1022"" alt=""image"" src=""https://user-images.githubusercontent.com/16205615/200814639-3549ae50-64e8-4d15-88d5-8b8dfc72e24f.png""> | ![image](https://user-images.githubusercontent.com/16205615/200810939-c0ed8674-116c-43b1-8266-fb5fe24546a4.png) |. In case somebody wonders:. The very first read through fuse apparently came from a hot OS cache.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:485,safety,hot,hot,485,"FYI: A 2GB opendata file in eos home, read & processed using 4 threads with RDF. | Throughput vs time | Aggregated Throughput |. | --- | --- |. | <img width=""1022"" alt=""image"" src=""https://user-images.githubusercontent.com/16205615/200814639-3549ae50-64e8-4d15-88d5-8b8dfc72e24f.png""> | ![image](https://user-images.githubusercontent.com/16205615/200810939-c0ed8674-116c-43b1-8266-fb5fe24546a4.png) |. In case somebody wonders:. The very first read through fuse apparently came from a hot OS cache.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:189,usability,user,user-images,189,"FYI: A 2GB opendata file in eos home, read & processed using 4 threads with RDF. | Throughput vs time | Aggregated Throughput |. | --- | --- |. | <img width=""1022"" alt=""image"" src=""https://user-images.githubusercontent.com/16205615/200814639-3549ae50-64e8-4d15-88d5-8b8dfc72e24f.png""> | ![image](https://user-images.githubusercontent.com/16205615/200810939-c0ed8674-116c-43b1-8266-fb5fe24546a4.png) |. In case somebody wonders:. The very first read through fuse apparently came from a hot OS cache.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:304,usability,user,user-images,304,"FYI: A 2GB opendata file in eos home, read & processed using 4 threads with RDF. | Throughput vs time | Aggregated Throughput |. | --- | --- |. | <img width=""1022"" alt=""image"" src=""https://user-images.githubusercontent.com/16205615/200814639-3549ae50-64e8-4d15-88d5-8b8dfc72e24f.png""> | ![image](https://user-images.githubusercontent.com/16205615/200810939-c0ed8674-116c-43b1-8266-fb5fe24546a4.png) |. In case somebody wonders:. The very first read through fuse apparently came from a hot OS cache.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:50,integrability,interfac,interface,50,This looks great (delta the code location and the interface question). Thanks!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:50,interoperability,interfac,interface,50,This looks great (delta the code location and the interface question). Thanks!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:50,modifiability,interfac,interface,50,This looks great (delta the code location and the interface question). Thanks!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:245,integrability,pub,publicly,245,"Thanks, @pcanal. I will move the code. Hopefully after that we can merge. I also had a request to test this across the ocean, so if you could try to compare before/after by running something simple using data at CERN (or let me know of a file publicly avaiable via XRootD in Fermilab or other location in the US), I would appreciate it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:98,safety,test,test,98,"Thanks, @pcanal. I will move the code. Hopefully after that we can merge. I also had a request to test this across the ocean, so if you could try to compare before/after by running something simple using data at CERN (or let me know of a file publicly avaiable via XRootD in Fermilab or other location in the US), I would appreciate it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:98,testability,test,test,98,"Thanks, @pcanal. I will move the code. Hopefully after that we can merge. I also had a request to test this across the ocean, so if you could try to compare before/after by running something simple using data at CERN (or let me know of a file publicly avaiable via XRootD in Fermilab or other location in the US), I would appreciate it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:193,testability,simpl,simple,193,"Thanks, @pcanal. I will move the code. Hopefully after that we can merge. I also had a request to test this across the ocean, so if you could try to compare before/after by running something simple using data at CERN (or let me know of a file publicly avaiable via XRootD in Fermilab or other location in the US), I would appreciate it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:193,usability,simpl,simple,193,"Thanks, @pcanal. I will move the code. Hopefully after that we can merge. I also had a request to test this across the ocean, so if you could try to compare before/after by running something simple using data at CERN (or let me know of a file publicly avaiable via XRootD in Fermilab or other location in the US), I would appreciate it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,deployability,configurat,configuration,458,"As for the behavior when using `file://`, I guess we can follow what other redirections are doing. I don't have a strong feeling, but having `file://` disable the redirection was indeed the intention, apart from the fact that with `TChain` it cannot be disabled due to the fact that it strips the prefix. If you think we should be stripping in `TUrl`, I could add that, then the redirections would be controlled only by `TFile.CrossProtocolRedirects` in the configuration (which is enabled by default).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,integrability,configur,configuration,458,"As for the behavior when using `file://`, I guess we can follow what other redirections are doing. I don't have a strong feeling, but having `file://` disable the redirection was indeed the intention, apart from the fact that with `TChain` it cannot be disabled due to the fact that it strips the prefix. If you think we should be stripping in `TUrl`, I could add that, then the redirections would be controlled only by `TFile.CrossProtocolRedirects` in the configuration (which is enabled by default).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,modifiability,configur,configuration,458,"As for the behavior when using `file://`, I guess we can follow what other redirections are doing. I don't have a strong feeling, but having `file://` disable the redirection was indeed the intention, apart from the fact that with `TChain` it cannot be disabled due to the fact that it strips the prefix. If you think we should be stripping in `TUrl`, I could add that, then the redirections would be controlled only by `TFile.CrossProtocolRedirects` in the configuration (which is enabled by default).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:401,security,control,controlled,401,"As for the behavior when using `file://`, I guess we can follow what other redirections are doing. I don't have a strong feeling, but having `file://` disable the redirection was indeed the intention, apart from the fact that with `TChain` it cannot be disabled due to the fact that it strips the prefix. If you think we should be stripping in `TUrl`, I could add that, then the redirections would be controlled only by `TFile.CrossProtocolRedirects` in the configuration (which is enabled by default).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,security,configur,configuration,458,"As for the behavior when using `file://`, I guess we can follow what other redirections are doing. I don't have a strong feeling, but having `file://` disable the redirection was indeed the intention, apart from the fact that with `TChain` it cannot be disabled due to the fact that it strips the prefix. If you think we should be stripping in `TUrl`, I could add that, then the redirections would be controlled only by `TFile.CrossProtocolRedirects` in the configuration (which is enabled by default).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:401,testability,control,controlled,401,"As for the behavior when using `file://`, I guess we can follow what other redirections are doing. I don't have a strong feeling, but having `file://` disable the redirection was indeed the intention, apart from the fact that with `TChain` it cannot be disabled due to the fact that it strips the prefix. If you think we should be stripping in `TUrl`, I could add that, then the redirections would be controlled only by `TFile.CrossProtocolRedirects` in the configuration (which is enabled by default).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:11,usability,behavi,behavior,11,"As for the behavior when using `file://`, I guess we can follow what other redirections are doing. I don't have a strong feeling, but having `file://` disable the redirection was indeed the intention, apart from the fact that with `TChain` it cannot be disabled due to the fact that it strips the prefix. If you think we should be stripping in `TUrl`, I could add that, then the redirections would be controlled only by `TFile.CrossProtocolRedirects` in the configuration (which is enabled by default).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:75,integrability,interfac,interface,75,On `file:\\` I hesitate on whether this is a user request to use the posix interface no matter what or whether the performance difference between `posix-eos` and `xrootd-eos` is always so great that we should make the right choice for the user.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:75,interoperability,interfac,interface,75,On `file:\\` I hesitate on whether this is a user request to use the posix interface no matter what or whether the performance difference between `posix-eos` and `xrootd-eos` is always so great that we should make the right choice for the user.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:75,modifiability,interfac,interface,75,On `file:\\` I hesitate on whether this is a user request to use the posix interface no matter what or whether the performance difference between `posix-eos` and `xrootd-eos` is always so great that we should make the right choice for the user.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:115,performance,perform,performance,115,On `file:\\` I hesitate on whether this is a user request to use the posix interface no matter what or whether the performance difference between `posix-eos` and `xrootd-eos` is always so great that we should make the right choice for the user.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:45,usability,user,user,45,On `file:\\` I hesitate on whether this is a user request to use the posix interface no matter what or whether the performance difference between `posix-eos` and `xrootd-eos` is always so great that we should make the right choice for the user.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:115,usability,perform,performance,115,On `file:\\` I hesitate on whether this is a user request to use the posix interface no matter what or whether the performance difference between `posix-eos` and `xrootd-eos` is always so great that we should make the right choice for the user.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:239,usability,user,user,239,On `file:\\` I hesitate on whether this is a user request to use the posix interface no matter what or whether the performance difference between `posix-eos` and `xrootd-eos` is always so great that we should make the right choice for the user.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:98,energy efficiency,current,currently,98,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:108,reliability,doe,does,108,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:159,reliability,doe,does,159,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:189,security,certif,certificate,189,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:67,testability,simpl,simple,67,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:67,usability,simpl,simple,67,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:20,availability,consist,consistently,20,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:152,energy efficiency,predict,predict,152,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:33,safety,prevent,prevent,33,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:152,safety,predict,predict,152,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:33,security,preven,prevent,33,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:139,testability,understand,understand,139,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:20,usability,consist,consistently,20,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:114,usability,behavi,behavior,114,"If `file://` cannot consistently prevent redirection (also for `TChain`) then this mechanism is inconsistent, the behavior will be hard to understand / predict, and we should always redirect (or fix the `TChain` case). I find it a good idea to have an `Info` once per process that the URL is redirected. Neither of these two are super strong opinions of mine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:476,availability,consist,consistent,476,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:48,deployability,configurat,configuration,48,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:308,energy efficiency,current,current,308,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:48,integrability,configur,configuration,48,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:209,integrability,messag,messages,209,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:268,integrability,messag,message,268,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:209,interoperability,messag,messages,209,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:268,interoperability,messag,message,268,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:48,modifiability,configur,configuration,48,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:48,security,configur,configuration,48,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:464,usability,behavi,behavior,464,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:476,usability,consist,consistent,476,"This seems to be the only other place where the configuration setting is checked:. https://github.com/root-project/root/blob/master/io/io/src/TFile.cxx#L4201-L4209. I think people may be annoyed by the `Info` messages and we'd need some static storage to store if the message has been emitted or not for the current process, so I'm not a fan of adding it (although I have no strong feelings about this either). I will add stripping of `file://` prefix so that the behavior is consistent (always redirect) then. I tried and didn't find an easy way to get `file://` to disable the redirection in the case of `TChain`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:47,deployability,patch,patch,47,"@pcanal, I guess you mean line 4057 after this patch, so [this line](https://github.com/root-project/root/blob/6858acbeec33a4230a097d04e82c5fe8102b3b25/io/io/src/TFile.cxx#L4057), right? I will move the code and update this pull request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:212,deployability,updat,update,212,"@pcanal, I guess you mean line 4057 after this patch, so [this line](https://github.com/root-project/root/blob/6858acbeec33a4230a097d04e82c5fe8102b3b25/io/io/src/TFile.cxx#L4057), right? I will move the code and update this pull request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:47,safety,patch,patch,47,"@pcanal, I guess you mean line 4057 after this patch, so [this line](https://github.com/root-project/root/blob/6858acbeec33a4230a097d04e82c5fe8102b3b25/io/io/src/TFile.cxx#L4057), right? I will move the code and update this pull request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:212,safety,updat,update,212,"@pcanal, I guess you mean line 4057 after this patch, so [this line](https://github.com/root-project/root/blob/6858acbeec33a4230a097d04e82c5fe8102b3b25/io/io/src/TFile.cxx#L4057), right? I will move the code and update this pull request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:47,security,patch,patch,47,"@pcanal, I guess you mean line 4057 after this patch, so [this line](https://github.com/root-project/root/blob/6858acbeec33a4230a097d04e82c5fe8102b3b25/io/io/src/TFile.cxx#L4057), right? I will move the code and update this pull request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:212,security,updat,update,212,"@pcanal, I guess you mean line 4057 after this patch, so [this line](https://github.com/root-project/root/blob/6858acbeec33a4230a097d04e82c5fe8102b3b25/io/io/src/TFile.cxx#L4057), right? I will move the code and update this pull request.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:260,availability,consist,consistent,260,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:414,availability,error,errors,414,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,availability,Error,Error,458,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:489,availability,ERROR,ERROR,489,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:521,availability,error,error,521,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:19,deployability,updat,updated,19,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:31,deployability,patch,patch,31,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:74,deployability,updat,updated,74,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:103,deployability,releas,release,103,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:881,deployability,contain,contained,881,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:909,deployability,manag,management,909,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:909,energy efficiency,manag,management,909,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:414,performance,error,errors,414,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,performance,Error,Error,458,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:489,performance,ERROR,ERROR,489,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:521,performance,error,error,521,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:19,safety,updat,updated,19,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:31,safety,patch,patch,31,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:74,safety,updat,updated,74,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:414,safety,error,errors,414,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,safety,Error,Error,458,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:489,safety,ERROR,ERROR,489,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:521,safety,error,error,521,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:627,safety,input,input,627,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:665,safety,test,tested,665,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:909,safety,manag,management,909,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:19,security,updat,updated,19,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:31,security,patch,patch,31,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:74,security,updat,updated,74,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:665,testability,test,tested,665,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:241,usability,behavi,behavior,241,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:260,usability,consist,consistent,260,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:414,usability,error,errors,414,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:458,usability,Error,Error,458,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:489,usability,ERROR,ERROR,489,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:521,usability,error,error,521,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:627,usability,input,input,627,"@Axel-Naumann I've updated the patch to use `TUrl` and always redirect. I updated the code comment and release notes to match. The way to disable the redirection then will be to set `TFile.CrossProtocolRedirects` to `0` in `rootrc`. Now the behavior should be consistent between plain `TFile::Open` calls and `TChain`. @pcanal I tried moving the code after line 4057 and using `expandedUrl` but it started showing errors like this when using `TChain`:. ```. Error in <TNetXNGFile::Open>: [ERROR] Server responded with an error: [3001] Required argument not present. ```. So I moved it back where it was before and use only the input `url` to `TFile::Open` as is. I tested that this now works both for plain `TFile::Open` calls as well as with `TChain` and the redirection always happens as long as the file being opened is on EOS. The problem was that the `exapandedUrl` sometimes contained only the base EOS management URL, which broke it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:50,deployability,contain,contained,50,"> The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. Can you give a concrete illustration?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:78,deployability,manag,management,78,"> The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. Can you give a concrete illustration?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:78,energy efficiency,manag,management,78,"> The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. Can you give a concrete illustration?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:78,safety,manag,management,78,"> The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. Can you give a concrete illustration?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:52,deployability,contain,contained,52,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:80,deployability,manag,management,80,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4567,deployability,manag,management,4567,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:80,energy efficiency,manag,management,80,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1873,energy efficiency,charg,charge,1873,"...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with the redirection enabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffe7c400bd8 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1913,energy efficiency,charg,charge,1913,"n2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with the redirection enabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffe7c400bd8 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:2828,energy efficiency,charg,charge,2828," ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with the redirection enabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffe7c400bd8 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root""",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:2868,energy efficiency,charg,charge,2868,"e charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with the redirection enabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffe7c400bd8 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4305,energy efficiency,charg,charge,4305,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4345,energy efficiency,charg,charge,4345,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4567,energy efficiency,manag,management,4567,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4446,reliability,doe,doesn,4446,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4625,reliability,doe,doesn,4625,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:80,safety,manag,management,80,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4567,safety,manag,management,4567,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4676,safety,safe,safe,4676,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:4690,safety,avoid,avoid,4690,"ked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can see, in the case using `expandedUrl`, sometimes the URL returned is only the base management URL, and the file may be opened via FUSE. This doesn't always happen, but I thought I'd be on the safe side and avoid potential problems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:166,security,session,session,166,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:409,security,access,access,409,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:485,security,access,access,485,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:887,security,access,access,887,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:963,security,access,access,963,"> > The problem was that the exapandedUrl sometimes contained only the base EOS management URL, which broke it. > . > Can you give a concrete illustration? Here is a session with `strace` with the redirection disabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1365,security,access,access,1365,"...], 0x7ffd2e39de38 /* 49 vars */) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with the redirection enabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffe7c400bd8 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root:/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1441,security,access,access,1441,"C_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 4. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 5. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. one with the redirection enabled:. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffe7c400bd8 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:3408,security,access,access,3408,"etxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=3",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:3484,security,access,access,3484,"9. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. and finally, one with the code moved to the place you suggested (using `expandedUrl`):. ```bash. $ strace ./dimuon Run2012BC_DoubleMuParked_Muons.root 2>&1 | grep Muons. execve(""./dimuon"", [""./dimuon"", ""Run2012BC_DoubleMuParked_Muons.r""...], 0x7ffccf746158 /* 49 vars */) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", F_OK) = 0. access(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", O_RDONLY) = 12. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. write(1, ""Muons with opposite charge: pass""..., 97Muons with opposite charge: pass=24067843 all=31104343 -- eff=77.38 % cumulative eff=39.11 %. ```. It is a bit puzzling (doesn't always happen), but as you can se",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1381,deployability,observ,observe,1381,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:141,safety,test,test,141,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:174,safety,test,test,174,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:307,safety,test,test,307,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:363,safety,test,test,363,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:368,safety,test,test,368,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:391,safety,test,test,391,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:448,safety,test,test,448,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:459,safety,test,test,459,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:467,safety,test,test,467,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:525,safety,test,test,525,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:579,safety,test,test,579,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:684,safety,test,test,684,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:734,safety,test,test,734,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:794,safety,test,test,794,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:848,safety,test,test,848,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:940,safety,test,test,940,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1034,safety,test,test,1034,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1039,safety,test,test,1039,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1062,safety,test,test,1062,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1119,safety,test,test,1119,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1130,safety,test,test,1130,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1138,safety,test,test,1138,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1196,safety,test,test,1196,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1250,safety,test,test,1250,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:657,security,access,access,657,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:707,security,access,access,707,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:141,testability,test,test,141,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:174,testability,test,test,174,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:307,testability,test,test,307,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:363,testability,test,test,363,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:368,testability,test,test,368,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:391,testability,test,test,391,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:448,testability,test,test,448,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:459,testability,test,test,459,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:467,testability,test,test,467,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:525,testability,test,test,525,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:579,testability,test,test,579,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:684,testability,test,test,684,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:734,testability,test,test,734,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:794,testability,test,test,794,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:848,testability,test,test,848,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:940,testability,test,test,940,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1034,testability,test,test,1034,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1039,testability,test,test,1039,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1062,testability,test,test,1062,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1119,testability,test,test,1119,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1130,testability,test,test,1130,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1138,testability,test,test,1138,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1196,testability,test,test,1196,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1250,testability,test,test,1250,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1381,testability,observ,observe,1381,"More puzzling, here are two consecutive runs without changing anything (using `expandedUrl`):. ```bash. lcgapp-centos8-physical amadio $ cat test.C. #include ""TFile.h"". void test(const char* filename, const char* options). {. auto f = TFile::Open(filename, options);. }. int main(int argc, char **argv). {. test(argv[1], argv[2]);. }. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fffd10a02b8 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 54. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 54) = 54. access(""/eos/home-a/amadio/test.root"", F_OK) = 0. access(""/eos/home-a/amadio/test.root"", R_OK) = 0. openat(AT_FDCWD, ""/eos/home-a/amadio/test.root"", O_RDONLY) = 11. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. lstat(""/eos/home-a/amadio/test.root"", {st_mode=S_IFREG|0644, st_size=2244449133, ...}) = 0. $ cat ~/.rootrc && strace ./test test.root 2>&1 | grep ""test.root"". TFile.CrossProtocolRedirects: yes. execve(""./test"", [""./test"", ""test.root""], 0x7fff277b6488 /* 49 vars */) = 0. getxattr(""test.root"", ""eos.url.xroot"", NULL, 0) = 53. getxattr(""test.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 53) = 53. ```. So better keep the code where it is, as I never observe this sort of thing in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:352,availability,failur,failures,352,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:20,deployability,build,build,20,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:31,deployability,fail,fail,31,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:352,deployability,fail,failures,352,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:352,performance,failur,failures,352,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:31,reliability,fail,fail,31,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:352,reliability,fail,failures,352,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:49,safety,test,tests,49,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:49,testability,test,tests,49,"For the record, the build will fail because some tests based on reference files now have some unexpected warning:. ```. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. +ld: warning: -undefined dynamic_lookup may not work with chained fixups. ```. These are not caused by my changes, so I will merge this if those are the only failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1064,availability,consist,consistent,1064,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1372,deployability,fail,failing,1372,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:224,energy efficiency,load,load,224,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1219,interoperability,semant,semantically,1219,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:54,modifiability,concern,concerning,54,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:224,performance,load,load,224,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:7,reliability,doe,doesn,7,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:115,reliability,pra,practical,115,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1372,reliability,fail,failing,1372,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:896,safety,input,input,896,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:54,testability,concern,concerning,54,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:896,usability,input,input,896,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1064,usability,consist,consistent,1064,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1100,usability,behavi,behavior,1100,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1399,usability,behavi,behavior,1399,"> This doesn't always happen, ... This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). In the first strace, I see:. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. ```. vs. ```. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. ```. which ""seems"" to mean that goven the exact same input `getxattr` returns different result. Why would that be? >More puzzling, here are two consecutive runs without changing anything (using expandedUrl):. That seems ""consistent"" with the ""inconsistent"" behavior I just talked about. So there is something wrong about `expandfilename` that we need to fix since:. (a) it is semantically necessary to call it. (b) it behaves oddly in this case but also probably also in other case without us knowing. so since we have a running failing example of the odd behavior we may as well investigate it now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1814,deployability,fail,fails,1814,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1969,deployability,instal,installed,1969,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:232,energy efficiency,load,load,232,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:62,modifiability,concern,concerning,62,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:232,performance,load,load,232,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1286,performance,time,time,1286,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1316,performance,time,times,1316,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:9,reliability,doe,doesn,9,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:123,reliability,pra,practical,123,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1814,reliability,fail,fails,1814,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:946,safety,input,input,946,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1932,safety,test,test,1932,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:62,testability,concern,concerning,62,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1932,testability,test,test,1932,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:946,usability,input,input,946,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11644:1515,usability,user,user,1515,"> > This doesn't always happen, ... > . > This actually quite concerning ... In the use case you show, there should be not practical difference as the filename should be strictly the same before and after the expand. (As opposed to load ""/eos/home-a/amadio/Run2012BC_DoubleMuParked_Muons.root"" vs ""$MY_EOS_DIR/Run2012BC_DoubleMuParked_Muons.root"" where the redirection would work only for the 1st one without the expansion). > . > In the first strace, I see:. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 79. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch//eos/us""..., 79) = 79. > ```. > . > vs. > . > ```. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", NULL, 0) = 25. > getxattr(""Run2012BC_DoubleMuParked_Muons.root"", ""eos.url.xroot"", ""root://eoshome-a.cern.ch/"", 25) = 25. > ```. > . > which ""seems"" to mean that given the exact same input `getxattr` returns different result. Why would that be? Good question, and I'm not sure. This seems to be a problem with EOS (see below). @apeters1971 Do you know what could cause this? To reproduce, all you need is to copy a file with a different name, then call `getfattr` on it and it will return the wrong URL, at least the first time (but potentially several times):. ```bash. $ cp hsimple.root mytest.root. $ getfattr -n eos.url.xroot hsimple.root && getfattr -n eos.url.xroot mytest.root. # file: hsimple.root. eos.url.xroot=""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root"". # file: mytest.root. eos.url.xroot=""root://eoshome-a.cern.ch/"". ```. So I guess we *could* move the code after the expansion after all, as the problem is not coming from ROOT, but from EOS. When the wrong URL is returned, all that happens is that the opening via XRootD fails and it falls back to use FUSE, so I guess it should still be fine to merge this, if only for allowing people to test more easily once ROOT master is installed somewhere in CVMFS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644
https://github.com/root-project/root/pull/11645:36,availability,error,errors,36,This PR in roottest should fixe the errors: https://github.com/root-project/roottest/pull/911,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11645
https://github.com/root-project/root/pull/11645:36,performance,error,errors,36,This PR in roottest should fixe the errors: https://github.com/root-project/roottest/pull/911,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11645
https://github.com/root-project/root/pull/11645:36,safety,error,errors,36,This PR in roottest should fixe the errors: https://github.com/root-project/roottest/pull/911,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11645
https://github.com/root-project/root/pull/11645:36,usability,error,errors,36,This PR in roottest should fixe the errors: https://github.com/root-project/roottest/pull/911,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11645
https://github.com/root-project/root/issues/11647:61,availability,avail,available,61,The larger discussion about whether `ROOT.std.any` should be available by default is probably better suited for upstream cppyy (https://github.com/wlav/cppyy).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:61,reliability,availab,available,61,The larger discussion about whether `ROOT.std.any` should be available by default is probably better suited for upstream cppyy (https://github.com/wlav/cppyy).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:61,safety,avail,available,61,The larger discussion about whether `ROOT.std.any` should be available by default is probably better suited for upstream cppyy (https://github.com/wlav/cppyy).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:61,security,availab,available,61,The larger discussion about whether `ROOT.std.any` should be available by default is probably better suited for upstream cppyy (https://github.com/wlav/cppyy).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:207,deployability,upgrad,upgrade,207,"No, that discussion is not relevant upstream:. ```. >>> import cppyy. >>> cppyy.gbl.std.any. <class cppyy.gbl.std.any at 0x113f04c30>. ```. Any ""larger discussion"" should be on whether ROOT is ever going to upgrade to the latest version of cppyy? What you have in ROOT is at least 2 years or more behind in development.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:229,deployability,version,version,229,"No, that discussion is not relevant upstream:. ```. >>> import cppyy. >>> cppyy.gbl.std.any. <class cppyy.gbl.std.any at 0x113f04c30>. ```. Any ""larger discussion"" should be on whether ROOT is ever going to upgrade to the latest version of cppyy? What you have in ROOT is at least 2 years or more behind in development.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:229,integrability,version,version,229,"No, that discussion is not relevant upstream:. ```. >>> import cppyy. >>> cppyy.gbl.std.any. <class cppyy.gbl.std.any at 0x113f04c30>. ```. Any ""larger discussion"" should be on whether ROOT is ever going to upgrade to the latest version of cppyy? What you have in ROOT is at least 2 years or more behind in development.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:207,modifiability,upgrad,upgrade,207,"No, that discussion is not relevant upstream:. ```. >>> import cppyy. >>> cppyy.gbl.std.any. <class cppyy.gbl.std.any at 0x113f04c30>. ```. Any ""larger discussion"" should be on whether ROOT is ever going to upgrade to the latest version of cppyy? What you have in ROOT is at least 2 years or more behind in development.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/issues/11647:229,modifiability,version,version,229,"No, that discussion is not relevant upstream:. ```. >>> import cppyy. >>> cppyy.gbl.std.any. <class cppyy.gbl.std.any at 0x113f04c30>. ```. Any ""larger discussion"" should be on whether ROOT is ever going to upgrade to the latest version of cppyy? What you have in ROOT is at least 2 years or more behind in development.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11647
https://github.com/root-project/root/pull/11650:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:192,reliability,doe,does,192,"Hi, thanks for the PR! And nice, it seems you have uncovered a unit test that did not really work with the offsetting to begin with! How do you want to proceed? Can the unit test be fixed, or does it need to be disabled?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:68,safety,test,test,68,"Hi, thanks for the PR! And nice, it seems you have uncovered a unit test that did not really work with the offsetting to begin with! How do you want to proceed? Can the unit test be fixed, or does it need to be disabled?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:174,safety,test,test,174,"Hi, thanks for the PR! And nice, it seems you have uncovered a unit test that did not really work with the offsetting to begin with! How do you want to proceed? Can the unit test be fixed, or does it need to be disabled?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:63,testability,unit,unit,63,"Hi, thanks for the PR! And nice, it seems you have uncovered a unit test that did not really work with the offsetting to begin with! How do you want to proceed? Can the unit test be fixed, or does it need to be disabled?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:68,testability,test,test,68,"Hi, thanks for the PR! And nice, it seems you have uncovered a unit test that did not really work with the offsetting to begin with! How do you want to proceed? Can the unit test be fixed, or does it need to be disabled?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:169,testability,unit,unit,169,"Hi, thanks for the PR! And nice, it seems you have uncovered a unit test that did not really work with the offsetting to begin with! How do you want to proceed? Can the unit test be fixed, or does it need to be disabled?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:174,testability,test,test,174,"Hi, thanks for the PR! And nice, it seems you have uncovered a unit test that did not really work with the offsetting to begin with! How do you want to proceed? Can the unit test be fixed, or does it need to be disabled?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:40,usability,close,closed,40,"Hi @Zeff020 and @egpbos! Can this PR be closed without merging after #11717 is merged, or is the disclaimer still relevant then? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:271,reliability,doe,does,271,"Hi @guitargeek,. This disclaimer is still relevant after that MR that you referred to is merged. This MR is about the RooRealL passed to the RooMinimizerFcn not having offsetting implemented, and really not even being intended for minimisation. The MR that you linked to does not address this issue as far as I can tell.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:231,usability,minim,minimisation,231,"Hi @guitargeek,. This disclaimer is still relevant after that MR that you referred to is merged. This MR is about the RooRealL passed to the RooMinimizerFcn not having offsetting implemented, and really not even being intended for minimisation. The MR that you linked to does not address this issue as far as I can tell.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:135,integrability,interfac,interface,135,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:135,interoperability,interfac,interface,135,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:135,modifiability,interfac,interface,135,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:221,performance,time,time,221,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:120,safety,test,teststatistics-interface,120,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:285,safety,reme,remember,285,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:120,testability,test,teststatistics-interface,120,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:251,usability,close,closed,251,"Alright, thanks for the clarification! Then you need to rebase this PR now and force-push to the `roofit-dev/offsetting-teststatistics-interface` Maybe we can get around having to open a new PR just for the rebasing this time, to not spam the list of closed PRs to ROOT too much. If I remember correctly, the problem was that `roofit-dev` didn't allow force pushes? Maybe this can be changed? Thanks for considering this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:96,interoperability,conflict,conflict,96,"Probably best to wait for #11717, since there I also edited RooMinimizer, so we'll again have a conflict after that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:41,deployability,fail,failing,41,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:268,deployability,fail,fails,268,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:41,reliability,fail,failing,41,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:268,reliability,fail,fails,268,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:21,safety,test,tests,21,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:180,safety,test,test,180,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:205,safety,test,testLikelihoodGradientJob,205,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:338,safety,test,test,338,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:818,safety,valid,valid,818,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:21,testability,test,tests,21,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:180,testability,test,test,180,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:205,testability,test,testLikelihoodGradientJob,205,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:338,testability,test,test,338,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:347,testability,simpl,simply,347,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:347,usability,simpl,simply,347,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:. 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`. 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:61,deployability,fail,failing,61,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:205,deployability,build,build,205,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:157,interoperability,specif,specifically,157,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:61,reliability,fail,failing,61,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:28,safety,test,tests,28,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:148,safety,test,test,148,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:215,safety,test,test,215,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:28,testability,test,tests,28,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:148,testability,test,test,148,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:215,testability,test,test,215,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:175,usability,behavi,behaviour,175,"Hi @guitargeek, I fixed the tests which were now (correctly) failing basically by the suggestions given by @egpbos here before and also added a new test for specifically this behaviour. After a successful build and test run this should be fine to merge from my side now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:169,interoperability,conflict,conflict,169,"Hi @Zeff020! Sorry for asking this again, but after https://github.com/root-project/root/pull/11793 was merged you got to rebase and force push again to resolve another conflict. Also, please fix this trailing whitespace that is introduced by this PR when you are already at it. Sorry again for this, your PR will be merged next!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11650:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650
https://github.com/root-project/root/pull/11652:229,availability,error,error,229,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:149,deployability,updat,update,149,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:235,energy efficiency,estimat,estimation,235,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:229,performance,error,error,229,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:140,safety,input,input,140,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:149,safety,updat,update,149,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:229,safety,error,error,229,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:149,security,updat,update,149,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:140,usability,input,input,140,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:229,usability,error,error,229,"PS: Speaking of this code, it seems very odd to me that in the case of `delgam < 0`, the `DavidonErrorUpdator` still tries to use the given input to update the Hesse matrix. That just seems like an obvious situation in which the error estimation is definitely not working and sure enough, directly after `delgam < 0`, I am used to getting `non-positive diagonal element in covariance matrix`-type warnings.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/pull/11652:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2204/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11652
https://github.com/root-project/root/issues/11653:355,deployability,version,version,355,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1655,deployability,automat,automatically,1655,"e.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1855,deployability,version,version,1855,"me(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1869,deployability,Version,Version,1869,"har *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2057,deployability,version,version,2057,"lfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:3073,deployability,automat,automatically,3073,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1221,energy efficiency,Profil,Profile,1221,"s by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.ce",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2915,energy efficiency,Profil,Profile,2915,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:355,integrability,version,version,355,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:553,integrability,pub,public,553,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1855,integrability,version,version,1855,"me(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1869,integrability,Version,Version,1869,"har *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2057,integrability,version,version,2057,"lfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2255,integrability,pub,public,2255,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:351,interoperability,xml,xml,351,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:399,interoperability,xml,xmlns,399,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:422,interoperability,xml,xml,422,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1157,interoperability,distribut,distribution,1157,"file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2053,interoperability,xml,xml,2053,"//localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the loca",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2101,interoperability,xml,xmlns,2101,"file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be dif",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2124,interoperability,xml,xml,2124,"KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2851,interoperability,distribut,distribution,2851,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:253,modifiability,variab,variable,253,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:355,modifiability,version,version,355,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1706,modifiability,variab,variables,1706,"ALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histogr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1855,modifiability,version,version,1855,"me(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1869,modifiability,Version,Version,1869,"har *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2057,modifiability,version,version,2057,"lfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1221,performance,Profil,Profile,1221,"s by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.ce",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2915,performance,Profil,Profile,2915,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1427,reliability,doe,doesn,1427,"etalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1729,security,ssh,ssh,1729,"t -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		r",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:1655,testability,automat,automatically,1655,"e.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:3073,testability,automat,automatically,3073,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:642,usability,user,user,642,"It turns out that this is already possible, although not enabled by default. The trick is that you need to give `TFile::Open` a properly crafted URL for the local file, and you need to enable processing of local metalink files by setting an environment variable first. Here is how I opened a meta4 file on my machine:. ```bash. $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. $ env XRD_LOCALMETALINKFILE=1 root -l. root [0] auto f = TFile::Open(""root://localfile//home/amadio/hsimple.meta4""). (TFile *) @0x7fff1a925858. root [1] f->GetName(). (const char *) ""root://localfile//home/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://localfile//home/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2344,usability,user,user,2344,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2563,usability,user,user,2563,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2656,usability,user,user,2656,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:2760,usability,user,user,2760,"KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. ```. Note that you must use the deprecated form for the URL (`root://localfile//...`), using the new form with `file://localhost/path/file.meta4` doesn't work (at least I could not make it work). That said, now that #11644 is merged, if you use ROOT's master branch and place your .meta4 file somewhere on EOS (i.e. somewhere in `/eos/...`), the redirection will now happen automatically, without the need to set environment variables:. ```bash. $ ssh lxplus9. lxplus ~ $ source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos9-gcc12-opt/setup.sh . lxplus ~ $ root --version. ROOT Version: 6.27/01. Built for linuxx8664gcc on Nov 12 2022, 00:16:00. From heads/master@v6-25-02-2732-ga05d4beded. lxplus ~ $ cd /eos/home-a/amadio. lxplus amadio $ cat hsimple.meta4. <?xml version=""1.0"" encoding=""UTF-8""?>. <metalink xmlns=""urn:ietf:params:xml:ns:metalink"">. <file name=""hsimple.root"">. <url location=""ch"" priority=""1"">root://eosproject-r.cern.ch//eos/project/r/root-eos/public/hsimple.root</url>. <url location=""ch"" priority=""2"">root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.root</url>. </file>. </metalink>. lxplus amadio $ root -l. root [0] auto f = TFile::Open(""hsimple.meta4""). (TFile *) 0x2679210. root [1] f->GetName(). (const char *) ""root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4"". root [2] f->ls(). TNetXNGFile**		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. TNetXNGFile*		root://eoshome-a.cern.ch//eos/user/a/amadio/hsimple.meta4	Demo ROOT file with histograms. KEY: TH1F	hpx;1	This is the px distribution. KEY: TH2F	hpxpy;1	py vs px. KEY: TProfile	hprof;1	Profile of pz versus px. KEY: TNtuple	ntuple;1	Demo ntuple. root [3] .q. ```. Adding a bit of extra code in `TFile::Open` to handle the local meta4 file case automatically should not be difficult, so I will see if I can make that happen sometime this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:96,availability,sla,slac,96,"great! thanks a lot! only at your mention i noticed that [XRD_LOCALMETALINKFILE](https://xrootd.slac.stanford.edu/doc/xrdcl-docs/www/xrdcldocs.html#x1-230004.2.13) have a default of 0 and actually have indication on how should be used (for some reason in Python bindings this is not required, i can use directly a metafile as source, and the same is for xrdcp)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:262,interoperability,bind,bindings,262,"great! thanks a lot! only at your mention i noticed that [XRD_LOCALMETALINKFILE](https://xrootd.slac.stanford.edu/doc/xrdcl-docs/www/xrdcldocs.html#x1-230004.2.13) have a default of 0 and actually have indication on how should be used (for some reason in Python bindings this is not required, i can use directly a metafile as source, and the same is for xrdcp)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:262,modifiability,bind,bindings,262,"great! thanks a lot! only at your mention i noticed that [XRD_LOCALMETALINKFILE](https://xrootd.slac.stanford.edu/doc/xrdcl-docs/www/xrdcldocs.html#x1-230004.2.13) have a default of 0 and actually have indication on how should be used (for some reason in Python bindings this is not required, i can use directly a metafile as source, and the same is for xrdcp)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:96,reliability,sla,slac,96,"great! thanks a lot! only at your mention i noticed that [XRD_LOCALMETALINKFILE](https://xrootd.slac.stanford.edu/doc/xrdcl-docs/www/xrdcldocs.html#x1-230004.2.13) have a default of 0 and actually have indication on how should be used (for some reason in Python bindings this is not required, i can use directly a metafile as source, and the same is for xrdcp)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/issues/11653:202,usability,indicat,indication,202,"great! thanks a lot! only at your mention i noticed that [XRD_LOCALMETALINKFILE](https://xrootd.slac.stanford.edu/doc/xrdcl-docs/www/xrdcldocs.html#x1-230004.2.13) have a default of 0 and actually have indication on how should be used (for some reason in Python bindings this is not required, i can use directly a metafile as source, and the same is for xrdcp)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11653
https://github.com/root-project/root/pull/11654:600,deployability,depend,depend,600,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:600,integrability,depend,depend,600,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:695,integrability,interfac,interface,695,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:695,interoperability,interfac,interface,695,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:600,modifiability,depend,depend,600,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:695,modifiability,interfac,interface,695,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:600,safety,depend,depend,600,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:600,testability,depend,depend,600,"> Just one idea: Maybe @jalopezg-r00t knows of a better way of getting these infos from gCling directly rather than having to go through a temporary file write and parse? I see that the PR has been merged already, but to reply to the question: in principle, yes. TL;DR the header `interpreter/cling/include/cling/MetaProcessor/Display.h` provides the declaration `void DisplayGlobals(llvm::raw_ostream &stream, const Interpreter *interpreter);`, i.e. the same output can be rendered to a `llvm::raw_ostream`. The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM headers (for `llvm::raw_ostream`). We could, however provide an interface that, e.g. returns a `std::string` or writes to a `std::ostream`, if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:93,deployability,depend,depend,93,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:93,integrability,depend,depend,93,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:190,integrability,interfac,interface,190,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:190,interoperability,interfac,interface,190,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:93,modifiability,depend,depend,93,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:190,modifiability,interfac,interface,190,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:342,modifiability,interm,intermediate,342,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:93,safety,depend,depend,93,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:93,testability,depend,depend,93,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:428,usability,command,command,428,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11654:487,usability,command,command,487,"> The only problem with the above is that the code calling the aforementioned function would depend on both, Cling and LLVM . > headers (for llvm::raw_ostream). We could, however provide an interface that, e.g. returns a std::string or writes to a. > std::ostream, if need be. For the moment it is not that important - `RBrowser` anyway uses intermediate file output to get all kind of console output when executing any kind of command in the prompt. Therefore usage and parsing of `.g` command is looking fine for me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11654
https://github.com/root-project/root/pull/11655:38,deployability,releas,release,38,"Thanks, @vepadulano, for checking the release notes. Please let me merge, I want to update the commit message adding the link above to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11655
https://github.com/root-project/root/pull/11655:84,deployability,updat,update,84,"Thanks, @vepadulano, for checking the release notes. Please let me merge, I want to update the commit message adding the link above to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11655
https://github.com/root-project/root/pull/11655:102,integrability,messag,message,102,"Thanks, @vepadulano, for checking the release notes. Please let me merge, I want to update the commit message adding the link above to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11655
https://github.com/root-project/root/pull/11655:102,interoperability,messag,message,102,"Thanks, @vepadulano, for checking the release notes. Please let me merge, I want to update the commit message adding the link above to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11655
https://github.com/root-project/root/pull/11655:84,safety,updat,update,84,"Thanks, @vepadulano, for checking the release notes. Please let me merge, I want to update the commit message adding the link above to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11655
https://github.com/root-project/root/pull/11655:84,security,updat,update,84,"Thanks, @vepadulano, for checking the release notes. Please let me merge, I want to update the commit message adding the link above to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11655
https://github.com/root-project/root/issues/11657:22,availability,error,error,22,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:335,availability,error,error,335,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:375,interoperability,mismatch,mismatch,375,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:22,performance,error,error,22,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:335,performance,error,error,335,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:22,safety,error,error,22,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:335,safety,error,error,335,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:22,usability,error,error,22,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:335,usability,error,error,335,"I looked at the first error. ```. /usr/bin/cmake -E copy_if_different /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/tutorials/tree/jets.C /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08_build/tutorials/tree/jets.C. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/zebra.f:767:72: error: type of <E2><80>-Werror=lto-type-mismatch][]]. 767 | + ISTAT). | ^. /var/tmp/portage/sci-physics/root-6.26.08/work/root-6.26.08/misc/minicern/src/cernlib.c:107:6: note: cfget_ was previously declared here. 107 | void cfget_(int *lundes, int *medium, int *nwrec, int *nwtak, char *mbuf,. | ^. ```. I checked the code. Seems to me it is correct. In the c part, `istat` is declared as `int *istat`. which is normal because FORTRAN always passes by address. and in the FORTRAN part, we have `ISTAT` which is an integer as it starts with `I`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:216,availability,error,error,216,"I think the problem might actually be due to the `char *mbuf` that comes before. That looks like it's treated as `int` by Fortran too, no? The type that is mismatched is the type of the function, if I understood the error correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:156,interoperability,mismatch,mismatched,156,"I think the problem might actually be due to the `char *mbuf` that comes before. That looks like it's treated as `int` by Fortran too, no? The type that is mismatched is the type of the function, if I understood the error correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:216,performance,error,error,216,"I think the problem might actually be due to the `char *mbuf` that comes before. That looks like it's treated as `int` by Fortran too, no? The type that is mismatched is the type of the function, if I understood the error correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:216,safety,error,error,216,"I think the problem might actually be due to the `char *mbuf` that comes before. That looks like it's treated as `int` by Fortran too, no? The type that is mismatched is the type of the function, if I understood the error correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11657:216,usability,error,error,216,"I think the problem might actually be due to the `char *mbuf` that comes before. That looks like it's treated as `int` by Fortran too, no? The type that is mismatched is the type of the function, if I understood the error correctly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11657
https://github.com/root-project/root/issues/11663:83,usability,close,closer,83,I agree that `TTask` and `TThread` are legacy. `TFolder` is distinct from those 2 (closer tied to `TTree` usage),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:27,testability,understand,understand,27,"OK so @klenze we'd like to understand your use case. @couet please mark `TTask` (and while you're at it also `TThread` and `TFolder`) as legacy (i.e. doc), without deprecating them (i.e. code).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:73,deployability,build,build,73,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:32,integrability,event,event,32,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:543,performance,time,time,543,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:657,testability,assert,assert,657,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:221,usability,behavi,behavior,221,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:244,usability,user,user,244,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:647,usability,prefer,prefer,647,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:978,usability,close,close,978,"I ended up using it because our event processing framework happens to be build around TTask :-). https://github.com/FairRootGroup/FairRoot/blob/master/base/steer/FairTask.h#L40. I concede that the potential for undefined behavior is limited. A user handling two TList* at once, one to GetListOfTasks() and one to something else, and adding a TCanvas* to the former by mistake is not a terribly likely thing to happen. (I just am generally not a fan of static or C-style casts -- which are the casts mostly used in my collaboration. 95% of the time, the object is of the type you expected and nothing bad happens. But in the rare case it is not, I prefer an assert (or even a null pointer dereference) to just reinterpreting the object as a different type and seeing where that takes the code.). Marking it as deprecated works for me. . I consider the issue resolved but will keep the issue open for a bit so that people have a chance to comment on my wall of text. Feel free to close it as resolved, otherwise I will do so in a few days. . Thanks,. Philipp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11663:114,usability,confirm,confirming,114,"Yeah totally, we still want to fix the cast. Your use case is the only legit one that I'm aware of ;-) Thanks for confirming!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11663
https://github.com/root-project/root/issues/11665:379,security,auth,authors,379,"Hi @Anas-Alaali! You have already opened these two previous issues that were not related to ROOT:. * https://github.com/root-project/root/issues/11636. * https://github.com/root-project/root/issues/11626. The ROOT GitHub issues are for bug reports, feature requests, and improvement ideas for ROOT. If you have problems with the STARlight, please get in touch with the starlight authors or ask a colleague who might know about this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11665
https://github.com/root-project/root/issues/11667:82,energy efficiency,core,core,82,Maybe related with this comment: https://github.com/root-project/root/blob/master/core/metacling/src/TCling.cxx#L6250,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11667
https://github.com/root-project/root/issues/11667:22,testability,trace,trace,22,Relevant lines in the trace: . ![image](https://github.com/root-project/root/assets/10653970/d3955eea-13b6-46a0-a2fc-5b984fc6e62d). Maybe @vgvassilev can provide some insights on the mechanism.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11667
https://github.com/root-project/root/pull/11669:23,deployability,build,build,23,I checked with a local build that `stressRooStats` is passing with an ASAN build again now!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11669
https://github.com/root-project/root/pull/11669:75,deployability,build,build,75,I checked with a local build that `stressRooStats` is passing with an ASAN build again now!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11669
https://github.com/root-project/root/issues/11671:340,deployability,contain,containers,340,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11671:373,deployability,contain,containers,373,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11671:259,energy efficiency,alloc,allocate,259,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11671:393,energy efficiency,optim,optimization,393,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11671:430,energy efficiency,alloc,allocation,430,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11671:2,modifiability,Reu,Reuse,2,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11671:393,performance,optimiz,optimization,393,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11671:445,usability,user,user,445,> Reuse vs. destruct/reallocate for collection items: suggested by @pcanal https://github.com/root-project/root/pull/11525#discussion_r997337292 and https://github.com/root-project/root/pull/11525#discussion_r997343681. The 2nd one is actual about resize/pre-allocate in one go (instead of incrementally). The pattern can be applied to all containers. Even with non-vector containers it is an optimization as it cut the number of allocation (of user objects) in half (i.e only the final object rather than create a temporary object and copy over to the final object).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11671
https://github.com/root-project/root/issues/11673:415,deployability,manag,manage,415,"Lets start with the requirement:. What I want is a way to create a default object for one of the fields. Right now I need to do this:. `obj = entry->GetValue(fieldname).GetField()->GenerateValue().GetRawPtr();`. `entry->CaptureValueUnsafe( fieldname, obj );`. which is very convoluted and in addition it leaves object ownership to me for no good reason. I think AddValue() can do all this and even make the RNTuple manage the created object, is that right? (if not, that is what I would actually prefer). Cheers, Marcin.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11673
https://github.com/root-project/root/issues/11673:415,energy efficiency,manag,manage,415,"Lets start with the requirement:. What I want is a way to create a default object for one of the fields. Right now I need to do this:. `obj = entry->GetValue(fieldname).GetField()->GenerateValue().GetRawPtr();`. `entry->CaptureValueUnsafe( fieldname, obj );`. which is very convoluted and in addition it leaves object ownership to me for no good reason. I think AddValue() can do all this and even make the RNTuple manage the created object, is that right? (if not, that is what I would actually prefer). Cheers, Marcin.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11673
https://github.com/root-project/root/issues/11673:415,safety,manag,manage,415,"Lets start with the requirement:. What I want is a way to create a default object for one of the fields. Right now I need to do this:. `obj = entry->GetValue(fieldname).GetField()->GenerateValue().GetRawPtr();`. `entry->CaptureValueUnsafe( fieldname, obj );`. which is very convoluted and in addition it leaves object ownership to me for no good reason. I think AddValue() can do all this and even make the RNTuple manage the created object, is that right? (if not, that is what I would actually prefer). Cheers, Marcin.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11673
https://github.com/root-project/root/issues/11673:496,usability,prefer,prefer,496,"Lets start with the requirement:. What I want is a way to create a default object for one of the fields. Right now I need to do this:. `obj = entry->GetValue(fieldname).GetField()->GenerateValue().GetRawPtr();`. `entry->CaptureValueUnsafe( fieldname, obj );`. which is very convoluted and in addition it leaves object ownership to me for no good reason. I think AddValue() can do all this and even make the RNTuple manage the created object, is that right? (if not, that is what I would actually prefer). Cheers, Marcin.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11673
https://github.com/root-project/root/issues/11673:214,integrability,Event,Event,214,"Yes, I create the Entry this way:. `entry = ntupleWriter->GetModel()->CreateBareEntry();`. In most cases the objects to be added to the ntuple are already existing, but in some cases one may be missing for a given Event so I create a default objects to fill out the empty Field.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11673
https://github.com/root-project/root/pull/11680:37,deployability,patch,patches,37,This PR is trying to merge the v5-34 patches branch with the master which probably not what you meant :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:37,safety,patch,patches,37,This PR is trying to merge the v5-34 patches branch with the master which probably not what you meant :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:37,security,patch,patches,37,This PR is trying to merge the v5-34 patches branch with the master which probably not what you meant :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:196,deployability,patch,patches,196,"And the (Likely) commits that do ""[thisroot: Clean JUPYTER related variables possibly set by ROOT 6](https://github.com/root-project/root/pull/11680#top)"" have already been merged in the v5-34-00-patches branches (earlier today)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:67,modifiability,variab,variables,67,"And the (Likely) commits that do ""[thisroot: Clean JUPYTER related variables possibly set by ROOT 6](https://github.com/root-project/root/pull/11680#top)"" have already been merged in the v5-34-00-patches branches (earlier today)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:196,safety,patch,patches,196,"And the (Likely) commits that do ""[thisroot: Clean JUPYTER related variables possibly set by ROOT 6](https://github.com/root-project/root/pull/11680#top)"" have already been merged in the v5-34-00-patches branches (earlier today)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:196,security,patch,patches,196,"And the (Likely) commits that do ""[thisroot: Clean JUPYTER related variables possibly set by ROOT 6](https://github.com/root-project/root/pull/11680#top)"" have already been merged in the v5-34-00-patches branches (earlier today)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:1,deployability,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:1,safety,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:1,security,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:1,deployability,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:1,safety,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11680:1,security,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11680
https://github.com/root-project/root/pull/11687:65,energy efficiency,load,loading,65,"> Just out of curiosity: did you consider the alternative of not loading Rint.pcm, at least not for rootcling? I did not .. but I suspect there would be a risk that its content may then inadvertently be included in another pcm, isn't ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:65,performance,load,loading,65,"> Just out of curiosity: did you consider the alternative of not loading Rint.pcm, at least not for rootcling? I did not .. but I suspect there would be a risk that its content may then inadvertently be included in another pcm, isn't ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:169,performance,content,content,169,"> Just out of curiosity: did you consider the alternative of not loading Rint.pcm, at least not for rootcling? I did not .. but I suspect there would be a risk that its content may then inadvertently be included in another pcm, isn't ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:155,safety,risk,risk,155,"> Just out of curiosity: did you consider the alternative of not loading Rint.pcm, at least not for rootcling? I did not .. but I suspect there would be a risk that its content may then inadvertently be included in another pcm, isn't ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:155,security,risk,risk,155,"> Just out of curiosity: did you consider the alternative of not loading Rint.pcm, at least not for rootcling? I did not .. but I suspect there would be a risk that its content may then inadvertently be included in another pcm, isn't ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:38,availability,servic,services,38,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:165,availability,failur,failure,165,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:38,deployability,servic,services,38,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:90,deployability,build,build,90,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:165,deployability,fail,failure,165,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:38,integrability,servic,services,38,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:38,modifiability,servic,services,38,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:165,performance,failur,failure,165,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:165,reliability,fail,failure,165,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:103,safety,test,testReport,103,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:141,safety,test,test,141,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:103,testability,test,testReport,103,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/pull/11687:141,testability,test,test,141,The [test_webgui_ping](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/158835/testReport/projectroot.gui.webdisplay/test/test_webgui_ping/) failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11687
https://github.com/root-project/root/issues/11689:1,deployability,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11689
https://github.com/root-project/root/issues/11689:1,safety,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11689
https://github.com/root-project/root/issues/11689:1,security,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11689
https://github.com/root-project/root/issues/11689:1,deployability,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11689
https://github.com/root-project/root/issues/11689:1,safety,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11689
https://github.com/root-project/root/issues/11689:1,security,patch,patch,1,.patch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11689
https://github.com/root-project/root/pull/11690:0,availability,Error,Errors,0,Errors are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11690
https://github.com/root-project/root/pull/11690:0,performance,Error,Errors,0,Errors are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11690
https://github.com/root-project/root/pull/11690:0,safety,Error,Errors,0,Errors are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11690
https://github.com/root-project/root/pull/11690:0,usability,Error,Errors,0,Errors are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11690
https://github.com/root-project/root/pull/11691:16,deployability,build,builds,16,Stopping the CI builds as the last run was green and I only changed the commit log.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11691
https://github.com/root-project/root/pull/11691:79,deployability,log,log,79,Stopping the CI builds as the last run was green and I only changed the commit log.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11691
https://github.com/root-project/root/pull/11691:43,energy efficiency,green,green,43,Stopping the CI builds as the last run was green and I only changed the commit log.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11691
https://github.com/root-project/root/pull/11691:79,safety,log,log,79,Stopping the CI builds as the last run was green and I only changed the commit log.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11691
https://github.com/root-project/root/pull/11691:79,security,log,log,79,Stopping the CI builds as the last run was green and I only changed the commit log.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11691
https://github.com/root-project/root/pull/11691:79,testability,log,log,79,Stopping the CI builds as the last run was green and I only changed the commit log.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11691
https://github.com/root-project/root/pull/11691:0,usability,Stop,Stopping,0,Stopping the CI builds as the last run was green and I only changed the commit log.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11691
https://github.com/root-project/root/pull/11693:6,availability,failur,failure,6,MacOS failure is pre-existing (and about to be fixed by a PR in roottest),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11693
https://github.com/root-project/root/pull/11693:6,deployability,fail,failure,6,MacOS failure is pre-existing (and about to be fixed by a PR in roottest),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11693
https://github.com/root-project/root/pull/11693:6,performance,failur,failure,6,MacOS failure is pre-existing (and about to be fixed by a PR in roottest),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11693
https://github.com/root-project/root/pull/11693:6,reliability,fail,failure,6,MacOS failure is pre-existing (and about to be fixed by a PR in roottest),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11693
https://github.com/root-project/root/issues/11694:582,deployability,build,building-starlight,582,"Hi @Anas-Alaali! You have already opened these three previous issues that were not related to ROOT bugs or feature and improvement requests! Can you **please** stop this spam? * https://github.com/root-project/root/issues/11665. * https://github.com/root-project/root/issues/11636. * https://github.com/root-project/root/issues/11626. If you have problems with the STARlight, please get in touch with the starlight authors or ask a colleague who might know about this. Also you already have opened a thread on the ROOT forum about this:. https://root-forum.cern.ch/t/run-make-after-building-starlight/52336/4",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11694
https://github.com/root-project/root/issues/11694:415,security,auth,authors,415,"Hi @Anas-Alaali! You have already opened these three previous issues that were not related to ROOT bugs or feature and improvement requests! Can you **please** stop this spam? * https://github.com/root-project/root/issues/11665. * https://github.com/root-project/root/issues/11636. * https://github.com/root-project/root/issues/11626. If you have problems with the STARlight, please get in touch with the starlight authors or ask a colleague who might know about this. Also you already have opened a thread on the ROOT forum about this:. https://root-forum.cern.ch/t/run-make-after-building-starlight/52336/4",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11694
https://github.com/root-project/root/issues/11694:160,usability,stop,stop,160,"Hi @Anas-Alaali! You have already opened these three previous issues that were not related to ROOT bugs or feature and improvement requests! Can you **please** stop this spam? * https://github.com/root-project/root/issues/11665. * https://github.com/root-project/root/issues/11636. * https://github.com/root-project/root/issues/11626. If you have problems with the STARlight, please get in touch with the starlight authors or ask a colleague who might know about this. Also you already have opened a thread on the ROOT forum about this:. https://root-forum.cern.ch/t/run-make-after-building-starlight/52336/4",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11694
https://github.com/root-project/root/issues/11699:663,deployability,resourc,resource,663,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:589,energy efficiency,CPU,CPU,589,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:663,energy efficiency,resourc,resource,663,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:19,integrability,asynchron,asynchronous,19,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:156,integrability,asynchron,asynchronous,156,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:573,integrability,sub,subscribing,573,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:19,performance,asynch,asynchronous,19,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:156,performance,asynch,asynchronous,156,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:299,performance,lock,locks,299,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:337,performance,lock,locks,337,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:377,performance,lock,locks,377,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:434,performance,lock,lock,434,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:522,performance,lock,locks,522,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:551,performance,lock,locks,551,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:589,performance,CPU,CPU,589,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:663,performance,resourc,resource,663,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:730,performance,multi-thread,multi-threading,730,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:324,safety,risk,risk,324,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:560,safety,risk,risk,560,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:663,safety,resourc,resource,663,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:299,security,lock,locks,299,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:324,security,risk,risk,324,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:337,security,lock,locks,337,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:377,security,lock,locks,377,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:434,security,lock,lock,434,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:522,security,lock,locks,522,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:551,security,lock,locks,551,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:560,security,risk,risk,560,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:663,testability,resourc,resource,663,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:51,usability,clear,clear,51,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:85,usability,support,support,85,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:478,usability,user,user,478,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:. * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one). * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks. * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). . * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:223,performance,time,time,223,"Thanks for this nice proposal. . I would like to close the issue. I do not think we will implement this, the second bullet raised by @pcanal is alone probably enough to dismiss the idea, which seemed very good to me at the time, too. @vgvassilev what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/issues/11699:49,usability,close,close,49,"Thanks for this nice proposal. . I would like to close the issue. I do not think we will implement this, the second bullet raised by @pcanal is alone probably enough to dismiss the idea, which seemed very good to me at the time, too. @vgvassilev what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699
https://github.com/root-project/root/pull/11700:13,availability,error,errors,13,"Warnings and errors are preexisting, Windows is bogus.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11700
https://github.com/root-project/root/pull/11700:13,performance,error,errors,13,"Warnings and errors are preexisting, Windows is bogus.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11700
https://github.com/root-project/root/pull/11700:13,safety,error,errors,13,"Warnings and errors are preexisting, Windows is bogus.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11700
https://github.com/root-project/root/pull/11700:13,usability,error,errors,13,"Warnings and errors are preexisting, Windows is bogus.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11700
https://github.com/root-project/root/pull/11702:8,availability,error,errors,8,Windows errors seem unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11702
https://github.com/root-project/root/pull/11702:8,performance,error,errors,8,Windows errors seem unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11702
https://github.com/root-project/root/pull/11702:8,safety,error,errors,8,Windows errors seem unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11702
https://github.com/root-project/root/pull/11702:8,usability,error,errors,8,Windows errors seem unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11702
https://github.com/root-project/root/pull/11703:158,safety,compl,completely,158,"> While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. I am not sure I completely understand. Can you suggest a change?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:158,security,compl,completely,158,"> While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. I am not sure I completely understand. Can you suggest a change?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:169,testability,understand,understand,169,"> While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. I am not sure I completely understand. Can you suggest a change?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:514,deployability,automat,automatically,514,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:551,deployability,depend,depending,551,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:551,integrability,depend,depending,551,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:551,modifiability,depend,depending,551,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:529,reliability,doe,does,529,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:166,safety,compl,completely,166,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:551,safety,depend,depending,551,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:166,security,compl,completely,166,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:177,testability,understand,understand,177,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:514,testability,automat,automatically,514,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11703:551,testability,depend,depending,551,"> > While we are at it, the Clang libraries should probably be linked with `clang_target_link_libraries` to make `CLANG_LINK_CLANG_DYLIB` work. > . > I am not sure I completely understand. Can you suggest a change? I think the first branch should read something like. ```cmake. set(LIBS. clingInterpreter. clingMetaProcessor. clingUserInterface. clingUtils. ). add_cling_executable(cling. cling.cpp. ). clang_target_link_libraries(cling. clangFrontendTool. ). ```. `clang_target_link_libraries` is a function that automatically ""does the right thing"" depending on `CLANG_LINK_CLANG_DYLIB`. But we can do that in another PR, if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11703
https://github.com/root-project/root/pull/11704:22,availability,Ping,Ping,22,Passes all the tests. Ping.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11704
https://github.com/root-project/root/pull/11704:15,safety,test,tests,15,Passes all the tests. Ping.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11704
https://github.com/root-project/root/pull/11704:15,testability,test,tests,15,Passes all the tests. Ping.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11704
https://github.com/root-project/root/pull/11704:70,usability,close,close,70,This issue was fixed independently in #12187. Since that was merged I close this.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11704
https://github.com/root-project/root/issues/11707:86,availability,Error,Error,86,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:712,availability,error,error,712,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:470,deployability,version,version,470,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:470,integrability,version,version,470,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:470,modifiability,version,version,470,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:86,performance,Error,Error,86,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:712,performance,error,error,712,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:86,safety,Error,Error,86,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:712,safety,error,error,712,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:309,security,Team,Team,309,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:86,usability,Error,Error,86,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:518,usability,help,help,518,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:712,usability,error,error,712,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:753,usability,clear,clear,753,"I do not get this crash:. ```. % root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Nov 15 2022, 10:28:34 |. | From heads/master@v6-25-02-2747-g7a90392f2a |. | With Apple clang version 14.0.0 (clang-1400.0.29.202) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . ```. For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:18,availability,error,error,18,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:198,deployability,stack,stackoverflow,198,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:243,deployability,fail,failed-to-call-main-to-execute-the-macro,243,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:18,performance,error,error,18,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:243,reliability,fail,failed-to-call-main-to-execute-the-macro,243,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:18,safety,error,error,18,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:18,usability,error,error,18,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:59,usability,clear,clear,59,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:102,usability,user,users,102,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:200,availability,error,error,200,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:149,energy efficiency,core,core,149,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:40,integrability,messag,message,40,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:40,interoperability,messag,message,40,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:200,performance,error,error,200,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:200,safety,error,error,200,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:26,usability,clear,clear,26,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:200,usability,error,error,200,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:304,usability,clear,clearer,304,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:107,availability,error,error,107,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:247,availability,Error,Error,247,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:876,availability,Error,Error,876,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:1670,deployability,stack,stack,1670,"'.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x0000",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2418,deployability,Stack,StackTrace,2418,"--------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=132",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3919,deployability,stack,stack,3919,"e/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. Root > . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:1989,energy efficiency,optim,optimized,1989,"------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalCo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2139,energy efficiency,optim,optimized,2139," Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2344,energy efficiency,core,core,2344,"', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2468,energy efficiency,core,core,2468," root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2628,energy efficiency,core,core,2628,"mentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2749,energy efficiency,core,core,2749,"=======. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2846,energy efficiency,core,core,2846,"8, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then pl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3043,energy efficiency,core,core,3043," options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. =================",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3209,energy efficiency,core,core,3209,"in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:113,integrability,messag,message,113,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3853,integrability,sub,submit,3853,"e/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. Root > . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:113,interoperability,messag,message,113,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:107,performance,error,error,107,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:247,performance,Error,Error,247,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:876,performance,Error,Error,876,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:1989,performance,optimiz,optimized,1989,"------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalCo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:2139,performance,optimiz,optimized,2139," Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:107,safety,error,error,107,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:247,safety,Error,Error,247,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:876,safety,Error,Error,876,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:470,security,Team,Team,470,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:1099,security,Team,Team,1099,"ormal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3015,security,sign,signum,3015,"_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3181,security,sign,signum,3181,"171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3270,security,sign,signal,3270,"f580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:1676,testability,trace,trace,1676,"'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backtrace.sh 95620 1>&2"") at /opt/root_src/core/unix/src/TUnixSystem.cxx:2104. #4 0x00007f7b9fc5c4d3 in TUnixSystem::StackTrace (this=0x55d680e3b800) at /opt/root_src/core/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3925,testability,trace,trace,3925,"e/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. Root > . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:71,usability,behavi,behavior,71,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:107,usability,error,error,107,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:247,usability,Error,Error,247,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:675,usability,help,help,675,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:876,usability,Error,Error,876,"> For me, on Mac, it is protected. It seems to me that it is undefined behavior. Sometimes, I get a normal error message, sometimes I get the crash. See here below consecutive runs:. ```. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:1304,usability,help,help,1304," TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... Error in <TApplication::TApplication>: only one instance of TApplication allowed. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 30 2022, 13:52:01 |. | From heads/master@v6-25-01-4921-gdfd0f52391 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] .q. /tmp$ root -l main.cpp . root [0] . Processing main.cpp... *** Break *** segmentation violation. ===========================================================. There was a crash (kSigSegmentationViolation). This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f7b9f49845a in __GI___wait4 (pid=95642, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0, usage=usage. entry=0x0) at ../sysdeps/unix/sysv/linux/wait4.c:30. #1 0x00007f7b9f49841b in __GI___waitpid (pid=<optimized out>, stat_loc=stat_loc. entry=0x7ffd4f13a298, options=options. entry=0) at ./posix/waitpid.c:38. #2 0x00007f7b9f3febcb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:171. #3 0x00007f7b9fc5bc22 in TUnixSystem::Exec (this=0x55d680e3b800, shellcmd=0x55d681cbf580 ""/opt/root_bld/etc/gdb-backt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3686,usability,hint,hint,3686,"e/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. Root > . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:3730,usability,help,help,3730,"e/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. Root > . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:4001,usability,help,help,4001,"e/unix/src/TUnixSystem.cxx:2395. #5 0x00007f7b9fc60174 in TUnixSystem::DispatchSignals (this=0x55d680e3b800, sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3615. #6 0x00007f7b9fc5790e in SigHandler (sig=kSigSegmentationViolation) at /opt/root_src/core/unix/src/TUnixSystem.cxx:395. #7 0x00007f7b9fc60081 in sighandler (sig=11) at /opt/root_src/core/unix/src/TUnixSystem.cxx:3586. #8 0x00007f7b9fc509d0 in textinput::TerminalConfigUnix::HandleSignal (this=0x7f7ba0144ae0 <textinput::TerminalConfigUnix::Get()::s>, signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:99. #9 0x00007f7b9fc506ec in (anonymous namespace)::TerminalConfigUnix__handleSignal (signum=11) at /opt/root_src/core/textinput/src/textinput/TerminalConfigUnix.cpp:36. #10 <signal handler called>. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #11 __strcmp_avx2 () at ../sysdeps/x86_64/multiarch/strcmp-avx2.S:115. #12 0x000055d67fa00eba in handle_notebook_option (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:39. #13 0x000055d67fa0109c in main (argc=1326708416, argv=0x55d681c181b0) at /opt/root_src/main/src/rmain.cxx:78. ===========================================================. Root > . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:337,integrability,event,event,337,"If in rmain.cxx, i use:. ```. int main(int argc, char **argv). {. fprintf(stderr, ""%d %s\n"", argc, ""a"");. handle_notebook_option(argc, argv);. TRint *theApp = new TRint(""Rint"", &argc, argv, /*options*/ nullptr, /*numOptions*/ 0, /*noLogo*/ kFALSE,. /*exitOnUnknownArgs*/ kTRUE);. fprintf(stderr, ""%d %s\n"", argc, ""b"");. // and enter the event loop... theApp->Run();. delete theApp;. return 0;. }. ```. Then I get:. ```. 4 a. 1 b. Processing /tmp/main.cpp... 283144112 a. *** Break *** segmentation violation. ```. So the second time this function is called, argc is random memory I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:528,performance,time,time,528,"If in rmain.cxx, i use:. ```. int main(int argc, char **argv). {. fprintf(stderr, ""%d %s\n"", argc, ""a"");. handle_notebook_option(argc, argv);. TRint *theApp = new TRint(""Rint"", &argc, argv, /*options*/ nullptr, /*numOptions*/ 0, /*noLogo*/ kFALSE,. /*exitOnUnknownArgs*/ kTRUE);. fprintf(stderr, ""%d %s\n"", argc, ""b"");. // and enter the event loop... theApp->Run();. delete theApp;. return 0;. }. ```. Then I get:. ```. 4 a. 1 b. Processing /tmp/main.cpp... 283144112 a. *** Break *** segmentation violation. ```. So the second time this function is called, argc is random memory I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:573,performance,memor,memory,573,"If in rmain.cxx, i use:. ```. int main(int argc, char **argv). {. fprintf(stderr, ""%d %s\n"", argc, ""a"");. handle_notebook_option(argc, argv);. TRint *theApp = new TRint(""Rint"", &argc, argv, /*options*/ nullptr, /*numOptions*/ 0, /*noLogo*/ kFALSE,. /*exitOnUnknownArgs*/ kTRUE);. fprintf(stderr, ""%d %s\n"", argc, ""b"");. // and enter the event loop... theApp->Run();. delete theApp;. return 0;. }. ```. Then I get:. ```. 4 a. 1 b. Processing /tmp/main.cpp... 283144112 a. *** Break *** segmentation violation. ```. So the second time this function is called, argc is random memory I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/issues/11707:573,usability,memor,memory,573,"If in rmain.cxx, i use:. ```. int main(int argc, char **argv). {. fprintf(stderr, ""%d %s\n"", argc, ""a"");. handle_notebook_option(argc, argv);. TRint *theApp = new TRint(""Rint"", &argc, argv, /*options*/ nullptr, /*numOptions*/ 0, /*noLogo*/ kFALSE,. /*exitOnUnknownArgs*/ kTRUE);. fprintf(stderr, ""%d %s\n"", argc, ""b"");. // and enter the event loop... theApp->Run();. delete theApp;. return 0;. }. ```. Then I get:. ```. 4 a. 1 b. Processing /tmp/main.cpp... 283144112 a. *** Break *** segmentation violation. ```. So the second time this function is called, argc is random memory I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707
https://github.com/root-project/root/pull/11708:34,deployability,releas,releasing,34,I'll merge (I'm in the process of releasing),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11708
https://github.com/root-project/root/pull/11716:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11716
https://github.com/root-project/root/pull/11716:69,reliability,doe,doesn,69,Thanks for the review @guitargeek and good to hear that this removal doesn't break anything. I will follow your suggestion: this can be merged now and I will rebase #11717 to remove this commit from there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11716
https://github.com/root-project/root/pull/11716:15,safety,review,review,15,Thanks for the review @guitargeek and good to hear that this removal doesn't break anything. I will follow your suggestion: this can be merged now and I will rebase #11717 to remove this commit from there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11716
https://github.com/root-project/root/pull/11716:15,testability,review,review,15,Thanks for the review @guitargeek and good to hear that this removal doesn't break anything. I will follow your suggestion: this can be merged now and I will rebase #11717 to remove this commit from there.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11716
https://github.com/root-project/root/pull/11717:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:26,availability,failur,failures,26,"I don't think the Windows failures were related to this PR, but restarted them just to be sure. Note that CI on #11716 (which corresponds to the first commit in this PR) already passed fully.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:26,deployability,fail,failures,26,"I don't think the Windows failures were related to this PR, but restarted them just to be sure. Note that CI on #11716 (which corresponds to the first commit in this PR) already passed fully.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:26,performance,failur,failures,26,"I don't think the Windows failures were related to this PR, but restarted them just to be sure. Note that CI on #11716 (which corresponds to the first commit in this PR) already passed fully.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:26,reliability,fail,failures,26,"I don't think the Windows failures were related to this PR, but restarted them just to be sure. Note that CI on #11716 (which corresponds to the first commit in this PR) already passed fully.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:21,safety,review,review,21,"CI passed, ready for review @lmoneta.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:21,testability,review,review,21,"CI passed, ready for review @lmoneta.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:4,safety,review,review,4,"All review comments addressed, if this passes CI I think we can merge it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:4,testability,review,review,4,"All review comments addressed, if this passes CI I think we can merge it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:11,deployability,fail,failing,11,The single failing test is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:11,reliability,fail,failing,11,The single failing test is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:19,safety,test,test,19,The single failing test is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11717:19,testability,test,test,19,The single failing test is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11717
https://github.com/root-project/root/pull/11721:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/noimt, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11721
https://github.com/root-project/root/issues/11722:946,availability,Down,Downloads,946,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:707,deployability,updat,updated,707,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:715,deployability,version,version,715,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1222,deployability,contain,contained,1222,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1377,deployability,updat,updated,1377,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:57,energy efficiency,current,currently,57,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:398,energy efficiency,load,load,398,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1110,energy efficiency,load,loadFinderBinning,1110,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1131,energy efficiency,Load,Loading,1131,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:45,integrability,messag,message,45,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:147,integrability,wrap,wrap,147,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:715,integrability,version,version,715,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:45,interoperability,messag,message,45,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:917,interoperability,share,shared,917,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:715,modifiability,version,version,715,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:398,performance,load,load,398,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1110,performance,load,loadFinderBinning,1110,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1131,performance,Load,Loading,1131,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:256,reliability,pra,pragma,256,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:312,reliability,pra,pragma,312,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:707,safety,updat,updated,707,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1377,safety,updat,updated,1377,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:707,security,updat,updated,707,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:1377,security,updat,updated,1377,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:74,usability,support,support,74,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11722:933,usability,User,Users,933,"There is indeed a missing protection/warning message. We currently do not support storing `std::array` as a top level objects. Instead you need to wrap it into a struct. For example, this can be done in your example by adding:. ```. #ifdef __ROOTCLING__. #pragma link C++ class std::vector<std::vector<int>>+;. #pragma link C++ class Binner+;. #endif. ```. to a linkdef file (or your script if you load it via ACLiC). and writing with . ```. fout->WriteObject(this,""binner""); // i.e. you using don't need to give the class name, the compiler can pass enough information. ```. and read with:. ```. auto binner = f->Get<Binner>(""binner""); // Not casting needed here, binner will be a `Binner*`. ```. With the updated version of the script I get:. [example.C.txt](https://github.com/root-project/root/files/10025600/example.C.txt). ```. $ root.exe -b -l. root [0] .L example.C+. Info in <TMacOSXSystem::ACLiC>: creating shared library /Users/pcanal/Downloads/./example_C.so. root [1] finderBinner(). Creating std::array<std::array<std::vector<std::vector<Int_t>>, LAYER1>, LAYER2> in FinderBinning.root. root [2] loadFinderBinning(). Loading FinderBinning.root. root [3] . ```. Cheers,. Philippe. PS. Side note the example.C contained:. ```. mBinsS = castedBinsS;. ```. which ended up copying all the data from castedBinsS to mBinsS which was wastefull. See my alternative in the updated script.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11722
https://github.com/root-project/root/issues/11723:62,energy efficiency,Draw,DrawMap,62,"Yes, I see that. I will investigate. I was not aware of this ""DrawMap"". Thanks for the report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:36,deployability,roll,rolled,36,The issue is in TFileDrawMap.cxx. I rolled back to a version of 2008. The issue is still there. So that's not something introduced recently. Deeper investigations are needed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:53,deployability,version,version,53,The issue is in TFileDrawMap.cxx. I rolled back to a version of 2008. The issue is still there. So that's not something introduced recently. Deeper investigations are needed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:53,integrability,version,version,53,The issue is in TFileDrawMap.cxx. I rolled back to a version of 2008. The issue is still there. So that's not something introduced recently. Deeper investigations are needed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:53,modifiability,version,version,53,The issue is in TFileDrawMap.cxx. I rolled back to a version of 2008. The issue is still there. So that's not something introduced recently. Deeper investigations are needed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:452,availability,avail,available,452,"Ok, I talked to Ren, it seems that what we get is correct. This functionality shows where the objects in a file are, and their occupancy. It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Then moving the mouse on the canvas you see where the objects are. According to Ren, this functionality makes sense only for big files with many objects. I cannot tell whether it can be improved or not. There is no picture reference available. . Edit: I am investigating where the boxes' colors are coming from and also why there are no labels on the axis (it seems there must be some according to the doc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:179,integrability,Event,Event,179,"Ok, I talked to Ren, it seems that what we get is correct. This functionality shows where the objects in a file are, and their occupancy. It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Then moving the mouse on the canvas you see where the objects are. According to Ren, this functionality makes sense only for big files with many objects. I cannot tell whether it can be improved or not. There is no picture reference available. . Edit: I am investigating where the boxes' colors are coming from and also why there are no labels on the axis (it seems there must be some according to the doc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:452,reliability,availab,available,452,"Ok, I talked to Ren, it seems that what we get is correct. This functionality shows where the objects in a file are, and their occupancy. It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Then moving the mouse on the canvas you see where the objects are. According to Ren, this functionality makes sense only for big files with many objects. I cannot tell whether it can be improved or not. There is no picture reference available. . Edit: I am investigating where the boxes' colors are coming from and also why there are no labels on the axis (it seems there must be some according to the doc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:452,safety,avail,available,452,"Ok, I talked to Ren, it seems that what we get is correct. This functionality shows where the objects in a file are, and their occupancy. It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Then moving the mouse on the canvas you see where the objects are. According to Ren, this functionality makes sense only for big files with many objects. I cannot tell whether it can be improved or not. There is no picture reference available. . Edit: I am investigating where the boxes' colors are coming from and also why there are no labels on the axis (it seems there must be some according to the doc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:452,security,availab,available,452,"Ok, I talked to Ren, it seems that what we get is correct. This functionality shows where the objects in a file are, and their occupancy. It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Then moving the mouse on the canvas you see where the objects are. According to Ren, this functionality makes sense only for big files with many objects. I cannot tell whether it can be improved or not. There is no picture reference available. . Edit: I am investigating where the boxes' colors are coming from and also why there are no labels on the axis (it seems there must be some according to the doc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:185,usability,Statu,Statusbar,185,"Ok, I talked to Ren, it seems that what we get is correct. This functionality shows where the objects in a file are, and their occupancy. It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Then moving the mouse on the canvas you see where the objects are. According to Ren, this functionality makes sense only for big files with many objects. I cannot tell whether it can be improved or not. There is no picture reference available. . Edit: I am investigating where the boxes' colors are coming from and also why there are no labels on the axis (it seems there must be some according to the doc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:234,usability,mous,mouse,234,"Ok, I talked to Ren, it seems that what we get is correct. This functionality shows where the objects in a file are, and their occupancy. It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Then moving the mouse on the canvas you see where the objects are. According to Ren, this functionality makes sense only for big files with many objects. I cannot tell whether it can be improved or not. There is no picture reference available. . Edit: I am investigating where the boxes' colors are coming from and also why there are no labels on the axis (it seems there must be some according to the doc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:123,energy efficiency,Draw,DrawMap,123,"> It makes sense only if you turn on the ""Event Statusbar"". I guess that should be turned on by default when someone uses `DrawMap` then",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:42,integrability,Event,Event,42,"> It makes sense only if you turn on the ""Event Statusbar"". I guess that should be turned on by default when someone uses `DrawMap` then",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:48,usability,Statu,Statusbar,48,"> It makes sense only if you turn on the ""Event Statusbar"". I guess that should be turned on by default when someone uses `DrawMap` then",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:53,energy efficiency,draw,drawmap,53,"It makes more sense with a bit of tuning:. ```. void drawmap() {. auto f = new TFile(""hsimple.root"");. TNtuple *n = (TNtuple*)f->Get(""ntuple"");. n->GetBranch(""px"")->SetFillColor(kRed);. n->GetBranch(""py"")->SetFillColor(kBlue);. n->GetBranch(""pz"")->SetFillColor(kGreen);. n->GetBranch(""random"")->SetFillColor(kYellow);. f->DrawMap();. }. ```. <img width=""602"" alt=""Screenshot 2022-11-17 at 13 37 43"" src=""https://user-images.githubusercontent.com/4697738/202448606-6f176ce6-03e8-435a-adcd-109cd8bb32cf.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:322,energy efficiency,Draw,DrawMap,322,"It makes more sense with a bit of tuning:. ```. void drawmap() {. auto f = new TFile(""hsimple.root"");. TNtuple *n = (TNtuple*)f->Get(""ntuple"");. n->GetBranch(""px"")->SetFillColor(kRed);. n->GetBranch(""py"")->SetFillColor(kBlue);. n->GetBranch(""pz"")->SetFillColor(kGreen);. n->GetBranch(""random"")->SetFillColor(kYellow);. f->DrawMap();. }. ```. <img width=""602"" alt=""Screenshot 2022-11-17 at 13 37 43"" src=""https://user-images.githubusercontent.com/4697738/202448606-6f176ce6-03e8-435a-adcd-109cd8bb32cf.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:412,usability,user,user-images,412,"It makes more sense with a bit of tuning:. ```. void drawmap() {. auto f = new TFile(""hsimple.root"");. TNtuple *n = (TNtuple*)f->Get(""ntuple"");. n->GetBranch(""px"")->SetFillColor(kRed);. n->GetBranch(""py"")->SetFillColor(kBlue);. n->GetBranch(""pz"")->SetFillColor(kGreen);. n->GetBranch(""random"")->SetFillColor(kYellow);. f->DrawMap();. }. ```. <img width=""602"" alt=""Screenshot 2022-11-17 at 13 37 43"" src=""https://user-images.githubusercontent.com/4697738/202448606-6f176ce6-03e8-435a-adcd-109cd8bb32cf.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:92,integrability,Event,Event,92,"Shouldn't that be the default behavior? :smile: . > It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Where in the doc? https://root.cern/doc/master/classTFile.html#abfd68d5396de59a1c3cf6a2e1bdb8563",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:30,usability,behavi,behavior,30,"Shouldn't that be the default behavior? :smile: . > It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Where in the doc? https://root.cern/doc/master/classTFile.html#abfd68d5396de59a1c3cf6a2e1bdb8563",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:98,usability,Statu,Statusbar,98,"Shouldn't that be the default behavior? :smile: . > It makes sense only if you turn on the ""Event Statusbar"" (as said in the doc). Where in the doc? https://root.cern/doc/master/classTFile.html#abfd68d5396de59a1c3cf6a2e1bdb8563",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:268,deployability,automat,automatic,268,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:629,deployability,automat,automatically,629,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:650,deployability,automat,automatic,650,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:15,integrability,discover,discovering,15,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:467,integrability,Event,Event,467,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:15,interoperability,discover,discovering,15,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:331,performance,time,time,331,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:268,testability,automat,automatic,268,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:629,testability,automat,automatically,629,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:650,testability,automat,automatic,650,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:15,usability,discov,discovering,15,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:473,usability,Statu,Status,473,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11723:618,usability,statu,status,618,"@eguiraud I am discovering this functionality. Surely it can be improved. I am on it. I will make a PR. In particular to have the axis label (I have the fix). Then the color is taken from the branch itself. So the color has to be set somehow. Again we can invent some automatic coloring (as it is ""fashion"" these days) but for the time being, I am just resurrecting this stuff. The doc needs to be improved with an example. There is none right now. And regarding the Event Status, it is [there](https://root.cern/doc/master/classTFileDrawMap.html), that's too hidden. I will make it easier to find, or maybe force the status bar automatically (again automatic stuff :-) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11723
https://github.com/root-project/root/issues/11728:30,deployability,patch,patches,30,This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:30,safety,patch,patches,30,This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:30,security,patch,patches,30,This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:32,deployability,patch,patches,32,> This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier. Perhaps python (different version) checks could be part of of your CI run?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:112,deployability,version,version,112,> This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier. Perhaps python (different version) checks could be part of of your CI run?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:112,integrability,version,version,112,> This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier. Perhaps python (different version) checks could be part of of your CI run?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:112,modifiability,version,version,112,> This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier. Perhaps python (different version) checks could be part of of your CI run?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:32,safety,patch,patches,32,> This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier. Perhaps python (different version) checks could be part of of your CI run?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/issues/11728:32,security,patch,patches,32,> This is now fixed in v6-26-00-patches. Sorry for not backporting the fixes earlier. Perhaps python (different version) checks could be part of of your CI run?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11728
https://github.com/root-project/root/pull/11729:15,reliability,doe,does,15,"Wit this, ROOT does not quit if the new browser gets closed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11729
https://github.com/root-project/root/pull/11729:53,usability,close,closed,53,"Wit this, ROOT does not quit if the new browser gets closed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11729
https://github.com/root-project/root/pull/11729:17,reliability,doe,does,17,"> Wit this, ROOT does not quit if the new browser gets closed? Nope. There is no signal emitted. But at least ROOT doesn't crash...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11729
https://github.com/root-project/root/pull/11729:115,reliability,doe,doesn,115,"> Wit this, ROOT does not quit if the new browser gets closed? Nope. There is no signal emitted. But at least ROOT doesn't crash...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11729
https://github.com/root-project/root/pull/11729:81,security,sign,signal,81,"> Wit this, ROOT does not quit if the new browser gets closed? Nope. There is no signal emitted. But at least ROOT doesn't crash...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11729
https://github.com/root-project/root/pull/11729:55,usability,close,closed,55,"> Wit this, ROOT does not quit if the new browser gets closed? Nope. There is no signal emitted. But at least ROOT doesn't crash...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11729
https://github.com/root-project/root/pull/11731:101,availability,avail,available,101,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:54,integrability,interfac,interface,54,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:190,integrability,interfac,interface,190,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:54,interoperability,interfac,interface,54,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:190,interoperability,interfac,interface,190,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:54,modifiability,interfac,interface,54,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:190,modifiability,interfac,interface,190,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:228,performance,perform,performance,228,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:521,performance,disk,disk,521,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:101,reliability,availab,available,101,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:101,safety,avail,available,101,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:101,security,availab,available,101,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:278,testability,simpl,simple,278,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:341,testability,simpl,simply,341,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:228,usability,perform,performance,228,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:278,usability,simpl,simple,278,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:341,usability,simpl,simply,341,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:55,deployability,updat,updated,55,"@jblomer @pcanal The pull request description has been updated to show an evaluation of the overhead of setting a post-read callback. Given the results, the PR will be merged today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:92,performance,overhead,overhead,92,"@jblomer @pcanal The pull request description has been updated to show an evaluation of the overhead of setting a post-read callback. Given the results, the PR will be merged today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:55,safety,updat,updated,55,"@jblomer @pcanal The pull request description has been updated to show an evaluation of the overhead of setting a post-read callback. Given the results, the PR will be merged today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/pull/11731:55,security,updat,updated,55,"@jblomer @pcanal The pull request description has been updated to show an evaluation of the overhead of setting a post-read callback. Given the results, the PR will be merged today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731
https://github.com/root-project/root/issues/11732:108,integrability,Event,Event,108,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/issues/11732:351,integrability,schema,schema,351,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/issues/11732:523,integrability,schema,schema,523,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/issues/11732:190,interoperability,format,format,190,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/issues/11732:212,safety,except,except,212,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/issues/11732:139,usability,GUID,GUIDs,139,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/issues/11732:229,usability,user,user,229,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/issues/11732:544,usability,help,help,544,"Right, I am making this request on behalf of ATLAS, who are writing this type of data member as part of the Event Header structure (in the GUIDs to be exact) which means it is in every data format ever produced (except maybe end-user flat ntuple files). And we have a single global EDM for everything, so changing the Header definition would create a schema difference between the new class and the old one in files. I am a bit afraid to go in that direction, it may create a mess. . I will still check if some clever ROOT schema evolution may help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11732
https://github.com/root-project/root/pull/11736:398,deployability,integr,integration,398,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:354,integrability,messag,message,354,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:398,integrability,integr,integration,398,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:456,integrability,sub,subtly,456,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:354,interoperability,messag,message,354,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:398,interoperability,integr,integration,398,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:398,modifiability,integr,integration,398,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:362,reliability,doe,doesn,362,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:398,reliability,integr,integration,398,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:530,reliability,doe,doesn,530,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:906,reliability,pra,practice,906,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:398,security,integr,integration,398,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:398,testability,integr,integration,398,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:953,usability,user,user,953,"Indeed, they were not virtual before 23d8612, but they were originally, see e.g. https://github.com/root-project/root/blob/73fd43959e45e0e9e1d2537b93615cb2a58b9c03/roofit/roofitcore/inc/RooDataHist.h#L161. They were changed in 2019 in the following commit: https://github.com/root-project/root/commit/155032e6b4de3e4a50434cfe0b9e9286bc048fa7. The commit message doesn't say why. At this point, the integration with RooFitExtensions may have already broken subtly. `RooExpandedDataHist::get_wgt` was still virtual (_edit: actually doesn't matter that it was virtual, I guess, it was just shadowing_), so from this point it would be shadowing `RooDataHist::get_wgt`: it would no longer be relegated to from inside `RooDataHist` as it would before 155032e, but would only be called from inside RooFitExtensions, leading to two different `get_wgt` calls. I'm not sure how much of a difference this has made in practice in the past three years, as I'm not a user of RooFitExtensions. Maybe @cburgard can say more (or find someone who knows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:263,deployability,version,versions,263,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:597,deployability,fail,failed,597,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:263,integrability,version,versions,263,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:263,modifiability,version,versions,263,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:597,reliability,fail,failed,597,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:514,safety,avoid,avoids,514,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:323,usability,user,users,323,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/pull/11736:330,usability,workflow,workflows,330,"Ok, after discussing this with @cburgard and others, we think we came up with a solution that leaves the ROOT side untouched for now, but deprecates the functionality that uses `get_wgt` on the RooFitExtensions side when using RooFitExtensions together with ROOT versions later than 6.18.x. This may break RooFitExtensions users' workflows (we unfortunately don't know who still uses the affected functionality), in which case we will have to revisit the suggestions made in this PR. But in any case this solution avoids the unacceptable situation of leaving things as they are which has silently failed for some years now. Hopefully, nobody misses the functionality in RooFitExtensions, so we can let this rest permanently :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11736
https://github.com/root-project/root/issues/11738:99,interoperability,distribut,distribution,99,See also the original forum post:. https://root-forum.cern.ch/t/root-v6-26-08-pullhist-shows-wrong-distribution/52417/4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11738
https://github.com/root-project/root/issues/11738:350,deployability,patch,patch,350,"Hi @ciccinocino, thanks for opening this issue! I realize know that this is a solved issue where the fix is already in `master`:. https://github.com/root-project/root/pull/11566. However, there is no backport to the 6.28 branch yet, but I created it now:. https://github.com/root-project/root/pull/11748. Sorry for the delay in this! Once a new 6.28 patch release is out, i.e. 6.26.12, this will be fixed again!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11738
https://github.com/root-project/root/issues/11738:356,deployability,releas,release,356,"Hi @ciccinocino, thanks for opening this issue! I realize know that this is a solved issue where the fix is already in `master`:. https://github.com/root-project/root/pull/11566. However, there is no backport to the 6.28 branch yet, but I created it now:. https://github.com/root-project/root/pull/11748. Sorry for the delay in this! Once a new 6.28 patch release is out, i.e. 6.26.12, this will be fixed again!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11738
https://github.com/root-project/root/issues/11738:350,safety,patch,patch,350,"Hi @ciccinocino, thanks for opening this issue! I realize know that this is a solved issue where the fix is already in `master`:. https://github.com/root-project/root/pull/11566. However, there is no backport to the 6.28 branch yet, but I created it now:. https://github.com/root-project/root/pull/11748. Sorry for the delay in this! Once a new 6.28 patch release is out, i.e. 6.26.12, this will be fixed again!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11738
https://github.com/root-project/root/issues/11738:350,security,patch,patch,350,"Hi @ciccinocino, thanks for opening this issue! I realize know that this is a solved issue where the fix is already in `master`:. https://github.com/root-project/root/pull/11566. However, there is no backport to the 6.28 branch yet, but I created it now:. https://github.com/root-project/root/pull/11748. Sorry for the delay in this! Once a new 6.28 patch release is out, i.e. 6.26.12, this will be fixed again!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11738
https://github.com/root-project/root/pull/11740:11,deployability,build,build,11,@phsft-bot build with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:11,deployability,build,build,11,@phsft-bot build with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:11,deployability,build,build,11,@phsft-bot build just on ROOT-debian10-i386/soversion with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:23,safety,test,test,23,Good to see these long test reports! I have opened an issue for the RooStats problem:. https://github.com/root-project/root/issues/11814,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:23,testability,test,test,23,Good to see these long test reports! I have opened an issue for the RooStats problem:. https://github.com/root-project/root/issues/11814,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:0,availability,Failur,Failure,0,Failure is unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:0,deployability,Fail,Failure,0,Failure is unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:0,performance,Failur,Failure,0,Failure is unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11740:0,reliability,Fail,Failure,0,Failure is unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11740
https://github.com/root-project/root/pull/11742:31,deployability,depend,dependencies,31,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:124,deployability,depend,dependencies,124,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:177,deployability,fail,failing,177,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:208,deployability,instal,installed,208,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:232,deployability,instal,installed,232,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:412,deployability,fail,fails,412,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:735,deployability,updat,updated,735,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:12,integrability,configur,configure,12,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:31,integrability,depend,dependencies,31,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:105,integrability,configur,configure,105,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:124,integrability,depend,dependencies,124,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:279,integrability,configur,configure,279,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:12,modifiability,configur,configure,12,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:31,modifiability,depend,dependencies,31,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:105,modifiability,configur,configure,105,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:124,modifiability,depend,dependencies,124,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:279,modifiability,configur,configure,279,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:332,performance,time,time,332,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:425,performance,content,content,425,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:438,performance,time,time,438,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:467,performance,time,time,467,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:493,performance,time,time,493,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:561,performance,time,time,561,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:579,performance,content,content,579,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:177,reliability,fail,failing,177,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:412,reliability,fail,fails,412,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:505,reliability,doe,does,505,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:31,safety,depend,dependencies,31,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:124,safety,depend,dependencies,124,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:152,safety,input,input,152,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:735,safety,updat,updated,735,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:12,security,configur,configure,12,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:105,security,configur,configure,105,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:279,security,configur,configure,279,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:735,security,updat,updated,735,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:31,testability,depend,dependencies,31,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:124,testability,depend,dependencies,124,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:152,usability,input,input,152,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:403,usability,behavi,behavior,403,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:473,usability,close,close,473,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:660,usability,behavi,behavior,660,"> where the configure/Makefile dependencies (e.g. autoconf) . I think you might have meant:. > where the configure/Makefile dependencies (e.g. autoconf input files) . As in the failing case `autoconf` is not installed and if it was installed and was causing the problem, having `configure/Makefile` appear older than the extraction time would only make thing worse, woudn't it. (i.e. the reason the new behavior fails is the content's is time stamp to some arbitrary time (close to extraction time) which does not respect (anymore) the internal ordering of the time stamp of the content. This sounds literally like a bug in `CMake`'s implementation of the new behavior (which is very desirable ... for the cases where the tar files is updated more than once per decades).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:7,deployability,log,log,7,"Commit log updated, with a link to the (already existing) bug report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:11,deployability,updat,updated,11,"Commit log updated, with a link to the (already existing) bug report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:7,safety,log,log,7,"Commit log updated, with a link to the (already existing) bug report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:11,safety,updat,updated,11,"Commit log updated, with a link to the (already existing) bug report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:7,security,log,log,7,"Commit log updated, with a link to the (already existing) bug report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:11,security,updat,updated,11,"Commit log updated, with a link to the (already existing) bug report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11742:7,testability,log,log,7,"Commit log updated, with a link to the (already existing) bug report.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11742
https://github.com/root-project/root/pull/11744:270,availability,sli,slightly,270,"@linev What issue lead you to work on this change? `TString::Format` and `Form` should be equally thread safe and the main difference is that `Form` does not support arguments that are creating using itself (i.e. indirectly or directly `Form(..., Form(...)...)`) but is slightly faster than `TString::Format`, so may still be the right choice for `TThread`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:61,interoperability,Format,Format,61,"@linev What issue lead you to work on this change? `TString::Format` and `Form` should be equally thread safe and the main difference is that `Form` does not support arguments that are creating using itself (i.e. indirectly or directly `Form(..., Form(...)...)`) but is slightly faster than `TString::Format`, so may still be the right choice for `TThread`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:301,interoperability,Format,Format,301,"@linev What issue lead you to work on this change? `TString::Format` and `Form` should be equally thread safe and the main difference is that `Form` does not support arguments that are creating using itself (i.e. indirectly or directly `Form(..., Form(...)...)`) but is slightly faster than `TString::Format`, so may still be the right choice for `TThread`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:149,reliability,doe,does,149,"@linev What issue lead you to work on this change? `TString::Format` and `Form` should be equally thread safe and the main difference is that `Form` does not support arguments that are creating using itself (i.e. indirectly or directly `Form(..., Form(...)...)`) but is slightly faster than `TString::Format`, so may still be the right choice for `TThread`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:270,reliability,sli,slightly,270,"@linev What issue lead you to work on this change? `TString::Format` and `Form` should be equally thread safe and the main difference is that `Form` does not support arguments that are creating using itself (i.e. indirectly or directly `Form(..., Form(...)...)`) but is slightly faster than `TString::Format`, so may still be the right choice for `TThread`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:105,safety,safe,safe,105,"@linev What issue lead you to work on this change? `TString::Format` and `Form` should be equally thread safe and the main difference is that `Form` does not support arguments that are creating using itself (i.e. indirectly or directly `Form(..., Form(...)...)`) but is slightly faster than `TString::Format`, so may still be the right choice for `TThread`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:158,usability,support,support,158,"@linev What issue lead you to work on this change? `TString::Format` and `Form` should be equally thread safe and the main difference is that `Form` does not support arguments that are creating using itself (i.e. indirectly or directly `Form(..., Form(...)...)`) but is slightly faster than `TString::Format`, so may still be the right choice for `TThread`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:126,integrability,buffer,buffer,126,"@pcanal . On several places I saw `gROOT->ProcessLine(Form(...))` commands. . In my mind, it is not good practice that global buffer used to execute interpreter code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:105,reliability,pra,practice,105,"@pcanal . On several places I saw `gROOT->ProcessLine(Form(...))` commands. . In my mind, it is not good practice that global buffer used to execute interpreter code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:66,usability,command,commands,66,"@pcanal . On several places I saw `gROOT->ProcessLine(Form(...))` commands. . In my mind, it is not good practice that global buffer used to execute interpreter code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:161,safety,input,input,161,"Right. Indeed, it is also a problem to pass the result of `Form` to a `ROOT` function that may also use `Form` internally and thus inadvertently replace its own input. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/pull/11744:161,usability,input,input,161,"Right. Indeed, it is also a problem to pass the result of `Form` to a `ROOT` function that may also use `Form` internally and thus inadvertently replace its own input. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11744
https://github.com/root-project/root/issues/11746:174,reliability,doe,does,174,"Hi, . That commit changed that behaviour on purpose, since there is no defined x and y value when the axis is alphanumeric. The bin centre corresponding to an arbitrary axes does not make sense. . What is your use case and why you need to have the histogram x and y statistics for the label case ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:31,usability,behavi,behaviour,31,"Hi, . That commit changed that behaviour on purpose, since there is no defined x and y value when the axis is alphanumeric. The bin centre corresponding to an arbitrary axes does not make sense. . What is your use case and why you need to have the histogram x and y statistics for the label case ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:247,deployability,updat,update,247,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:632,deployability,patch,patches,632,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:421,energy efficiency,Current,Currently,421,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:461,reliability,doe,doesn,461,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:247,safety,updat,update,247,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:632,safety,patch,patches,632,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:247,security,updat,update,247,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:632,security,patch,patches,632,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:673,usability,close,close,673,"I don't need the axis statistics, I just think that incrementing `fTsumwx2` twice in this function isn't correct. It might be that the code in the `if` rarely happens and that if they are calculated the value is meaningless, but since the code to update the weighted axis sums exists, I would assume it should be the same as in all the other `TH2::Fill` functions and increment `fTsum(w|w2|wx|wx2|wy|wy2|wxy)` once each. Currently, TH2::Fill with two bin names doesn't do that, instead it increments `fTsumwx2` twice. I'm sorry if I misunderstood the function, I just stumbled upon what seemed to be a typo when rebasing some other patches. If I'm wrong about this, please close the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:107,availability,error,error,107,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:78,deployability,updat,update,78,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:107,performance,error,error,107,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:78,safety,updat,update,78,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:107,safety,error,error,107,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:78,security,updat,update,78,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:5,testability,understand,understand,5,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11746:107,usability,error,error,107,"Ah I understand now, yes in the case the condition is true, `fTsumwxy` is not update. This is certainly an error, I will make a PR fixing this. Thank you for finding this out!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11746
https://github.com/root-project/root/issues/11750:10,testability,simpl,simply,10,Can't you simply use the `-Dbuiltin_xrootd=ON` option?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:10,usability,simpl,simply,10,Can't you simply use the `-Dbuiltin_xrootd=ON` option?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:134,deployability,version,version,134,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:134,integrability,version,version,134,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:117,interoperability,specif,specifying,117,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:208,interoperability,standard,standard,208,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:134,modifiability,version,version,134,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:64,reliability,doe,doesn,64,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:186,reliability,Doe,Does,186,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:72,usability,help,help,72,And I suppose adding the XROOTD you want in `CMAKE_PREFIX_PATH` doesn't help either? So should we introduce a way of specifying which version and/or which location XROOTD is taken from? Does XROOTD provide a standard way of finding it with CMake?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:149,deployability,version,version,149,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:280,deployability,version,version,280,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:412,deployability,build,build,412,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:449,deployability,instal,install,449,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:558,deployability,build,build,558,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:595,deployability,instal,install,595,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:149,integrability,version,version,149,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:280,integrability,version,version,280,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:149,modifiability,version,version,149,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/issues/11750:280,modifiability,version,version,280,"The problem is that `find_library` just looks in the system library location finds the library and makes ROOT link against it. So something like `if version < 5` around this `find_library` call would probably already solve the issue. I.e., from the opening post this finds xrootd version 5.3.1 from where we put it, but then just adds `/usr/lib64/libXrdClient.so` into the mix. ```. -- libraries: /data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdUtils.so;/usr/lib64/libXrdClient.so;/data/sftnight/build/workspace/lcg_release_pipeline/install/xrootd/5.3.1/aarch64-centos7-gcc8-opt/lib64/libXrdCl.so. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750
https://github.com/root-project/root/pull/11752:90,energy efficiency,green,green,90,"ROOT-performance-centos8-multicore/cxx17 ran out of disk space during roottest, otherwise green.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11752
https://github.com/root-project/root/pull/11752:5,performance,perform,performance-,5,"ROOT-performance-centos8-multicore/cxx17 ran out of disk space during roottest, otherwise green.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11752
https://github.com/root-project/root/pull/11752:52,performance,disk,disk,52,"ROOT-performance-centos8-multicore/cxx17 ran out of disk space during roottest, otherwise green.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11752
https://github.com/root-project/root/pull/11752:5,usability,perform,performance-,5,"ROOT-performance-centos8-multicore/cxx17 ran out of disk space during roottest, otherwise green.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11752
https://github.com/root-project/root/pull/11754:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11754
https://github.com/root-project/root/pull/11754:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11754
https://github.com/root-project/root/pull/11755:11,deployability,build,build,11,@phsft-bot build just on ROOT-performance-centos8-multicore/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:30,performance,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:30,usability,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:11,deployability,build,build,11,@phsft-bot build just on ROOT-performance-centos8-multicore.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:30,performance,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:30,usability,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:206,integrability,interfac,interface,206,Given e.g. the comment by Jonas:. > I will probably have more comments later when working on connecting this to the RooMinimizer. What do we gain from merging this into 6.28? Do we expect users of this new interface already for 6.28?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:206,interoperability,interfac,interface,206,Given e.g. the comment by Jonas:. > I will probably have more comments later when working on connecting this to the RooMinimizer. What do we gain from merging this into 6.28? Do we expect users of this new interface already for 6.28?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:206,modifiability,interfac,interface,206,Given e.g. the comment by Jonas:. > I will probably have more comments later when working on connecting this to the RooMinimizer. What do we gain from merging this into 6.28? Do we expect users of this new interface already for 6.28?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:188,usability,user,users,188,Given e.g. the comment by Jonas:. > I will probably have more comments later when working on connecting this to the RooMinimizer. What do we gain from merging this into 6.28? Do we expect users of this new interface already for 6.28?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:37,security,expos,expose,37,"I think we gain by having in 6.28 to expose this to the users. This will fix issues happening with fits using the `G` option (external gradient) and in addition, will give us more feedback on using an external Hessian computation. This will be certainly useful. . In addition, the PR, improves significantly the Minuit2/Fumili algorithm, especially for the case of binned likelihood fit. I think also this is worth having in 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:294,security,sign,significantly,294,"I think we gain by having in 6.28 to expose this to the users. This will fix issues happening with fits using the `G` option (external gradient) and in addition, will give us more feedback on using an external Hessian computation. This will be certainly useful. . In addition, the PR, improves significantly the Minuit2/Fumili algorithm, especially for the case of binned likelihood fit. I think also this is worth having in 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:56,usability,user,users,56,"I think we gain by having in 6.28 to expose this to the users. This will fix issues happening with fits using the `G` option (external gradient) and in addition, will give us more feedback on using an external Hessian computation. This will be certainly useful. . In addition, the PR, improves significantly the Minuit2/Fumili algorithm, especially for the case of binned likelihood fit. I think also this is worth having in 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11755:180,usability,feedback,feedback,180,"I think we gain by having in 6.28 to expose this to the users. This will fix issues happening with fits using the `G` option (external gradient) and in addition, will give us more feedback on using an external Hessian computation. This will be certainly useful. . In addition, the PR, improves significantly the Minuit2/Fumili algorithm, especially for the case of binned likelihood fit. I think also this is worth having in 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755
https://github.com/root-project/root/pull/11759:11,deployability,build,build,11,@phsft-bot build with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11759
https://github.com/root-project/root/pull/11759:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11759
https://github.com/root-project/root/pull/11759:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11759
https://github.com/root-project/root/issues/11760:4,testability,context,context,4,"For context, see https://root-forum.cern.ch/t/normalization-of-pdfs-with-rooformulavar/52485.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:319,deployability,manag,manage,319,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:375,deployability,version,version,375,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:831,deployability,scale,scaled,831,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:971,deployability,version,version,971,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:1306,deployability,releas,released,1306,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:319,energy efficiency,manag,manage,319,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:831,energy efficiency,scale,scaled,831,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:1358,energy efficiency,model,models,1358,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:375,integrability,version,version,375,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:695,integrability,event,events,695,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:971,integrability,version,version,971,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:375,modifiability,version,version,375,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:831,modifiability,scal,scaled,831,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:971,modifiability,version,version,971,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:831,performance,scale,scaled,831,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:946,reliability,doe,doesn,946,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:1508,reliability,Doe,Does,1508,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:319,safety,manag,manage,319,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:655,security,modif,modified,655,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:1358,security,model,models,1358,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:1445,testability,regress,regression,1445,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:558,usability,user,user-images,558,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:884,usability,support,support,884,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:994,usability,custom,custom,994,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:1136,usability,support,support,1136,"Hi! Thanks for opening the issue. I have first added the `priority-high` label because it appeared like a usecase that worked in 6.24 was broken in 6.26, but I don't this is the case. Yes, the normalization was not off in 6.24, but the fit gave nonsensical results anyway for different reasons also in 6.24. Or did you manage to make this shifted RooHistPdf work in any ROOT version? To me, the result of your script looks like this both in ROOT 6.24 and in ROOT `master` (upcoming 6.28, where the normalization issue got fixed by the way):. ![plot](https://user-images.githubusercontent.com/6578603/203787998-2652e495-f6b6-4d54-a2fc-64c66a96ac8a.png). I modified your script a bit to have more events in the toy dataset, and fixed the plotting order (you got to plot the data always the very first, otherwise the PDFs will not be scaled correctly). I think the best we can do now to support your usecase is this:. 1. Since shifting a RooHistPdf doesn't work in any ROOT version, I implement a custom PDF class that can do that which you can readily use. 2. For the upcoming ROOT 6.28, we will also make sure that the actual RooHistPdf support the shift. 3. About this issue with the normalization in 6.26, I'm not sure if it's worth it to address this since the problem is gone in ROOT 6.28 which will be released soon. Anyway, the problem only appears for models where the fit result was also wrong before for other reasons, so that temporary regression in 6.26 probably didn't break any existing usecase. Does that make sense to you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:236,interoperability,specif,specific,236,"Hi, thanks for your support. In Root 6.24 everything works well and looks exactly like the plot you attached. However if the problem is not there anymore in root 6.28 it is probably not worth to do anything about this as this is a very specific and small problem. As I also have a linux computer with root 6.24 it should not be too big a problem for me. But again, thank you very much for taking a look at my problem. Thanks,. Emil",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:20,usability,support,support,20,"Hi, thanks for your support. In Root 6.24 everything works well and looks exactly like the plot you attached. However if the problem is not there anymore in root 6.28 it is probably not worth to do anything about this as this is a very specific and small problem. As I also have a linux computer with root 6.24 it should not be too big a problem for me. But again, thank you very much for taking a look at my problem. Thanks,. Emil",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:277,energy efficiency,model,modeled,277,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:217,integrability,compon,component,217,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:217,interoperability,compon,component,217,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:217,modifiability,compon,component,217,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:22,reliability,doe,doesn,22,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:96,reliability,doe,does,96,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:349,safety,compl,completely,349,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:277,security,model,modeled,277,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:349,security,compl,completely,349,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:506,testability,understand,understand,506,"Okay! But actually it doesn't work also in 6.24 no? The plot that I attached shows that the fit does the wrong thing: instead of shifting the red template to match the data generated according to the black curve, the component normalizations are fitted such that the tails are modeled fine, but in the middle the fit represented by the blue line is completely off because no shift on the x-axis happened. So we still need to fix the problem with the shifted RooHistPdf before you can do your work, or do I understand something wrongly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:473,availability,error,error,473,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:42,modifiability,concern,concerning,42,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:143,modifiability,paramet,parameter,143,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:612,modifiability,concern,concern,612,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:403,performance,time,time,403,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:473,performance,error,error,473,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:557,reliability,doe,does,557,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:473,safety,error,error,473,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:42,testability,concern,concerning,42,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:612,testability,concern,concern,612,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:157,usability,close,close,157,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:334,usability,custom,custom,334,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:473,usability,error,error,473,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:624,usability,help,help,624,"It is true that the fit could work better concerning the shift. I think the shift is being fitted but the result is almost always the starting parameter (or close to that). But in my real work I have to fit line shaped that are obtained from histograms and are different for every fit I do, so I do not know if an implementation of a custom PDF class is worth the effort if the Line Shape changes every time. Therefore I will probably just determine the shifts by ""try and error"" until my fits are alright. My main problem was the wrong normalization which does not happen in root 6.24. Still thank you for your concern and help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:128,safety,test,test,128,"Okay great, thank you very much for clarifying your usecase! I'll close this issue then after I implemented your code as a unit test in ROOT such that the normalization is not allowed to break again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:123,testability,unit,unit,123,"Okay great, thank you very much for clarifying your usecase! I'll close this issue then after I implemented your code as a unit test in ROOT such that the normalization is not allowed to break again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:128,testability,test,test,128,"Okay great, thank you very much for clarifying your usecase! I'll close this issue then after I implemented your code as a unit test in ROOT such that the normalization is not allowed to break again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:66,usability,close,close,66,"Okay great, thank you very much for clarifying your usecase! I'll close this issue then after I implemented your code as a unit test in ROOT such that the normalization is not allowed to break again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:80,deployability,integr,integration,80,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:406,deployability,integr,integration,406,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:80,integrability,integr,integration,80,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:112,integrability,Batch,BatchMode,112,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:290,integrability,Batch,BatchMode,290,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:368,integrability,Batch,BatchMode,368,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:406,integrability,integr,integration,406,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:51,interoperability,specif,specifically,51,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:80,interoperability,integr,integration,80,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:406,interoperability,integr,integration,406,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:80,modifiability,integr,integration,80,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:406,modifiability,integr,integration,406,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:112,performance,Batch,BatchMode,112,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:290,performance,Batch,BatchMode,290,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:368,performance,Batch,BatchMode,368,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:80,reliability,integr,integration,80,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:406,reliability,integr,integration,406,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:80,security,integr,integration,80,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:406,security,integr,integration,406,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:80,testability,integr,integration,80,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/issues/11760:406,testability,integr,integration,406,"I finally figured out what the problem was in 6.26 specifically. In the numeric integration of the PDF, the new BatchMode was used, but it still had some bugs in ROOT 6.26. That's why we didn't see the problem in 6.24. And in ROOT master, we also didn't see it because the problem with the BatchMode got fixed. To fix the problem also in 6.26, I opened a PR where the BatchMode is disabled for the numeric integration of the PDF:. https://github.com/root-project/root/pull/11961",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11760
https://github.com/root-project/root/pull/11764:65,security,modif,modifies,65,> And you cannot use the range dyncast facility because the loop modifies the collection? I did not want to stop the loop at the first unexpected element (by rather skip them) and wanted to minimize the amount of change in this deprecated code.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11764
https://github.com/root-project/root/pull/11764:108,usability,stop,stop,108,> And you cannot use the range dyncast facility because the loop modifies the collection? I did not want to stop the loop at the first unexpected element (by rather skip them) and wanted to minimize the amount of change in this deprecated code.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11764
https://github.com/root-project/root/pull/11764:190,usability,minim,minimize,190,> And you cannot use the range dyncast facility because the loop modifies the collection? I did not want to stop the loop at the first unexpected element (by rather skip them) and wanted to minimize the amount of change in this deprecated code.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11764
https://github.com/root-project/root/issues/11765:15,availability,error,error,15,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:172,availability,error,error,172,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:222,availability,error,errors,222,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:95,deployability,build,build,95,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:21,integrability,messag,message,21,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:21,interoperability,messag,message,21,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:15,performance,error,error,15,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:172,performance,error,error,172,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:222,performance,error,errors,222,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:15,safety,error,error,15,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:172,safety,error,error,172,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:222,safety,error,errors,222,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:15,usability,error,error,15,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:172,usability,error,error,172,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:222,usability,error,errors,222,"Looking at the error message, it seems `FWCoreFramework` has not been built yet when trying to build `CalibTrackerRecords`. Do you know why that is, has there been another error? This *may* propagate to weird redefinition errors...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:158,deployability,upgrad,upgrade,158,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:234,deployability,modul,modules,234,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:302,deployability,continu,continue,302,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:277,interoperability,standard,standards,277,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:158,modifiability,upgrad,upgrade,158,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:234,modifiability,modul,modules,234,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:234,safety,modul,modules,234,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:292,usability,prefer,prefer,292,Hi @aandvalenzuela! Generally we track such issues in cmssw as that's not really a problem with ROOT. I will have a look but generally we wait for the llvm13 upgrade to land (#10294) as it will bring many improvements with respect to modules especially for newer C++ codes and standards. I'd prefer to continue keeping track of https://github.com/cms-sw/cmsdist/issues/8197 where it is.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11765:59,usability,close,close,59,"Hi @vgvassilev,. Sure, sorry for the inconvenience. Let me close this issue then. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11765
https://github.com/root-project/root/issues/11769:34,availability,error,error,34,#12137 Makes this setup a visible error pending the actual implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11769:34,performance,error,error,34,#12137 Makes this setup a visible error pending the actual implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11769:34,safety,error,error,34,#12137 Makes this setup a visible error pending the actual implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11769:34,usability,error,error,34,#12137 Makes this setup a visible error pending the actual implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11769:8,availability,error,error,8,As this error is now unsilenced in 6.28 we can at least remove the blocker.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11769:8,performance,error,error,8,As this error is now unsilenced in 6.28 we can at least remove the blocker.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11769:8,safety,error,error,8,As this error is now unsilenced in 6.28 we can at least remove the blocker.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11769:8,usability,error,error,8,As this error is now unsilenced in 6.28 we can at least remove the blocker.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11769
https://github.com/root-project/root/issues/11770:140,deployability,stack,stackoverflow,140,"Detecting if a debugger is attached isn't very straightforward unless on Windows. I can add something similar to the solution here: https://stackoverflow.com/questions/3596781/how-to-detect-if-the-current-process-is-being-run-by-gdb, but not sure if that's ideal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:197,energy efficiency,current,current-process-is-being-run-by-gdb,197,"Detecting if a debugger is attached isn't very straightforward unless on Windows. I can add something similar to the solution here: https://stackoverflow.com/questions/3596781/how-to-detect-if-the-current-process-is-being-run-by-gdb, but not sure if that's ideal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:0,safety,Detect,Detecting,0,"Detecting if a debugger is attached isn't very straightforward unless on Windows. I can add something similar to the solution here: https://stackoverflow.com/questions/3596781/how-to-detect-if-the-current-process-is-being-run-by-gdb, but not sure if that's ideal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:183,safety,detect,detect-if-the-current-process-is-being-run-by-gdb,183,"Detecting if a debugger is attached isn't very straightforward unless on Windows. I can add something similar to the solution here: https://stackoverflow.com/questions/3596781/how-to-detect-if-the-current-process-is-being-run-by-gdb, but not sure if that's ideal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:0,security,Detect,Detecting,0,"Detecting if a debugger is attached isn't very straightforward unless on Windows. I can add something similar to the solution here: https://stackoverflow.com/questions/3596781/how-to-detect-if-the-current-process-is-being-run-by-gdb, but not sure if that's ideal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:183,security,detect,detect-if-the-current-process-is-being-run-by-gdb,183,"Detecting if a debugger is attached isn't very straightforward unless on Windows. I can add something similar to the solution here: https://stackoverflow.com/questions/3596781/how-to-detect-if-the-current-process-is-being-run-by-gdb, but not sure if that's ideal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:72,deployability,depend,dependent,72,"As @devajithvs says, not easy to implement on linux/mac for reasons not dependent on us.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:72,integrability,depend,dependent,72,"As @devajithvs says, not easy to implement on linux/mac for reasons not dependent on us.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:72,modifiability,depend,dependent,72,"As @devajithvs says, not easy to implement on linux/mac for reasons not dependent on us.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:72,safety,depend,dependent,72,"As @devajithvs says, not easy to implement on linux/mac for reasons not dependent on us.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/issues/11770:72,testability,depend,dependent,72,"As @devajithvs says, not easy to implement on linux/mac for reasons not dependent on us.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11770
https://github.com/root-project/root/pull/11773:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:29,deployability,updat,updating,29,"Hi @grimmmyshini, thanks for updating the PR! Before we can run the CI again, you got to resolve the conflicts though. Can you please rebase your branch on top of the current ROOT master and force-push again? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:167,energy efficiency,current,current,167,"Hi @grimmmyshini, thanks for updating the PR! Before we can run the CI again, you got to resolve the conflicts though. Can you please rebase your branch on top of the current ROOT master and force-push again? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:101,interoperability,conflict,conflicts,101,"Hi @grimmmyshini, thanks for updating the PR! Before we can run the CI again, you got to resolve the conflicts though. Can you please rebase your branch on top of the current ROOT master and force-push again? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:29,safety,updat,updating,29,"Hi @grimmmyshini, thanks for updating the PR! Before we can run the CI again, you got to resolve the conflicts though. Can you please rebase your branch on top of the current ROOT master and force-push again? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:29,security,updat,updating,29,"Hi @grimmmyshini, thanks for updating the PR! Before we can run the CI again, you got to resolve the conflicts though. Can you please rebase your branch on top of the current ROOT master and force-push again? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:11,deployability,build,build,11,@phsft-bot build! cc: @Axel-Naumann can we add Garima in the list?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:35,deployability,updat,updating,35,"Hi Garima, thank you very much for updating the PR and fixing all the warnings! This will not be a short review as it's a fundamental change, so I will address things step by step, starting with the less RooFit-specific things but more for the JIT and clad side, to maximally benefit for your expertise :+1:. I'll address the items in separate comments even if it's not an inline comment, so you can mark them as outdated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:211,interoperability,specif,specific,211,"Hi Garima, thank you very much for updating the PR and fixing all the warnings! This will not be a short review as it's a fundamental change, so I will address things step by step, starting with the less RooFit-specific things but more for the JIT and clad side, to maximally benefit for your expertise :+1:. I'll address the items in separate comments even if it's not an inline comment, so you can mark them as outdated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:35,safety,updat,updating,35,"Hi Garima, thank you very much for updating the PR and fixing all the warnings! This will not be a short review as it's a fundamental change, so I will address things step by step, starting with the less RooFit-specific things but more for the JIT and clad side, to maximally benefit for your expertise :+1:. I'll address the items in separate comments even if it's not an inline comment, so you can mark them as outdated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:105,safety,review,review,105,"Hi Garima, thank you very much for updating the PR and fixing all the warnings! This will not be a short review as it's a fundamental change, so I will address things step by step, starting with the less RooFit-specific things but more for the JIT and clad side, to maximally benefit for your expertise :+1:. I'll address the items in separate comments even if it's not an inline comment, so you can mark them as outdated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:35,security,updat,updating,35,"Hi Garima, thank you very much for updating the PR and fixing all the warnings! This will not be a short review as it's a fundamental change, so I will address things step by step, starting with the less RooFit-specific things but more for the JIT and clad side, to maximally benefit for your expertise :+1:. I'll address the items in separate comments even if it's not an inline comment, so you can mark them as outdated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:105,testability,review,review,105,"Hi Garima, thank you very much for updating the PR and fixing all the warnings! This will not be a short review as it's a fundamental change, so I will address things step by step, starting with the less RooFit-specific things but more for the JIT and clad side, to maximally benefit for your expertise :+1:. I'll address the items in separate comments even if it's not an inline comment, so you can mark them as outdated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:361,availability,error,errors,361,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:394,availability,error,error,394,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:558,availability,error,error,558,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1205,availability,ERROR,ERROR,1205,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1227,integrability,Translat,Translated,1227,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1227,interoperability,Translat,Translated,1227,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:361,performance,error,errors,361,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:394,performance,error,error,394,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:558,performance,error,error,558,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1205,performance,ERROR,ERROR,1205,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1339,performance,time,times,1339,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:361,safety,error,errors,361,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:394,safety,error,error,394,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:558,safety,error,error,558,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1205,safety,ERROR,ERROR,1205,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:361,usability,error,errors,361,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:394,usability,error,error,394,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:558,usability,error,error,558,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1205,usability,ERROR,ERROR,1205,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1211,usability,Minim,Minimization,1211,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:1366,usability,support,support,1366,"I was running the [basic RooFit tutorial with a Gaussian fit](https://root.cern.ch/doc/master/rf101__basics_8C.html), using your code squashing. Meaning I changed the call to `fitTo` with:. ```c++. gauss.fitTo(*data, CodeSquashing(true));. ```. It works, which is really nice! But to be sure it's stable, I called it twice in a row. But then I get redefinition errors:. ```. input_line_54:1:8: error: redefinition of 'func'. double func(double* in) {. ^. input_line_31:1:8: note: previous definition is here. double func(double* in) {. ^. input_line_54:4:8: error: redefinition of '_weight'. double _weight[25]{ 0.000000, 0.000000, 0.000000, 2.000000, 0.000000, 2.000000, 6.000000, 3.000000, 5.000000, 7.000000, 5.000000, 10.000000, 8.000000, 18.000000, 10.000000, 12.000000, 3.000000, 2.000000, 2.000000, 3.000000, 1.000000, 1.000000, 0.000000, 0.000000, 0.000000};. ^. input_line_54:3:8: note: previous definition is here. double _weight[25]{ 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000};. ^. [#3] ERROR:Minimization -- Translated code for AD could not be compiled. See above for details. ```. But in general, you call `fitTo` many times in a script. Can you support this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:298,integrability,wrap,wrapper,298,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:298,interoperability,wrapper,wrapper,298,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:70,performance,time,times,70,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:116,performance,memor,memory,116,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:179,performance,time,time,179,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:187,performance,memor,memory,187,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:214,performance,time,times,214,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:116,usability,memor,memory,116,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:187,usability,memor,memory,187,"Related to the previous comment. Since people often call `fitTo` many times in a row, are we sure that there is no ""memory leak""? I guess these compiled functions take quite some time in memory if you do a fit 100 times. Can you clean up all the stuff that you declared to the interpreter when the wrapper gets out of scope?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:203,availability,slo,slow,203,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:31,deployability,observ,observables,31,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:314,deployability,observ,observables,314,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:420,deployability,observ,observable,420,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:150,integrability,event,events,150,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:252,integrability,event,events,252,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:511,integrability,wrap,wrapper,511,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:511,interoperability,wrapper,wrapper,511,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:193,performance,time,time,193,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:203,reliability,slo,slow,203,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:25,safety,input,input,25,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:340,safety,input,input,340,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:47,security,hardcod,hardcoded,47,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:31,testability,observ,observables,31,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:314,testability,observ,observables,314,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:420,testability,observ,observable,420,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:25,usability,input,input,25,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:340,usability,input,input,340,"I see that the arrays of input observables get hardcoded into the generated the function. This is not acceptable, because often you have thousands of events, which I tried out too. The `fitTo` time gets slow very quicky when you increase the number of events. I think the effort of generating a function where the observables are passed as input arrays instead would really pay off. You already know how to retrieve the observable values via `RooAbsData::getBatches`. Is it possible to save these arrays in the wrapper and then pass them to the generated function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:66,interoperability,platform,platforms,66,"From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:216,interoperability,specif,specifics,216,"From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:42,reliability,doe,does,42,"From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:155,testability,understand,understand,155,"From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:307,usability,help,help,307,"From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:184,deployability,Releas,ReleaseNotes,184,"Since you are contributing to ROOT starting with this PR, can you please also add a commit where you add you name to this file? https://github.com/root-project/root/blob/master/README/ReleaseNotes/v628/index.md",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:326,deployability,contain,contain,326,"Thanks for adding this first commit where you mode the header files from `res` to `src`! Since the PR touched many files only because of that commit, we risk getting into conflicts again just because of this change. Can you please open a separate PR just with the first commit? Then I can merge it ASAP, and this PR will only contain the remaining commits after the first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:171,interoperability,conflict,conflicts,171,"Thanks for adding this first commit where you mode the header files from `res` to `src`! Since the PR touched many files only because of that commit, we risk getting into conflicts again just because of this change. Can you please open a separate PR just with the first commit? Then I can merge it ASAP, and this PR will only contain the remaining commits after the first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:153,safety,risk,risk,153,"Thanks for adding this first commit where you mode the header files from `res` to `src`! Since the PR touched many files only because of that commit, we risk getting into conflicts again just because of this change. Can you please open a separate PR just with the first commit? Then I can merge it ASAP, and this PR will only contain the remaining commits after the first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:153,security,risk,risk,153,"Thanks for adding this first commit where you mode the header files from `res` to `src`! Since the PR touched many files only because of that commit, we risk getting into conflicts again just because of this change. Can you please open a separate PR just with the first commit? Then I can merge it ASAP, and this PR will only contain the remaining commits after the first.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:358,availability,error,error,358,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:68,interoperability,platform,platforms,68,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:218,interoperability,specif,specifics,218,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:358,performance,error,error,358,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:44,reliability,doe,does,44,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:358,safety,error,error,358,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:404,safety,test,test,404,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:157,testability,understand,understand,157,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:404,testability,test,test,404,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:309,usability,help,help,309,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:358,usability,error,error,358,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:430,usability,hint,hint,430,"> From the CI, it seems the code generation does not work on 32 bit platforms like `windows10` and `debian10-i386`. Why is that? I think it would be good to understand this, and I don't think this is related to RooFit specifics. Maybe some overflows in the generated code on 32 bit? Maybe we can also use the help of @vgvassilev here. Is there a compilation error? If not then we can run valgrind on the test case and maybe get a hint of what goes wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:31,availability,error,error,31,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:31,performance,error,error,31,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:31,safety,error,error,31,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:305,safety,test,test,305,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:420,safety,input,inputs,420,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:305,testability,test,test,305,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:31,usability,error,error,31,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:285,usability,help,helpful,285,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/pull/11773:420,usability,input,inputs,420,"I don't know where exactly the error is. All we see for example [here](https://github.com/root-project/root/pull/11773#issuecomment-1343515182) is that the NLL returned by the generated code is `-inf` instead of the expected value. As I also told Garima on other channels, it could be helpful to make the test more verbose to see from the CI response what is going on (e.g. printing the generated code, and printing the inputs when you call it).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11773
https://github.com/root-project/root/issues/11781:595,deployability,Build,BuildCache,595,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:908,deployability,Build,Building,908,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1346,deployability,Fail,Failed,1346,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1145,energy efficiency,model,modeler,1145,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:917,performance,cach,cache,917,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1346,reliability,Fail,Failed,1346,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:170,safety,detect,detectors,170,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:186,safety,test,testcase,186,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:170,security,detect,detectors,170,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1145,security,model,modeler,1145,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:186,testability,test,testcase,186,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:0,usability,Confirm,Confirmed,0,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:789,usability,Close,CloseGeometry,789,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:892,usability,Close,CloseGeometry,892,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1019,usability,Close,CloseGeometry,1019,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1053,usability,UI,UID,1053,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1113,usability,Close,CloseGeometry,1113,"Confirmed that this occurs on `master` (though the top node is a nullptr when using the previous separate constructor and Import):. ```. 12:24:51 wdconinc@menelaos ~/EIC/detectors/epic (testcase *$%=) $ root -l. root [0] auto* geo = TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Info in <TGeoManager::SetTopVolume>: Top volume is worldVOL. Master volume is worldVOL. Info in <TGeoNavigator::BuildCache>: --- Maximum geometry depth set to 100. Info in <TGeoManager::CheckGeometry>: Fixing runtime shapes... Info in <TGeoManager::CheckGeometry>: ...Nothing to fix. Info in <TGeoManager::CloseGeometry>: Counting nodes... Info in <TGeoManager::Voxelize>: Voxelizing... Info in <TGeoManager::CloseGeometry>: Building cache... Info in <TGeoManager::CountLevels>: max level = 1, max placements = 2. Info in <TGeoManager::CloseGeometry>: 3 nodes/ 2 volume UID's in Geometry imported from GDML. Info in <TGeoManager::CloseGeometry>: ----------------modeler ready----------------. (TGeoManager *) 0x56439e0ddb00. root [1] geo->CheckOverlaps(). Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.1. warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. root [2] geo->PrintOverlaps(). === Overlaps for Default ===. = Overlap ov00000: worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 overlapping worldVOL/PV-LV_HCAL_Chimney_Sector_Half_Plate__Meshed_1 ovlp=7.60311. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:109,deployability,Fail,Failed,109,"This overlap is flagged for both mesh and sampling methods. ```. root [1] geo->CheckGeometryFull(). warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. ====================================================================. STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ===",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:301,deployability,STAGE,STAGE,301,"This overlap is flagged for both mesh and sampling methods. ```. root [1] geo->CheckGeometryFull(). warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. ====================================================================. STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ===",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1061,deployability,STAGE,STAGE,1061," root [1] geo->CheckGeometryFull(). warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. ====================================================================. STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ===================================================================",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1496,deployability,STAGE,STAGE,1496,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1930,deployability,STAGE,STAGE,1930,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:2255,deployability,STAGE,STAGE,2255,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1728,performance,Time,Time,1728,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1777,performance,Time,Time,1777,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1959,performance,time,time,1959,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:2067,performance,Time,Time,2067,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:2140,performance,Time,Time,2140,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:109,reliability,Fail,Failed,109,"This overlap is flagged for both mesh and sampling methods. ```. root [1] geo->CheckGeometryFull(). warning: Failed to call `P020_REveGeoPainter()` to execute the macro. Add this function or rename the macro. Falling back to `.L`. ====================================================================. STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ===",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1984,safety,safe,safety,1984,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:2263,safety,compl,completed,2263,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:2263,security,compl,completed,2263,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1948,usability,navigat,navigation,1948,"STAGE 1: Overlap checking by sampling within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps by sampling <s> for worldVOL and daughters. Info in <TGeoNodeMatrix::CheckOverlaps>: === NOTE: Extrusions NOT checked with sampling option ! ===. Info in <TGeoChecker::CheckOverlapsBySampling>: #Found 1 overlaps adding-up to 443214 +/- 52974.2 [cm3] for daughters of worldVOL. Check overlaps: [==========] 3 [100.00 %]. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 2: Global overlap/extrusion checking within 10 microns. ====================================================================. Info in <TGeoNodeMatrix::CheckOverlaps>: Checking overlaps for worldVOL and daughters within 0.001. Check overlaps: [==========] 3 [100.00 %] 00:00. Info in <TGeoNodeMatrix::CheckOverlaps>: Number of illegal overlaps/extrusions : 1. ====================================================================. STAGE 3: Propagating 1000000 tracks starting from vertex. and counting number of boundary crossings... ====================================================================. Transporting tracks [==========] 1000000 [100.00 %] 00:01. Time for crossing 10673 boundaries: 990000 [ms]. Time per track for full geometry traversal: 0.99 [ms], per crossing: 92.7574 [ms]. ====================================================================. STAGE 4: How much navigation time per volume per next+safety call. ====================================================================. Time for volume worldVOL (assemb=0): 0.72 [ms] ndaughters=2 ncross=4956. Time for volume LV_HCAL_Chimney_Sector_Half_Plate__Meshed_0 (shape=Mesh2Tess): 0.34 [ms] ndaughters=0 ncross=5717. STAGE 4 completed [======| ] 2 [ 66.67 %]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:564,integrability,schema,schema,564,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:636,interoperability,specif,specifies,636,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:966,safety,compl,complexType,966,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1004,safety,compl,complexContent,1004,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1230,safety,compl,complexContent,1230,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1252,safety,compl,complexType,1252,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:226,security,rotat,rotation,226,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:507,security,rotat,rotations,507,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:754,security,rotat,rotation,754,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:770,security,rotat,rotationType,770,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:837,security,rotat,rotation,837,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:966,security,compl,complexType,966,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:984,security,rotat,rotationType,984,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1004,security,compl,complexContent,1004,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1043,security,Ident,IdentifiableQuantityVectorType,1043,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1230,security,compl,complexContent,1230,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1252,security,compl,complexType,1252,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:206,testability,unit,unit,206,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:492,testability,unit,unit,492,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:658,testability,unit,unit,658,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:855,testability,unit,unit,855,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:1131,testability,unit,unit,1131,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:86,usability,user,user-images,86,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:308,usability,user,user-images,308,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:676,usability,document,documentation,676,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:807,usability,document,documentation,807,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:871,usability,document,documentation,871,"Here is how ROOT reads the geometry (how Geant4 reads it is above):. ![image](https://user-images.githubusercontent.com/4656391/204106765-c0eeee10-d707-434d-9c6c-31682c7c3807.png). When adding an explicit `unit=""rad""` to the `rotation` definitions, we get the following (without overlaps):. ![image](https://user-images.githubusercontent.com/4656391/204106794-87e80ee5-abae-474b-a1bc-5f254e73666e.png). This seems to be attributable to a different assumption on the default value of for the `unit` field in rotations: geant4 follows the default value in the [gdml schema](https://gdml.web.cern.ch/GDML/gdmlschema.html) which explicitly specifies the default unit, both in the documentation:. ```xsd. <xs:element maxOccurs=""unbounded"" minOccurs=""0"" name=""rotation"" type=""rotationType"">. <xs:annotation>. <xs:documentation>Named cartesian rotation, default unit radian</xs:documentation>. </xs:annotation>. </xs:element>. ```. and in the type definition:. ```xsd. <xs:complexType name=""rotationType"">. <xs:complexContent>. <xs:restriction base=""IdentifiableQuantityVectorType"">. <xs:attribute default=""radian"" type=""xs:string"" name=""unit""/>. <xs:attribute default=""cartesian"" type=""xs:string"" name=""type""/>. </xs:restriction>. </xs:complexContent>. </xs:complexType>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:106,interoperability,compatib,compatibility,106,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:356,performance,Lock,LockDefaultUnits,356,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:450,performance,Lock,LockDefaultUnits,450,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:356,security,Lock,LockDefaultUnits,356,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:450,security,Lock,LockDefaultUnits,450,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:54,testability,unit,units,54,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:211,testability,unit,units,211,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:274,testability,unit,units,274,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:21,usability,support,supports,21,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:123,usability,prefer,prefer,123,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:148,usability,behavi,behavior,148,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:242,usability,prefer,preferred,242,"This is because TGeo supports two internal systems of units, the default being the ROOT one. For backward compatibility, I prefer not changing this behavior. There are two possible solutions:. 1. Using explicit units in the GDML description (preferred). 2. Using G4 default units by calling the sequence (before creating any materials):. ```. TGeoManager::LockDefaultUnits(kFALSE);. TGeoManager::SetDefaultUnits(TGeoManager::kG4Units);. TGeoManager::LockDefaultUnits(kTRUE);. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:28,interoperability,compatib,compatibility,28,I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:170,interoperability,specif,specified,170,I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:2,testability,understand,understand,2,I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:120,testability,unit,unit,120,I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:151,testability,unit,unit,151,I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:289,deployability,log,log,289,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:357,deployability,contain,contains,357,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:30,interoperability,compatib,compatibility,30,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:172,interoperability,specif,specified,172,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:289,safety,log,log,289,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:289,security,log,log,289,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:4,testability,understand,understand,4,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:122,testability,unit,unit,122,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:153,testability,unit,unit,153,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:216,testability,unit,unit-unaware,216,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:289,testability,log,log,289,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:366,testability,unit,unitless,366,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:430,usability,behavi,behavior,430,"> I understand that backwards compatibility is a strong factor. Would it be possible to print a warning when the internal unit system is assumed when no unit is explicitly specified? The difficulty is that the large unit-unaware GDML files may generate tons of such warnings, bloating the log files. Also, printing just a general warning once that the file contains unitless entities may pass unnoticed. What would you expect the behavior to be?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:266,integrability,schema,schema,266,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:141,interoperability,specif,specified,141,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:174,interoperability,standard,standard,174,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:385,security,auth,author,385,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:48,testability,unit,unitless,48,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:80,testability,unit,unitless,80,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:313,testability,unit,units,313,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:367,testability,unit,units,367,"I don't think it should print a warning for all unitless entities, but for each unitless entity where the default in ROOT differs from those specified explicitly in the GDML standard (which are mm and radians). As it is, the GDML is parsed incorrectly according the schema it is written in when using the default units in ROOT. Putting the burden for adding explicit units on the GDML author is perfectly fine, but they can only become aware of this through a warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:74,integrability,translat,translations,74,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:165,integrability,messag,message,165,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:260,integrability,transform,transformations,260,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:74,interoperability,translat,translations,74,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:165,interoperability,messag,message,165,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:260,interoperability,transform,transformations,260,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:64,security,rotat,rotations,64,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:55,testability,unit,unitless,55,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:209,usability,user,user,209,"Sure, I agree with this, but there may be thousands of unitless rotations/translations in a GDML file, do you expect each one to issue a warning, or to just get the message at the first encounter, telling the user in case of using cm/deg defaults to check all transformations, or use G4 defaults?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:14,energy efficiency,load,loading,14,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:420,energy efficiency,current,currently,420,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:513,integrability,schema,schema,513,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:14,performance,load,loading,14,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:776,safety,test,tests,776,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:385,testability,unit,units,385,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:410,testability,unit,units,410,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:435,testability,unit,units,435,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:565,testability,unit,units,565,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:776,testability,test,tests,776,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/issues/11781:478,usability,behavi,behaviour,478,"@wdconinc now loading this file produces:. ```. root [0] TGeoManager::Import(""HCAL_Chimney_Sector_Half_Plate.gdml""). Info in <TGeoManager::Import>: Reading geometry from file: HCAL_Chimney_Sector_Half_Plate.gdml. Info in <TGeoManager::TGeoManager>: Geometry GDMLImport, Geometry imported from GDML created. Warning in <TGDMLParse::GDMLReadFile>: Found 2 GDML entities missing explicit units, while the default units are currently ROOT units [cm, deg]. This can cause unexpected behaviour with respect to the GDML schema. To remove this warning, either use explicit units or call the static method TGeoManager::SetDefaultUnits(kG4Units) before importing the GDML file HCAL_Chimney_Sector_Half_Plate.gdml . ... ```. Let me know if OK with you or if you want to do further local tests with #11801",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11781
https://github.com/root-project/root/pull/11782:89,testability,simpl,simpler,89,"> Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) . You're right, thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782
https://github.com/root-project/root/pull/11782:89,usability,simpl,simpler,89,"> Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) . You're right, thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782
https://github.com/root-project/root/pull/11782:91,testability,simpl,simpler,91,"> > Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) slightly_smiling_face. > . > You're right, thanks! Can we squash the changes in a single commit on merge? Many thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782
https://github.com/root-project/root/pull/11782:91,usability,simpl,simpler,91,"> > Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) slightly_smiling_face. > . > You're right, thanks! Can we squash the changes in a single commit on merge? Many thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782
https://github.com/root-project/root/pull/11782:93,testability,simpl,simpler,93,"> > > Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) slightly_smiling_face. > > . > > . > > You're right, thanks! > . > Can we squash the changes in a single commit on merge? Many thanks! Indeed!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782
https://github.com/root-project/root/pull/11782:93,usability,simpl,simpler,93,"> > > Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) slightly_smiling_face. > > . > > . > > You're right, thanks! > . > Can we squash the changes in a single commit on merge? Many thanks! Indeed!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782
https://github.com/root-project/root/issues/11784:134,integrability,wrap,wrapper,134,"Hi, this happens because the overlap checking in TGeo relies on navigation functionality for shapes and TGeoTesselated is just a mesh wrapper that does not provide navigation, so it wrongly used its bounding box functionality. Geometries with tessellations should only be used for conversions/visualization. I am providing a protection as PR for skipping overlap checks if a partner is a tessellation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11784
https://github.com/root-project/root/issues/11784:134,interoperability,wrapper,wrapper,134,"Hi, this happens because the overlap checking in TGeo relies on navigation functionality for shapes and TGeoTesselated is just a mesh wrapper that does not provide navigation, so it wrongly used its bounding box functionality. Geometries with tessellations should only be used for conversions/visualization. I am providing a protection as PR for skipping overlap checks if a partner is a tessellation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11784
https://github.com/root-project/root/issues/11784:281,interoperability,convers,conversions,281,"Hi, this happens because the overlap checking in TGeo relies on navigation functionality for shapes and TGeoTesselated is just a mesh wrapper that does not provide navigation, so it wrongly used its bounding box functionality. Geometries with tessellations should only be used for conversions/visualization. I am providing a protection as PR for skipping overlap checks if a partner is a tessellation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11784
https://github.com/root-project/root/issues/11784:147,reliability,doe,does,147,"Hi, this happens because the overlap checking in TGeo relies on navigation functionality for shapes and TGeoTesselated is just a mesh wrapper that does not provide navigation, so it wrongly used its bounding box functionality. Geometries with tessellations should only be used for conversions/visualization. I am providing a protection as PR for skipping overlap checks if a partner is a tessellation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11784
https://github.com/root-project/root/issues/11784:64,usability,navigat,navigation,64,"Hi, this happens because the overlap checking in TGeo relies on navigation functionality for shapes and TGeoTesselated is just a mesh wrapper that does not provide navigation, so it wrongly used its bounding box functionality. Geometries with tessellations should only be used for conversions/visualization. I am providing a protection as PR for skipping overlap checks if a partner is a tessellation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11784
https://github.com/root-project/root/issues/11784:164,usability,navigat,navigation,164,"Hi, this happens because the overlap checking in TGeo relies on navigation functionality for shapes and TGeoTesselated is just a mesh wrapper that does not provide navigation, so it wrongly used its bounding box functionality. Geometries with tessellations should only be used for conversions/visualization. I am providing a protection as PR for skipping overlap checks if a partner is a tessellation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11784
https://github.com/root-project/root/issues/11784:293,usability,visual,visualization,293,"Hi, this happens because the overlap checking in TGeo relies on navigation functionality for shapes and TGeoTesselated is just a mesh wrapper that does not provide navigation, so it wrongly used its bounding box functionality. Geometries with tessellations should only be used for conversions/visualization. I am providing a protection as PR for skipping overlap checks if a partner is a tessellation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11784
https://github.com/root-project/root/issues/11787:42,safety,test,tested,42,"FYI, ROOT on Windows arm64 has never been tested. I'll keep this issue open until we have an arm64 machine...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:42,testability,test,tested,42,"FYI, ROOT on Windows arm64 has never been tested. I'll keep this issue open until we have an arm64 machine...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:114,availability,error,errors,114,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:180,availability,error,error,180,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:449,availability,error,error,449,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1564,availability,error,error,1564,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:30,deployability,build,build,30,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:94,deployability,fail,failed,94,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:345,deployability,build,build,345,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:571,deployability,build,build,571,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:660,deployability,Build,Build,660,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1079,deployability,instal,install,1079,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1258,deployability,Configurat,Configuration,1258,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1272,deployability,Releas,Release,1272,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1537,deployability,build,build,1537,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1258,integrability,Configur,Configuration,1258,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1238,interoperability,Platform,Platform,1238,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1258,modifiability,Configur,Configuration,1258,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:114,performance,error,errors,114,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:180,performance,error,error,180,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:449,performance,error,error,449,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1564,performance,error,error,1564,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:94,reliability,fail,failed,94,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:114,safety,error,errors,114,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:180,safety,error,error,180,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:449,safety,error,error,449,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1564,safety,error,error,1564,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1258,security,Configur,Configuration,1258,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:114,usability,error,errors,114,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:130,usability,help,help,130,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:180,usability,error,error,180,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:449,usability,error,error,449,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:697,usability,tool,tools,697,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:703,usability,command,command,703,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:872,usability,Visual,Visual,872,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:910,usability,Tool,Tools,910,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1108,usability,Visual,Visual,1108,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1564,usability,error,error,1564,"Hi @bellenot, I also tried to build ROOT target to **ARM64EC** follow the below steps, and it failed due to below errors, can you help take a look? Thanks. ```. 52>rtm_mutex.obj : error LNK2019: unresolved external symbol _xbegin referenced in function #_xbegin$exit_thunk (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. 52>rtm_rw_mutex.obj : error LNK2001: unresolved external symbol _xbegin (EC Symbol) [C:\gitP\root-project\root\build_arm64ec\TBB-prefix\src\TBB-build\src\tbb\tbb.vcxproj] [C:\gitP\root-project\root\build_arm64ec\TBB.vcxproj]. ```. **Build steps:**. 1. Open a x64 native tools command prompt for VS 2022. 2. git clone https://github.com/root-project/root C:\gitP\root-project\root. 3. set VSCMD_SKIP_SENDTELEMETRY=1 & ""C:\Program Files\Microsoft Visual Studio\2022\Enterprise\Common7\Tools\VsDevCmd.bat"" -host_arch=amd64 -arch=arm64. 4. mkdir C:\gitP\root-project\root\build_arm64ec & cd /d C:\gitP\root-project\root\build_arm64ec. 5. python.exe -m pip install pytest. 6. cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off .. 7. msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild. **Note:** . I changed this line https://github.com/root-project/root/blob/master/builtins/zstd/common/compiler.h#L124 to be `if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_I86)) && !defined(_M_ARM64EC)`, otherwise, the build will report `C1189: #error: this header should only be included through <intrin.h>`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:161,availability,error,error,161,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:431,availability,error,error,431,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:567,availability,error,error,567,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:112,deployability,fail,failed,112,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:378,deployability,Configurat,Configuration,378,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:392,deployability,Releas,Release,392,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:589,deployability,build,build,589,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:944,deployability,log,logs,944,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:971,deployability,log,log,971,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1046,deployability,log,log,1046,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1072,deployability,log,log,1072,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1147,deployability,log,log,1147,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:378,integrability,Configur,Configuration,378,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:437,integrability,messag,message,437,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:358,interoperability,Platform,Platform,358,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:437,interoperability,messag,message,437,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:378,modifiability,Configur,Configuration,378,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:161,performance,error,error,161,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:431,performance,error,error,431,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:567,performance,error,error,567,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:112,reliability,fail,failed,112,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:161,safety,error,error,161,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:431,safety,error,error,431,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:567,safety,error,error,567,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:944,safety,log,logs,944,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:971,safety,log,log,971,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1046,safety,log,log,1046,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1072,safety,log,log,1072,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1147,safety,log,log,1147,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:378,security,Configur,Configuration,378,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:944,security,log,logs,944,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:971,security,log,log,971,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1046,security,log,log,1046,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1072,security,log,log,1072,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1147,security,log,log,1147,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:944,testability,log,logs,944,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:971,testability,log,log,971,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1046,testability,log,log,1046,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1072,testability,log,log,1072,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1147,testability,log,log,1147,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:161,usability,error,error,161,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:196,usability,Visual,Visual,196,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:431,usability,error,error,431,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:475,usability,Visual,Visual,475,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:567,usability,error,error,567,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:582,usability,Custom,Custom,582,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:995,usability,user,user-attachments,995,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:1096,usability,user,user-attachments,1096,"> `-Dimt=OFF -Dbuiltin_tbb=OFF`. I tried to add the 2 options you said, you can check the below steps, it still failed. The result look the same as the original error of this issue. 1. `cmake -G ""Visual Studio 17 2022"" -A ARM64EC -DCMAKE_SYSTEM_VERSION=10.0.22621.0 -Dtesting=ON -Droottest=ON -Droofit=off -Dimt=OFF -Dbuiltin_tbb=OFF ..` . 2. `msbuild /m /p:Platform=ARM64EC /p:Configuration=Release ALL_BUILD.vcxproj /t:Rebuild`. error message:. `C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\v170\Microsoft.CppCommon.targets(254,5): error MSB8066: Custom build for 'C:\gitP\root-project\root\build_arm64ec\CMakeFiles\c47203b562f7dfc78de28a6cb0d4e391\Options.inc.rule;C:\gitP\root-project\root\build_arm64ec\CMakeFiles\ef6b5551e87d9b29a1350db42d169b36\ClangDriverOptions.rule;C:\gitP\root-project\root\interpreter\llvm-project\clang\include\clang\Driver\CMakeLists.txt' exited with code -1073741819.`. detailed logs:. [ROOT_Setup_arm64ec.log](https://github.com/user-attachments/files/16309437/ROOT_Setup_arm64ec.log). [ROOT_build_arm64ec.log](https://github.com/user-attachments/files/16309436/ROOT_build_arm64ec.log).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:14,availability,error,errors,14,"OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:14,performance,error,errors,14,"OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:14,safety,error,errors,14,"OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:81,safety,test,test,81,"OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:81,testability,test,test,81,"OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:14,usability,error,errors,14,"OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:16,availability,error,errors,16,"> OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do... Hi @bellenot, in fact, I am also using an amd64 machine, but I am doing cross-compilation, and the target architecture is arm64ec.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:237,interoperability,architectur,architecture,237,"> OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do... Hi @bellenot, in fact, I am also using an amd64 machine, but I am doing cross-compilation, and the target architecture is arm64ec.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:16,performance,error,errors,16,"> OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do... Hi @bellenot, in fact, I am also using an amd64 machine, but I am doing cross-compilation, and the target architecture is arm64ec.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:16,safety,error,errors,16,"> OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do... Hi @bellenot, in fact, I am also using an amd64 machine, but I am doing cross-compilation, and the target architecture is arm64ec.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:83,safety,test,test,83,"> OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do... Hi @bellenot, in fact, I am also using an amd64 machine, but I am doing cross-compilation, and the target architecture is arm64ec.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:83,testability,test,test,83,"> OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do... Hi @bellenot, in fact, I am also using an amd64 machine, but I am doing cross-compilation, and the target architecture is arm64ec.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:16,usability,error,errors,16,"> OK, there are errors already in LLVM/Clang, and as I said, there is no way I can test on ARM64, so there is not much I can do... Hi @bellenot, in fact, I am also using an amd64 machine, but I am doing cross-compilation, and the target architecture is arm64ec.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:83,performance,time,time,83,"OK, I think this has never been tested (at least not by me). I'll try to find some time to try it next week or the week after",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:32,safety,test,tested,32,"OK, I think this has never been tested (at least not by me). I'll try to find some time to try it next week or the week after",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/issues/11787:32,testability,test,tested,32,"OK, I think this has never been tested (at least not by me). I'll try to find some time to try it next week or the week after",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11787
https://github.com/root-project/root/pull/11788:41,availability,failur,failure,41,@bellenot can you have a quick look? The failure on Windows is due to un-related tests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11788
https://github.com/root-project/root/pull/11788:41,deployability,fail,failure,41,@bellenot can you have a quick look? The failure on Windows is due to un-related tests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11788
https://github.com/root-project/root/pull/11788:41,performance,failur,failure,41,@bellenot can you have a quick look? The failure on Windows is due to un-related tests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11788
https://github.com/root-project/root/pull/11788:41,reliability,fail,failure,41,@bellenot can you have a quick look? The failure on Windows is due to un-related tests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11788
https://github.com/root-project/root/pull/11788:81,safety,test,tests,81,@bellenot can you have a quick look? The failure on Windows is due to un-related tests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11788
https://github.com/root-project/root/pull/11788:81,testability,test,tests,81,@bellenot can you have a quick look? The failure on Windows is due to un-related tests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11788
https://github.com/root-project/root/pull/11789:258,interoperability,bind,bind,258,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:258,modifiability,bind,bind,258,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:391,performance,memor,memory,391,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:340,safety,compl,complications,340,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:340,security,compl,complications,340,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:209,testability,simpl,simple,209,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:263,testability,unit,units,263,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:424,testability,unit,units,424,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:184,usability,behavi,behavior,184,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:209,usability,simpl,simple,209,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:328,usability,support,support,328,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:391,usability,memor,memory,391,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the. > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of. > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11789:48,usability,support,support,48,No. I think for now we certainly do not want to support this. I am sure this would only create confusion.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789
https://github.com/root-project/root/pull/11791:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:148,deployability,build,building,148,"Hi @guitargeek, I've fixed the compiler warning that it was showing before and also resolved a merge conflict that was still present. Could you try building again? The merge conflict had nothing to do with changes I made in this branch though so I just set it to the way it was present on master. It was related to some change you made a month ago. Could you please check to ensure that that is how you intended it? It is just a single line.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:101,interoperability,conflict,conflict,101,"Hi @guitargeek, I've fixed the compiler warning that it was showing before and also resolved a merge conflict that was still present. Could you try building again? The merge conflict had nothing to do with changes I made in this branch though so I just set it to the way it was present on master. It was related to some change you made a month ago. Could you please check to ensure that that is how you intended it? It is just a single line.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:174,interoperability,conflict,conflict,174,"Hi @guitargeek, I've fixed the compiler warning that it was showing before and also resolved a merge conflict that was still present. Could you try building again? The merge conflict had nothing to do with changes I made in this branch though so I just set it to the way it was present on master. It was related to some change you made a month ago. Could you please check to ensure that that is how you intended it? It is just a single line.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1591,deployability,updat,updated,1591,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1084,energy efficiency,current,current,1084,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1389,energy efficiency,current,current,1389,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:254,integrability,repositor,repository,254,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:60,interoperability,conflict,conflicts,60,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:254,interoperability,repositor,repository,254,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:552,interoperability,conflict,conflicts,552,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:755,interoperability,conflict,conflicts,755,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1150,interoperability,conflict,conflicts,1150,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:606,safety,compl,complicated,606,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1591,safety,updat,updated,1591,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1622,safety,compl,complicated,1622,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:606,security,compl,complicated,606,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1591,security,updat,updated,1591,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:1622,security,compl,complicated,1622,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:948,usability,command,command,948,"Hi @Zeff020, thanks for the PR! Yes, you resolved the merge conflicts correctly. But the problem is still tat you resolved them by merging `master` in your MR branch, meaning that your MR branch is now not a trivial fast-forward branch anymore. The ROOT repository settings only allow fast-forward branches to be merged, and also the CI can only deal with fast forward branches. IMO this is done for good reasons: if you first merge `master` into your branch and then your branch is merged back into master, with a potential merge commit that resolves conflicts in every step, the git history becomes some complicated zipped mess. This is also something you should keep in mind for development with git in general. That means you should not resolve merge conflicts by merging `master`, but by rebasing your PR branch on top of master with `git rebase`. Let's say you want to rebase the last 8 commits of your development branch `processtimer`, the command would be:. ```. git rebase --onto master HEAD~8 processtimer. ```. Where `master` is now a local branch that corresponds to the current `root-project/master`. And then you are by git to fix the conflicts in the rebasing process. Unfortunately, you can't do this anymore now because you have merged master into your branch, so your developments are not the last n commits of the branch anymore. I would maybe create a new branch form current `master`, cherry-pick your original commits on top of it with `git cherry-pick`, and then change the name of the new branch to `processtimer` again such that when you force push, the PR will be updated. Sorry for this overly complicated technical stuff!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:97,interoperability,conflict,conflicts,97,"Hi @guitargeek, no worries. And thanks for the comment! This time actually GitHub had a ""resolve conflicts"" button in the browser that I used but this made the merge commit. I agree, it is not so nice for the commit history. Anyway, I will do as you suggested and fix the commit history locally.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:61,performance,time,time,61,"Hi @guitargeek, no worries. And thanks for the comment! This time actually GitHub had a ""resolve conflicts"" button in the browser that I used but this made the merge commit. I agree, it is not so nice for the commit history. Anyway, I will do as you suggested and fix the commit history locally.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:38,interoperability,conflict,conflicts,38,"Hi @zeff020, little reminder that the conflicts here still need to be resolved",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:12,interoperability,conflict,conflicts,12,@guitargeek conflicts resolved,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:53,availability,error,errors,53,"Hi @guitargeek, do I need to look into these windows errors? Do we expect this to work on windows?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:53,performance,error,errors,53,"Hi @guitargeek, do I need to look into these windows errors? Do we expect this to work on windows?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:53,safety,error,errors,53,"Hi @guitargeek, do I need to look into these windows errors? Do we expect this to work on windows?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:53,usability,error,errors,53,"Hi @guitargeek, do I need to look into these windows errors? Do we expect this to work on windows?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:255,availability,error,error,255,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:145,deployability,modul,modules,145,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:145,modifiability,modul,modules,145,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:255,performance,error,error,255,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:145,safety,modul,modules,145,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:255,safety,error,error,255,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:29,usability,support,supported,29,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:255,usability,error,error,255,@Zeff020 Multiprocess is not supported on Windows (see [RootBuildOptions.cmake#L352-L355](https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L352-L355)). The relevant code must be protected and not cause any compilation error,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:165,availability,error,errors,165,"@guitargeek I think these windows issues should be resolved with my most recent commit, at least I ensured that compilation without MultiProcessing enabled gives no errors or warnings. I cannot fully test a windows compilation since I have no windows machine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:165,performance,error,errors,165,"@guitargeek I think these windows issues should be resolved with my most recent commit, at least I ensured that compilation without MultiProcessing enabled gives no errors or warnings. I cannot fully test a windows compilation since I have no windows machine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:165,safety,error,errors,165,"@guitargeek I think these windows issues should be resolved with my most recent commit, at least I ensured that compilation without MultiProcessing enabled gives no errors or warnings. I cannot fully test a windows compilation since I have no windows machine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:200,safety,test,test,200,"@guitargeek I think these windows issues should be resolved with my most recent commit, at least I ensured that compilation without MultiProcessing enabled gives no errors or warnings. I cannot fully test a windows compilation since I have no windows machine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:200,testability,test,test,200,"@guitargeek I think these windows issues should be resolved with my most recent commit, at least I ensured that compilation without MultiProcessing enabled gives no errors or warnings. I cannot fully test a windows compilation since I have no windows machine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:165,usability,error,errors,165,"@guitargeek I think these windows issues should be resolved with my most recent commit, at least I ensured that compilation without MultiProcessing enabled gives no errors or warnings. I cannot fully test a windows compilation since I have no windows machine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:86,deployability,Log,LogTimings,86,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:170,energy efficiency,profil,profiling,170,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:517,energy efficiency,Heat,HeatmapAnalyzer,517,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:170,performance,profil,profiling,170,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:86,safety,Log,LogTimings,86,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:249,safety,test,test,249,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:385,safety,test,test,385,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:504,safety,test,tests,504,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:86,security,Log,LogTimings,86,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:86,testability,Log,LogTimings,86,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:249,testability,test,test,249,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:361,testability,simpl,simply,361,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:385,testability,test,test,385,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:499,testability,unit,unit,499,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:504,testability,test,tests,504,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:127,usability,clear,clear,127,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:361,usability,simpl,simply,361,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11791:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791
https://github.com/root-project/root/pull/11793:95,safety,test,testLikelihoodGradientJob,95,"Hi Patrick, thanks for looking at the code! It's good to know that the original author of the `testLikelihoodGradientJob` test approves the changes! The other two commits are very minor anyway and don't really need a more in-depth review.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11793
https://github.com/root-project/root/pull/11793:122,safety,test,test,122,"Hi Patrick, thanks for looking at the code! It's good to know that the original author of the `testLikelihoodGradientJob` test approves the changes! The other two commits are very minor anyway and don't really need a more in-depth review.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11793
https://github.com/root-project/root/pull/11793:231,safety,review,review,231,"Hi Patrick, thanks for looking at the code! It's good to know that the original author of the `testLikelihoodGradientJob` test approves the changes! The other two commits are very minor anyway and don't really need a more in-depth review.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11793
https://github.com/root-project/root/pull/11793:80,security,auth,author,80,"Hi Patrick, thanks for looking at the code! It's good to know that the original author of the `testLikelihoodGradientJob` test approves the changes! The other two commits are very minor anyway and don't really need a more in-depth review.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11793
https://github.com/root-project/root/pull/11793:95,testability,test,testLikelihoodGradientJob,95,"Hi Patrick, thanks for looking at the code! It's good to know that the original author of the `testLikelihoodGradientJob` test approves the changes! The other two commits are very minor anyway and don't really need a more in-depth review.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11793
https://github.com/root-project/root/pull/11793:122,testability,test,test,122,"Hi Patrick, thanks for looking at the code! It's good to know that the original author of the `testLikelihoodGradientJob` test approves the changes! The other two commits are very minor anyway and don't really need a more in-depth review.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11793
https://github.com/root-project/root/pull/11793:231,testability,review,review,231,"Hi Patrick, thanks for looking at the code! It's good to know that the original author of the `testLikelihoodGradientJob` test approves the changes! The other two commits are very minor anyway and don't really need a more in-depth review.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11793
https://github.com/root-project/root/issues/11797:283,availability,reliab,reliably,283,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:83,deployability,depend,depend,83,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:194,deployability,build,build,194,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:305,deployability,version,versions,305,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:412,deployability,instal,installed,412,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:511,deployability,instal,installed,511,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:83,integrability,depend,depend,83,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:167,integrability,interfac,interface,167,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:305,integrability,version,versions,305,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:167,interoperability,interfac,interface,167,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:83,modifiability,depend,depend,83,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:167,modifiability,interfac,interface,167,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:305,modifiability,version,versions,305,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:359,modifiability,variab,variables,359,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:283,reliability,reliab,reliably,283,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:567,reliability,doe,doesn,567,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:83,safety,depend,depend,83,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:136,safety,compl,complains,136,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:136,security,compl,complains,136,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:83,testability,depend,depend,83,"I agree that there is a problem, and it comes from the fact that you cannot easily depend on Vdt via targets when Vdt is builtin. CMake complains about headers in the interface which are in the build directory in that case, so a lot of workarounds are needed and no workaround works reliably across CMake versions. When I last touched this, we decided to use variables and rely on the fact that vdt headers were installed into the same place as ROOT headers when Vdt was builtin. However, when Vdt and ROOT are installed separately and into different locations, this doesn't work so well indeed. Fixing this is overdue, but we unfortunately have to keep it working for both builtin/external Vdt. I think that the solution proposed by @krasznaa is in the right direction.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:50,deployability,build,build,50,Reassigning to Bertrand as this is a more general build system issue than an issue with how libVecOps is set up (as I first assumed).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:109,deployability,version,versions,109,"For anyone trying to fix this, please make sure to try with at least the earliest and latest supported CMake versions, and both for builtin/external Vdt. Maybe the situation improved with CMake 3.16 and above, but when I last touched this stuff, CMake was broken enough that I could not find a way not to do what I did by just using variables. To fix, one could try to revert commit a363eca1701c4606fed0df6296b11143306f29e6 referenced in the issue above, and try to fix the problem without getting rid of the `Vdt::Vdt` target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:109,integrability,version,versions,109,"For anyone trying to fix this, please make sure to try with at least the earliest and latest supported CMake versions, and both for builtin/external Vdt. Maybe the situation improved with CMake 3.16 and above, but when I last touched this stuff, CMake was broken enough that I could not find a way not to do what I did by just using variables. To fix, one could try to revert commit a363eca1701c4606fed0df6296b11143306f29e6 referenced in the issue above, and try to fix the problem without getting rid of the `Vdt::Vdt` target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:109,modifiability,version,versions,109,"For anyone trying to fix this, please make sure to try with at least the earliest and latest supported CMake versions, and both for builtin/external Vdt. Maybe the situation improved with CMake 3.16 and above, but when I last touched this stuff, CMake was broken enough that I could not find a way not to do what I did by just using variables. To fix, one could try to revert commit a363eca1701c4606fed0df6296b11143306f29e6 referenced in the issue above, and try to fix the problem without getting rid of the `Vdt::Vdt` target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:333,modifiability,variab,variables,333,"For anyone trying to fix this, please make sure to try with at least the earliest and latest supported CMake versions, and both for builtin/external Vdt. Maybe the situation improved with CMake 3.16 and above, but when I last touched this stuff, CMake was broken enough that I could not find a way not to do what I did by just using variables. To fix, one could try to revert commit a363eca1701c4606fed0df6296b11143306f29e6 referenced in the issue above, and try to fix the problem without getting rid of the `Vdt::Vdt` target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:93,usability,support,supported,93,"For anyone trying to fix this, please make sure to try with at least the earliest and latest supported CMake versions, and both for builtin/external Vdt. Maybe the situation improved with CMake 3.16 and above, but when I last touched this stuff, CMake was broken enough that I could not find a way not to do what I did by just using variables. To fix, one could try to revert commit a363eca1701c4606fed0df6296b11143306f29e6 referenced in the issue above, and try to fix the problem without getting rid of the `Vdt::Vdt` target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4172,availability,robust,robust,4172,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:141,deployability,build,build,141,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:271,deployability,modul,modules,271,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:317,deployability,modul,modules,317,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:405,deployability,modul,modules,405,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:456,deployability,modul,modules,456,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1019,deployability,build,build,1019,"ime... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1025,deployability,configurat,configuration,1025," basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1272,deployability,build,building,1272,"es/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:2664,deployability,configurat,configuration,2664,"IVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUB",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:2695,deployability,build,build,2695,"NTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3052,deployability,build,building,3052," would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_li",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4389,deployability,updat,updated,4389,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3381,energy efficiency,Core,Core,3381,"ind_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be man",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:582,integrability,COMPON,COMPONENT,582,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1025,integrability,configur,configuration,1025," basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1697,integrability,INTERFAC,INTERFACE,1697,"roperty(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1890,integrability,PUB,PUBLIC,1890,"}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeL",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1951,integrability,PUB,PUBLIC,1951,"). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vec",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:2664,integrability,configur,configuration,2664,"IVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUB",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3485,integrability,INTERFAC,INTERFACE,3485,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3668,integrability,PUB,PUBLIC,3668,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3803,integrability,PUB,PUBLIC,3803,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4013,integrability,PUB,PUBLIC,4013,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4075,integrability,PUB,PUBLIC,4075,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:582,interoperability,COMPON,COMPONENT,582,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1697,interoperability,INTERFAC,INTERFACE,1697,"roperty(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3485,interoperability,INTERFAC,INTERFACE,3485,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:271,modifiability,modul,modules,271,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:317,modifiability,modul,modules,317,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:405,modifiability,modul,modules,405,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:456,modifiability,modul,modules,456,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:582,modifiability,COMPON,COMPONENT,582,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1025,modifiability,configur,configuration,1025," basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1298,modifiability,pac,package,1298,".cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1697,modifiability,INTERFAC,INTERFACE,1697,"roperty(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:2664,modifiability,configur,configuration,2664,"IVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUB",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3078,modifiability,pac,package,3078,"needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:3485,modifiability,INTERFAC,INTERFACE,3485,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:21,performance,time,time,21,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:619,performance,CACH,CACHE,619,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4172,reliability,robust,robust,4172,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:271,safety,modul,modules,271,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:317,safety,modul,modules,317,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:405,safety,modul,modules,405,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:456,safety,modul,modules,456,"Okay, CMake tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Fin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4172,safety,robust,robust,4172,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4389,safety,updat,updated,4389,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1025,security,configur,configuration,1025," basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:2664,security,configur,configuration,2664,"IVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUB",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4389,security,updat,updated,4389,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1006,testability,simpl,simplify,1006,"e tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1006,usability,simpl,simplify,1006,"e tutorial time... You basically have 2 ways in my mind to solve this nicely. 1. Switch to using the `VDT::VDT` library during the build. - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff. diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake. index 7947fddfc0..7ad5fd91af 100644. --- a/cmake/modules/SearchInstalledSoftware.cmake. +++ b/cmake/modules/SearchInstalledSoftware.cmake. @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt). DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL). + set_target_properties(VDT::VDT. + PROPERTIES. + IMPORTED_LOCATION ""${VDT_LIBRARIES}"". + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + ). endif(). endif(). ```. - At this point you could simplify the build configuration to:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..e15b5ea186 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. ). . if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:2649,usability,prefer,prefer,2649,"ories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. -if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). -elseif(vdt). - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT). endif(). . if(MSVC). ```. - Finally, you would have to ensure that `find_package(ROOT)` would look for VDT if it needs to. Like:. ```diff. diff --git a/cmake/scripts/ROOTConfig.cmake.in b/cmake/scripts/ROOTConfig.cmake.in. index 54f1a17140..054954ac8c 100644. --- a/cmake/scripts/ROOTConfig.cmake.in. +++ b/cmake/scripts/ROOTConfig.cmake.in. @@ -97,6 +97,9 @@ if(ROOT_minuit2_omp_FOUND). find_dependency(OpenMP). find_dependency(Threads). endif(). +if(@vdt@ OR @builtin_vdt@). + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:4117,usability,person,personally,4117,". + find_dependency(Vdt). +endif(). . #----------------------------------------------------------------------------. # Now set them to ROOT_LIBRARIES. ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff. diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt. index 09fde3eb40..dd998c1a9b 100644. --- a/math/vecops/CMakeLists.txt. +++ b/math/vecops/CMakeLists.txt. @@ -8,10 +8,6 @@. # CMakeLists.txt file for building ROOT math/vecops package. ############################################################################. . -if(builtin_vdt). - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}). -endif(). -. ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. HEADERS. ROOT/RVec.hxx. @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps. Core. ). . -if(builtin_vdt OR vdt). - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>). -endif(). -. if(builtin_vdt). - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}). + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:149,deployability,build,build,149,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:315,deployability,instal,install,315,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:455,deployability,version,versions,455,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:323,integrability,interfac,interface,323,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:455,integrability,version,versions,455,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:323,interoperability,interfac,interface,323,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:323,modifiability,interfac,interface,323,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:455,modifiability,version,versions,455,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:56,reliability,doe,doesn,56,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:476,usability,support,support,476,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:507,usability,prefer,preferred,507,"You option 1 is more or less what we used to do, and it doesn't work when Vdt is builtin, because `INTERFACE_INCLUDE_DIRECTORIES` will be inside the build directory. Your option 2 will likely not work with static external Vdt because of `${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}` used in the install interface. I agree with you, however, if your option one can be made to work correctly when Vdt is external/builtin and the several versions of CMake we support, then that would be my preferred option too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:735,deployability,instal,installed,735,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:745,deployability,version,version,745,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:104,integrability,PUB,PUBLIC,104,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:235,integrability,PUB,PUBLIC,235,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:441,integrability,PUB,PUBLIC,441,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:503,integrability,PUB,PUBLIC,503,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:745,integrability,version,version,745,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:745,modifiability,version,version,745,":confused: My option 2 has this code:. ```cmake. if(builtin_vdt). target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>). target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>. $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>). elseif(vdt). target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}). target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}). endif(). ```. Though I disagree that option 1 would not work. The whole point of using imported targets is that CMake would not care about where they point exactly. As they will need to be re-found on the ""installed version"" of ROOT anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:19,integrability,sub,submit,19,"You are welcome to submit a pull request with option 1, and yes, I misread your option 2, I think that should be doable at least as an intermediate fix.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:135,modifiability,interm,intermediate,135,"You are welcome to submit a pull request with option 1, and yes, I misread your option 2, I think that should be doable at least as an intermediate fix.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:226,deployability,depend,dependency,226,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:264,deployability,build,build-time,264,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:281,deployability,depend,dependency,281,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:219,integrability,pub,public,219,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:226,integrability,depend,dependency,226,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:281,integrability,depend,dependency,281,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:226,modifiability,depend,dependency,226,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:281,modifiability,depend,dependency,281,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:270,performance,time,time,270,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:302,performance,time,time,302,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:226,safety,depend,dependency,226,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:281,safety,depend,dependency,281,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:226,testability,depend,dependency,226,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:281,testability,depend,dependency,281,"Looking at the history, commit https://github.com/root-project/root/commit/378f961faf3ccc2f3272c27c7f45b38479ad3693#diff-b7e4b08bc7e019d35a141d4c27ebc7e748b5f4580d6f9d840dda0c70cc185cbe is actually wrong, it replaced a public dependency on Vdt with a private (and build-time only) dependency. The last time I touched this file was in commit 7d88a0fc8b0fa604b5fee0174fdac88885cc6f5f, when we had something similar to your option 2 in place.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:471,availability,error,errors,471,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1688,energy efficiency,green,green,1688,"ng target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:530,integrability,COMPON,COMPONENT,530,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1083,integrability,INTERFAC,INTERFACE,1083,"ng target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:530,interoperability,COMPON,COMPONENT,530,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:926,interoperability,SHARE,SHARED,926,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1083,interoperability,INTERFAC,INTERFACE,1083,"ng target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1238,interoperability,share,shared,1238,"ng target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:530,modifiability,COMPON,COMPONENT,530,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1083,modifiability,INTERFAC,INTERFACE,1083,"ng target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:321,performance,time,time,321,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:471,performance,error,errors,471,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:567,performance,CACH,CACHE,567,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1763,reliability,Doe,Does,1763,"ng target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:471,safety,error,errors,471,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:471,usability,error,errors,471,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/issues/11797:1847,usability,clear,clear,1847,"ng target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:. https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):. ```diff. DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers). set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE). set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT). - add_library(VDT::VDT STATIC IMPORTED GLOBAL). - set_target_properties(VDT::VDT. - PROPERTIES. - IMPORTED_LOCATION ""${VDT_LIBRARIES}"". - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}"". + add_library(VDT IMPORTED SHARED). + add_dependencies(VDT BUILTIN_VDT). + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""). + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>). ). endif(). endif(). ```. Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ? ### Edit . And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797
https://github.com/root-project/root/pull/11798:0,availability,Failur,Failure,0,Failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11798
https://github.com/root-project/root/pull/11798:0,deployability,Fail,Failure,0,Failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11798
https://github.com/root-project/root/pull/11798:0,performance,Failur,Failure,0,Failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11798
https://github.com/root-project/root/pull/11798:0,reliability,Fail,Failure,0,Failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11798
https://github.com/root-project/root/pull/11799:196,performance,time,time,196,"The one thing you lose is what you probably meant originally. i.e. an indicator that these members (as opposed to the other members) are only modified at construction (and now also at assignment) time. So you may want to consider adding a comment to that effect. [But of course, you are still losing the compiler enforcement thereof but that's probably okay]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:142,security,modif,modified,142,"The one thing you lose is what you probably meant originally. i.e. an indicator that these members (as opposed to the other members) are only modified at construction (and now also at assignment) time. So you may want to consider adding a comment to that effect. [But of course, you are still losing the compiler enforcement thereof but that's probably okay]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:70,usability,indicat,indicator,70,"The one thing you lose is what you probably meant originally. i.e. an indicator that these members (as opposed to the other members) are only modified at construction (and now also at assignment) time. So you may want to consider adding a comment to that effect. [But of course, you are still losing the compiler enforcement thereof but that's probably okay]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:225,availability,state,state,225,"Thanks Philippe, Vincenzo. I'd rather not put a comment that says ""these should be const except for move-assignment"" as it can go out of date fast, without anyone noticing. It would be nice to have a compiler-enforced way to state the intent. We can apply similar changes to other files in other PRs.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:225,integrability,state,state,225,"Thanks Philippe, Vincenzo. I'd rather not put a comment that says ""these should be const except for move-assignment"" as it can go out of date fast, without anyone noticing. It would be nice to have a compiler-enforced way to state the intent. We can apply similar changes to other files in other PRs.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:89,safety,except,except,89,"Thanks Philippe, Vincenzo. I'd rather not put a comment that says ""these should be const except for move-assignment"" as it can go out of date fast, without anyone noticing. It would be nice to have a compiler-enforced way to state the intent. We can apply similar changes to other files in other PRs.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:54,availability,state,state,54,> It would be nice to have a compiler-enforced way to state the intent. . There is but it might be too expensive for the gain. You could keep the members `const` and implemented the move and assignment operator using `const_cast`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:202,availability,operat,operator,202,> It would be nice to have a compiler-enforced way to state the intent. . There is but it might be too expensive for the gain. You could keep the members `const` and implemented the move and assignment operator using `const_cast`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:54,integrability,state,state,54,> It would be nice to have a compiler-enforced way to state the intent. . There is but it might be too expensive for the gain. You could keep the members `const` and implemented the move and assignment operator using `const_cast`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/pull/11799:75,availability,operat,operator,75,> You could keep the members const and implemented the move and assignment operator using const_cast. That's UB :grimacing:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11799
https://github.com/root-project/root/issues/11800:64,interoperability,specif,specified,64,@pcanal IIUC what you are saying is that if the branch title is specified manually at the time of writing then TTree::Print will show the wrong branch type? I'm not sure why the two things are entangled.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11800
https://github.com/root-project/root/issues/11800:90,performance,time,time,90,@pcanal IIUC what you are saying is that if the branch title is specified manually at the time of writing then TTree::Print will show the wrong branch type? I'm not sure why the two things are entangled.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11800
https://github.com/root-project/root/issues/11800:574,safety,compl,complicated,574,"Mmmh yeah there is a weird interaction between `branch->SetTitle` and the output of `tree->Print()`:. ```cpp. #include <TFile.h>. #include <TTree.h>. int main() {. {. TFile f(""f.root"", ""recreate"");. TTree t(""t"", ""t"");. int *x = new int[42]{42};. auto *b = t.Branch(""x"", x, ""x[42]/I"");. // with this line: *Br 0 :x : Int_t. // without this line: *Br 0 :x : x[42]/I. b->SetTitle(""x"");. t.Fill();. t.Write();. }. TFile f(""f.root"");. f.Get<TTree>(""t"")->Print();. }. ```. I would expect the type information to be correctly displayed independently of the branch title, as [it is complicated](https://github.com/root-project/root/blob/8f72f53fbf9b42ef7e18d6e63dd606c4f503deae/tree/dataframe/src/RDFUtils.cxx#L138-L216) to find out the type of a branch by other means.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11800
https://github.com/root-project/root/issues/11800:574,security,compl,complicated,574,"Mmmh yeah there is a weird interaction between `branch->SetTitle` and the output of `tree->Print()`:. ```cpp. #include <TFile.h>. #include <TTree.h>. int main() {. {. TFile f(""f.root"", ""recreate"");. TTree t(""t"", ""t"");. int *x = new int[42]{42};. auto *b = t.Branch(""x"", x, ""x[42]/I"");. // with this line: *Br 0 :x : Int_t. // without this line: *Br 0 :x : x[42]/I. b->SetTitle(""x"");. t.Fill();. t.Write();. }. TFile f(""f.root"");. f.Get<TTree>(""t"")->Print();. }. ```. I would expect the type information to be correctly displayed independently of the branch title, as [it is complicated](https://github.com/root-project/root/blob/8f72f53fbf9b42ef7e18d6e63dd606c4f503deae/tree/dataframe/src/RDFUtils.cxx#L138-L216) to find out the type of a branch by other means.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11800
https://github.com/root-project/root/issues/11800:27,usability,interact,interaction,27,"Mmmh yeah there is a weird interaction between `branch->SetTitle` and the output of `tree->Print()`:. ```cpp. #include <TFile.h>. #include <TTree.h>. int main() {. {. TFile f(""f.root"", ""recreate"");. TTree t(""t"", ""t"");. int *x = new int[42]{42};. auto *b = t.Branch(""x"", x, ""x[42]/I"");. // with this line: *Br 0 :x : Int_t. // without this line: *Br 0 :x : x[42]/I. b->SetTitle(""x"");. t.Fill();. t.Write();. }. TFile f(""f.root"");. f.Get<TTree>(""t"")->Print();. }. ```. I would expect the type information to be correctly displayed independently of the branch title, as [it is complicated](https://github.com/root-project/root/blob/8f72f53fbf9b42ef7e18d6e63dd606c4f503deae/tree/dataframe/src/RDFUtils.cxx#L138-L216) to find out the type of a branch by other means.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11800
https://github.com/root-project/root/pull/11803:0,availability,ping,ping,0,ping @Axel-Naumann @vgvassilev,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:41,safety,review,review,41,LGTM but I'd like to have @vgvassilev 's review.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:41,testability,review,review,41,LGTM but I'd like to have @vgvassilev 's review.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:308,safety,input,inputs,308,"> LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:458,safety,review,reviews,458,"> LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:458,testability,review,reviews,458,"> LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:308,usability,input,inputs,308,"> LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:316,safety,input,inputs,316,"> > LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. > . > Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658. Awesome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:466,safety,review,reviews,466,"> > LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. > . > Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658. Awesome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:466,testability,review,reviews,466,"> > LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. > . > Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658. Awesome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11803:316,usability,input,inputs,316,"> > LGTM! I am wondering if we will have the same problem with clang-repl, because the compiler instance bootstrapping soon will be moved to what we have upstream. > . > Yes, I think the equivalent code is https://github.com/llvm/llvm-project/blob/main/clang/lib/Interpreter/Interpreter.cpp#L103-L104 (btw, the `<<< inputs >>>` should probably be a constant because it needs to agree with line 149). But it shouldn't be a real problem anymore after I landed https://reviews.llvm.org/D138658. Awesome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11803
https://github.com/root-project/root/pull/11804:355,availability,error,errors,355,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:465,availability,error,error,465,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:581,availability,error,error,581,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:554,deployability,fail,fail,554,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:435,energy efficiency,reduc,reduce,435,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:54,integrability,batch,batch,54,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:559,integrability,event,eventually,559,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:587,integrability,messag,messages,587,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:587,interoperability,messag,messages,587,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:54,performance,batch,batch,54,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:355,performance,error,errors,355,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:465,performance,error,error,465,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:581,performance,error,error,581,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:554,reliability,fail,fail,554,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:27,safety,review,review,27,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:88,safety,test,tested,88,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:355,safety,error,errors,355,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:465,safety,error,error,465,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:522,safety,test,tests,522,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:581,safety,error,error,581,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:27,testability,review,review,27,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:88,testability,test,tested,88,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:522,testability,test,tests,522,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:355,usability,error,errors,355,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:460,usability,user,user,460,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:465,usability,error,error,465,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:581,usability,error,error,581,"Hi @egpbos, thanks for the review! You are right, the batch mode stuff should better be tested somewhere else, so I removed some commits from this PR. What is left in this PR is the question about the constrain settings that might not make sense. Let's discuss this in the next RooFit meeting then! What I ultimately want to achieve is that RooFit prints errors if you have constrained settings that statistically don't make sense, to reduce the potential for user error. That means we can't have ""unphysical"" fits in our tests too, otherwise they would fail eventually from these error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:61,integrability,batch,batch,61,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:38,modifiability,reu,reuse,38,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:61,performance,batch,batch,61,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:48,safety,test,testcase,48,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:72,safety,test,tests,72,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:227,safety,test,test,227,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:48,testability,test,testcase,48,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:72,testability,test,tests,72,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:227,testability,test,test,227,"Makes total sense. If you're going to reuse the testcase for batch mode tests later on, it would probably still be good to extract the common code into a utility header. I liked a lot the cleanup you already did before on this test file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:193,integrability,sub,subset,193,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:212,modifiability,paramet,parameters,212,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:45,safety,test,test,45,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:61,safety,test,test,61,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:45,testability,test,test,45,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:61,testability,test,test,61,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:77,testability,plan,plan,77,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11804:149,usability,user,users,149,"* superseded by other improvement PRs to the test statistics test. * I don't plan to remove `RooFit::Constrain()` after all, because I realized some users are relying on it to constrain only a subset of nuisance parameters for checks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11804
https://github.com/root-project/root/pull/11805:23,usability,stop,stop,23,"BTW, one should really stop casting pointers to long. I was surprised to see this again, we are in 2022!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11805
https://github.com/root-project/root/pull/11808:4,deployability,version,version,4,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:147,deployability,version,versions-of-the-codeql-action,147,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:244,deployability,version,version,244,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:4,integrability,version,version,4,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:147,integrability,version,versions-of-the-codeql-action,147,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:244,integrability,version,version,244,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:4,modifiability,version,version,4,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:147,modifiability,version,versions-of-the-codeql-action,147,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:244,modifiability,version,version,244,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11808:137,usability,support,supported-versions-of-the-codeql-action,137,"The version of the CodeQL action suggested in this PR is already deprecated:. https://github.com/github/codeql-action?tab=readme-ov-file#supported-versions-of-the-codeql-action. In case we want to use this action, we can create our own PR with version 3.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11808
https://github.com/root-project/root/pull/11813:23,modifiability,variab,variable,23,Just fixing the unused variable warning,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11813
https://github.com/root-project/root/pull/11816:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11816
https://github.com/root-project/root/pull/11817:0,energy efficiency,Current,Current,0,"Current status. ```python. >>> import ROOT. >>> v = ROOT.std.vector[ROOT.VecOps.RVec[int]](5, [1,2,3]). >>> v. vector<ROOT::VecOps::RVec<int> >{ { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 } }. >>> df = ROOT.RDataFrame(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). >>> df.GetColumnNames(). vector<string>{ ""Muon_charge"", ""Muon_eta"", ""Muon_mass"", ""Muon_phi"", ""Muon_pt"", ""nMuon"" }. >>> ROOT.gInterpreter.Declare(""struct MyInt{ int mI{42}; };""). True. >>> ROOT.std.vector[ROOT.MyInt](10). vector<MyInt>{ @0x5641786b1400, @0x5641786b1404, @0x5641786b1408, @0x5641786b140c, @0x5641786b1410, @0x5641786b1414, @0x5641786b1418, @0x5641786b141c, @0x5641786b1420, @0x5641786b1424 }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11817
https://github.com/root-project/root/pull/11817:238,integrability,Event,Events,238,"Current status. ```python. >>> import ROOT. >>> v = ROOT.std.vector[ROOT.VecOps.RVec[int]](5, [1,2,3]). >>> v. vector<ROOT::VecOps::RVec<int> >{ { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 } }. >>> df = ROOT.RDataFrame(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). >>> df.GetColumnNames(). vector<string>{ ""Muon_charge"", ""Muon_eta"", ""Muon_mass"", ""Muon_phi"", ""Muon_pt"", ""nMuon"" }. >>> ROOT.gInterpreter.Declare(""struct MyInt{ int mI{42}; };""). True. >>> ROOT.std.vector[ROOT.MyInt](10). vector<MyInt>{ @0x5641786b1400, @0x5641786b1404, @0x5641786b1408, @0x5641786b140c, @0x5641786b1410, @0x5641786b1414, @0x5641786b1418, @0x5641786b141c, @0x5641786b1420, @0x5641786b1424 }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11817
https://github.com/root-project/root/pull/11817:8,usability,statu,status,8,"Current status. ```python. >>> import ROOT. >>> v = ROOT.std.vector[ROOT.VecOps.RVec[int]](5, [1,2,3]). >>> v. vector<ROOT::VecOps::RVec<int> >{ { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 }, { 1, 2, 3 } }. >>> df = ROOT.RDataFrame(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). >>> df.GetColumnNames(). vector<string>{ ""Muon_charge"", ""Muon_eta"", ""Muon_mass"", ""Muon_phi"", ""Muon_pt"", ""nMuon"" }. >>> ROOT.gInterpreter.Declare(""struct MyInt{ int mI{42}; };""). True. >>> ROOT.std.vector[ROOT.MyInt](10). vector<MyInt>{ @0x5641786b1400, @0x5641786b1404, @0x5641786b1408, @0x5641786b140c, @0x5641786b1410, @0x5641786b1414, @0x5641786b1418, @0x5641786b141c, @0x5641786b1420, @0x5641786b1424 }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11817
https://github.com/root-project/root/pull/11817:8,interoperability,compatib,compatibility,8,Python2 compatibility :smile:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11817
https://github.com/root-project/root/issues/11819:45,availability,error,error,45,"What commands did you type exactly? And what error do you get, if any?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:45,performance,error,error,45,"What commands did you type exactly? And what error do you get, if any?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:45,safety,error,error,45,"What commands did you type exactly? And what error do you get, if any?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:5,usability,command,commands,5,"What commands did you type exactly? And what error do you get, if any?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:45,usability,error,error,45,"What commands did you type exactly? And what error do you get, if any?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:113,deployability,configurat,configuration,113,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:144,deployability,contain,contain,144,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:113,integrability,configur,configuration,113,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:113,modifiability,configur,configuration,113,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:135,reliability,doe,does,135,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:113,security,configur,configuration,113,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:127,usability,command,command,127,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:264,usability,user,user,264,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:269,usability,support,support,269,"Hi @Es-said ,. this is not a ROOT bug. It looks like the ROOT source directory that you are passing to the cmake configuration command does not contain ROOT sources (which come with a `CMakeLists.txt` file). Feel free to use https://root-forum.cern.ch for further user support.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:88,availability,Error,Error,88,"the cammand that type is cmake ../root -Dall=ON. here is the erreur that recieve. CMake Error: The source directory ""/home/said/Desktop/product/root"" does not appear to contain CMakeLists.txt.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:169,deployability,contain,contain,169,"the cammand that type is cmake ../root -Dall=ON. here is the erreur that recieve. CMake Error: The source directory ""/home/said/Desktop/product/root"" does not appear to contain CMakeLists.txt.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:88,performance,Error,Error,88,"the cammand that type is cmake ../root -Dall=ON. here is the erreur that recieve. CMake Error: The source directory ""/home/said/Desktop/product/root"" does not appear to contain CMakeLists.txt.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:150,reliability,doe,does,150,"the cammand that type is cmake ../root -Dall=ON. here is the erreur that recieve. CMake Error: The source directory ""/home/said/Desktop/product/root"" does not appear to contain CMakeLists.txt.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:88,safety,Error,Error,88,"the cammand that type is cmake ../root -Dall=ON. here is the erreur that recieve. CMake Error: The source directory ""/home/said/Desktop/product/root"" does not appear to contain CMakeLists.txt.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/issues/11819:88,usability,Error,Error,88,"the cammand that type is cmake ../root -Dall=ON. here is the erreur that recieve. CMake Error: The source directory ""/home/said/Desktop/product/root"" does not appear to contain CMakeLists.txt.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11819
https://github.com/root-project/root/pull/11820:112,deployability,log,logic,112,"Thanks for the review, especially for looking also at the trivial changes and giving suggestions to improve the logic!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11820
https://github.com/root-project/root/pull/11820:15,safety,review,review,15,"Thanks for the review, especially for looking also at the trivial changes and giving suggestions to improve the logic!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11820
https://github.com/root-project/root/pull/11820:112,safety,log,logic,112,"Thanks for the review, especially for looking also at the trivial changes and giving suggestions to improve the logic!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11820
https://github.com/root-project/root/pull/11820:112,security,log,logic,112,"Thanks for the review, especially for looking also at the trivial changes and giving suggestions to improve the logic!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11820
https://github.com/root-project/root/pull/11820:15,testability,review,review,15,"Thanks for the review, especially for looking also at the trivial changes and giving suggestions to improve the logic!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11820
https://github.com/root-project/root/pull/11820:112,testability,log,logic,112,"Thanks for the review, especially for looking also at the trivial changes and giving suggestions to improve the logic!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11820
https://github.com/root-project/root/pull/11822:80,availability,failur,failures,80,"As seen above, CentOS 8 is quite unhappy about the changes here. I bisected the failures (except for `fit/graph2dfit.C` and `hist/hstack.C`, which will be taken care of by https://github.com/root-project/root/pull/11830) to commit 3ac1d584c821d21e4fae789f595eddf5833848c0. @linev do you see an obvious problem / have an idea?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11822
https://github.com/root-project/root/pull/11822:80,deployability,fail,failures,80,"As seen above, CentOS 8 is quite unhappy about the changes here. I bisected the failures (except for `fit/graph2dfit.C` and `hist/hstack.C`, which will be taken care of by https://github.com/root-project/root/pull/11830) to commit 3ac1d584c821d21e4fae789f595eddf5833848c0. @linev do you see an obvious problem / have an idea?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11822
https://github.com/root-project/root/pull/11822:80,performance,failur,failures,80,"As seen above, CentOS 8 is quite unhappy about the changes here. I bisected the failures (except for `fit/graph2dfit.C` and `hist/hstack.C`, which will be taken care of by https://github.com/root-project/root/pull/11830) to commit 3ac1d584c821d21e4fae789f595eddf5833848c0. @linev do you see an obvious problem / have an idea?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11822
https://github.com/root-project/root/pull/11822:80,reliability,fail,failures,80,"As seen above, CentOS 8 is quite unhappy about the changes here. I bisected the failures (except for `fit/graph2dfit.C` and `hist/hstack.C`, which will be taken care of by https://github.com/root-project/root/pull/11830) to commit 3ac1d584c821d21e4fae789f595eddf5833848c0. @linev do you see an obvious problem / have an idea?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11822
