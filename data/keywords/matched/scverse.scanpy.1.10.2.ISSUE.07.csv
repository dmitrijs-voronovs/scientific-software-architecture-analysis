id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/669:1689,usability,tool,tool,1689,"Proper way to calculate differential gene expression after batch alignment?; Hi, . I was wondering what is a good/accepted way to calculate differential gene expression after batch alignment of multiple datasets? After reading into it, it seems to me that the DEG are calculated on the raw (=non batch corrected values) and after all some batch correction algorithms don't even transform the data matrix (I don't understand why). See: [Mnn correct docs](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.external.pp.mnn_correct.html), [Seurat issue](https://github.com/satijalab/seurat/issues/1224#issuecomment-473416336), [Harmony preprint](https://www.biorxiv.org/content/biorxiv/early/2018/11/05/461954.full.pdf). But that means I would need to include _batch_ as an interaction in the DEG calculation, therefore I could use _logistic regression_ in scanpy with:. `scanpy.tl.rank_genes_groups(adata, use_raw=True, method='logreg')`. I am struggling though to find out how to add interactions to sklearns logistic regression via scanpy. When using sklearn directly it should work through [patsy or PolynomialFeatures()](https://stackoverflow.com/questions/45828964/how-to-add-interaction-term-in-python-sklearn). [Others](https://github.com/theislab/scanpy/issues/95) seem to use sklearn without the wrapper. Or maybe I don't need to add interactions if the biological difference between the samples is bigger than the batch effect? Do you think this is the right way to do this and could you point me in the right direction to solve this? I think this might actually be not an _issue_ of scanpy but more a matter of understanding how to properly do this and how to use the tool so no worries if you decide to close this. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669
https://github.com/scverse/scanpy/issues/669:1725,usability,close,close,1725,"Proper way to calculate differential gene expression after batch alignment?; Hi, . I was wondering what is a good/accepted way to calculate differential gene expression after batch alignment of multiple datasets? After reading into it, it seems to me that the DEG are calculated on the raw (=non batch corrected values) and after all some batch correction algorithms don't even transform the data matrix (I don't understand why). See: [Mnn correct docs](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.external.pp.mnn_correct.html), [Seurat issue](https://github.com/satijalab/seurat/issues/1224#issuecomment-473416336), [Harmony preprint](https://www.biorxiv.org/content/biorxiv/early/2018/11/05/461954.full.pdf). But that means I would need to include _batch_ as an interaction in the DEG calculation, therefore I could use _logistic regression_ in scanpy with:. `scanpy.tl.rank_genes_groups(adata, use_raw=True, method='logreg')`. I am struggling though to find out how to add interactions to sklearns logistic regression via scanpy. When using sklearn directly it should work through [patsy or PolynomialFeatures()](https://stackoverflow.com/questions/45828964/how-to-add-interaction-term-in-python-sklearn). [Others](https://github.com/theislab/scanpy/issues/95) seem to use sklearn without the wrapper. Or maybe I don't need to add interactions if the biological difference between the samples is bigger than the batch effect? Do you think this is the right way to do this and could you point me in the right direction to solve this? I think this might actually be not an _issue_ of scanpy but more a matter of understanding how to properly do this and how to use the tool so no worries if you decide to close this. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669
https://github.com/scverse/scanpy/issues/670:7,availability,Cluster,Clustering,7,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:113,availability,cluster,clustering,113,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:259,availability,cluster,clusters,259,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:351,availability,cluster,cluster,351,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:7,deployability,Cluster,Clustering,7,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:113,deployability,cluster,clustering,113,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:139,deployability,modul,modularity,139,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:186,deployability,modul,modularity,186,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:259,deployability,cluster,clusters,259,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:351,deployability,cluster,cluster,351,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:130,energy efficiency,optim,optimize,130,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:385,energy efficiency,optim,optimum,385,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:139,integrability,modular,modularity,139,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:186,integrability,modular,modularity,186,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:139,modifiability,modul,modularity,139,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:186,modifiability,modul,modularity,186,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:221,modifiability,paramet,parameter,221,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:402,modifiability,paramet,parameter,402,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:130,performance,optimiz,optimize,130,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:139,safety,modul,modularity,139,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:186,safety,modul,modularity,186,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:169,security,access,access,169,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:139,testability,modula,modularity,139,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/670:186,testability,modula,modularity,186,"Scanpy Clustering; Hi,. I have few queries regarding scanpy. 1. As scanpy is using Louvain Leiden algorithms for clustering which optimize modularity 'Q', so how we can access and print modularity funciton? 2. Resolution parameter gave us different number of clusters when we iterated between the best suggested 0.6-1.2. So how we know best number of cluster and how we can choose the optimum value of parameter 'resolution'? Thanks,. Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670
https://github.com/scverse/scanpy/issues/671:156,interoperability,stub,stub,156,"log_transformed parameter seems to not be used in rank_genes_groups; Hi,. the parameter `log_transformed` looks as it's not used inside the method. Is it a stub or is it used in other ways? https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/671
https://github.com/scverse/scanpy/issues/671:16,modifiability,paramet,parameter,16,"log_transformed parameter seems to not be used in rank_genes_groups; Hi,. the parameter `log_transformed` looks as it's not used inside the method. Is it a stub or is it used in other ways? https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/671
https://github.com/scverse/scanpy/issues/671:78,modifiability,paramet,parameter,78,"log_transformed parameter seems to not be used in rank_genes_groups; Hi,. the parameter `log_transformed` looks as it's not used inside the method. Is it a stub or is it used in other ways? https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/671
https://github.com/scverse/scanpy/issues/671:156,testability,stub,stub,156,"log_transformed parameter seems to not be used in rank_genes_groups; Hi,. the parameter `log_transformed` looks as it's not used inside the method. Is it a stub or is it used in other ways? https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/671
https://github.com/scverse/scanpy/issues/671:278,usability,tool,tools,278,"log_transformed parameter seems to not be used in rank_genes_groups; Hi,. the parameter `log_transformed` looks as it's not used inside the method. Is it a stub or is it used in other ways? https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/671
https://github.com/scverse/scanpy/issues/672:27,deployability,scale,scale,27,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:243,deployability,scale,scales,243,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:27,energy efficiency,scale,scale,27,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:243,energy efficiency,scale,scales,243,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:27,modifiability,scal,scale,27,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:243,modifiability,scal,scales,243,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:27,performance,scale,scale,27,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:243,performance,scale,scales,243,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/672:410,usability,user,user-images,410,"sc.pl.stacked_violin weird scale; I have an anndata called violin_adata like this:. AnnData object with n_obs × n_vars = 2995 × 10 . obs: 'louvain'. All values in this adata is between 0 and 1; however when I plot the violin plot, it gets the scales to negative or 2. What should I adjust? `ax = sc.pl.stacked_violin(violin_adata, genes,. groupby='louvain',dendrogram=True,swap_axes=True). `. ![image](https://user-images.githubusercontent.com/10880134/58738109-4321fc80-83b9-11e9-9fdd-52b367290cad.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/672
https://github.com/scverse/scanpy/issues/674:748,deployability,version,version,748,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:821,deployability,version,versions,821,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:137,integrability,messag,messages,137,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:540,integrability,messag,message,540,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:581,integrability,messag,message,581,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:748,integrability,version,version,748,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:821,integrability,version,versions,821,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:137,interoperability,messag,messages,137,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:540,interoperability,messag,message,540,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:581,interoperability,messag,message,581,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:192,modifiability,paramet,parameters,192,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:618,modifiability,pac,package,618,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:748,modifiability,version,version,748,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:821,modifiability,version,versions,821,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:205,safety,test,test,205,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:216,safety,test,test,216,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:205,testability,test,test,205,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:216,testability,test,test,216,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:702,usability,learn,learn,702,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/issues/674:929,usability,learn,learn,929,"RuntimeWarning: invalid value encountered in greater return (self.a < x) & (x < self.b); Hello everyone,. I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less. return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal. cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674
https://github.com/scverse/scanpy/pull/676:0,deployability,Log,Logging,0,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:156,deployability,log,logging,156,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:597,deployability,log,logging,597,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:642,deployability,log,loglevel,642,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:720,deployability,log,log,720,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:520,integrability,messag,message,520,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:263,interoperability,format,formatter,263,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:520,interoperability,messag,message,520,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:0,safety,Log,Logging,0,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:156,safety,log,logging,156,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:597,safety,log,logging,597,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:642,safety,log,loglevel,642,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:720,safety,log,log,720,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:0,security,Log,Logging,0,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:156,security,log,logging,156,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:333,security,hack,hackily,333,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:597,security,log,logging,597,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:642,security,log,loglevel,642,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:720,security,log,log,720,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:0,testability,Log,Logging,0,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:156,testability,log,logging,156,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:597,testability,log,logging,597,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:642,testability,log,loglevel,642,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/pull/676:720,testability,log,log,720,"Logging overhaul; Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct? If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676
https://github.com/scverse/scanpy/issues/677:195,availability,error,error,195,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:550,deployability,version,versions,550,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:582,deployability,Version,Versions,582,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:843,deployability,version,versions,843,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:875,deployability,Version,Versions,875,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1770,deployability,updat,updated,1770,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:20,integrability,compon,components,20,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:120,integrability,compon,components,120,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:146,integrability,compon,components,146,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:288,integrability,compon,components,288,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:522,integrability,compon,components,522,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:550,integrability,version,versions,550,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:582,integrability,Version,Versions,582,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:843,integrability,version,versions,843,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:875,integrability,Version,Versions,875,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1089,integrability,compon,components,1089,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1705,integrability,compon,components,1705,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:20,interoperability,compon,components,20,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:120,interoperability,compon,components,120,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:146,interoperability,compon,components,146,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:288,interoperability,compon,components,288,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:522,interoperability,compon,components,522,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1089,interoperability,compon,components,1089,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1705,interoperability,compon,components,1705,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:20,modifiability,compon,components,20,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:31,modifiability,paramet,parameter,31,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:120,modifiability,compon,components,120,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:146,modifiability,compon,components,146,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:164,modifiability,paramet,parameter,164,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:288,modifiability,compon,components,288,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:522,modifiability,compon,components,522,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:550,modifiability,version,versions,550,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:582,modifiability,Version,Versions,582,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:614,modifiability,pac,packages,614,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:843,modifiability,version,versions,843,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:875,modifiability,Version,Versions,875,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:907,modifiability,pac,packages,907,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1089,modifiability,compon,components,1089,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1101,modifiability,layer,layer,1101,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1705,modifiability,compon,components,1705,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:195,performance,error,error,195,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:195,safety,error,error,195,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1770,safety,updat,updated,1770,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1608,security,sign,signature,1608,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1770,security,updat,updated,1770,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:395,testability,Trace,Traceback,395,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:42,usability,document,documentation,42,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:195,usability,error,error,195,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/issues/677:1746,usability,document,documentation,1746,"umap 3d projection (components parameter) documentation is misleading; Hi,. I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter. However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). in . 1 #%%. ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 283 """""". --> 284 return plot_scatter(adata, 'umap', **kwargs). 285 . 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 191 if projection == '3d':. 192 cax = ax.scatter(. --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],. 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2. ```. I was able to plot in 3d by changing it to the following method signature:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']). ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677
https://github.com/scverse/scanpy/pull/678:55,integrability,compon,components,55,fix for #677; This PR correctly returns lists of three components when `projection=3d` is set together with `components=all`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/678
https://github.com/scverse/scanpy/pull/678:109,integrability,compon,components,109,fix for #677; This PR correctly returns lists of three components when `projection=3d` is set together with `components=all`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/678
https://github.com/scverse/scanpy/pull/678:55,interoperability,compon,components,55,fix for #677; This PR correctly returns lists of three components when `projection=3d` is set together with `components=all`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/678
https://github.com/scverse/scanpy/pull/678:109,interoperability,compon,components,109,fix for #677; This PR correctly returns lists of three components when `projection=3d` is set together with `components=all`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/678
https://github.com/scverse/scanpy/pull/678:55,modifiability,compon,components,55,fix for #677; This PR correctly returns lists of three components when `projection=3d` is set together with `components=all`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/678
https://github.com/scverse/scanpy/pull/678:109,modifiability,compon,components,109,fix for #677; This PR correctly returns lists of three components when `projection=3d` is set together with `components=all`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/678
https://github.com/scverse/scanpy/issues/680:18,availability,Cluster,Clusters,18,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:159,availability,cluster,clusters,159,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:315,availability,cluster,clusters,315,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:550,availability,cluster,cluster,550,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:18,deployability,Cluster,Clusters,18,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:44,deployability,manag,managed,44,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:159,deployability,cluster,clusters,159,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:292,deployability,integr,integrating,292,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:315,deployability,cluster,clusters,315,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:550,deployability,cluster,cluster,550,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:44,energy efficiency,manag,managed,44,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:292,integrability,integr,integrating,292,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:292,interoperability,integr,integrating,292,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:292,modifiability,integr,integrating,292,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:345,performance,perform,perform,345,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:692,performance,perform,perform,692,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:292,reliability,integr,integrating,292,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:44,safety,manag,managed,44,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:168,security,ident,identified,168,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:292,security,integr,integrating,292,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:292,testability,integr,integrating,292,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:345,usability,perform,perform,345,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:447,usability,user,user-images,447,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/680:692,usability,perform,perform,692,"PAGA using Seurat Clusters; Hello, . I have managed to get my Seurat object converted into Loom and then read into Scanpy. Now my main objective is to use the clusters identified using Seurat in order to create a PAGA trajectory map. I was able to do a similar thing for Seurat -> Monocle by integrating the Seurat clusters and allow Monocle to perform a trajectory analysis on them. . I have the following Scanpy object:. ![scanpy_adata](https://user-images.githubusercontent.com/11708268/58907732-7a075380-86d4-11e9-9f2a-4c539ea58c80.png). All the cluster information along with cell ids are present in the obs part of the Scanpy object. Is there anyway to use that information in order to perform a PAGA trajectory analysis? Thank you,. Behram.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680
https://github.com/scverse/scanpy/issues/681:169,deployability,version,version,169,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:182,deployability,depend,dependencies,182,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:169,integrability,version,version,169,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:182,integrability,depend,dependencies,182,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:169,modifiability,version,version,169,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:182,modifiability,depend,dependencies,182,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:182,safety,depend,dependencies,182,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:182,testability,depend,dependencies,182,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:256,usability,command,commands,256,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:381,usability,user,user-images,381,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/681:576,usability,user,user-images,576,"Different results in manifold topology; Hi. I have a problem with reproducing my analysis using scanpy 1.4.3. I have used two different machines using the same software version (all dependencies as well), and I keep having different results using the same commands and seed numbers. In one machine I get this:. <img width=""340"" alt=""Screenshot 2019-06-05 at 15 44 31"" src=""https://user-images.githubusercontent.com/3297906/58965800-13a03500-87a9-11e9-8a7c-bec104f4718e.png"">. and in the other I get this:. <img width=""334"" alt=""Screenshot 2019-06-05 at 15 44 14"" src=""https://user-images.githubusercontent.com/3297906/58965827-1e5aca00-87a9-11e9-95e5-90c09303a1c2.png"">. Can you recommend which aspects to check? or how to deal with this issue? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681
https://github.com/scverse/scanpy/issues/682:292,availability,cluster,clusters,292,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:373,availability,cluster,clusters,373,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:84,deployability,API,API,84,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:292,deployability,cluster,clusters,292,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:373,deployability,cluster,clusters,373,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:84,integrability,API,API,84,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:84,interoperability,API,API,84,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:211,testability,simul,simulated,211,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/issues/682:221,testability,simul,simulated,221,"How to plot with paga_path, sorted by pseudo_time; I would like to use the plotting API of `paga_path()` like in [this tutorial (last figure)](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/simulated/simulated.ipynb). However, I noticed that cells are being sorted intra-clusters. I would like to sort only by ""distance"" (pseudotime), but keeping the ""clusters"" annotation. Is it possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/682
https://github.com/scverse/scanpy/pull/683:0,integrability,Filter,Filter,0,Filter warning from rank_genes_groups; Filtered warning for when all zero genes have a t-test run on them. There may be a more elegant solution for this.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/683
https://github.com/scverse/scanpy/pull/683:39,integrability,Filter,Filtered,39,Filter warning from rank_genes_groups; Filtered warning for when all zero genes have a t-test run on them. There may be a more elegant solution for this.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/683
https://github.com/scverse/scanpy/pull/683:89,safety,test,test,89,Filter warning from rank_genes_groups; Filtered warning for when all zero genes have a t-test run on them. There may be a more elegant solution for this.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/683
https://github.com/scverse/scanpy/pull/683:89,testability,test,test,89,Filter warning from rank_genes_groups; Filtered warning for when all zero genes have a t-test run on them. There may be a more elegant solution for this.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/683
https://github.com/scverse/scanpy/issues/684:4,deployability,log,logging,4,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:42,deployability,log,logging,42,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:50,deployability,modul,module,50,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:50,modifiability,modul,module,50,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:4,safety,log,logging,4,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:42,safety,log,logging,42,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:50,safety,modul,module,50,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:4,security,log,logging,4,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:42,security,log,logging,42,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:4,testability,log,logging,4,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:42,testability,log,logging,42,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/issues/684:261,usability,user,user-images,261,"New logging clutters output; The rehauled logging module tends to clutter output, see, for instance. ```. import scanpy as sc. sc.settings.verbosity = 2. adata_sc = sc.datasets.pbmc68k_reduced(). sc.pp.neighbors(adata_sc). ```. which produces. ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684
https://github.com/scverse/scanpy/pull/685:24,safety,test,tests,24,"Move adding `--internet-tests` option back to `conftest.py`; `pytest_addoption` and `pytest_collection_modifyitems` have to be defined where `pytest` gets called from, otherwise they don't work. @flying-sheep, I saw you had changed this in d979267f48607fd609954c96cd5c586b6135dc30. Was there a functional reason you moved these things, or was it aesthetic?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/685
https://github.com/scverse/scanpy/pull/685:24,testability,test,tests,24,"Move adding `--internet-tests` option back to `conftest.py`; `pytest_addoption` and `pytest_collection_modifyitems` have to be defined where `pytest` gets called from, otherwise they don't work. @flying-sheep, I saw you had changed this in d979267f48607fd609954c96cd5c586b6135dc30. Was there a functional reason you moved these things, or was it aesthetic?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/685
https://github.com/scverse/scanpy/pull/685:346,usability,aesthet,aesthetic,346,"Move adding `--internet-tests` option back to `conftest.py`; `pytest_addoption` and `pytest_collection_modifyitems` have to be defined where `pytest` gets called from, otherwise they don't work. @flying-sheep, I saw you had changed this in d979267f48607fd609954c96cd5c586b6135dc30. Was there a functional reason you moved these things, or was it aesthetic?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/685
https://github.com/scverse/scanpy/issues/686:19,deployability,fail,fails,19,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:403,deployability,fail,fails,403,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:530,deployability,modul,module,530,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:820,integrability,compon,components,820,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:820,interoperability,compon,components,820,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:61,modifiability,paramet,parameter,61,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:530,modifiability,modul,module,530,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:721,modifiability,pac,packages,721,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:820,modifiability,compon,components,820,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:19,reliability,fail,fails,19,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:403,reliability,fail,fails,403,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:428,safety,except,exception,428,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:504,safety,input,input-,504,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:530,safety,modul,module,530,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:460,testability,Trace,Traceback,460,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/686:504,usability,input,input-,504,"sc.pl.paga_compare fails when color is different than groups parameter of sc.tl.paga; When I run the following code:. ```python. import scanpy as sc. sc.set_figure_params(dpi=70). adata = sc.datasets.paul15(). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.tl.leiden(adata). sc.tl.paga(adata, groups='paul15_clusters'). print(adata.uns['paga'].keys()). sc.pl.paga_compare(adata, color='leiden'). ```. It fails with the following exception:. ```python. KeyError Traceback (most recent call last). <ipython-input-1-5ec08bc29df7> in <module>. 7 sc.tl.leiden(adata). 8 sc.tl.paga(adata, groups='paul15_clusters'). ----> 9 sc.pl.paga_compare(adata, color='leiden'). 10 adata.uns['paga'].keys(). ~/.anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 108 paga_graph_params['pos'] = utils._tmp_cluster_pos. 109 else:. --> 110 paga_graph_params['pos'] = adata.uns['paga']['pos']. 111 xlim, ylim = axs[0].get_xlim(), axs[0].get_ylim(). 112 axs[1].set_xlim(xlim). KeyError: 'pos'. ```. and it prints:. ```. dict_keys(['connectivities', 'connectivities_tree', 'groups']). ```. @falexwolf might have broken this with https://github.com/theislab/scanpy/commit/504b87e57327be8824d0697b92bac30fd86f0a82 :) but I didn't fully debug.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/686
https://github.com/scverse/scanpy/issues/687:248,availability,error,error,248,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:111,deployability,instal,installed,111,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:136,deployability,instal,install,136,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:429,deployability,modul,module,429,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:596,deployability,modul,module,596,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:565,interoperability,distribut,distributions,565,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:56,modifiability,pac,package,56,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:429,modifiability,modul,module,429,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:544,modifiability,pac,packages,544,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:596,modifiability,modul,module,596,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:248,performance,error,error,248,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:248,safety,error,error,248,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:402,safety,input,input-,402,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:429,safety,modul,module,429,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:596,safety,modul,module,596,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:358,testability,Trace,Traceback,358,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:248,usability,error,error,248,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/687:402,usability,input,input-,402,"scipy.misc factorial is depreciated; Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:. ----------------------------------------------------------------------------------------. ImportError Traceback (most recent call last). <ipython-input-54-c0d016811ded> in <module>(). ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames. /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(). 5 import numpy as np. 6 from numpy.polynomial.hermite_e import HermiteE. ----> 7 from scipy.misc import factorial. 8 from scipy.stats import rv_continuous. 9 import scipy.special as special. ImportError: cannot import name 'factorial'. ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687
https://github.com/scverse/scanpy/issues/688:254,availability,replic,replicated,254,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2522,availability,error,errors,2522,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:62,deployability,version,version,62,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:199,deployability,build,builds,199,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:217,deployability,build,builds,217,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:227,deployability,fail,fail,227,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:268,deployability,build,building,268,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:300,deployability,contain,container,300,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:386,deployability,contain,container,386,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:540,deployability,contain,container,540,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:628,deployability,contain,container,628,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:941,deployability,api,api,941,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:1374,deployability,fail,failed,1374,"uilt the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:62,integrability,version,version,62,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:941,integrability,api,api,941,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:941,interoperability,api,api,941,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:62,modifiability,version,version,62,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:1222,modifiability,pac,packages,1222," fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated be",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:1531,modifiability,pac,packages,1531,"paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:1752,modifiability,pac,packages,1752,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:1916,modifiability,pac,packages,1916,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2046,modifiability,pac,packages,2046,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2428,modifiability,pac,packages,2428,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2522,performance,error,errors,2522,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:227,reliability,fail,fail,227,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:1374,reliability,fail,failed,1374,"uilt the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:741,safety,input,input,741,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:769,safety,input,input,769,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:888,safety,input,input,888,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2195,safety,detect,detected,2195,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2522,safety,error,errors,2522,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2195,security,detect,detected,2195,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:357,testability,simpl,simplicity,357,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:357,usability,simpl,simplicity,357,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:451,usability,Minim,Minimum,451,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:741,usability,input,input,741,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:769,usability,input,input,769,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:888,usability,input,input,888,"Untyped global name 'nearest_neighbors'; With the most recent version of scanpy, I'm getting the above mentioned warning, which causes the [`dynverse/ti_paga`](https://travis-ci.org/dynverse/ti_paga/builds/544731805) builds to fail. . The problem can be replicated by building the `dynverse/ti_paga` container manually and trying to run it. For the sake of simplicity, I have built the container for you and pushed it to `dynverse/ti_paga_issue`. ### Minimum reproducible example. Inside terminal:. ```bash. # fetch newest dynverse/ti_paga container in which this problem occurs. docker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2224,usability,behavi,behaviour,2224,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2367,usability,behavi,behaviour-when-using-jit,2367,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/688:2522,usability,error,errors,2522,"ocker pull dynverse/ti_paga_issue. # enter the container . docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5. /code/example.sh /input.h5. # enter python. python. ```. Inside python. ```python. import dynclipy. task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc. import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts). sc.pp.recipe_zheng17(adata, n_top_genes=101). sc.tl.pca(adata, n_comps=50). sc.pp.neighbors(adata, n_neighbors=15). ```. Which generates the following warning:. ```. /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688
https://github.com/scverse/scanpy/issues/689:9,availability,avail,available,9,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:29,modifiability,paramet,parameter,29,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:156,performance,perform,perform,156,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:9,reliability,availab,available,9,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:9,safety,avail,available,9,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:9,security,availab,available,9,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:43,usability,tool,tool,43,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:93,usability,tool,tool,93,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:118,usability,tool,tool,118,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/689:156,usability,perform,perform,156,"UMAP: no available 'use_rep' parameter for tool.umap() ; Hi,. I found there is 'use_rep' for tool.tsne(), but not for tool.umap(). Is there any solution to perform umap on a selected anndata's obsm? Thanks in advance,. BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689
https://github.com/scverse/scanpy/issues/690:343,deployability,version,version,343,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/690:343,integrability,version,version,343,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/690:272,modifiability,layer,layer,272,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/690:278,modifiability,layer,layers,278,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/690:343,modifiability,version,version,343,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/690:390,modifiability,layer,layer,390,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/690:432,modifiability,layer,layer,432,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/690:363,security,access,access,363,"Warning sc.pl.scatter; Hi I got this warning when I used sc.pl.scatter:. ```. .../scanpy/plotting/_anndata.py:311: DeprecationWarning: Use obs_vector instead of _get_obs_array, _get_obs_array will be removed in the future. x_arr = adata._get_obs_array(x, use_raw=use_raw, layer=layers[0]). .../anndata/base.py:1618: FutureWarning: In a future version of AnnData, access to `.X` by passing `layer='X'` will be removed. Instead pass `layer=None`. FutureWarning. ```. I would like to know if the plots generated with this warning are correct. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/690
https://github.com/scverse/scanpy/issues/691:56,availability,cluster,cluster,56,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:504,availability,error,error,504,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:56,deployability,cluster,cluster,56,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:139,energy efficiency,model,model,139,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:11,integrability,batch,batch,11,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:111,integrability,batch,batch,111,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:197,integrability,batch,batch,197,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:11,performance,batch,batch,11,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:111,performance,batch,batch,111,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:197,performance,batch,batch,197,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:504,performance,error,error,504,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:504,safety,error,error,504,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:139,security,model,model,139,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:156,security,ident,identification,156,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:97,usability,user,users,97,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/691:504,usability,error,error,504,"Can we use batch as block when finding markers for each cluster?; Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful). Can I do similar things in scanpy? Thanks! I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:. ```. ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings. ```. I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,. BP.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691
https://github.com/scverse/scanpy/issues/695:11,availability,error,error,11,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:471,availability,error,error,471,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:643,deployability,modul,module,643,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:814,energy efficiency,model,model,814,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:156,modifiability,variab,variable,156,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:643,modifiability,modul,module,643,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:742,modifiability,pac,packages,742,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:1098,modifiability,pac,packages,1098,"ed to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:1406,modifiability,pac,packages,1406,"data_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/miniconda3/envs/wot/lib/python3.6/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:1683,modifiability,pac,packages,1683,"put-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/miniconda3/envs/wot/lib/python3.6/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,. TypeError: object of type 'numpy.float64' has no len(). ```. I would be happy about any suggestions. Keep up the nice work! Kevin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:1933,modifiability,pac,packages,1933,"put-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/miniconda3/envs/wot/lib/python3.6/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,. TypeError: object of type 'numpy.float64' has no len(). ```. I would be happy about any suggestions. Keep up the nice work! Kevin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:2208,modifiability,pac,packages,2208,"put-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/miniconda3/envs/wot/lib/python3.6/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,. TypeError: object of type 'numpy.float64' has no len(). ```. I would be happy about any suggestions. Keep up the nice work! Kevin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:11,performance,error,error,11,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:471,performance,error,error,471,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:11,safety,error,error,11,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:471,safety,error,error,471,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:615,safety,input,input-,615,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:643,safety,modul,module,643,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:814,security,model,model,814,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:571,testability,Trace,Traceback,571,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:11,usability,error,error,11,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:193,usability,command,commands,193,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:471,usability,error,error,471,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:615,usability,input,input-,615,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:758,usability,tool,tools,758,"sc.tl.PAGA error: object of type 'numpy.float64' has no len(); After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:1114,usability,tool,tools,1114,"to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:. ```python. sc.pp.neighbors(adata_hvg). sc.tl.louvain(adata_hvg). sc.tl.draw_graph(adata_hvg). ```. Till here, everything works nicely, but then I try to get the PAGA representation:. ```python. sc.tl.paga(adata_hvg, groups=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 79",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/695:1422,usability,tool,tools,1422,"s=""louvain""). ```. This returns the following error:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-249-7cc787ba28f9> in <module>. ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/miniconda3/envs/wot/lib/python3.6/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695
https://github.com/scverse/scanpy/issues/696:67,deployability,updat,updating,67,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:345,deployability,modul,module,345,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:507,energy efficiency,model,model,507,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:345,modifiability,modul,module,345,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:435,modifiability,pac,packages,435,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:787,modifiability,pac,packages,787,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:1091,modifiability,pac,packages,1091,"get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:1364,modifiability,pac,packages,1364,"----------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,. TypeError: object of type 'numpy.float64' has no len()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:1610,modifiability,pac,packages,1610,"----------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,. TypeError: object of type 'numpy.float64' has no len()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:1881,modifiability,pac,packages,1881,"----------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,. TypeError: object of type 'numpy.float64' has no len()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:67,safety,updat,updating,67,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:317,safety,input,input-,317,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:345,safety,modul,module,345,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:67,security,updat,updating,67,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:507,security,model,model,507,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:273,testability,Trace,Traceback,273,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:317,usability,input,input-,317,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:451,usability,tool,tools,451,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:803,usability,tool,tools,803,"PAGA TypeError: object of type 'numpy.float64' has no len(); After updating to Scanpy v1.4.3 I get this TypeError when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/696:1107,usability,tool,tools,1107,"ror when running tl.paga. sc.tl.paga(adata, groups='leiden'). running PAGA. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-185-c12b5d98b62c> in <module>. ----> 1 sc.tl.paga(adata, groups='leiden'). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 93 adata.uns['paga'] = {}. 94 if not use_rna_velocity:. ---> 95 paga.compute_connectivities(). 96 adata.uns['paga']['connectivities'] = paga.connectivities. 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in compute_connectivities(self). 127 def compute_connectivities(self):. 128 if self._model == 'v1.2':. --> 129 return self._compute_connectivities_v1_2(). 130 elif self._model == 'v1.0':. 131 return self._compute_connectivities_v1_0(). ~/Library/Python/3.7/lib/python/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self). 161 if scaled_value > 1:. 162 scaled_value = 1. --> 163 connectivities[i, j] = scaled_value. 164 expected_n_edges[i, j] = expected_random_null. 165 # set attributes. ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x). 67 if x.size != 1:. 68 raise ValueError('Trying to assign a sequence to an item'). ---> 69 self._set_intXint(row, col, x.flat[0]). 70 return. 71 . ~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x). 795 def _set_intXint(self, row, col, x):. 796 i, j = self._swap((row, col)). --> 797 self._set_many(i, j, x). 798 . 799 def _set_arrayXarray(self, row, col, x):. ~/Library/Python/3.7/lib/python/site-packages/anndata/h5py/h5sparse.py in _set_many(self, i, j, x). 176 i, j, M, N = self._prepare_indices(i, j). 177 . --> 178 n_samples = len(x). 179 offsets = np.empty(n_samples, dtype=self.indices.dtype). 180 ret = _sparsetools.cs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/696
https://github.com/scverse/scanpy/issues/697:160,usability,support,supported,160,"Development roadmap; Hi all, this is not really an issue, but is there a development roadmap for scanpy? What features are going to be added? What data will be supported? Is github the right place to discuss this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/697
https://github.com/scverse/scanpy/issues/698:18,safety,test,test,18,"Wilcoxon-Rank-Sum test in rank_genes_groups: suspicious code & ties not corrected; Hi,. Thanks a lot for the library. We're having some issues with Wilcoxon-Rank-Sum test in `rank_genes_groups`. And I noticed a suspicious code in the [implementation](https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L311):. ```. scores[left:right] = np.sum(ranks.loc[0:n_active, :]). ```. Shouldn't it be `.iloc`? Additionally, it seems there is no tie correction in the code. I think for sparse data correction this could be an issue. ![image](https://user-images.githubusercontent.com/671660/59773834-9ac3d180-92ae-11e9-9530-b8d271bd58e5.png). There is an [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tiecorrect.html?highlight=tiecorrect#scipy.stats.tiecorrect) of `tiecorrect` in scipy. Thanks,. Iakov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698
https://github.com/scverse/scanpy/issues/698:166,safety,test,test,166,"Wilcoxon-Rank-Sum test in rank_genes_groups: suspicious code & ties not corrected; Hi,. Thanks a lot for the library. We're having some issues with Wilcoxon-Rank-Sum test in `rank_genes_groups`. And I noticed a suspicious code in the [implementation](https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L311):. ```. scores[left:right] = np.sum(ranks.loc[0:n_active, :]). ```. Shouldn't it be `.iloc`? Additionally, it seems there is no tie correction in the code. I think for sparse data correction this could be an issue. ![image](https://user-images.githubusercontent.com/671660/59773834-9ac3d180-92ae-11e9-9530-b8d271bd58e5.png). There is an [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tiecorrect.html?highlight=tiecorrect#scipy.stats.tiecorrect) of `tiecorrect` in scipy. Thanks,. Iakov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698
https://github.com/scverse/scanpy/issues/698:18,testability,test,test,18,"Wilcoxon-Rank-Sum test in rank_genes_groups: suspicious code & ties not corrected; Hi,. Thanks a lot for the library. We're having some issues with Wilcoxon-Rank-Sum test in `rank_genes_groups`. And I noticed a suspicious code in the [implementation](https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L311):. ```. scores[left:right] = np.sum(ranks.loc[0:n_active, :]). ```. Shouldn't it be `.iloc`? Additionally, it seems there is no tie correction in the code. I think for sparse data correction this could be an issue. ![image](https://user-images.githubusercontent.com/671660/59773834-9ac3d180-92ae-11e9-9530-b8d271bd58e5.png). There is an [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tiecorrect.html?highlight=tiecorrect#scipy.stats.tiecorrect) of `tiecorrect` in scipy. Thanks,. Iakov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698
https://github.com/scverse/scanpy/issues/698:166,testability,test,test,166,"Wilcoxon-Rank-Sum test in rank_genes_groups: suspicious code & ties not corrected; Hi,. Thanks a lot for the library. We're having some issues with Wilcoxon-Rank-Sum test in `rank_genes_groups`. And I noticed a suspicious code in the [implementation](https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L311):. ```. scores[left:right] = np.sum(ranks.loc[0:n_active, :]). ```. Shouldn't it be `.iloc`? Additionally, it seems there is no tie correction in the code. I think for sparse data correction this could be an issue. ![image](https://user-images.githubusercontent.com/671660/59773834-9ac3d180-92ae-11e9-9530-b8d271bd58e5.png). There is an [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tiecorrect.html?highlight=tiecorrect#scipy.stats.tiecorrect) of `tiecorrect` in scipy. Thanks,. Iakov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698
https://github.com/scverse/scanpy/issues/698:339,usability,tool,tools,339,"Wilcoxon-Rank-Sum test in rank_genes_groups: suspicious code & ties not corrected; Hi,. Thanks a lot for the library. We're having some issues with Wilcoxon-Rank-Sum test in `rank_genes_groups`. And I noticed a suspicious code in the [implementation](https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L311):. ```. scores[left:right] = np.sum(ranks.loc[0:n_active, :]). ```. Shouldn't it be `.iloc`? Additionally, it seems there is no tie correction in the code. I think for sparse data correction this could be an issue. ![image](https://user-images.githubusercontent.com/671660/59773834-9ac3d180-92ae-11e9-9530-b8d271bd58e5.png). There is an [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tiecorrect.html?highlight=tiecorrect#scipy.stats.tiecorrect) of `tiecorrect` in scipy. Thanks,. Iakov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698
https://github.com/scverse/scanpy/issues/698:604,usability,user,user-images,604,"Wilcoxon-Rank-Sum test in rank_genes_groups: suspicious code & ties not corrected; Hi,. Thanks a lot for the library. We're having some issues with Wilcoxon-Rank-Sum test in `rank_genes_groups`. And I noticed a suspicious code in the [implementation](https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L311):. ```. scores[left:right] = np.sum(ranks.loc[0:n_active, :]). ```. Shouldn't it be `.iloc`? Additionally, it seems there is no tie correction in the code. I think for sparse data correction this could be an issue. ![image](https://user-images.githubusercontent.com/671660/59773834-9ac3d180-92ae-11e9-9530-b8d271bd58e5.png). There is an [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tiecorrect.html?highlight=tiecorrect#scipy.stats.tiecorrect) of `tiecorrect` in scipy. Thanks,. Iakov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698
https://github.com/scverse/scanpy/issues/699:162,deployability,log,logging,162,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:276,deployability,scale,scale,276,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:584,deployability,scale,scale,584,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:723,deployability,modul,module,723,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:844,deployability,scale,scale,844,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:851,deployability,scale,scale,851,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1037,deployability,scale,scale,1037,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1189,deployability,scale,scale,1189,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1195,deployability,scale,scale,1195,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:276,energy efficiency,scale,scale,276,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:584,energy efficiency,scale,scale,584,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:844,energy efficiency,scale,scale,844,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:851,energy efficiency,scale,scale,851,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1037,energy efficiency,scale,scale,1037,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1189,energy efficiency,scale,scale,1189,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1195,energy efficiency,scale,scale,1195,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:90,integrability,sub,subsetted,90,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:276,modifiability,scal,scale,276,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:486,modifiability,pac,packages,486,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:584,modifiability,scal,scale,584,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:723,modifiability,modul,module,723,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:788,modifiability,pac,packages,788,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:844,modifiability,scal,scale,844,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:851,modifiability,scal,scale,851,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:981,modifiability,pac,packages,981,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1037,modifiability,scal,scale,1037,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1124,modifiability,pac,packages,1124,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1189,modifiability,scal,scale,1189,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1195,modifiability,scal,scale,1195,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1272,modifiability,pac,packages,1272,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:276,performance,scale,scale,276,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:584,performance,scale,scale,584,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:844,performance,scale,scale,844,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:851,performance,scale,scale,851,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1037,performance,scale,scale,1037,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1189,performance,scale,scale,1189,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:1195,performance,scale,scale,1195,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:162,safety,log,logging,162,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:723,safety,modul,module,723,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:162,security,log,logging,162,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:162,testability,log,logging,162,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:659,testability,Trace,Traceback,659,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/699:402,usability,learn,learn,402,"""IndexError: boolean index did not match indexed array along dimension"" when working with subsetted anndata object; When I run this. ```. import scanpy as sc. sc.logging.print_versions(). pbmc = sc.datasets.pbmc68k_reduced(). pbmc = pbmc[pbmc.obs['louvain'] == '0', :]. sc.pp.scale(pbmc). ```. I get this. ```. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0. /stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:1120: RuntimeWarning: invalid value encountered in sqrt. scale = np.sqrt(var). Trying to set attribute `.X` of view, making a copy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 860, in scale. scale(adata.X, zero_center=zero_center, max_value=max_value, copy=False). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 876, in scale. _scale(X, zero_center). File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 1126, in _scale. scale[scale == 0] = 1e-12. File ""/stor/home/ericb123/miniconda3/lib/python3.7/site-packages/anndata/base.py"", line 392, in __setitem__. getattr(adata_view, attr_name)[idx] = value. IndexError: boolean index did not match indexed array along dimension 0; dimension is 130 but corresponding boolean dimension is 765. ```. Any idea what's going on? Thanks,. -Eric.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/699
https://github.com/scverse/scanpy/issues/700:22,availability,error,error,22,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:157,availability,error,error,157,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:202,deployability,releas,release,202,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:615,deployability,modul,module,615,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:194,energy efficiency,current,current,194,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1259,integrability,compon,components,1259,"py as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1259,interoperability,compon,components,1259,"py as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1875,interoperability,bind,bind,1875,"gs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4448 if plotnonfinite and colors is None:. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in _parse_scatter_color_args(c, edgecolors, kwargs, xshape, yshape, get_next_color_func). 4249 isinstance(c, str) or. 4250 (isinstance(c, collections.abc.Iterable) and. -> 4251 len(c) > 0 and. 4252 isinstance(cbook.safe_first_element(c), str))):. 4253 c_array = None. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:40,modifiability,layer,layers,40,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:122,modifiability,layer,layer,122,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:137,modifiability,layer,layer,137,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:317,modifiability,layer,layers,317,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:380,modifiability,layer,layer,380,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:615,modifiability,modul,module,615,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:671,modifiability,layer,layers,671,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:742,modifiability,layer,layer,742,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:809,modifiability,pac,packages,809,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1077,modifiability,pac,packages,1077,"r a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1259,modifiability,compon,components,1259,"py as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1271,modifiability,layer,layer,1271,"pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1640,modifiability,pac,packages,1640,".pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4448 if plotnonfinite and colors is None:. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in _parse_scatter_color_args(c, edgecolors, kwargs, xshape, yshape, get_next_color_func). 4249 isinstance(c, str) or. 4250 (isinstance(c, collections.abc.Iterable) and. -> 4251 len(c) > 0 and. 4252 isinstance(cbook.safe_first_element(c), str)))",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1875,modifiability,bind,bind,1875,"gs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4448 if plotnonfinite and colors is None:. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in _parse_scatter_color_args(c, edgecolors, kwargs, xshape, yshape, get_next_color_func). 4249 isinstance(c, str) or. 4250 (isinstance(c, collections.abc.Iterable) and. -> 4251 len(c) > 0 and. 4252 isinstance(cbook.safe_first_element(c), str))):. 4253 c_array = None. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:1952,modifiability,pac,packages,1952," """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4448 if plotnonfinite and colors is None:. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in _parse_scatter_color_args(c, edgecolors, kwargs, xshape, yshape, get_next_color_func). 4249 isinstance(c, str) or. 4250 (isinstance(c, collections.abc.Iterable) and. -> 4251 len(c) > 0 and. 4252 isinstance(cbook.safe_first_element(c), str))):. 4253 c_array = None. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:2366,modifiability,pac,packages,2366,"/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4448 if plotnonfinite and colors is None:. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in _parse_scatter_color_args(c, edgecolors, kwargs, xshape, yshape, get_next_color_func). 4249 isinstance(c, str) or. 4250 (isinstance(c, collections.abc.Iterable) and. -> 4251 len(c) > 0 and. 4252 isinstance(cbook.safe_first_element(c), str))):. 4253 c_array = None. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:2718,modifiability,pac,packages,2718,"/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4448 if plotnonfinite and colors is None:. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in _parse_scatter_color_args(c, edgecolors, kwargs, xshape, yshape, get_next_color_func). 4249 isinstance(c, str) or. 4250 (isinstance(c, collections.abc.Iterable) and. -> 4251 len(c) > 0 and. 4252 isinstance(cbook.safe_first_element(c), str))):. 4253 c_array = None. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:22,performance,error,error,22,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:157,performance,error,error,157,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:22,safety,error,error,22,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:157,safety,error,error,157,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:589,safety,input,input-,589,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:615,safety,modul,module,615,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:2819,safety,except,exception,2819,"/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs). 4444 self._parse_scatter_color_args(. 4445 c, edgecolors, kwargs, xshape, yshape,. -> 4446 get_next_color_func=self._get_patches_for_fill.get_next_color). 4447 . 4448 if plotnonfinite and colors is None:. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in _parse_scatter_color_args(c, edgecolors, kwargs, xshape, yshape, get_next_color_func). 4249 isinstance(c, str) or. 4250 (isinstance(c, collections.abc.Iterable) and. -> 4251 len(c) > 0 and. 4252 isinstance(cbook.safe_first_element(c), str))):. 4253 c_array = None. ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:424,testability,Trace,Traceback,424,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:545,testability,Trace,Traceback,545,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:22,usability,error,error,22,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:157,usability,error,error,157,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/700:589,usability,input,input-,589,"`plot_scatter` throws error when sparse layers used for color; If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.layers[""sparse""] = pbmc.raw.X. sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") . ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-89244dc07987> in <module>. 3 pbmc = sc.datasets.pbmc68k_reduced(). 4 pbmc.layers[""sparse""] = pbmc.raw.X. ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 411 """""". --> 412 return plot_scatter(adata, 'pca', **kwargs). 413 . 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 199 _data_points[:, 0], _data_points[:, 1],. 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 201 **kwargs,. 202 ). 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1587 def inner(ax, *args, data=None, **kwargs):. 1588 if data is None:. -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs). 1590 . 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700
https://github.com/scverse/scanpy/issues/701:90,availability,cluster,clusters,90,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:208,availability,cluster,cluster,208,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:269,availability,cluster,cluster,269,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:382,availability,down,down,382,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:434,availability,down,down,434,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:90,deployability,cluster,clusters,90,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:208,deployability,cluster,cluster,208,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:269,deployability,cluster,cluster,269,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:473,safety,isol,isolate,473,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:473,security,iso,isolate,473,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:517,security,sign,significant,517,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/701:473,testability,isol,isolate,473,"Rank_genes_groups p-values of 1?; After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701
https://github.com/scverse/scanpy/issues/702:188,integrability,batch,batch,188,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/issues/702:328,integrability,batch,batch,328,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/issues/702:188,performance,batch,batch,188,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/issues/702:328,performance,batch,batch,328,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/issues/702:14,usability,workflow,workflow,14,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/issues/702:92,usability,user,user,92,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/issues/702:145,usability,workflow,workflow,145,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/issues/702:154,usability,command,commands,154,"Merge dataset workflow? ; Hi All, . Not really an issue, but I'm very new to SCANPY (Seurat user before this) and was wondering what the general workflow/commands would be for merging and batch correcting multiple datasets together? For example, something like this (but for SCANPY, of course, and including info on merging and batch correcting):. https://satijalab.org/seurat/essential_commands.html. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702
https://github.com/scverse/scanpy/pull/703:536,availability,down,down,536,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:209,energy efficiency,cpu,cpu,209,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:498,energy efficiency,cpu,cpu,498,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:104,performance,time,time,104,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:209,performance,cpu,cpu,209,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:400,performance,time,time,400,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:498,performance,cpu,cpu,498,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:548,performance,time,time,548,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:186,usability,user,user,186,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/703:475,usability,user,user,475,"Defer import of seaborn; Cuts around 1 second off import of scanpy. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn . python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total. isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn . Switched to branch 'master'. Your branch is up to date with 'upstream/master'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master . python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total. ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703
https://github.com/scverse/scanpy/pull/704:91,availability,down,down,91,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:126,deployability,depend,dependency,126,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:147,deployability,depend,dependency,147,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:370,deployability,scale,scale,370,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:6,energy efficiency,load,loading,6,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:370,energy efficiency,scale,scale,370,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:547,energy efficiency,cpu,cpu,547,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:859,energy efficiency,cpu,cpu,859,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:126,integrability,depend,dependency,126,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:147,integrability,depend,dependency,147,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:126,modifiability,depend,dependency,126,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:147,modifiability,depend,dependency,147,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:370,modifiability,scal,scale,370,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:6,performance,load,loading,6,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:85,performance,time,times,85,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:256,performance,time,times,256,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:370,performance,scale,scale,370,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:435,performance,time,time,435,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:547,performance,cpu,cpu,547,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:743,performance,time,time,743,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:859,performance,cpu,cpu,859,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:115,reliability,doe,does,115,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:126,safety,depend,dependency,126,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:147,safety,depend,dependency,147,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:126,testability,depend,dependency,126,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:147,testability,depend,dependency,147,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:524,usability,user,user,524,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/704:836,usability,user,user,836,"Defer loading of umap to speed up import; Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master . python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total. isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master . Switched to branch 'defer-umap'. Your branch is up to date with 'origin/defer-umap'. isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap . python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704
https://github.com/scverse/scanpy/pull/705:55,modifiability,variab,variable,55,"making Cell ranger's normalized dispersion (for highly variable gene selection) not absolute; Deleted abs(...) from normalized dispersion definition. Taking the absolute dispersion will also result in selection of genes with dispersion lower than the bin's median, whereas we only want to select genes with dispersion higher than the bin's median.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/705
https://github.com/scverse/scanpy/issues/706:39,availability,error,error,39,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:368,availability,error,error,368,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:663,availability,cluster,clusters,663,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:705,availability,replic,replicating,705,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1055,availability,error,error,1055,"); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_tran",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1454,availability,error,error,1454,"e running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Ori",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:2362,availability,error,error,2362,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:505,deployability,log,logreg,505,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:663,deployability,cluster,clusters,663,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:865,deployability,releas,release,865,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1550,deployability,modul,module,1550,"d='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1408,interoperability,share,sharey,1408," #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1846,interoperability,share,sharey,1846,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:2290,interoperability,distribut,distributions,2290,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1550,modifiability,modul,module,1550,"d='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1882,modifiability,pac,packages,1882,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:39,performance,error,error,39,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:333,performance,time,time,333,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:368,performance,error,error,368,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1055,performance,error,error,1055,"); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_tran",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1454,performance,error,error,1454,"e running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Ori",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:2362,performance,error,error,2362,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:39,safety,error,error,39,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:306,safety,test,test,306,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:368,safety,error,error,368,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:497,safety,test,test,497,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:505,safety,log,logreg,505,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1055,safety,error,error,1055,"); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_tran",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1454,safety,error,error,1454,"e running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Ori",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1522,safety,input,input-,1522,"only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/is",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1550,safety,modul,module,1550,"d='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:2362,safety,error,error,2362,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:505,security,log,logreg,505,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:306,testability,test,test,306,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:497,testability,test,test,497,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:505,testability,log,logreg,505,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1478,testability,Trace,Traceback,1478,"roups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:39,usability,error,error,39,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:131,usability,close,closed,131,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:368,usability,error,error,368,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:656,usability,custom,custom,656,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:730,usability,workflow,workflow,730,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:770,usability,experien,experience,770,"Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1017,usability,help,help,1017,"_groups math domain error (Scanpy 1.4.3); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_add",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1055,usability,error,error,1055,"); Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_tran",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1454,usability,error,error,1454,"e running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Ori",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1522,usability,input,input-,1522,"only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/is",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:1898,usability,tool,tools,1898,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/706:2362,usability,error,error,2362,"ilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far! _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706
https://github.com/scverse/scanpy/issues/707:239,integrability,batch,batch,239,"Regress Out using all genes; Why can't I use regress_out function for scRNA-seq data without applying highly_variable_genes. Also I think regress_out function should be before highly_variable_genes, because in this way we can first remove batch effect and then select important genes. . sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). #adata = adata[:, adata.var['highly_variable']]. print(adata). # Regressing. sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/707
https://github.com/scverse/scanpy/issues/707:239,performance,batch,batch,239,"Regress Out using all genes; Why can't I use regress_out function for scRNA-seq data without applying highly_variable_genes. Also I think regress_out function should be before highly_variable_genes, because in this way we can first remove batch effect and then select important genes. . sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). #adata = adata[:, adata.var['highly_variable']]. print(adata). # Regressing. sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/707
https://github.com/scverse/scanpy/issues/707:0,testability,Regress,Regress,0,"Regress Out using all genes; Why can't I use regress_out function for scRNA-seq data without applying highly_variable_genes. Also I think regress_out function should be before highly_variable_genes, because in this way we can first remove batch effect and then select important genes. . sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). #adata = adata[:, adata.var['highly_variable']]. print(adata). # Regressing. sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/707
https://github.com/scverse/scanpy/issues/707:467,testability,Regress,Regressing,467,"Regress Out using all genes; Why can't I use regress_out function for scRNA-seq data without applying highly_variable_genes. Also I think regress_out function should be before highly_variable_genes, because in this way we can first remove batch effect and then select important genes. . sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). #adata = adata[:, adata.var['highly_variable']]. print(adata). # Regressing. sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/707
https://github.com/scverse/scanpy/issues/709:9,integrability,batch,batches,9,"Plotting batches singularly; Hello, . Is there a way to plot a single sample within a merged, batch corrected adata? I know you can set (color = 'batch'), but this plots all samples, whereas I would like to color in a single sample in the UMAP. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/709
https://github.com/scverse/scanpy/issues/709:94,integrability,batch,batch,94,"Plotting batches singularly; Hello, . Is there a way to plot a single sample within a merged, batch corrected adata? I know you can set (color = 'batch'), but this plots all samples, whereas I would like to color in a single sample in the UMAP. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/709
https://github.com/scverse/scanpy/issues/709:146,integrability,batch,batch,146,"Plotting batches singularly; Hello, . Is there a way to plot a single sample within a merged, batch corrected adata? I know you can set (color = 'batch'), but this plots all samples, whereas I would like to color in a single sample in the UMAP. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/709
https://github.com/scverse/scanpy/issues/709:9,performance,batch,batches,9,"Plotting batches singularly; Hello, . Is there a way to plot a single sample within a merged, batch corrected adata? I know you can set (color = 'batch'), but this plots all samples, whereas I would like to color in a single sample in the UMAP. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/709
https://github.com/scverse/scanpy/issues/709:94,performance,batch,batch,94,"Plotting batches singularly; Hello, . Is there a way to plot a single sample within a merged, batch corrected adata? I know you can set (color = 'batch'), but this plots all samples, whereas I would like to color in a single sample in the UMAP. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/709
https://github.com/scverse/scanpy/issues/709:146,performance,batch,batch,146,"Plotting batches singularly; Hello, . Is there a way to plot a single sample within a merged, batch corrected adata? I know you can set (color = 'batch'), but this plots all samples, whereas I would like to color in a single sample in the UMAP. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/709
https://github.com/scverse/scanpy/issues/710:15,availability,error,error,15,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:87,availability,error,error,87,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:8,performance,memor,memory,8,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:15,performance,error,error,15,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:80,performance,memor,memory,80,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:87,performance,error,error,87,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:217,performance,perform,performing,217,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:271,performance,memor,memory,271,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:15,safety,error,error,15,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:87,safety,error,error,87,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:8,usability,memor,memory,8,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:15,usability,error,error,15,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:80,usability,memor,memory,80,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:87,usability,error,error,87,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:217,usability,perform,performing,217,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/issues/710:271,usability,memor,memory,271,"3d UMAP memory error on ~1 million cells; Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM. Is there a way to decrease memory usage? I would appreciate your advice! Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710
https://github.com/scverse/scanpy/pull/711:151,deployability,fail,fail,151,"Fix obs_df, var_df for sparse obsm, varm; Previously, retrieving values from sparse matrices stored in obsm, varm via obs_df and var_df would silently fail.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/711
https://github.com/scverse/scanpy/pull/711:151,reliability,fail,fail,151,"Fix obs_df, var_df for sparse obsm, varm; Previously, retrieving values from sparse matrices stored in obsm, varm via obs_df and var_df would silently fail.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/711
https://github.com/scverse/scanpy/pull/713:29,modifiability,layer,layers,29,Fix scatter plots for sparse layers; Fixes #700. This should also future proof retrieving colors for always-2d anndata.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/713
https://github.com/scverse/scanpy/issues/714:53,availability,cluster,cluster,53,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:201,availability,cluster,cluster,201,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:53,deployability,cluster,cluster,53,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:177,deployability,version,version,177,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:201,deployability,cluster,cluster,201,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:15,energy efficiency,heat,heatmap,15,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:291,energy efficiency,heat,heatmap,291,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:177,integrability,version,version,177,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:251,interoperability,specif,specify,251,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:177,modifiability,version,version,177,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:271,modifiability,paramet,parameter,271,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/714:185,reliability,doe,doesn,185,"Allow plotting heatmap with smoothed expressions per cluster; When dealing with many cells, it can be hard to see expression patterns without smoothing. using the PAGA smoothed version doesn’t respect cluster border, however. It should be possible to specify a smoothing parameter to `sc.pl.heatmap`. cc @sophietr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/714
https://github.com/scverse/scanpy/issues/715:166,availability,slo,slows,166,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:48,energy efficiency,heat,heatmap,48,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:126,energy efficiency,draw,drawing,126,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:212,energy efficiency,heat,heatmap,212,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:257,modifiability,paramet,parameter,257,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:166,reliability,slo,slows,166,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:306,reliability,pra,practical,306,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:4,testability,simpl,simplified,4,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/issues/715:4,usability,simpl,simplified,4,Use simplified dendrogram for speed; Plotting a heatmap with many genes results in the dendrogram being impractical since the drawing of uncountable individual lines slows the plotting process to a crawl. `sc.pl.heatmap` should grow a dendrogram resolution parameter that limits the dendrogram levels to a practical amount by default. cc @sophietr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/715
https://github.com/scverse/scanpy/pull/716:0,deployability,Updat,Update,0,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/716:215,interoperability,exchang,exchanged,215,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/716:0,safety,Updat,Update,0,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/716:175,safety,prevent,preventing,175,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/716:0,security,Updat,Update,0,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/716:175,security,preven,preventing,175,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/716:241,testability,simpl,simple,241,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/716:241,usability,simpl,simple,241,"Update verbosity call in sc.external.tl.phate; The phate too makes a call to a function named `_settings_verbosity_greater_or_equal_than()`, which appears to no longer exist, preventing phate from running at all. I exchanged that call for a simple comparison that yields what I believe the old function returned. In any case, the change results in phate being able to run.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/716
https://github.com/scverse/scanpy/pull/717:179,deployability,API,API,179,"Enable caching of datasets on travis; Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717
https://github.com/scverse/scanpy/pull/717:179,integrability,API,API,179,"Enable caching of datasets on travis; Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717
https://github.com/scverse/scanpy/pull/717:179,interoperability,API,API,179,"Enable caching of datasets on travis; Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717
https://github.com/scverse/scanpy/pull/717:7,performance,cach,caching,7,"Enable caching of datasets on travis; Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717
https://github.com/scverse/scanpy/pull/717:38,performance,Cach,Cache,38,"Enable caching of datasets on travis; Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717
https://github.com/scverse/scanpy/pull/717:65,safety,test,tests,65,"Enable caching of datasets on travis; Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717
https://github.com/scverse/scanpy/pull/717:65,testability,test,tests,65,"Enable caching of datasets on travis; Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717
https://github.com/scverse/scanpy/issues/718:133,deployability,automat,automated,133,"outlier detection in scanpy?; Hi there, . instead of a fixed mito-percent cutoff that I have to set each time, does scanpy have some automated way of finding outliers of some heuristic to find a reasonable cutoff? If not, do you think 5% is a good cutoff for most datasets? I'm looking for a scanpy function similar to detect_outliers() in the R package scPipe. . Sorry if this has been asked before, I did some searching in the issues but couldn't find anything. best. Max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718
https://github.com/scverse/scanpy/issues/718:346,modifiability,pac,package,346,"outlier detection in scanpy?; Hi there, . instead of a fixed mito-percent cutoff that I have to set each time, does scanpy have some automated way of finding outliers of some heuristic to find a reasonable cutoff? If not, do you think 5% is a good cutoff for most datasets? I'm looking for a scanpy function similar to detect_outliers() in the R package scPipe. . Sorry if this has been asked before, I did some searching in the issues but couldn't find anything. best. Max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718
https://github.com/scverse/scanpy/issues/718:105,performance,time,time,105,"outlier detection in scanpy?; Hi there, . instead of a fixed mito-percent cutoff that I have to set each time, does scanpy have some automated way of finding outliers of some heuristic to find a reasonable cutoff? If not, do you think 5% is a good cutoff for most datasets? I'm looking for a scanpy function similar to detect_outliers() in the R package scPipe. . Sorry if this has been asked before, I did some searching in the issues but couldn't find anything. best. Max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718
https://github.com/scverse/scanpy/issues/718:111,reliability,doe,does,111,"outlier detection in scanpy?; Hi there, . instead of a fixed mito-percent cutoff that I have to set each time, does scanpy have some automated way of finding outliers of some heuristic to find a reasonable cutoff? If not, do you think 5% is a good cutoff for most datasets? I'm looking for a scanpy function similar to detect_outliers() in the R package scPipe. . Sorry if this has been asked before, I did some searching in the issues but couldn't find anything. best. Max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718
https://github.com/scverse/scanpy/issues/718:8,safety,detect,detection,8,"outlier detection in scanpy?; Hi there, . instead of a fixed mito-percent cutoff that I have to set each time, does scanpy have some automated way of finding outliers of some heuristic to find a reasonable cutoff? If not, do you think 5% is a good cutoff for most datasets? I'm looking for a scanpy function similar to detect_outliers() in the R package scPipe. . Sorry if this has been asked before, I did some searching in the issues but couldn't find anything. best. Max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718
https://github.com/scverse/scanpy/issues/718:8,security,detect,detection,8,"outlier detection in scanpy?; Hi there, . instead of a fixed mito-percent cutoff that I have to set each time, does scanpy have some automated way of finding outliers of some heuristic to find a reasonable cutoff? If not, do you think 5% is a good cutoff for most datasets? I'm looking for a scanpy function similar to detect_outliers() in the R package scPipe. . Sorry if this has been asked before, I did some searching in the issues but couldn't find anything. best. Max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718
https://github.com/scverse/scanpy/issues/718:133,testability,automat,automated,133,"outlier detection in scanpy?; Hi there, . instead of a fixed mito-percent cutoff that I have to set each time, does scanpy have some automated way of finding outliers of some heuristic to find a reasonable cutoff? If not, do you think 5% is a good cutoff for most datasets? I'm looking for a scanpy function similar to detect_outliers() in the R package scPipe. . Sorry if this has been asked before, I did some searching in the issues but couldn't find anything. best. Max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718
https://github.com/scverse/scanpy/issues/719:55,reliability,doe,does,55,"Embedding density limited to 10 groups?; @LuckyMD, why does `sc.tl.embedding_density` limit itself to running on labels with 10 or less categories?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/719
https://github.com/scverse/scanpy/issues/720:210,modifiability,paramet,parameter,210,"Contour plot; Hi,. Is there a way to plot UMAP/tSNE/PCA/etc. projections as contour plots instead of dot plots? Looking at the code, there does not seem to be an easy way to support this. Ideally it could be a parameter passed to the respective plotting function, e.g. sc.pl.umap(*args, contour = True)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/720
https://github.com/scverse/scanpy/issues/720:139,reliability,doe,does,139,"Contour plot; Hi,. Is there a way to plot UMAP/tSNE/PCA/etc. projections as contour plots instead of dot plots? Looking at the code, there does not seem to be an easy way to support this. Ideally it could be a parameter passed to the respective plotting function, e.g. sc.pl.umap(*args, contour = True)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/720
https://github.com/scverse/scanpy/issues/720:174,usability,support,support,174,"Contour plot; Hi,. Is there a way to plot UMAP/tSNE/PCA/etc. projections as contour plots instead of dot plots? Looking at the code, there does not seem to be an easy way to support this. Ideally it could be a parameter passed to the respective plotting function, e.g. sc.pl.umap(*args, contour = True)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/720
https://github.com/scverse/scanpy/pull/721:107,deployability,api,api,107,"Make External more visible in docs; Fixes #588. I'm not sure how to deal with references to external under api, so there are two copies of external at the moment. Sphinx gives warnings about this, and it'll probably mess with search. Any ideas @flying-sheep?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/721
https://github.com/scverse/scanpy/pull/721:107,integrability,api,api,107,"Make External more visible in docs; Fixes #588. I'm not sure how to deal with references to external under api, so there are two copies of external at the moment. Sphinx gives warnings about this, and it'll probably mess with search. Any ideas @flying-sheep?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/721
https://github.com/scverse/scanpy/pull/721:107,interoperability,api,api,107,"Make External more visible in docs; Fixes #588. I'm not sure how to deal with references to external under api, so there are two copies of external at the moment. Sphinx gives warnings about this, and it'll probably mess with search. Any ideas @flying-sheep?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/721
https://github.com/scverse/scanpy/issues/722:373,security,intercept,intercept,373,"sc.pp.regress_out and sc.pp.highly_variable interplay; Hi all,. I've been wondering about this for a while. As `sc.pp.regress_out` only leaves residuals, the resulting expression values have 0 mean. Thus, you can no longer use `sc.pp.highly_variable` afterwards (it bins by mean expression value per gene). This seems like a bad idea. An easy fix would be to also keep the intercept value and not only the residuals from `sc.pp.regress_out`. What do you guys think? If this sounds like a good idea to you, I will put it on my todo list for a pull request.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/722
https://github.com/scverse/scanpy/issues/723:64,interoperability,specif,specific,64,"rank_genes_groups refactoring; Hi, @falexwolf . Do you have any specific things in mind for `rank_genes_groups` refactoring? What should be done?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723
https://github.com/scverse/scanpy/issues/723:18,modifiability,refact,refactoring,18,"rank_genes_groups refactoring; Hi, @falexwolf . Do you have any specific things in mind for `rank_genes_groups` refactoring? What should be done?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723
https://github.com/scverse/scanpy/issues/723:112,modifiability,refact,refactoring,112,"rank_genes_groups refactoring; Hi, @falexwolf . Do you have any specific things in mind for `rank_genes_groups` refactoring? What should be done?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723
https://github.com/scverse/scanpy/issues/723:18,performance,refactor,refactoring,18,"rank_genes_groups refactoring; Hi, @falexwolf . Do you have any specific things in mind for `rank_genes_groups` refactoring? What should be done?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723
https://github.com/scverse/scanpy/issues/723:112,performance,refactor,refactoring,112,"rank_genes_groups refactoring; Hi, @falexwolf . Do you have any specific things in mind for `rank_genes_groups` refactoring? What should be done?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723
https://github.com/scverse/scanpy/pull/724:94,availability,error,error,94,Fix init_pos argument of sc.tl.umap; * Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`). * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32. * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released. * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724
https://github.com/scverse/scanpy/pull/724:363,deployability,releas,released,363,Fix init_pos argument of sc.tl.umap; * Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`). * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32. * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released. * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724
https://github.com/scverse/scanpy/pull/724:94,performance,error,error,94,Fix init_pos argument of sc.tl.umap; * Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`). * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32. * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released. * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724
https://github.com/scverse/scanpy/pull/724:94,safety,error,error,94,Fix init_pos argument of sc.tl.umap; * Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`). * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32. * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released. * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724
https://github.com/scverse/scanpy/pull/724:94,usability,error,error,94,Fix init_pos argument of sc.tl.umap; * Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`). * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32. * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released. * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724
https://github.com/scverse/scanpy/issues/725:27,deployability,integr,integration,27,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:125,deployability,pipelin,pipelines,125,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:150,deployability,integr,integration,150,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:27,integrability,integr,integration,27,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:125,integrability,pipelin,pipelines,125,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:150,integrability,integr,integration,150,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:27,interoperability,integr,integration,27,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:150,interoperability,integr,integration,150,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:27,modifiability,integr,integration,27,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:150,modifiability,integr,integration,150,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:27,reliability,integr,integration,27,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:150,reliability,integr,integration,150,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:27,security,integr,integration,27,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:150,security,integr,integration,150,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:10,testability,plan,plans,10,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:27,testability,integr,integration,27,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:94,testability,plan,plans,94,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/725:150,testability,integr,integration,150,"Question: plans for scATAC integration with scRNA?; I was just wondering if you guys have any plans for scATAC data analysis pipelines and especially integration with scRNA-seq? . cheers,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/725
https://github.com/scverse/scanpy/issues/728:1854,availability,sli,slice,1854,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2532,availability,state,statements,2532,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:79,deployability,upgrad,upgrade,79,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2240,deployability,observ,observation,2240,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2420,deployability,observ,observation,2420,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:693,energy efficiency,core,core,693,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:965,energy efficiency,core,core,965,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1161,energy efficiency,core,core,1161,"umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1496,energy efficiency,core,core,1496,"ype', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1792,energy efficiency,core,core,1792,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2158,energy efficiency,core,core,2158,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2532,integrability,state,statements,2532,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2284,interoperability,format,format,2284,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:79,modifiability,upgrad,upgrade,79,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:676,modifiability,pac,packages,676,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:745,modifiability,layer,layer,745,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:893,modifiability,layer,layer,893,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:899,modifiability,layer,layer,899,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:948,modifiability,pac,packages,948,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1144,modifiability,pac,packages,1144,"ata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1479,modifiability,pac,packages,1479,"iosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1775,modifiability,pac,packages,1775,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2141,modifiability,pac,packages,2141,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2252,modifiability,variab,variable,2252,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2432,modifiability,variab,variable,2432,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1854,reliability,sli,slice,1854,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2234,safety,valid,valid,2234,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2414,safety,valid,valid,2414,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2240,testability,observ,observation,2240,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2343,testability,understand,understand,2343,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2420,testability,observ,observation,2420,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:224,usability,learn,learn,224,"n_counts not found?; suddenly I have this problem, maybe related to an anndata upgrade. pip says all requirements are satisfied:. scanpy==1.4.3 anndata==0.6.22rc1 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1 . ```. . adata . AnnData object with n_obs × n_vars = 466 × 28685 . obs: 'GEO_Sample_age', 'age', 'age_unit', 'biosample_source_life_stage', 'biosample_source_gender', 'sample_category', 'biosample_cell_type', 'n_genes', 'n_counts', 'percent_mito'. var: 'n_cells'. fig1 = sc.pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:1867,usability,stop,stop,1867,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/issues/728:2470,usability,clear,clearly,2470,".pl.scatter(adata, x='n_counts', y='n_genes', save=""_gene_count""). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _get_obs_array(self, k, use_raw, layer). 1527 obs.keys and then var.index."""""". 1528 if use_raw:. -> 1529 return self.raw.obs_vector(k). 1530 else:. 1531 return self.obs_vector(k=k, layer=layer). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in obs_vector(self, k). 408 as `.obs_names`. 409 """""". --> 410 a = self[:, k].X. 411 if issparse(a):. 412 a = a.toarray(). ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in __getitem__(self, index). 331 . 332 def __getitem__(self, index):. --> 333 oidx, vidx = self._normalize_indices(index). 334 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]. 335 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_indices(self, packed_index). 360 obs, var = unpack_index(packed_index). 361 obs = _normalize_index(obs, self._adata.obs_names). --> 362 var = _normalize_index(var, self.var_names). 363 return obs, var. 364 . ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in _normalize_index(index, names). 153 return slice(start, stop, step). 154 elif isinstance(index, (np.integer, int, str)):. --> 155 return name_idx(index). 156 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 157 # here, we replaced the implementation based on name_idx with this. ~/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py in name_idx(i). 140 raise IndexError(. 141 'Key ""{}"" is not valid observation/variable name/index.'. --> 142 .format(i)). 143 i = i_found[0]. 144 return i. ```. I don't understand why anndata thinks that . IndexError: Key ""n_counts"" is not valid observation/variable name/index. even though it's clearly in adata.obs... any suggestions what to do? add print statements to the various functions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728
https://github.com/scverse/scanpy/pull/729:55,deployability,log,logic,55,Implicit copy fixes; Fixes #699. Corrects inconsistent logic about when a copy of a view would be made by preprocessing functions. Discussed here: https://github.com/theislab/anndata/issues/171#issuecomment-508619952,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/729
https://github.com/scverse/scanpy/pull/729:55,safety,log,logic,55,Implicit copy fixes; Fixes #699. Corrects inconsistent logic about when a copy of a view would be made by preprocessing functions. Discussed here: https://github.com/theislab/anndata/issues/171#issuecomment-508619952,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/729
https://github.com/scverse/scanpy/pull/729:55,security,log,logic,55,Implicit copy fixes; Fixes #699. Corrects inconsistent logic about when a copy of a view would be made by preprocessing functions. Discussed here: https://github.com/theislab/anndata/issues/171#issuecomment-508619952,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/729
https://github.com/scverse/scanpy/pull/729:55,testability,log,logic,55,Implicit copy fixes; Fixes #699. Corrects inconsistent logic about when a copy of a view would be made by preprocessing functions. Discussed here: https://github.com/theislab/anndata/issues/171#issuecomment-508619952,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/729
https://github.com/scverse/scanpy/pull/730:395,modifiability,layer,layer,395,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/pull/730:640,modifiability,layer,layers,640,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/pull/730:119,security,access,access,119,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/pull/730:139,security,access,access,139,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/pull/730:321,security,access,access,321,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/pull/730:630,security,access,access,630,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/pull/730:441,usability,support,supported,441,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/pull/730:714,usability,support,support,714,"Fix warnings from anndata `v0.6.22`; Fixes for deprecation warnings from anndata`v0.6.22`. This is mostly by replacing access to `.X` with access via `{obs,var}_vector` or `sc.get.obs_df`. Supercedes #713, fixes #700 and #690. Functions changed:. * `sc.pl.violin`. * Dataframe for plotting now constructed with `obs_df`, access to `adata.X` no longer used. * `sc.pl.scatter`. * Changed default `layer` from `""X""` to `""None""`. `""X""` is still supported, but should throw a deprecation warning if it's explicitly used. * Replace usage of `._get_obs_array` with `.obs_vector`. * `sc.pl._tools.scatterplots.plot_scatter`. * Normalized access to layers, now sparse and dense should similarly. * `sc.get.obs_df`. * Added support for `use_raw`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730
https://github.com/scverse/scanpy/issues/731:34,availability,error,error,34,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:99,availability,error,error,99,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:1028,availability,error,error,1028,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:6,deployability,scale,scale,6,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:77,deployability,scale,scale,77,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:983,deployability,scale,scale,983,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:6,energy efficiency,scale,scale,6,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:77,energy efficiency,scale,scale,77,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:983,energy efficiency,scale,scale,983,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:6,modifiability,scal,scale,6,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:77,modifiability,scal,scale,77,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:448,modifiability,variab,variable,448,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:983,modifiability,scal,scale,983,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:6,performance,scale,scale,6,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:34,performance,error,error,34,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:77,performance,scale,scale,77,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:99,performance,error,error,99,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:133,performance,time,time,133,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:983,performance,scale,scale,983,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:1028,performance,error,error,1028,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:34,safety,error,error,34,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:99,safety,error,error,99,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:1028,safety,error,error,1028,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:621,testability,regress,regress,621,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:34,usability,error,error,34,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:99,usability,error,error,99,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:283,usability,user,user-images,283,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:703,usability,user,user-images,703,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:1028,usability,error,error,1028,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:1151,usability,user,user-images,1151,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/731:1440,usability,learn,learn,1440,"sc.pp.scale and sc.pp.regress_out error on first run of copied object; sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get . ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks! sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731
https://github.com/scverse/scanpy/issues/732:51,energy efficiency,heat,heatmap,51,"Showing obs_names instead of names of `groupby` in heatmap; Hi,. I am wondering can obs_names pass along within heatmap function and be shown in heatmap? Thanks! ![Screen Shot 2019-07-08 at 2 55 56 PM](https://user-images.githubusercontent.com/15947971/60838635-c42a9b80-a190-11e9-8ca5-0ff979e91ddf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/732
https://github.com/scverse/scanpy/issues/732:112,energy efficiency,heat,heatmap,112,"Showing obs_names instead of names of `groupby` in heatmap; Hi,. I am wondering can obs_names pass along within heatmap function and be shown in heatmap? Thanks! ![Screen Shot 2019-07-08 at 2 55 56 PM](https://user-images.githubusercontent.com/15947971/60838635-c42a9b80-a190-11e9-8ca5-0ff979e91ddf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/732
https://github.com/scverse/scanpy/issues/732:145,energy efficiency,heat,heatmap,145,"Showing obs_names instead of names of `groupby` in heatmap; Hi,. I am wondering can obs_names pass along within heatmap function and be shown in heatmap? Thanks! ![Screen Shot 2019-07-08 at 2 55 56 PM](https://user-images.githubusercontent.com/15947971/60838635-c42a9b80-a190-11e9-8ca5-0ff979e91ddf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/732
https://github.com/scverse/scanpy/issues/732:210,usability,user,user-images,210,"Showing obs_names instead of names of `groupby` in heatmap; Hi,. I am wondering can obs_names pass along within heatmap function and be shown in heatmap? Thanks! ![Screen Shot 2019-07-08 at 2 55 56 PM](https://user-images.githubusercontent.com/15947971/60838635-c42a9b80-a190-11e9-8ca5-0ff979e91ddf.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/732
https://github.com/scverse/scanpy/pull/733:135,deployability,fail,fails,135,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:125,energy efficiency,current,currently,125,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:330,energy efficiency,Current,Currently,330,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:570,energy efficiency,core,core,570,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:194,integrability,sub,subset,194,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:405,integrability,sub,subset,405,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:22,interoperability,distribut,distributed,22,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:76,interoperability,distribut,distributed,76,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:107,interoperability,distribut,distributed,107,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/pull/733:135,reliability,fail,fails,135,"Check return types of distributed computations; Add checks to make sure the distributed backend is staying distributed. This currently fails for dask arrays, since they become numpy arrays when subset. @tomwhite Is this it right to assume that dask arrays should stay as dask arrays, and Zappy arrays should stay as Zappy arrays? Currently dask arrays are becoming numpy arrays when the parent AnnData is subset via the last line here (though this exact code is being replaced):. https://github.com/theislab/anndata/blob/75296bb210d141fa1de24960412bfcab77a9604d/anndata/core/anndata.py#L637-L657. Also, are `ZappyArray`s always read-only like the `DirectZappyArray`s are? I'm wondering about the set of anndata features they should work with.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733
https://github.com/scverse/scanpy/issues/734:24,availability,Cluster,Clustering,24,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:184,availability,Cluster,Clustering,184,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:395,availability,error,errors,395,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:24,deployability,Cluster,Clustering,24,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:184,deployability,Cluster,Clustering,184,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:445,deployability,log,logging,445,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1469,deployability,modul,module,1469,"esults_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/U",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1563,deployability,Version,Versions,1563,".set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:114,energy efficiency,load,loaded,114,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1808,energy efficiency,core,core,1808,"n_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1999,energy efficiency,core,core,1999,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2181,energy efficiency,core,core,2181,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2388,energy efficiency,core,core,2388,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2567,energy efficiency,core,core,2567,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2777,energy efficiency,core,core,2777,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1563,integrability,Version,Versions,1563,".set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:955,interoperability,mismatch,mismatch,955,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1469,modifiability,modul,module,1469,"esults_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/U",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1563,modifiability,Version,Versions,1563,".set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1595,modifiability,pac,packages,1595,"a = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1760,modifiability,pac,packages,1760,"s'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1951,modifiability,pac,packages,1951,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2133,modifiability,pac,packages,2133,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2340,modifiability,pac,packages,2340,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2519,modifiability,pac,packages,2519,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2729,modifiability,pac,packages,2729,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:114,performance,load,loaded,114,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:395,performance,error,errors,395,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:681,performance,cach,cache,681,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1274,performance,cach,cache,1274,"`py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1285,performance,cach,cache,1285," numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:395,safety,error,errors,395,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:445,safety,log,logging,445,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1446,safety,test,test,1446,"ging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1469,safety,modul,module,1469,"esults_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/U",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:445,security,log,logging,445,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:127,testability,simpl,simple,127,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:445,testability,log,logging,445,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1404,testability,Trace,Traceback,1404,"rnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", lin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1446,testability,test,test,1446,"ging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:127,usability,simpl,simple,127,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:395,usability,error,errors,395,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:431,usability,hint,hints,431,"Having anndata issue in Clustering 3K PBMCs Following a Seurat Tutorial ; Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1088,usability,help,help,1088,"en trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1221,usability,learn,learn,1221,"utorial"" by trying to execute the following code:. ```py. import numpy as np. import pandas as pd. import scanpy as sc. import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_vi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1712,usability,User,Users,1712,"_unique() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1718,usability,Person,Person,1718,"e() # this is unnecessary if using 'gene_ids'. print(adata). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(). ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1903,usability,User,Users,1903,"he following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:1909,usability,Person,Person,1909,"lowing output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2085,usability,User,Users,2085,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2091,usability,Person,Person,2091,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2292,usability,User,Users,2292,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2298,usability,Person,Person,2298,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2471,usability,User,Users,2471,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2477,usability,Person,Person,2477,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2681,usability,User,Users,2681,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/734:2687,usability,Person,Person,2687,"tput (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance. Cheers. ```pytb. > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 . ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad. AnnData object with n_obs × n_vars = 2700 × 32738 . var: 'gene_ids'. Traceback (most recent call last):. File ""test.py"", line 23, in <module>. sc.pp.filter_cells(adata, min_genes=200). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells. adata._inplace_subset_obs(cell_subset). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs. adata_subset = self[index].copy(). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__. return self._getitem_view(index). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1234, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 561, in __init__. self._init_as_view(X, oidx, vidx). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 621, in _init_as_view. self._obs = DataFrameView(obs_sub, view_args=(self, 'obs')). File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/views.py"", line 41, in __init__. view_args = ViewArgs(*view_args). TypeError: __new__() missing 1 required positional argument: 'keys'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734
https://github.com/scverse/scanpy/issues/735:6,energy efficiency,heat,heatmap,6,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:181,energy efficiency,Heat,Heatmaps,181,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:198,energy efficiency,heat,heatmap,198,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:501,energy efficiency,heat,heatmap,501,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:14,reliability,doe,doesn,14,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:226,safety,input,input,226,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:151,usability,visual,visualizing-marker-genes,151,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:226,usability,input,input,226,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:371,usability,user,user-images,371,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/735:541,usability,user,user-images,541,"sc.pl.heatmap doesn't recognize a dictionary of genes and show `IndexError`; Hi, . In the [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps) `sc.pl.heatmap` take genes_dict as input, but I have `IndexError` when I use genes_dict. It was working for me before so I am wondering if there is a bug. Thanks. ![image](https://user-images.githubusercontent.com/15947971/60994831-e2220880-a316-11e9-9bd0-706bae059d1c.png). BTW a flatten list works for sc.pl.heatmap in my dataset. ![image](https://user-images.githubusercontent.com/15947971/60994955-27ded100-a317-11e9-943a-6ffdb20db75d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/735
https://github.com/scverse/scanpy/issues/736:5,energy efficiency,Draw,Drawing,5,"TSNE Drawing Problem; when i use `sc.pl.tsne` to draw a TSNE plot, saved in PDF format. It does works, but when open the PDF with adobe illustrator, something unusual happened as follow:. ![image](https://user-images.githubusercontent.com/44384930/61019375-8ca83300-a3cc-11e9-8a29-bc64916bd7ef.png). the title in the image is single charater with a single text box. and other text also has this problem，for one more axample:. ![image](https://user-images.githubusercontent.com/44384930/61019597-5323f780-a3cd-11e9-8d03-2e2044330e30.png). The right one should be:. ![image](https://user-images.githubusercontent.com/44384930/61019513-02ac9a00-a3cd-11e9-8ed7-bdba3feece7b.png). code:. ```. from os.path import basename. sc.pl.tsne(adata, color=['GCG', 'INS', 'PPY', 'SST',. 'PRSS1'], ncols=2, color_map=cm, save=basename(file)[:-4]). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/736
https://github.com/scverse/scanpy/issues/736:49,energy efficiency,draw,draw,49,"TSNE Drawing Problem; when i use `sc.pl.tsne` to draw a TSNE plot, saved in PDF format. It does works, but when open the PDF with adobe illustrator, something unusual happened as follow:. ![image](https://user-images.githubusercontent.com/44384930/61019375-8ca83300-a3cc-11e9-8a29-bc64916bd7ef.png). the title in the image is single charater with a single text box. and other text also has this problem，for one more axample:. ![image](https://user-images.githubusercontent.com/44384930/61019597-5323f780-a3cd-11e9-8d03-2e2044330e30.png). The right one should be:. ![image](https://user-images.githubusercontent.com/44384930/61019513-02ac9a00-a3cd-11e9-8ed7-bdba3feece7b.png). code:. ```. from os.path import basename. sc.pl.tsne(adata, color=['GCG', 'INS', 'PPY', 'SST',. 'PRSS1'], ncols=2, color_map=cm, save=basename(file)[:-4]). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/736
https://github.com/scverse/scanpy/issues/736:80,interoperability,format,format,80,"TSNE Drawing Problem; when i use `sc.pl.tsne` to draw a TSNE plot, saved in PDF format. It does works, but when open the PDF with adobe illustrator, something unusual happened as follow:. ![image](https://user-images.githubusercontent.com/44384930/61019375-8ca83300-a3cc-11e9-8a29-bc64916bd7ef.png). the title in the image is single charater with a single text box. and other text also has this problem，for one more axample:. ![image](https://user-images.githubusercontent.com/44384930/61019597-5323f780-a3cd-11e9-8d03-2e2044330e30.png). The right one should be:. ![image](https://user-images.githubusercontent.com/44384930/61019513-02ac9a00-a3cd-11e9-8ed7-bdba3feece7b.png). code:. ```. from os.path import basename. sc.pl.tsne(adata, color=['GCG', 'INS', 'PPY', 'SST',. 'PRSS1'], ncols=2, color_map=cm, save=basename(file)[:-4]). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/736
https://github.com/scverse/scanpy/issues/736:91,reliability,doe,does,91,"TSNE Drawing Problem; when i use `sc.pl.tsne` to draw a TSNE plot, saved in PDF format. It does works, but when open the PDF with adobe illustrator, something unusual happened as follow:. ![image](https://user-images.githubusercontent.com/44384930/61019375-8ca83300-a3cc-11e9-8a29-bc64916bd7ef.png). the title in the image is single charater with a single text box. and other text also has this problem，for one more axample:. ![image](https://user-images.githubusercontent.com/44384930/61019597-5323f780-a3cd-11e9-8d03-2e2044330e30.png). The right one should be:. ![image](https://user-images.githubusercontent.com/44384930/61019513-02ac9a00-a3cd-11e9-8ed7-bdba3feece7b.png). code:. ```. from os.path import basename. sc.pl.tsne(adata, color=['GCG', 'INS', 'PPY', 'SST',. 'PRSS1'], ncols=2, color_map=cm, save=basename(file)[:-4]). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/736
https://github.com/scverse/scanpy/issues/736:205,usability,user,user-images,205,"TSNE Drawing Problem; when i use `sc.pl.tsne` to draw a TSNE plot, saved in PDF format. It does works, but when open the PDF with adobe illustrator, something unusual happened as follow:. ![image](https://user-images.githubusercontent.com/44384930/61019375-8ca83300-a3cc-11e9-8a29-bc64916bd7ef.png). the title in the image is single charater with a single text box. and other text also has this problem，for one more axample:. ![image](https://user-images.githubusercontent.com/44384930/61019597-5323f780-a3cd-11e9-8d03-2e2044330e30.png). The right one should be:. ![image](https://user-images.githubusercontent.com/44384930/61019513-02ac9a00-a3cd-11e9-8ed7-bdba3feece7b.png). code:. ```. from os.path import basename. sc.pl.tsne(adata, color=['GCG', 'INS', 'PPY', 'SST',. 'PRSS1'], ncols=2, color_map=cm, save=basename(file)[:-4]). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/736
https://github.com/scverse/scanpy/issues/736:443,usability,user,user-images,443,"TSNE Drawing Problem; when i use `sc.pl.tsne` to draw a TSNE plot, saved in PDF format. It does works, but when open the PDF with adobe illustrator, something unusual happened as follow:. ![image](https://user-images.githubusercontent.com/44384930/61019375-8ca83300-a3cc-11e9-8a29-bc64916bd7ef.png). the title in the image is single charater with a single text box. and other text also has this problem，for one more axample:. ![image](https://user-images.githubusercontent.com/44384930/61019597-5323f780-a3cd-11e9-8d03-2e2044330e30.png). The right one should be:. ![image](https://user-images.githubusercontent.com/44384930/61019513-02ac9a00-a3cd-11e9-8ed7-bdba3feece7b.png). code:. ```. from os.path import basename. sc.pl.tsne(adata, color=['GCG', 'INS', 'PPY', 'SST',. 'PRSS1'], ncols=2, color_map=cm, save=basename(file)[:-4]). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/736
https://github.com/scverse/scanpy/issues/736:581,usability,user,user-images,581,"TSNE Drawing Problem; when i use `sc.pl.tsne` to draw a TSNE plot, saved in PDF format. It does works, but when open the PDF with adobe illustrator, something unusual happened as follow:. ![image](https://user-images.githubusercontent.com/44384930/61019375-8ca83300-a3cc-11e9-8a29-bc64916bd7ef.png). the title in the image is single charater with a single text box. and other text also has this problem，for one more axample:. ![image](https://user-images.githubusercontent.com/44384930/61019597-5323f780-a3cd-11e9-8d03-2e2044330e30.png). The right one should be:. ![image](https://user-images.githubusercontent.com/44384930/61019513-02ac9a00-a3cd-11e9-8ed7-bdba3feece7b.png). code:. ```. from os.path import basename. sc.pl.tsne(adata, color=['GCG', 'INS', 'PPY', 'SST',. 'PRSS1'], ncols=2, color_map=cm, save=basename(file)[:-4]). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/736
https://github.com/scverse/scanpy/issues/737:135,deployability,api,api,135,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:208,deployability,api,api,208,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:219,deployability,api,api,219,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:271,deployability,api,api,271,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:338,deployability,api,api,338,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:349,deployability,api,api,349,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:535,deployability,build,build,535,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:562,deployability,api,api,562,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:603,deployability,api,api,603,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:135,integrability,api,api,135,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:208,integrability,api,api,208,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:219,integrability,api,api,219,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:271,integrability,api,api,271,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:338,integrability,api,api,338,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:349,integrability,api,api,349,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:562,integrability,api,api,562,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:584,integrability,filter,filter,584,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:603,integrability,api,api,603,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:135,interoperability,api,api,135,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:208,interoperability,api,api,208,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:219,interoperability,api,api,219,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:271,interoperability,api,api,271,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:338,interoperability,api,api,338,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:349,interoperability,api,api,349,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:562,interoperability,api,api,562,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:603,interoperability,api,api,603,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:567,reliability,doe,does,567,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/737:40,usability,tool,tools,40,"Doc search incorrectly showing external tools; If you search for `mnn` or `bbknn` on `latest` read the docs, you get links to [`scanpy.api.pp.mnn_correct`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.mnn_correct.html?highlight=mnn) and [`scanpy.api.pp.bbknn`](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.api.pp.bbknn.html?highlight=bbknn). Oddly those links are also to the icb-scanpy site. On https://github.com/theislab/scanpy/pull/721, external correctly shows up when I search my local build of the docs, though `api` does too. Can we filter the `scanpy.api` results from the search?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/737
https://github.com/scverse/scanpy/issues/738:63,availability,error,error,63,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:264,availability,error,error,264,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:383,availability,error,error,383,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:53,deployability,scale,scale,53,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:241,deployability,scale,scale,241,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:834,deployability,scale,scale,834,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:53,energy efficiency,scale,scale,53,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:241,energy efficiency,scale,scale,241,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:834,energy efficiency,scale,scale,834,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:766,integrability,sub,subset,766,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:53,modifiability,scal,scale,53,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:106,modifiability,pac,package,106,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:241,modifiability,scal,scale,241,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:834,modifiability,scal,scale,834,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:53,performance,scale,scale,53,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:63,performance,error,error,63,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:241,performance,scale,scale,241,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:264,performance,error,error,264,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:383,performance,error,error,383,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:834,performance,scale,scale,834,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:63,safety,error,error,63,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:264,safety,error,error,264,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:383,safety,error,error,383,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:63,usability,error,error,63,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:264,usability,error,error,264,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/738:383,usability,error,error,383,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？; hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much. sc.pp.filter_genes(adata, min_counts = filter_min_counts). sc.pp.filter_cells(adata, min_counts = filter_min_counts). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True). adata = adata[:, adata.var[""highly_variable""]]. sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738
https://github.com/scverse/scanpy/issues/739:232,availability,error,error,232,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:59,deployability,version,version,59,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:72,deployability,Updat,Update,72,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:132,deployability,updat,updated,132,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:412,deployability,modul,module,412,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:493,deployability,modul,module,493,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:535,deployability,version,version,535,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:702,deployability,version,version,702,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:745,deployability,version,version,745,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:898,deployability,api,api,898,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:908,deployability,version,version,908,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:931,deployability,Version,Version,931,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1000,deployability,version,version,1000,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1097,deployability,api,api,1097,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1335,deployability,api,api,1335,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1528,deployability,instal,installed,1528,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1548,deployability,version,version,1548,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1585,deployability,version,version,1585,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:184,energy efficiency,load,load,184,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:59,integrability,version,version,59,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:535,integrability,version,version,535,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:702,integrability,version,version,702,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:745,integrability,version,version,745,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:898,integrability,api,api,898,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:908,integrability,version,version,908,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:931,integrability,Version,Version,931,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1000,integrability,version,version,1000,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1097,integrability,api,api,1097,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1174,integrability,sub,subclass,1174,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1335,integrability,api,api,1335,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1548,integrability,version,version,1548,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1585,integrability,version,version,1585,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:898,interoperability,api,api,898,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:978,interoperability,distribut,distribution,978,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1097,interoperability,api,api,1097,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1107,interoperability,distribut,distribution,1107,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1146,interoperability,Distribut,Distribution,1146,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1216,interoperability,Distribut,Distribution,1216,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1335,interoperability,api,api,1335,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1,modifiability,Pac,PackageNotFoundError,1,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:59,modifiability,version,version,59,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:321,modifiability,Pac,PackageNotFoundError,321,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:412,modifiability,modul,module,412,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:493,modifiability,modul,module,493,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:535,modifiability,version,version,535,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:702,modifiability,version,version,702,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:745,modifiability,version,version,745,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:870,modifiability,pac,packages,870,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:908,modifiability,version,version,908,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:916,modifiability,pac,package,916,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:931,modifiability,Version,Version,931,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:991,modifiability,pac,package,991,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1000,modifiability,version,version,1000,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1069,modifiability,pac,packages,1069,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1120,modifiability,pac,package,1120,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1239,modifiability,pac,package,1239,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1307,modifiability,pac,packages,1307,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1411,modifiability,Pac,PackageNotFoundError,1411,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1462,modifiability,Pac,PackageNotFoundError,1462,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1548,modifiability,version,version,1548,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1585,modifiability,version,version,1585,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:184,performance,load,load,184,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:232,performance,error,error,232,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:72,safety,Updat,Update,72,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:132,safety,updat,updated,132,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:232,safety,error,error,232,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:386,safety,input,input-,386,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:412,safety,modul,module,412,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:493,safety,modul,module,493,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:72,security,Updat,Update,72,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:132,security,updat,updated,132,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:342,testability,Trace,Traceback,342,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:28,usability,learn,learn,28,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:232,usability,error,error,232,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:386,usability,input,input-,386,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:759,usability,learn,learn,759,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1489,usability,learn,learn,1489,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1515,usability,learn,learn,1515,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/739:1632,usability,learn,learn,1632,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7; Hey! I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:. ``` ---------------------------------------------------------------------------. PackageNotFoundError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>. 25 __version__ = get_versions()['version']. 26 . ---> 27 check_versions(). 28 del get_versions, check_versions. 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(). 38 . 39 anndata_version = version(""anndata""). ---> 40 umap_version = version(""umap-learn""). 41 . 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package). 103 ""Version"" metadata key. 104 """""". --> 105 return distribution(package).version. 106 . 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package). 84 :return: A ``Distribution`` instance (or subclass thereof). 85 """""". ---> 86 return Distribution.from_name(package). 87 . 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name). 50 return resolved. 51 else:. ---> 52 raise PackageNotFoundError(name). 53 . 54 @staticmethod. PackageNotFoundError: umap-learn . ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf. Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739
https://github.com/scverse/scanpy/issues/740:299,availability,cluster,clusters,299,"sc.pl.palettes.godsnot_64 18th colour invisible against white BG; Hey @fidelram ! I've noticed this quite often... the 18th colour in `sc.pl.palettes.godsnot_64` is pretty much invisible against a white background. I otherwise consider this to be the best palette out there as it distinguishes cell clusters quite well. See ""Progenitor Leukocyte"" in the legend below. ![image](https://user-images.githubusercontent.com/13019956/61394373-3c950900-a8c3-11e9-9181-464f69ec095f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/740
https://github.com/scverse/scanpy/issues/740:299,deployability,cluster,clusters,299,"sc.pl.palettes.godsnot_64 18th colour invisible against white BG; Hey @fidelram ! I've noticed this quite often... the 18th colour in `sc.pl.palettes.godsnot_64` is pretty much invisible against a white background. I otherwise consider this to be the best palette out there as it distinguishes cell clusters quite well. See ""Progenitor Leukocyte"" in the legend below. ![image](https://user-images.githubusercontent.com/13019956/61394373-3c950900-a8c3-11e9-9181-464f69ec095f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/740
https://github.com/scverse/scanpy/issues/740:385,usability,user,user-images,385,"sc.pl.palettes.godsnot_64 18th colour invisible against white BG; Hey @fidelram ! I've noticed this quite often... the 18th colour in `sc.pl.palettes.godsnot_64` is pretty much invisible against a white background. I otherwise consider this to be the best palette out there as it distinguishes cell clusters quite well. See ""Progenitor Leukocyte"" in the legend below. ![image](https://user-images.githubusercontent.com/13019956/61394373-3c950900-a8c3-11e9-9181-464f69ec095f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/740
https://github.com/scverse/scanpy/pull/741:15,deployability,releas,release,15,"Bugfix for new release of ebi; With the new ebi single cell database release one of the files is a little different (col names/ obs_names). That part of the reader has been fixed, and I've updated the test for the reprocessed data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741
https://github.com/scverse/scanpy/pull/741:69,deployability,releas,release,69,"Bugfix for new release of ebi; With the new ebi single cell database release one of the files is a little different (col names/ obs_names). That part of the reader has been fixed, and I've updated the test for the reprocessed data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741
https://github.com/scverse/scanpy/pull/741:189,deployability,updat,updated,189,"Bugfix for new release of ebi; With the new ebi single cell database release one of the files is a little different (col names/ obs_names). That part of the reader has been fixed, and I've updated the test for the reprocessed data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741
https://github.com/scverse/scanpy/pull/741:189,safety,updat,updated,189,"Bugfix for new release of ebi; With the new ebi single cell database release one of the files is a little different (col names/ obs_names). That part of the reader has been fixed, and I've updated the test for the reprocessed data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741
https://github.com/scverse/scanpy/pull/741:201,safety,test,test,201,"Bugfix for new release of ebi; With the new ebi single cell database release one of the files is a little different (col names/ obs_names). That part of the reader has been fixed, and I've updated the test for the reprocessed data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741
https://github.com/scverse/scanpy/pull/741:189,security,updat,updated,189,"Bugfix for new release of ebi; With the new ebi single cell database release one of the files is a little different (col names/ obs_names). That part of the reader has been fixed, and I've updated the test for the reprocessed data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741
https://github.com/scverse/scanpy/pull/741:201,testability,test,test,201,"Bugfix for new release of ebi; With the new ebi single cell database release one of the files is a little different (col names/ obs_names). That part of the reader has been fixed, and I've updated the test for the reprocessed data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/741
https://github.com/scverse/scanpy/pull/742:502,usability,user,user-images,502,"use default_20 palette for scatter plots with less than 20 colors; Related to #740 . This PR changes changes the default color palette for scatter plots to use the palette at `scanpy.pl.palettes.default_20` when there are 20 or less categories present. Here's an example of what this would change. Using the following code:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). del pbmc.uns[""louvain_colors""]. sc.pl.umap(pbmc, color=""louvain""). ```. Without this PR:. ![image](https://user-images.githubusercontent.com/8238804/61576675-30f24e00-ab20-11e9-856e-db0717b8f8dd.png). With this PR:. ![image](https://user-images.githubusercontent.com/8238804/61576668-18823380-ab20-11e9-99ec-3597c59c01af.png). I think the colors used in default 20 are much easier to differentiate with this number of groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/742
https://github.com/scverse/scanpy/pull/742:628,usability,user,user-images,628,"use default_20 palette for scatter plots with less than 20 colors; Related to #740 . This PR changes changes the default color palette for scatter plots to use the palette at `scanpy.pl.palettes.default_20` when there are 20 or less categories present. Here's an example of what this would change. Using the following code:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). del pbmc.uns[""louvain_colors""]. sc.pl.umap(pbmc, color=""louvain""). ```. Without this PR:. ![image](https://user-images.githubusercontent.com/8238804/61576675-30f24e00-ab20-11e9-856e-db0717b8f8dd.png). With this PR:. ![image](https://user-images.githubusercontent.com/8238804/61576668-18823380-ab20-11e9-99ec-3597c59c01af.png). I think the colors used in default 20 are much easier to differentiate with this number of groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/742
https://github.com/scverse/scanpy/pull/743:68,modifiability,pac,package,68,Minor spelling fix; Unkown -> Unknown. Thanks for your time on this package :-),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/743
https://github.com/scverse/scanpy/pull/743:55,performance,time,time,55,Minor spelling fix; Unkown -> Unknown. Thanks for your time on this package :-),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/743
https://github.com/scverse/scanpy/issues/744:174,availability,Cluster,Clustering,174,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:1434,availability,Cluster,Clustering,1434,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:174,deployability,Cluster,Clustering,174,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:1406,deployability,continu,continue,1406,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:1434,deployability,Cluster,Clustering,1434,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:7,performance,perform analys,perform analysis,7,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:79,performance,perform analys,perform analysis,79,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:7,usability,perform,perform,7,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:79,usability,perform,perform,79,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:693,usability,Visual,Visualizing,693,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:781,usability,visual,visualizing-marker-genes,781,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/744:1459,usability,Visual,Visualizing,1459,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/744
https://github.com/scverse/scanpy/issues/745:174,availability,Cluster,Clustering,174,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:1473,availability,Cluster,Clustering,1473,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:174,deployability,Cluster,Clustering,174,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:1445,deployability,continu,continue,1445,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:1473,deployability,Cluster,Clustering,1473,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:7,performance,perform analys,perform analysis,7,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:79,performance,perform analys,perform analysis,79,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:7,usability,perform,perform,7,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:79,usability,perform,perform,79,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:693,usability,Visual,Visualizing,693,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:781,usability,visual,visualizing-marker-genes,781,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/745:1498,usability,Visual,Visualizing,1498,"how to perform analysis to get bulk_labels, S_score, G2M_score, phase?; how to perform analysis to get bulk_labels, S_score, G2M_score, phase? After following the tutorial ""[Clustering 3K PBMCs](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/pbmc3k.html)"", I got the object ""adata"" with following description:. _>>> adata. AnnData object with n_obs × n_vars = 691 × 4549. **obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'**. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_ . however, the tutorial ""[Visualizing marker genes](https://icb-scanpy-tutorials.readthedocs-hosted.com/en/latest/visualizing-marker-genes.html?highlight=%27bulk_labels%27)"" use the object ""pbmc"" with following description:. _>>> pbmc. AnnData object with n_obs × n_vars = 700 × 765. **obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'**. var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'. uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'_. i want to process my data according those two tutorials and got the figures. but without those information (obs: 'bulk_labels', 'S_score', 'G2M_score', 'phase'), i cannot continue the tutorial from ""Clustering 3K PBMCs"" to ""Visualizing marker genes""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/745
https://github.com/scverse/scanpy/issues/746:5,deployability,log,logging,5,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:75,deployability,log,logging,75,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:155,interoperability,cooperat,cooperate,155,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:293,reliability,doe,doesn,293,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:5,safety,log,logging,5,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:75,safety,log,logging,75,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:5,security,log,logging,5,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:75,security,log,logging,75,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:5,testability,log,logging,5,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:75,testability,log,logging,75,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:378,usability,user,user-images,378,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/746:663,usability,learn,learn,663,"deep logging not showing up; Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746
https://github.com/scverse/scanpy/issues/747:360,availability,error,error,360,"highly_variable_genes AssertionError: Don’t call _normalize_index with non-categorical/string names; Hi, I am using anndata 0.6.21 and scanpy 1.4.3. I executed this code:. ```. sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. ```. and I got this error:. `AssertionError: Don’t call _normalize_index with non-categorical/string names. `. Can you help me? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747
https://github.com/scverse/scanpy/issues/747:360,performance,error,error,360,"highly_variable_genes AssertionError: Don’t call _normalize_index with non-categorical/string names; Hi, I am using anndata 0.6.21 and scanpy 1.4.3. I executed this code:. ```. sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. ```. and I got this error:. `AssertionError: Don’t call _normalize_index with non-categorical/string names. `. Can you help me? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747
https://github.com/scverse/scanpy/issues/747:360,safety,error,error,360,"highly_variable_genes AssertionError: Don’t call _normalize_index with non-categorical/string names; Hi, I am using anndata 0.6.21 and scanpy 1.4.3. I executed this code:. ```. sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. ```. and I got this error:. `AssertionError: Don’t call _normalize_index with non-categorical/string names. `. Can you help me? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747
https://github.com/scverse/scanpy/issues/747:22,testability,Assert,AssertionError,22,"highly_variable_genes AssertionError: Don’t call _normalize_index with non-categorical/string names; Hi, I am using anndata 0.6.21 and scanpy 1.4.3. I executed this code:. ```. sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. ```. and I got this error:. `AssertionError: Don’t call _normalize_index with non-categorical/string names. `. Can you help me? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747
https://github.com/scverse/scanpy/issues/747:369,testability,Assert,AssertionError,369,"highly_variable_genes AssertionError: Don’t call _normalize_index with non-categorical/string names; Hi, I am using anndata 0.6.21 and scanpy 1.4.3. I executed this code:. ```. sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. ```. and I got this error:. `AssertionError: Don’t call _normalize_index with non-categorical/string names. `. Can you help me? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747
https://github.com/scverse/scanpy/issues/747:360,usability,error,error,360,"highly_variable_genes AssertionError: Don’t call _normalize_index with non-categorical/string names; Hi, I am using anndata 0.6.21 and scanpy 1.4.3. I executed this code:. ```. sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. ```. and I got this error:. `AssertionError: Don’t call _normalize_index with non-categorical/string names. `. Can you help me? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747
https://github.com/scverse/scanpy/issues/747:459,usability,help,help,459,"highly_variable_genes AssertionError: Don’t call _normalize_index with non-categorical/string names; Hi, I am using anndata 0.6.21 and scanpy 1.4.3. I executed this code:. ```. sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. ```. and I got this error:. `AssertionError: Don’t call _normalize_index with non-categorical/string names. `. Can you help me? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747
https://github.com/scverse/scanpy/issues/748:72,availability,cluster,clustering,72,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:72,deployability,cluster,clustering,72,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:178,integrability,sub,subgrouping,178,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:515,integrability,sub,subset,515,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:37,interoperability,specif,specific,37,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:158,interoperability,specif,specified,158,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:433,interoperability,specif,specify,433,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:852,interoperability,share,sharey,852,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:308,safety,test,test,308,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/748:308,testability,test,test,308,"sc.tl.rank_genes_groups to rank only specific genes of interest?; After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748
https://github.com/scverse/scanpy/issues/749:245,integrability,sub,subgroup,245,"sc.tl.dpt(adata, n_branchings=2) sometimes works sometimes doesn't; A very very strange issue:. I would want to visualize a huge dataset (10000+, 20000+). However, sc.tl.dpt(adata, n_branchings=2) doesn't work. If I happened to select a smaller subgroup, it might work but not all the time. Thanks in advance for your help. Allen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:285,performance,time,time,285,"sc.tl.dpt(adata, n_branchings=2) sometimes works sometimes doesn't; A very very strange issue:. I would want to visualize a huge dataset (10000+, 20000+). However, sc.tl.dpt(adata, n_branchings=2) doesn't work. If I happened to select a smaller subgroup, it might work but not all the time. Thanks in advance for your help. Allen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:59,reliability,doe,doesn,59,"sc.tl.dpt(adata, n_branchings=2) sometimes works sometimes doesn't; A very very strange issue:. I would want to visualize a huge dataset (10000+, 20000+). However, sc.tl.dpt(adata, n_branchings=2) doesn't work. If I happened to select a smaller subgroup, it might work but not all the time. Thanks in advance for your help. Allen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:197,reliability,doe,doesn,197,"sc.tl.dpt(adata, n_branchings=2) sometimes works sometimes doesn't; A very very strange issue:. I would want to visualize a huge dataset (10000+, 20000+). However, sc.tl.dpt(adata, n_branchings=2) doesn't work. If I happened to select a smaller subgroup, it might work but not all the time. Thanks in advance for your help. Allen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:112,usability,visual,visualize,112,"sc.tl.dpt(adata, n_branchings=2) sometimes works sometimes doesn't; A very very strange issue:. I would want to visualize a huge dataset (10000+, 20000+). However, sc.tl.dpt(adata, n_branchings=2) doesn't work. If I happened to select a smaller subgroup, it might work but not all the time. Thanks in advance for your help. Allen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:318,usability,help,help,318,"sc.tl.dpt(adata, n_branchings=2) sometimes works sometimes doesn't; A very very strange issue:. I would want to visualize a huge dataset (10000+, 20000+). However, sc.tl.dpt(adata, n_branchings=2) doesn't work. If I happened to select a smaller subgroup, it might work but not all the time. Thanks in advance for your help. Allen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/750:29,deployability,scale,scale,29,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:490,deployability,scale,scale,490,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:6,energy efficiency,heat,heatmap,6,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:29,energy efficiency,scale,scale,29,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:59,energy efficiency,heat,heatmap,59,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:324,energy efficiency,heat,heatmap,324,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:448,energy efficiency,heat,heatmap,448,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:490,energy efficiency,scale,scale,490,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:568,energy efficiency,heat,heatmap,568,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:29,modifiability,scal,scale,29,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:490,modifiability,scal,scale,490,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:29,performance,scale,scale,29,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:490,performance,scale,scale,490,"sc.pl.heatmap show the wrong scale; Dear, when I use sc.pl.heatmap(adata,markers,groupby='leiden',show_gene_labels=True) to show some marker genes, the colorbar value range is different from that generated by sc.pl.umap(). I am sure that umap show the expression value correctly and there must be something wrong with sc.pl.heatmap(), here are the images:. For example, the expression value of gene 'Sct' is 0-7.5, while it changes to 0-1e7 on the heatmap, the value is so high that it may scale other gene's expression value to almost zero and nothing can be seen on heatmap for other genes. Some other genes have the same issue. Do you know the reason ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/751:713,availability,error,error,713,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:218,energy efficiency,load,load,218,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:655,energy efficiency,load,load,655,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1085,integrability,filter,filter,1085,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1201,integrability,filter,filter,1201,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1099,interoperability,format,format,1099,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1215,interoperability,format,format,1215,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:218,performance,load,load,218,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:655,performance,load,load,655,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:713,performance,error,error,713,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:713,safety,error,error,713,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:359,usability,user,user-images,359,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:525,usability,user,user-images,525,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:713,usability,error,error,713,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1373,usability,help,help,1373,"Concatenate files issue; Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">. <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:. `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`. `adata = adata[adata.obs['mt_frac'] < 0.2]. print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`. `sc.pp.filter_cells(adata, min_genes = 700). print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/752:0,deployability,Fail,Failing,0,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:17,deployability,build,builds,17,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:34,deployability,build,builds,34,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:45,deployability,fail,failing,45,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:133,deployability,build,build,133,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:139,deployability,log,logs,139,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:0,reliability,Fail,Failing,0,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:45,reliability,fail,failing,45,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:139,safety,log,logs,139,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:139,security,log,logs,139,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:139,testability,log,logs,139,"Failing bioconda builds; Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/753:46,availability,down,down,46,"_rank_genes_groups.py, gene names are trimmed down to 50 characters. ; When using long gene names the rank_genes_groups function does not work properly anymore as long gene names are trimmed down to 50 characters, which makes it difficult to look them up again in the adata object. I think the problem is caused on this line:. https://github.com/theislab/scanpy/blob/c5c32f2277ad3f9c5388fc5d0a602151f3bab42b/scanpy/tools/_rank_genes_groups.py#L401 where the gene names are casted to an unicode array with 50 elements. ```. np.array(['LOOONG','SHORT'],dtype='U5'). > array(['LOOON', 'SHORT'], dtype='<U5'). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/753:191,availability,down,down,191,"_rank_genes_groups.py, gene names are trimmed down to 50 characters. ; When using long gene names the rank_genes_groups function does not work properly anymore as long gene names are trimmed down to 50 characters, which makes it difficult to look them up again in the adata object. I think the problem is caused on this line:. https://github.com/theislab/scanpy/blob/c5c32f2277ad3f9c5388fc5d0a602151f3bab42b/scanpy/tools/_rank_genes_groups.py#L401 where the gene names are casted to an unicode array with 50 elements. ```. np.array(['LOOONG','SHORT'],dtype='U5'). > array(['LOOON', 'SHORT'], dtype='<U5'). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/753:129,reliability,doe,does,129,"_rank_genes_groups.py, gene names are trimmed down to 50 characters. ; When using long gene names the rank_genes_groups function does not work properly anymore as long gene names are trimmed down to 50 characters, which makes it difficult to look them up again in the adata object. I think the problem is caused on this line:. https://github.com/theislab/scanpy/blob/c5c32f2277ad3f9c5388fc5d0a602151f3bab42b/scanpy/tools/_rank_genes_groups.py#L401 where the gene names are casted to an unicode array with 50 elements. ```. np.array(['LOOONG','SHORT'],dtype='U5'). > array(['LOOON', 'SHORT'], dtype='<U5'). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/753:415,usability,tool,tools,415,"_rank_genes_groups.py, gene names are trimmed down to 50 characters. ; When using long gene names the rank_genes_groups function does not work properly anymore as long gene names are trimmed down to 50 characters, which makes it difficult to look them up again in the adata object. I think the problem is caused on this line:. https://github.com/theislab/scanpy/blob/c5c32f2277ad3f9c5388fc5d0a602151f3bab42b/scanpy/tools/_rank_genes_groups.py#L401 where the gene names are casted to an unicode array with 50 elements. ```. np.array(['LOOONG','SHORT'],dtype='U5'). > array(['LOOON', 'SHORT'], dtype='<U5'). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/754:324,availability,sli,slightly,324,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:343,deployability,log,logfoldchanges,343,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:144,modifiability,variab,variable,144,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:324,reliability,sli,slightly,324,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:261,safety,test,test,261,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:343,safety,log,logfoldchanges,343,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:343,security,log,logfoldchanges,343,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:261,testability,test,test,261,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:343,testability,log,logfoldchanges,343,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:285,usability,command,commands,285,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:404,usability,statu,status,404,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:538,usability,statu,status,538,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1493,usability,help,help,1493,"different pvals when doing wilcoxon rank_genes_groups for treatment vs. ctrl and ctrl vs. treatment; Hi,. I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges. ```. sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False). sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False). ```. ```. 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS. 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73. 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64. 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45. 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41. 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39. 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36. 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34. 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33. 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32. 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31. 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27. 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28. 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25. 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25. ```. Am I not doing it right, or because of the tie issue mentioned here? #698 . Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/755:81,availability,error,error,81,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:563,availability,toler,tolerance,563,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2455,availability,toler,tolerance,2455,"s['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2651,availability,toler,tolerance,2651,"._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for yo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2661,availability,toler,tolerance,2661," 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your respons",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1149,deployability,modul,module,1149," I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:3264,deployability,instal,installation,3264,"self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your response. Best regards,. Mikhael",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:512,energy efficiency,core,core,512,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1278,energy efficiency,model,model,1278,"ummary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2147,energy efficiency,core,core,2147,"module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the backgrou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2404,energy efficiency,core,core,2404,"]['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:3421,interoperability,platform,platform,3421,"self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your response. Best regards,. Mikhael",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:496,modifiability,pac,packages,496,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1149,modifiability,modul,module,1149," I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1206,modifiability,pac,packages,1206,"```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1542,modifiability,pac,packages,1542,"lf, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1830,modifiability,pac,packages,1830,"as._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.I",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2131,modifiability,pac,packages,2131,"70e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise tha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2388,modifiability,pac,packages,2388,"ata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:3352,modifiability,pac,packages,3352,"self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your response. Best regards,. Mikhael",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:81,performance,error,error,81,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:563,reliability,toleran,tolerance,563,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2455,reliability,toleran,tolerance,2455,"s['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2651,reliability,toleran,tolerance,2651,"._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for yo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2661,reliability,toleran,tolerance,2661," 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your respons",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:81,safety,error,error,81,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:633,safety,except,except,633,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1029,safety,except,exception,1029,"BMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1048,safety,except,exception,1048,"r all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1122,safety,input,input-,1122,". Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1149,safety,modul,module,1149," I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2511,safety,except,except,2511,"_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:3175,safety,compl,complete,3175,"self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your response. Best regards,. Mikhael",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:843,security,hash,hashtable,843,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:939,security,hash,hashtable,939,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1278,security,model,model,1278,"ummary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:2912,security,hash,hashtable,2912,"self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your response. Best regards,. Mikhael",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:3008,security,hash,hashtable,3008,"self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your response. Best regards,. Mikhael",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:3175,security,compl,complete,3175,"self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:. ```. {'commit_hash': 'd774f565b',. 'commit_source': 'installation',. 'default_encoding': 'cp1252',. 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',. 'ipython_version': '7.4.0',. 'os_name': 'nt',. 'platform': 'Windows-10-10.0.18362-SP0',. 'sys_executable': 'C:\\Anaconda\\python.exe',. 'sys_platform': 'win32',. 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '. '(AMD64)]'}. ```. Thank you very much for your response. Best regards,. Mikhael",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:309,testability,Trace,Traceback,309,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:440,testability,Trace,Traceback,440,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1078,testability,Trace,Traceback,1078,"ror when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:81,usability,error,error,81,"KeyError: 'louvain' when running PBMC3k tutorial; Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1122,usability,input,input-,1122,". Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py. sc.tl.paga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1222,usability,tool,tools,1222,"ga(adata). ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb. running PAGA. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 29",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1558,usability,tool,tools,1558,", tolerance). 2656 try:. -> 2657 return self._engine.get_loc(key). 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:1846,usability,tool,tools,1846,"ble.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-31-5aa170e493c3> in <module>. ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy). 92 adata.uns['paga'] = {}. 93 if not use_rna_velocity:. ---> 94 paga.compute_connectivities(). 95 adata.uns['paga']['connectivities'] = paga.connectivities. 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self). 126 def compute_connectivities(self):. 127 if self._model == 'v1.2':. --> 128 return self._compute_connectivities_v1_2(). 129 elif self._model == 'v1.0':. 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self). 141 g = utils.get_igraph_from_adjacency(ones, directed=True). 142 vc = igraph.VertexClustering(. --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values). 144 ns = vc.sizes(). 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key). 2925 if self.columns.nlevels > 1:. 2926 return self._getitem_multilevel(key). -> 2927 indexer = self.columns.get_loc(key). 2928 if is_integer(indexer):. 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance). 2657 return self._engine.get_loc(key). 2658 except KeyError:. -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance). 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/756:68,deployability,api,api,68,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:68,integrability,api,api,68,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:68,interoperability,api,api,68,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:7,performance,perform,performance,7,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:100,performance,time,time,100,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:173,performance,time,times,173,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:738,performance,network,networkx,738,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:1026,performance,network,networkx,1026,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:305,security,ident,identify,305,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:378,security,ident,identified,378,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:738,security,network,networkx,738,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:1026,security,network,networkx,1026,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:7,usability,perform,performance,7,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:1084,usability,user,user-images,1084,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:1207,usability,user,user-images,1207,"Import performance part 3; In #406 we decided to get rid of `scanpy.api`, which worsened our import time. Thanks to @ivirshup (#703, #704), the main culprits to long import times are out of the game, but there’s still room for improvement. I used [profimp](https://github.com/boris-42/profimp/#readme) to identify the rest. I started with just `profimp --html 'import scanpy'`, identified the external imports that take a while, and created a file in which I imported them before finally importing scanpy:. `scanpy-imports.py`. ```python. # anndata big imports. import numpy. import pandas. import zarr. import h5py. # scanpy big imports. import numba. import sklearn # preprocessing._simple. #import sklearn.metrics # neighbors. #import networkx # diffmap, paga, plotting._utils. import leidenalg. import louvain. import matplotlib.pyplot. import tables # sim → readwrite. # rest. import scanpy. ```. ```console. $ profimp --html ""$(cat scanpy-imports.py)"" >! profimp-scanpy.htm. ```. <details>. <summary>Outdated: 1.4s with networkx and sklearn.metrics</summary>. ![grafik](https://user-images.githubusercontent.com/291575/62112333-d2149d80-b2b2-11e9-92e0-9887b8574c8e.png). </details>. ![grafik](https://user-images.githubusercontent.com/291575/62118538-207b6980-b2be-11e9-85fe-b70c234ea5f5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/757:982,deployability,modul,module,982,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:116,integrability,batch,batch,116,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:210,integrability,batch,batches,210,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:248,integrability,batch,batch,248,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:448,integrability,batch,batch,448,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:1983,integrability,batch,batch,1983,"<module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_unique='-',. batch_categories=None, k=20, sigma=1., cos_norm_in=True, cos_norm_out=True,. svd_dim=None, var_adj=True, compute_angle=False, mnn_order=None, svd_mode='rsvd',. do_concatenate=True, save_raw=False, n_jobs=None, **kwargs):. try:. from mnnpy import mnn_correct as mnn_cor. n_jobs = settings.n_jobs if n_jobs is None else n_jobs. datas, mnn_list, angle_list = mnn_cor(. *datas, var_index=var_index, var_subset=var_subset, batch_key=batch_key, index_unique=index_unique,. batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). return datas, mnn_list, angle_list. except ImportError:. ```. I think the point is that mnn_cor is not giving 3 values in this line:. ```py. datas, mnn_list, angle_list = mnn_cor(. ```. Can you pleas help me with that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:738,modifiability,pac,packages,738,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:982,modifiability,modul,module,982,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:1095,modifiability,pac,packages,1095," times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_unique='-',. batch_categories=None, k=20, sigma=1., cos_norm_in=True, cos_norm_out=True,. svd_dim=None",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:1898,modifiability,pac,package,1898,"lueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_unique='-',. batch_categories=None, k=20, sigma=1., cos_norm_in=True, cos_norm_out=True,. svd_dim=None, var_adj=True, compute_angle=False, mnn_order=None, svd_mode='rsvd',. do_concatenate=True, save_raw=False, n_jobs=None, **kwargs):. try:. from mnnpy import mnn_correct as mnn_cor. n_jobs = settings.n_jobs if n_jobs is None else n_jobs. datas, mnn_list, angle_list = mnn_cor(. *datas, var_index=var_index, var_subset=var_subset, batch_key=batch_key, index_unique=index_unique,. batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). return datas, mnn_list, angle_list. except ImportError:. ```. I think the point is that mnn_cor is not giving 3 values in this line:. ```py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:100,performance,time,times,100,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:116,performance,batch,batch,116,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:210,performance,batch,batches,210,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:248,performance,batch,batch,248,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:448,performance,batch,batch,448,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:1983,performance,batch,batch,1983,"<module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_unique='-',. batch_categories=None, k=20, sigma=1., cos_norm_in=True, cos_norm_out=True,. svd_dim=None, var_adj=True, compute_angle=False, mnn_order=None, svd_mode='rsvd',. do_concatenate=True, save_raw=False, n_jobs=None, **kwargs):. try:. from mnnpy import mnn_correct as mnn_cor. n_jobs = settings.n_jobs if n_jobs is None else n_jobs. datas, mnn_list, angle_list = mnn_cor(. *datas, var_index=var_index, var_subset=var_subset, batch_key=batch_key, index_unique=index_unique,. batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). return datas, mnn_list, angle_list. except ImportError:. ```. I think the point is that mnn_cor is not giving 3 values in this line:. ```py. datas, mnn_list, angle_list = mnn_cor(. ```. Can you pleas help me with that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:955,safety,input,input-,955,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:982,safety,modul,module,982,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:1710,safety,except,except,1710,"``. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_unique='-',. batch_categories=None, k=20, sigma=1., cos_norm_in=True, cos_norm_out=True,. svd_dim=None, var_adj=True, compute_angle=False, mnn_order=None, svd_mode='rsvd',. do_concatenate=True, save_raw=False, n_jobs=None, **kwargs):. try:. from mnnpy import mnn_correct as mnn_cor. n_jobs = settings.n_jobs if n_jobs is None else n_jobs. datas, mnn_list, angle_list = mnn_cor(. *datas, var_index=var_index, var_subset=var_subset, batch_key=batch_key, index_unique=index_unique,. batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. do_concatenate=do_concaten",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:2799,safety,except,except,2799,"<module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_unique='-',. batch_categories=None, k=20, sigma=1., cos_norm_in=True, cos_norm_out=True,. svd_dim=None, var_adj=True, compute_angle=False, mnn_order=None, svd_mode='rsvd',. do_concatenate=True, save_raw=False, n_jobs=None, **kwargs):. try:. from mnnpy import mnn_correct as mnn_cor. n_jobs = settings.n_jobs if n_jobs is None else n_jobs. datas, mnn_list, angle_list = mnn_cor(. *datas, var_index=var_index, var_subset=var_subset, batch_key=batch_key, index_unique=index_unique,. batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). return datas, mnn_list, angle_list. except ImportError:. ```. I think the point is that mnn_cor is not giving 3 values in this line:. ```py. datas, mnn_list, angle_list = mnn_cor(. ```. Can you pleas help me with that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:911,testability,Trace,Traceback,911,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:955,usability,input,input-,955,"mnn_correct() ValueError: not enough values to unpack (expected 3, got 1); Hello,. I am having hard times using the batch correction function running matching mutual nearest neighbors. I have an anndata with 3 batches. I want to point out that the batch correction using the sc.pp.combat() function works. . On the other hand, if I run (on the uncorrected adata):. ```py. sce.pp.mnn_correct(adata, . var_index=None, . var_subset=None, . batch_key='batch', . index_unique='-', . batch_categories=None, . k=20, . sigma=1.0, . cos_norm_in=True, . cos_norm_out=True, . svd_dim=None, . var_adj=True, . compute_angle=False, . mnn_order=None, . svd_mode='rsvd', . do_concatenate=True, . save_raw=False, . n_jobs=None). ```. I get:. in ..../site-packages/scanpy/preprocessing/_mnn_correct.py the man_correct function is:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-47-b453bc0c2cd4> in <module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:2963,usability,help,help,2963,"<module>. 16 do_concatenate=True,. 17 save_raw=False,. ---> 18 n_jobs=None). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 97 batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. 98 svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. ---> 99 do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). 100 return datas, mnn_list, angle_list. 101 except ImportError:. ValueError: not enough values to unpack (expected 3, got 1). ```. I checked _mnn_correct.py. and it basically defines a function mnn_cor on the mnn_correct from mnnpy package:. ```py. def mnn_correct(*datas, var_index=None, var_subset=None, batch_key='batch', index_unique='-',. batch_categories=None, k=20, sigma=1., cos_norm_in=True, cos_norm_out=True,. svd_dim=None, var_adj=True, compute_angle=False, mnn_order=None, svd_mode='rsvd',. do_concatenate=True, save_raw=False, n_jobs=None, **kwargs):. try:. from mnnpy import mnn_correct as mnn_cor. n_jobs = settings.n_jobs if n_jobs is None else n_jobs. datas, mnn_list, angle_list = mnn_cor(. *datas, var_index=var_index, var_subset=var_subset, batch_key=batch_key, index_unique=index_unique,. batch_categories=batch_categories, k=k, sigma=sigma, cos_norm_in=cos_norm_in, cos_norm_out=cos_norm_out,. svd_dim=svd_dim, var_adj=var_adj, compute_angle=compute_angle, mnn_order=mnn_order, svd_mode=svd_mode,. do_concatenate=do_concatenate, save_raw=save_raw, n_jobs=n_jobs, **kwargs). return datas, mnn_list, angle_list. except ImportError:. ```. I think the point is that mnn_cor is not giving 3 values in this line:. ```py. datas, mnn_list, angle_list = mnn_cor(. ```. Can you pleas help me with that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/758:57,energy efficiency,current,currently,57,"batch_key of highly_variable_genes not working; Hey! I'm currently having an issue with the `batch_key` functionality of `sc.pp.highly_variable_genes` introduced in https://github.com/theislab/scanpy/pull/622 by @gokceneraslan. If I try setting batch_key, I get a TypeError:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata, batch_key=""sample"", flavor='cell_ranger', n_top_genes=4000, inplace=False). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 336 dtypes.append([('highly_variable_nbatches', int),. 337 ('highly_variable_intersection', np.bool_)]). --> 338 return np.rec.fromarrays(arrays, dtype=dtypes). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 606 . 607 if dtype is not None:. --> 608 descr = sb.dtype(dtype). 609 _names = descr.names. 610 else:. TypeError: data type not understood. ```. I have tried with multiple categorical columns and it worked with none of them.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:983,energy efficiency,core,core,983,"batch_key of highly_variable_genes not working; Hey! I'm currently having an issue with the `batch_key` functionality of `sc.pp.highly_variable_genes` introduced in https://github.com/theislab/scanpy/pull/622 by @gokceneraslan. If I try setting batch_key, I get a TypeError:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata, batch_key=""sample"", flavor='cell_ranger', n_top_genes=4000, inplace=False). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 336 dtypes.append([('highly_variable_nbatches', int),. 337 ('highly_variable_intersection', np.bool_)]). --> 338 return np.rec.fromarrays(arrays, dtype=dtypes). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 606 . 607 if dtype is not None:. --> 608 descr = sb.dtype(dtype). 609 _names = descr.names. 610 else:. TypeError: data type not understood. ```. I have tried with multiple categorical columns and it worked with none of them.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:733,integrability,sub,subset,733,"batch_key of highly_variable_genes not working; Hey! I'm currently having an issue with the `batch_key` functionality of `sc.pp.highly_variable_genes` introduced in https://github.com/theislab/scanpy/pull/622 by @gokceneraslan. If I try setting batch_key, I get a TypeError:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata, batch_key=""sample"", flavor='cell_ranger', n_top_genes=4000, inplace=False). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 336 dtypes.append([('highly_variable_nbatches', int),. 337 ('highly_variable_intersection', np.bool_)]). --> 338 return np.rec.fromarrays(arrays, dtype=dtypes). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 606 . 607 if dtype is not None:. --> 608 descr = sb.dtype(dtype). 609 _names = descr.names. 610 else:. TypeError: data type not understood. ```. I have tried with multiple categorical columns and it worked with none of them.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:1038,interoperability,format,formats,1038,"batch_key of highly_variable_genes not working; Hey! I'm currently having an issue with the `batch_key` functionality of `sc.pp.highly_variable_genes` introduced in https://github.com/theislab/scanpy/pull/622 by @gokceneraslan. If I try setting batch_key, I get a TypeError:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata, batch_key=""sample"", flavor='cell_ranger', n_top_genes=4000, inplace=False). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 336 dtypes.append([('highly_variable_nbatches', int),. 337 ('highly_variable_intersection', np.bool_)]). --> 338 return np.rec.fromarrays(arrays, dtype=dtypes). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 606 . 607 if dtype is not None:. --> 608 descr = sb.dtype(dtype). 609 _names = descr.names. 610 else:. TypeError: data type not understood. ```. I have tried with multiple categorical columns and it worked with none of them.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:576,modifiability,pac,packages,576,"batch_key of highly_variable_genes not working; Hey! I'm currently having an issue with the `batch_key` functionality of `sc.pp.highly_variable_genes` introduced in https://github.com/theislab/scanpy/pull/622 by @gokceneraslan. If I try setting batch_key, I get a TypeError:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata, batch_key=""sample"", flavor='cell_ranger', n_top_genes=4000, inplace=False). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 336 dtypes.append([('highly_variable_nbatches', int),. 337 ('highly_variable_intersection', np.bool_)]). --> 338 return np.rec.fromarrays(arrays, dtype=dtypes). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 606 . 607 if dtype is not None:. --> 608 descr = sb.dtype(dtype). 609 _names = descr.names. 610 else:. TypeError: data type not understood. ```. I have tried with multiple categorical columns and it worked with none of them.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:968,modifiability,pac,packages,968,"batch_key of highly_variable_genes not working; Hey! I'm currently having an issue with the `batch_key` functionality of `sc.pp.highly_variable_genes` introduced in https://github.com/theislab/scanpy/pull/622 by @gokceneraslan. If I try setting batch_key, I get a TypeError:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata, batch_key=""sample"", flavor='cell_ranger', n_top_genes=4000, inplace=False). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 336 dtypes.append([('highly_variable_nbatches', int),. 337 ('highly_variable_intersection', np.bool_)]). --> 338 return np.rec.fromarrays(arrays, dtype=dtypes). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 606 . 607 if dtype is not None:. --> 608 descr = sb.dtype(dtype). 609 _names = descr.names. 610 else:. TypeError: data type not understood. ```. I have tried with multiple categorical columns and it worked with none of them.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:372,testability,Trace,Traceback,372,"batch_key of highly_variable_genes not working; Hey! I'm currently having an issue with the `batch_key` functionality of `sc.pp.highly_variable_genes` introduced in https://github.com/theislab/scanpy/pull/622 by @gokceneraslan. If I try setting batch_key, I get a TypeError:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata, batch_key=""sample"", flavor='cell_ranger', n_top_genes=4000, inplace=False). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 336 dtypes.append([('highly_variable_nbatches', int),. 337 ('highly_variable_intersection', np.bool_)]). --> 338 return np.rec.fromarrays(arrays, dtype=dtypes). ~/.conda/envs/sc-tutorial/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 606 . 607 if dtype is not None:. --> 608 descr = sb.dtype(dtype). 609 _names = descr.names. 610 else:. TypeError: data type not understood. ```. I have tried with multiple categorical columns and it worked with none of them.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/759:84,availability,cluster,clustering,84,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:84,deployability,cluster,clustering,84,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:134,integrability,batch,batch,134,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:179,integrability,batch,batch,179,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:390,integrability,batch,batch,390,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:481,integrability,sub,submerged,481,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:505,modifiability,layer,layer,505,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:714,modifiability,paramet,parameters,714,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:900,modifiability,variab,variable,900,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:134,performance,batch,batch,134,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:179,performance,batch,batch,179,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:390,performance,batch,batch,390,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:700,security,auth,authors,700,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:74,usability,visual,visualize,74,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:867,usability,support,support,867,"add restrict_to to sc.pl.umap function?; Hello,. In some cases, I need to visualize clustering results (categorical) on UMAP for each batch. . I know `sc.pl.umap(adata[adata.obs['batch] == 'batch1], color = 'louvain')` is a solution. However, other cells are missing. I think the other cells colored by grey as background should be a better way. . I notice that `sc.pl.umap(adata, color = 'batch', groups = ['batch1'] )` can retain other cells as grey, though sometimes cells were submerged in the bottom layer (I used reoder_categories to bypass this issue). But, `color` and `groups` must be correspondence! . Is there any way to fulfill my needs in `Scanpy` if I missed something. . Or, could the authors add a parameters, such as `restrict_to` in `sc.tl.louvain`, to implement this function: ① liberate strong associations between `color` and `groups`, and ② add support for ordering categorical variable.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/760:137,availability,error,error,137,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:449,availability,error,error,449,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:256,deployability,instal,installed,256,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:544,deployability,modul,module,544,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:143,integrability,messag,message,143,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:143,interoperability,messag,message,143,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:544,modifiability,modul,module,544,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:653,modifiability,pac,packages,653,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:137,performance,error,error,137,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:449,performance,error,error,449,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:137,safety,error,error,137,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:449,safety,error,error,449,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:516,safety,input,input-,516,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:544,safety,modul,module,544,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:472,testability,Trace,Traceback,472,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:137,usability,error,error,137,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:226,usability,behavi,behavior,226,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:363,usability,learn,learn,363,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:449,usability,error,error,449,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/760:516,usability,input,input-,516,"'concatenate not found; Hi. I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:. AttributeError Traceback (most recent call last). <ipython-input-187-32c3eda3cdc8> in <module>. ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr). 687 return self.getnnz(). 688 else:. --> 689 raise AttributeError(attr + "" not found""). 690 . 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760
https://github.com/scverse/scanpy/issues/761:24,reliability,doe,does,24,"sc.pl.umap ""legend_loc"" does not incorporate matplotlib.legend options; I'd like to shift a legend with long labels into the upper right corner of the UMAP projection, but going through the code, it appears that any value for legend_loc that is not ""right margin"" or ""on data"" becomes ""no legend."" . sc.pl.umap(adata,color=""samples"",legend_loc=""upper_right"")",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/761
https://github.com/scverse/scanpy/issues/762:43,availability,error,error,43,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:283,modifiability,pac,packages,283,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:395,modifiability,pac,packages,395,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:491,modifiability,layer,layer,491,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:497,modifiability,layer,layers,497,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:569,modifiability,layer,layer,569,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:889,modifiability,layer,layer,889,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:895,modifiability,layer,layers,895,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:957,modifiability,layer,layer,957,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:963,modifiability,layer,layers,963,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:1063,modifiability,layer,layer,1063,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:43,performance,error,error,43,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:1049,reliability,doe,does,1049,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:43,safety,error,error,43,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:43,usability,error,error,43,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:215,usability,custom,custom,215,"sc.pl.scatter for var; I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names. ```. File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter. ax=ax). File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs. c = adata.raw.obs_vector(key, layer=layers[2]). TypeError: obs_vector() got an unexpected keyword argument 'layer'. ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py. ``` python. # coloring according to gene expression. elif (use_raw. and adata.raw is not None. and key in adata.raw.var_names):. c = adata.raw.obs_vector(key). elif key in adata.var_names:. c = adata.raw.obs_vector(key, layer=layers[2]). ```. Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/763:293,availability,error,error,293,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1520,deployability,modul,module,1520,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2120,deployability,contain,contains,2120,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2198,deployability,contain,contains,2198,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2029,energy efficiency,core,core,2029,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:998,integrability,sub,subtract,998,".pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2078,interoperability,specif,specify,2078,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2159,interoperability,specif,specify,2159,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:359,modifiability,pac,packages,359,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:530,modifiability,pac,packages,530,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:706,modifiability,pac,packages,706,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:909,modifiability,pac,packages,909,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1119,modifiability,pac,packages,1119,"1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1303,modifiability,pac,packages,1303,"ome/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1520,modifiability,modul,module,1520,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1625,modifiability,pac,packages,1625,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1795,modifiability,pac,packages,1795,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2013,modifiability,pac,packages,2013,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2345,modifiability,variab,variable,2345,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:293,performance,error,error,293,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:293,safety,error,error,293,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1520,safety,modul,module,1520,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2106,safety,input,input,2106,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2187,safety,input,input,2187,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:1438,testability,Trace,Traceback,1438,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:293,usability,error,error,293,"sc.pp.highly_variable_genes: overflow encountered; Env:. * Ubuntu 16.04. * python 3.7. * pandas 0.25.0. * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do. `sc.pp.highly_variable_genes(adata)`. I get the following error. ```. /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2106,usability,input,input,2106,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:2187,usability,input,input,2187,"ed in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1. result = op(self._deduped_data()). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p. mean = np.log1p(mean). /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p. mean = np.log1p(mean). Traceback (most recent call last):. File ""../../scvi/scvi_adata.py"", line 75, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes. flavor=flavor). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 233, in cut. ""cannot specify integer `bins` when input data "" ""contains infinity"". ValueError: cannot specify integer `bins` when input data contains infinity. ```. Indeed, if I do `np.expm1(3701)` I get an overflow. I think it will be necessary to come up with a way to calculate highly variable genes without doing `expm1` on the raw counts, due to this overflow issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/pull/765:21,deployability,depend,dependency,21,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:88,deployability,depend,dependency,88,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:120,deployability,fail,fail,120,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:21,integrability,depend,dependency,21,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:88,integrability,depend,dependency,88,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:21,modifiability,depend,dependency,21,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:88,modifiability,depend,dependency,88,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:120,reliability,fail,fail,120,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:16,safety,test,test,16,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:21,safety,depend,dependency,21,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:88,safety,depend,dependency,88,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:114,safety,test,tests,114,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:16,testability,test,test,16,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:21,testability,depend,dependency,21,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:88,testability,depend,dependency,88,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/pull/765:114,testability,test,tests,114,Add fsspec as a test dependency due to dask; Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765
https://github.com/scverse/scanpy/issues/766:18,availability,cluster,clustering,18,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:174,availability,cluster,clustering,174,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:230,availability,cluster,clustering,230,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:381,availability,cluster,clustering,381,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:18,deployability,cluster,clustering,18,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:174,deployability,cluster,clustering,174,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:230,deployability,cluster,clustering,230,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:381,deployability,cluster,clustering,381,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:6,energy efficiency,heat,heatmap,6,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:45,energy efficiency,draw,draw,45,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:52,energy efficiency,heat,heatmap,52,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:154,energy efficiency,heat,heatmap,154,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:270,energy efficiency,heat,heatmap,270,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:419,energy efficiency,heat,heatmap,419,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:496,energy efficiency,heat,heatmap,496,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:304,interoperability,specif,specific,304,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:329,reliability,doe,does,329,"sc.pl.heatmap row clustering; Hi,. I want to draw a heatmap to show a group of genes that we interested in in which gropup of cells, However, seems sc.pl.heatmap can only do clustering for cell groups, has no function for the row clustering for genes? Like the attached heatmap, there are some genes are specific to some groups, does there any method or can add the method for row clustering in scanpy? Thanks,. Jphe. [heatmap.sepcific-Genes.pdf](https://github.com/theislab/scanpy/files/3464747/heatmap.sepcific-Genes.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/767:67,integrability,compon,component,67,Will scanpy implement ICA?; Are there plans to include independent component analysis (ICA) in Scanpy? This would be useful for me. I know that it is already implemented in Seurat. Thank you,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:67,interoperability,compon,component,67,Will scanpy implement ICA?; Are there plans to include independent component analysis (ICA) in Scanpy? This would be useful for me. I know that it is already implemented in Seurat. Thank you,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:67,modifiability,compon,component,67,Will scanpy implement ICA?; Are there plans to include independent component analysis (ICA) in Scanpy? This would be useful for me. I know that it is already implemented in Seurat. Thank you,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:38,testability,plan,plans,38,Will scanpy implement ICA?; Are there plans to include independent component analysis (ICA) in Scanpy? This would be useful for me. I know that it is already implemented in Seurat. Thank you,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/768:0,availability,Error,Error,0,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:138,availability,error,error,138,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:6,integrability,filter,filtering,6,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:77,integrability,filter,filters,77,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:0,performance,Error,Error,0,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:138,performance,error,error,138,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:0,safety,Error,Error,0,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:35,safety,valid,valid,35,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:138,safety,error,error,138,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:0,usability,Error,Error,0,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:138,usability,error,error,138,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:223,usability,user,user-images,223,"Error filtering 'Boolean index not valid'; Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/769:11,availability,error,error,11,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:121,availability,error,error,121,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:146,availability,error,error,146,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:441,availability,error,error,441,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:152,deployability,log,log,152,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:11,performance,error,error,11,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:121,performance,error,error,121,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:146,performance,error,error,146,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:441,performance,error,error,441,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:11,safety,error,error,11,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:121,safety,error,error,121,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:146,safety,error,error,146,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:152,safety,log,log,152,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:441,safety,error,error,441,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:152,security,log,log,152,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:152,testability,log,log,152,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:397,testability,understand,understand,397,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:11,usability,error,error,11,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:121,usability,error,error,121,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:146,usability,error,error,146,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:441,usability,error,error,441,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:546,usability,user,user-images,546,"sc.tl.umap error with init_pos=""paga""; Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue? Attached error. Any suggestions? . Thanks! <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/770:413,deployability,modul,module,413,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:749,deployability,instal,install,749,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:769,deployability,instal,install,769,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:974,deployability,log,logg,974,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:1224,deployability,log,logging,1224,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:272,integrability,batch,batch,272,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:521,integrability,batch,batch,521,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:413,modifiability,modul,module,413,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:602,modifiability,pac,packages,602,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:876,modifiability,pac,packages,876,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:1208,modifiability,pac,packages,1208,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:272,performance,batch,batch,272,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:521,performance,batch,batch,521,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:997,performance,time,time,997,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:385,safety,input,input-,385,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:413,safety,modul,module,413,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:699,safety,except,except,699,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:974,safety,log,logg,974,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:1224,safety,log,logging,1224,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:974,security,log,logg,974,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:1224,security,log,logging,1224,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:341,testability,Trace,Traceback,341,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:974,testability,log,logg,974,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:1224,testability,log,logging,1224,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:385,usability,input,input-,385,"sce.pp.bbknn() TypeError: msg() got an unexpected keyword argument 'deep'; Reproducible example. ```py. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sc.pp.pca(adata). sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`. ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-231-50baef9a10a9> in <module>. 5 pbmc = sc.datasets.pbmc68k_reduced(). 6 sc.pp.pca(adata). ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs). 82 except ImportError:. 83 raise ImportError('Please install bbknn: `pip install bbknn`.'). ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs). 281 . 282 	logg.info('	finished', time=start,. --> 283 		deep=('added to `.uns[\'neighbors\']`\n'. 284 ' \'distances\', weighted adjacency matrix\n'. 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs). 17 . 18 def info(*args, **kwargs):. ---> 19 return msg(*args, v='info', **kwargs). 20 . 21 . TypeError: msg() got an unexpected keyword argument 'deep'`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/pull/771:183,deployability,releas,release,183,Fix umap when init_coords=paga; Fixes #769. Looks like I only tested my use case in #724. Not sure if this will still be needed once https://github.com/lmcinnes/umap/pull/261 is in a release.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/771
https://github.com/scverse/scanpy/pull/771:62,safety,test,tested,62,Fix umap when init_coords=paga; Fixes #769. Looks like I only tested my use case in #724. Not sure if this will still be needed once https://github.com/lmcinnes/umap/pull/261 is in a release.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/771
https://github.com/scverse/scanpy/pull/771:62,testability,test,tested,62,Fix umap when init_coords=paga; Fixes #769. Looks like I only tested my use case in #724. Not sure if this will still be needed once https://github.com/lmcinnes/umap/pull/261 is in a release.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/771
https://github.com/scverse/scanpy/pull/772:0,deployability,Updat,Update,0,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:0,safety,Updat,Update,0,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:37,safety,test,tests,37,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:78,safety,test,tests,78,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:0,security,Updat,Update,0,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:37,testability,test,tests,37,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:78,testability,test,tests,78,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:20,usability,guid,guide,20,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/pull/772:115,usability,guid,guide,115,Update contributing guide to include tests; Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772
https://github.com/scverse/scanpy/issues/773:18,modifiability,layer,layer,18,rank_genes_groups layer option; Can a layer option be added to`sc.tl.rank_genes_groups`?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/773
https://github.com/scverse/scanpy/issues/773:38,modifiability,layer,layer,38,rank_genes_groups layer option; Can a layer option be added to`sc.tl.rank_genes_groups`?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/773
https://github.com/scverse/scanpy/issues/774:42,interoperability,format,format,42,"Code of ""converting Seurat object to loom format #652""; Hi, thanks for your previous job. And I converted the Seurat.object using as.SingleCellExperiment() according to [this page](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb). Sorry, I‘am a fresh man in this field. Now I wonder what kind of commond (such as write.csv or saveRDS) to use to save the ""pbmc_sce"" file, and how to read it in Scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/774
https://github.com/scverse/scanpy/issues/775:268,deployability,continu,continuous,268,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:320,deployability,scale,scale,320,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1464,deployability,continu,continuous,1464,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:320,energy efficiency,scale,scale,320,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1911,integrability,translat,translated,1911,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:366,interoperability,specif,specify,366,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1057,interoperability,specif,specify,1057,"ng functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1130,interoperability,share,shared,1130," of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it mak",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1168,interoperability,specif,specific,1168,"e our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1851,interoperability,specif,specify,1851,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1911,interoperability,translat,translated,1911,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:279,modifiability,variab,variables,279,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:320,modifiability,scal,scale,320,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:413,modifiability,variab,variables,413,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1145,modifiability,variab,variables,1145,"l hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1475,modifiability,variab,variable,1475,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1593,modifiability,variab,variable,1593,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1959,modifiability,variab,variable,1959,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:320,performance,scale,scale,320,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:564,reliability,doe,doesn,564,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1693,security,modif,modifications,1693,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:2369,security,access,accessible,2369,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:734,testability,understand,understand,734,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1047,testability,simpl,simply,1047," our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1325,testability,understand,understand,1325,". some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:168,usability,close,close,168,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:572,usability,help,help,572,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:673,usability,person,person,673,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:881,usability,custom,custom,881,"Normalization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:974,usability,custom,custom-normalization-manually-implement-two-linear-ranges,974,"malization fun with vmin/vmax; Dear people,. In our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.gith",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1047,usability,simpl,simply,1047," our plotting functions, vmin and vmax are great arguments, we all love them. First of all, let's all hold our hands, close our eyes and thank matplotlib developers for implementing them. But when we jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1246,usability,custom,custom,1246," jointly plot some continuous variables that are not on the exact same scale (e.g. some genes), it's not possible to specify a single vmin/vmax value that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1395,usability,custom,custom,1395," that fits all variables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1660,usability,user,user-friendly,1660,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1987,usability,user,user-images,1987,"ables especially if they have some outliers. This deeply saddens us and forces us to watch a few more episodes of Stranger Things and it certainly doesn't help :(. I would like to hear your thoughts about how to fix that. But before that, as a responsible person, I did some homework and I spent around 34 minutes to understand how color normalization works in matplotlib (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html) and tried to implement a custom normalization class (https://matplotlib.org/3.1.1/tutorials/colors/colormapnorms.html#custom-normalization-manually-implement-two-linear-ranges). . My idea is simply to specify vmin/vmax in terms of quantiles of the color vector which can be shared between variables instead of a specific value. One way, I thought, might be to pass a `norm` argument with a custom normalization object to our lovely `plot_scatter`. However, as far as I understand, it's not possible because in the quantile function in the custom normalization class requires the entire color vector for each continuous variable which is not super convenient because it's too much preprocessing to find different quantile values for each variable and pass a vmin/vmax vector to the plotting function. Not user-friendly and still requires modifications in the code :(. Instead, I added two ugly arguments named `vmin_quantile` and `vmax_quantile` to the `plot_scatter` function which allows me to specify a single quantile value for vmin/vmax which is then translated into real values separately for each variable:. ![image](https://user-images.githubusercontent.com/1140359/62720493-20731c00-b9d8-11e9-9dc9-f91cf052c4e1.png). This solved my problem but I was wondering if it makes sense to add this to scanpy. What do you think? Finally, here is the way I use it:. `plot_scatter(adata, basis='umap', color=['louvain', 'NKG7', 'GNLY', 'KIT'], cmap='Reds', vmax_quantile=0.999)`. PS: It needs a few more lines to be accessible from other functions like sc.pl.umap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/pull/776:158,interoperability,specif,specified,158,"Fix sc.pl.violin not making violinplots; When groupby is not None and multipanel is True, nothing is plotted. Now we fallback to non-multipanel if groupby is specified. Related to #348.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/776
https://github.com/scverse/scanpy/issues/777:448,deployability,scale,scale,448,"Bugs with reloaded anndata object from saved h5ad file; I generated and saved the scanpy object with following codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:2021,deployability,version,version,2021,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:448,energy efficiency,scale,scale,448,"Bugs with reloaded anndata object from saved h5ad file; I generated and saved the scanpy object with following codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1373,integrability,wrap,wrapper,1373,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1444,integrability,wrap,wrapper,1444,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:2021,integrability,version,version,2021,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1373,interoperability,wrapper,wrapper,1373,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1444,interoperability,wrapper,wrapper,1444,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:448,modifiability,scal,scale,448,"Bugs with reloaded anndata object from saved h5ad file; I generated and saved the scanpy object with following codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1018,modifiability,pac,packages,1018,"data object from saved h5ad file; I generated and saved the scanpy object with following codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1198,modifiability,pac,packages,1198,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1513,modifiability,pac,packages,1513,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1686,modifiability,pac,packages,1686,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1810,modifiability,pac,packages,1810,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:2021,modifiability,version,version,2021,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:2032,modifiability,pac,packages,2032,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:448,performance,scale,scale,448,"Bugs with reloaded anndata object from saved h5ad file; I generated and saved the scanpy object with following codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:736,security,session,session,736,"Bugs with reloaded anndata object from saved h5ad file; I generated and saved the scanpy object with following codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:965,usability,User,Users,965,"Bugs with reloaded anndata object from saved h5ad file; I generated and saved the scanpy object with following codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1145,usability,User,Users,1145,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1460,usability,User,Users,1460,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1633,usability,User,Users,1633,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:1757,usability,User,Users,1757,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:2104,usability,help,help,2104,"g codes:. ```. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=4, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='cell_types'). sc.pp.neighbors(adata, n_neighbors=20, n_pcs=20). sc.tl.louvain(adata). sc.tl.umap(adata). sc.tl.diffmap(adata, n_comps=15). adata.write(""Scanpy.h5ad""). ```. Then reload into another session and tring to plot:. ```. adata2 = anndata.read_h5ad(""Scanpy.h5ad"", backed = 'r'). sc.pl.umap(adata, color=['louvain', ""MMP3""]). ```. However the bug come out as:. ```. sc.pl.umap(adata, color=['louvain', ""MMP3""]). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap. return plot_scatter(adata, basis='umap', **kwargs). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 280, in plot_scatter. color_vector = color_vector[order]. File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 476, in __getitem__. selection = sel.select(self.shape, args, dsid=self.id). File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 72, in select. sel[arg]. File ""/Users/temp/anaconda/envs/python36/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 212, in __getitem__. raise TypeError(""PointSelection __getitem__ only works with bool arrays""). TypeError: PointSelection __getitem__ only works with bool arrays. ```. The version of packages:. ```. 1.4 for scanpy. 0.6.22 for anndata. ```. Thanks for the help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/778:45,availability,sli,sliced,45,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:120,availability,sli,sliced,120,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:313,availability,error,error,313,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:492,deployability,API,API,492,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:192,integrability,filter,filter,192,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:492,integrability,API,API,492,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:15,interoperability,coordinat,coordinates,15,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:101,interoperability,coordinat,coordinates,101,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:492,interoperability,API,API,492,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:313,performance,error,error,313,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:45,reliability,sli,sliced,45,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:120,reliability,sli,sliced,120,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:313,safety,error,error,313,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:0,security,Access,Accessing,0,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:89,security,access,access,89,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:399,security,access,access,399,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:313,usability,error,error,313,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:471,usability,behavi,behavior,471,"Accessing tSNE coordinates different between sliced and unsliced AnnData; I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/779:26,deployability,releas,release,26,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:56,safety,test,testing,56,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:150,safety,accid,accidentally,150,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:185,safety,except,exception,185,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:499,safety,test,tests,499,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:542,safety,except,exception,542,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:56,testability,test,testing,56,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:499,testability,test,tests,499,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:214,usability,user,user-images,214,"Preparations for UMAP 0.4 release; Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/780:21,integrability,batch,batch,21,"Covariates in combat batch correction; Hi,. I wonder how one should use the `covariates` argument of combat. I cannot find an example or more guidance about it. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:21,performance,batch,batch,21,"Covariates in combat batch correction; Hi,. I wonder how one should use the `covariates` argument of combat. I cannot find an example or more guidance about it. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:142,usability,guidanc,guidance,142,"Covariates in combat batch correction; Hi,. I wonder how one should use the `covariates` argument of combat. I cannot find an example or more guidance about it. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/781:201,reliability,doe,does,201,"get.rank_genes_groups() key argument not used; `rank_genes_groups_df` takes `key` as an argument and the docs says it is the key differential expression groups were stored under. However, the function does not use that key and fetches DE results from the default 'rank_genes_groups' key. line 55 under `rank_genes_groups_df() ` in scanpy/get.py. `d[k] = adata.uns[""rank_genes_groups""][k][group]` should be changed to `d[k] = adata.uns[key][k][group]`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/781
https://github.com/scverse/scanpy/pull/782:48,energy efficiency,heat,heatmap,48,fix alignment of lines separating categories in heatmap #637;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/782
https://github.com/scverse/scanpy/pull/784:26,deployability,releas,release,26,Preparations for UMAP 0.4 release; https://github.com/theislab/scanpy/issues/779. Also i see some changes in the internal nnescent of umap and it is problematic for [Ingest](https://github.com/theislab/scanpy/pull/651).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784
https://github.com/scverse/scanpy/issues/785:61,availability,Error,Error,61,"highly_variable_genes variance computation on dense matrix - Error; When calling highly_variable_genes on an adata object with dense matrix, I get. ```pytb. LinAlgError: Last 2 dimensions of the array must be square. ```. The problem seems to come from squaring the means in the `_get_mean_var` function (`scanpy/preprocessing/_utils.py`). ```py. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). ```. specifically the `mean**2`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/785
https://github.com/scverse/scanpy/issues/785:409,interoperability,specif,specifically,409,"highly_variable_genes variance computation on dense matrix - Error; When calling highly_variable_genes on an adata object with dense matrix, I get. ```pytb. LinAlgError: Last 2 dimensions of the array must be square. ```. The problem seems to come from squaring the means in the `_get_mean_var` function (`scanpy/preprocessing/_utils.py`). ```py. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). ```. specifically the `mean**2`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/785
https://github.com/scverse/scanpy/issues/785:61,performance,Error,Error,61,"highly_variable_genes variance computation on dense matrix - Error; When calling highly_variable_genes on an adata object with dense matrix, I get. ```pytb. LinAlgError: Last 2 dimensions of the array must be square. ```. The problem seems to come from squaring the means in the `_get_mean_var` function (`scanpy/preprocessing/_utils.py`). ```py. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). ```. specifically the `mean**2`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/785
https://github.com/scverse/scanpy/issues/785:61,safety,Error,Error,61,"highly_variable_genes variance computation on dense matrix - Error; When calling highly_variable_genes on an adata object with dense matrix, I get. ```pytb. LinAlgError: Last 2 dimensions of the array must be square. ```. The problem seems to come from squaring the means in the `_get_mean_var` function (`scanpy/preprocessing/_utils.py`). ```py. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). ```. specifically the `mean**2`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/785
https://github.com/scverse/scanpy/issues/785:61,usability,Error,Error,61,"highly_variable_genes variance computation on dense matrix - Error; When calling highly_variable_genes on an adata object with dense matrix, I get. ```pytb. LinAlgError: Last 2 dimensions of the array must be square. ```. The problem seems to come from squaring the means in the `_get_mean_var` function (`scanpy/preprocessing/_utils.py`). ```py. var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). ```. specifically the `mean**2`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/785
https://github.com/scverse/scanpy/issues/786:153,availability,error,error,153,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:172,availability,ERROR,ERROR,172,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:349,availability,error,error,349,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:371,availability,ERROR,ERROR,371,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:386,availability,error,errored,386,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:987,availability,error,error,987,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:1061,availability,avail,available,1061,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:10,deployability,instal,install,10,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:179,deployability,Fail,Failed,179,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:186,deployability,build,building,186,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:225,deployability,instal,install,225,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:273,deployability,instal,install,273,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:302,deployability,instal,install,302,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:322,deployability,instal,install,322,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:725,deployability,instal,install,725,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:750,deployability,instal,install-record,750,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:782,deployability,version,version-externally-managed,782,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:833,deployability,log,logs,833,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:884,deployability,instal,install,884,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:939,deployability,instal,install,939,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:801,energy efficiency,manag,managed,801,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:1076,energy efficiency,current,current,1076,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:782,integrability,version,version-externally-managed,782,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:782,modifiability,version,version-externally-managed,782,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:1007,modifiability,Pac,PackagesNotFoundError,1007,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:1044,modifiability,pac,packages,1044,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:153,performance,error,error,153,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:172,performance,ERROR,ERROR,172,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:349,performance,error,error,349,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:371,performance,ERROR,ERROR,371,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:386,performance,error,errored,386,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:987,performance,error,error,987,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:179,reliability,Fail,Failed,179,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:1061,reliability,availab,available,1061,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:153,safety,error,error,153,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:172,safety,ERROR,ERROR,172,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:349,safety,error,error,349,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:371,safety,ERROR,ERROR,371,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:386,safety,error,errored,386,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:801,safety,manag,managed,801,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:833,safety,log,logs,833,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:987,safety,error,error,987,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:1061,safety,avail,available,1061,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:507,security,token,tokenize,507,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:598,security,token,tokenize,598,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:833,security,log,logs,833,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:1061,security,availab,available,1061,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:833,testability,log,logs,833,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:153,usability,error,error,153,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:172,usability,ERROR,ERROR,172,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:349,usability,error,error,349,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:371,usability,ERROR,ERROR,371,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:378,usability,Command,Command,378,"unable to install louvain on Windows; Hi all,. I'm having a trouble in running a code: . sc.tl.louvain(adata). So, when I try to run the code, it has an error saying that. ERROR: Failed building wheel for louvain. I tried to install louvain in anaconda prompt, and I can't install it. When I use:. pip install louvain. to install louvain, I have an error that . ```pytb. ERROR: Command errored out with exit status 1:. 'c:\users\prince and jacky\anaconda3\python.exe' \. -u \. -c '. import sys, setuptools, tokenize. sys.argv[0] = "".../louvain/setup.py"". __file__="".../louvain/setup.py"". f=getattr(tokenize, ""open"", open)(__file__). code=f.read().replace(""\r\n"", ""\n""). f.close(). exec(compile(code, __file__, ""exec"")). ' \. install \. --record '.../install-record.txt' \. --single-version-externally-managed \. --compile. Check the logs for full command output. ```. I also tried to install using different codes such as:. ```bash. conda install -c conda-forge louvain. ```. There's an error saying that:. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
