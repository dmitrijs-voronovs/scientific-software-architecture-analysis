id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/264:10421,modifiability,pac,packages,10421,"n.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in _update_ticks(self, renderer). 1026 . 1027 interval = self.get_view_interval(). -> 1028 tick_tups = list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` wi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:10661,modifiability,version,versions,10661," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:10693,modifiability,Version,Versions,10693," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:10725,modifiability,pac,packages,10725," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:10966,modifiability,version,versions,10966," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:10998,modifiability,Version,Versions,10998," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11030,modifiability,pac,packages,11030," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11371,modifiability,compon,components,11371," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11556,modifiability,compon,components,11556," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:227,performance,error,error,227,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:52,safety,log,log,52,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:227,safety,error,error,227,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:308,safety,log,log,308,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:519,safety,log,log,519,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:527,safety,log,log,527,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:544,safety,log,log,544,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:689,safety,input,input-,689,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:715,safety,modul,module,715,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:730,safety,log,log,730,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:745,safety,log,logarithm,745,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:798,safety,log,log,798,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:965,safety,log,log,965,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1153,safety,log,log,1153,"h a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_convert",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1157,safety,log,log,1157,"very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_converted_l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1425,safety,log,log,1425,"site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_converted_limits(bottom, self.convert_yunits). 3458 top = self._validate_converted_limits(top, self.convert_yunits). 3459 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in _validate_converted_limits(self, limit, conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:6844,safety,updat,update,6844,"io.getvalue(). 127 if fmt == 'svg':. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs). 2261 orientation=orientation,. 2262 bbox_inches_restore=_bbox_inches_restore,. -> 2263 **kwargs). 2264 finally:. 2265 if bbox_inches and restore_bbox:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs). 515 . 516 def print_png(self, filename_or_obj, *args, **kwargs):. --> 517 FigureCanvasAgg.draw(self). 518 renderer = self.get_renderer(). 519 original_dpi = renderer.dpi. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw(self). 435 # if toolbar:. 436 # toolbar.set_cursor(cursors.WAIT). --> 437 self.figure.draw(self.renderer). 438 # A GUI class may be need to update a window using this draw, so. 439 # don't forget to call the superclass. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs). 53 renderer.start_filter(). 54 . ---> 55 return draw(artist, renderer, *args, **kwargs). 56 finally:. 57 if artist.get_agg_filter() is not None:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/figure.py in draw(self, renderer). 1491 . 1492 mimage._draw_list_compositing_images(. -> 1493 renderer, self, artists, self.suppressComposite). 1494 . 1495 renderer.close_group('figure'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite). 139 if not_composite or not has_images:. 140 for a in artists:. --> 141 a.draw(renderer). 142 else:. 143 # Composite any adjacent images together. ~/.pyenv/ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11402,safety,log,log,11402," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11413,safety,log,log,11413," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:52,security,log,log,52,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:308,security,log,log,308,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:519,security,log,log,519,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:527,security,log,log,527,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:544,security,log,log,544,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:730,security,log,log,730,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:745,security,log,logarithm,745,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:798,security,log,log,798,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:965,security,log,log,965,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1153,security,log,log,1153,"h a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_convert",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1157,security,log,log,1157,"very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_converted_l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1425,security,log,log,1425,"site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_converted_limits(bottom, self.convert_yunits). 3458 top = self._validate_converted_limits(top, self.convert_yunits). 3459 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in _validate_converted_limits(self, limit, conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:6844,security,updat,update,6844,"io.getvalue(). 127 if fmt == 'svg':. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs). 2261 orientation=orientation,. 2262 bbox_inches_restore=_bbox_inches_restore,. -> 2263 **kwargs). 2264 finally:. 2265 if bbox_inches and restore_bbox:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs). 515 . 516 def print_png(self, filename_or_obj, *args, **kwargs):. --> 517 FigureCanvasAgg.draw(self). 518 renderer = self.get_renderer(). 519 original_dpi = renderer.dpi. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw(self). 435 # if toolbar:. 436 # toolbar.set_cursor(cursors.WAIT). --> 437 self.figure.draw(self.renderer). 438 # A GUI class may be need to update a window using this draw, so. 439 # don't forget to call the superclass. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs). 53 renderer.start_filter(). 54 . ---> 55 return draw(artist, renderer, *args, **kwargs). 56 finally:. 57 if artist.get_agg_filter() is not None:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/figure.py in draw(self, renderer). 1491 . 1492 mimage._draw_list_compositing_images(. -> 1493 renderer, self, artists, self.suppressComposite). 1494 . 1495 renderer.close_group('figure'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite). 139 if not_composite or not has_images:. 140 for a in artists:. --> 141 a.draw(renderer). 142 else:. 143 # Composite any adjacent images together. ~/.pyenv/ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11402,security,log,log,11402," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11413,security,log,log,11413," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:52,testability,log,log,52,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:308,testability,log,log,308,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:519,testability,log,log,519,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:527,testability,log,log,527,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:544,testability,log,log,544,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:645,testability,Trace,Traceback,645,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:730,testability,log,log,730,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:745,testability,log,logarithm,745,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:798,testability,log,log,798,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:965,testability,log,log,965,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1153,testability,log,log,1153,"h a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_convert",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1157,testability,log,log,1157,"very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_converted_l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:1425,testability,log,log,1425,"site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw). 3455 bottom, top = bottom. 3456 . -> 3457 bottom = self._validate_converted_limits(bottom, self.convert_yunits). 3458 top = self._validate_converted_limits(top, self.convert_yunits). 3459 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in _validate_converted_limits(self, limit, conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:4384,testability,Trace,Traceback,4384,"te values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce. return ufunc.reduce(obj, axis, dtype, out, **passkwargs). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj). 339 pass. 340 else:. --> 341 return printer(obj). 342 # Finally look for special method names. 343 method = get_real_method(obj, self.print_method). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda>(fig). 241 png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs)). 242 if 'retina' in formats or 'png2x' in formats:. --> 243 png_formatter.for_type(Figure, lambda fig: retina_figure(fig, **kwargs)). 244 if 'jpg' in formats or 'jpeg' in formats:. 245 jpg_formatter.for_type(Figure, lambda fig: print_figure(fig, 'jpg', **kwargs)). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/pylabtools.py in retina_figure(fig, **kwargs). 131 def retina_figure(fig, **kwargs):. 132 """"""format a figure as a pixe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11402,testability,log,log,11402," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:11413,testability,log,log,11413," list(self.iter_ticks()) # iter_ticks calls the locator. 1029 if self._smart_bounds and tick_tups:. 1030 # handle inverted limits. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in iter_ticks(self). 969 Iterate through all of the major and minor ticks. 970 """""". --> 971 majorLocs = self.major.locator(). 972 majorTicks = self.get_major_ticks(len(majorLocs)). 973 self.major.formatter.set_locs(majorLocs). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in __call__(self). 1952 def __call__(self):. 1953 vmin, vmax = self.axis.get_view_interval(). -> 1954 return self.tick_values(vmin, vmax). 1955 . 1956 def tick_values(self, vmin, vmax):. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in tick_values(self, vmin, vmax). 1960 vmin, vmax = mtransforms.nonsingular(. 1961 vmin, vmax, expander=1e-13, tiny=1e-14). -> 1962 locs = self._raw_ticks(vmin, vmax). 1963 . 1964 prune = self._prune. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/ticker.py in _raw_ticks(self, vmin, vmax). 1906 if self._nbins == 'auto':. 1907 if self.axis is not None:. -> 1908 nbins = np.clip(self.axis.get_tick_space(),. 1909 max(1, self._min_n_ticks - 1), 9). 1910 else:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axis.py in get_tick_space(self). 2127 size = tick.label1.get_size() * 3. 2128 if size > 0:. -> 2129 return int(np.floor(length / size)). 2130 else:. 2131 return 2**31 - 1. ValueError: cannot convert float NaN to integer. <Figure size 800x800 with 1 Axes>. ```. I think the problem is that the variance explained for some components is 0, so taking the log (with `log=True` will ask scanpy to plot the variance explained starting from minus infinity. Would it be possible to plot only the non-zero variance components as a default? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:227,usability,error,error,227,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:350,usability,User,Users,350,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:356,usability,user,user,356,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:689,usability,input,input-,689,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:918,usability,tool,tools,918,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack; Hi,. I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:. ```python. sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ```. Result:. ```. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log. if log: scores = np.log(scores). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-48cc676a34cc> in <module>(). 1 # log is natural logarithm. ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save). 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}. 158 """""". --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log). 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save). 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show). 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]). 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,. --> 557 (1.05 if score_max > 0 else 0.95) * score_max). 558 if show == False: return gs. 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs). 1588 if not args and not kwargs:. 1589 return ax.get_ylim(). -> 1590 ret = ax.set_ylim(*args, **kwargs). 1591 return ret. 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:4064,usability,User,Users,4064,"ld be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce. return ufunc.reduce(obj, axis, dtype, out, **passkwargs). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj). 339 pass. 340 else:. --> 341 return printer(obj). 342 # Finally look for special method names. 343 method = get_real_method(obj, self.print_method). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda>(fig). 241 png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs)). 242 if 'retina' in formats or 'png2x' in formats:. --> 243 png_formatter.for_type(Figure, lambda fig: retina_figure(fig, **kwargs)). 244 if 'jpg' in format",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:4070,usability,user,user,4070," finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. posx and posy should be finite values. /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce. return ufunc.reduce(obj, axis, dtype, out, **passkwargs). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj). 339 pass. 340 else:. --> 341 return printer(obj). 342 # Finally look for special method names. 343 method = get_real_method(obj, self.print_method). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/pylabtools.py in <lambda>(fig). 241 png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs)). 242 if 'retina' in formats or 'png2x' in formats:. --> 243 png_formatter.for_type(Figure, lambda fig: retina_figure(fig, **kwargs)). 244 if 'jpg' in formats or ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:6720,usability,tool,toolbar,6720," bbox_inches, **kwargs). 123 . 124 bytes_io = BytesIO(). --> 125 fig.canvas.print_figure(bytes_io, **kw). 126 data = bytes_io.getvalue(). 127 if fmt == 'svg':. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs). 2261 orientation=orientation,. 2262 bbox_inches_restore=_bbox_inches_restore,. -> 2263 **kwargs). 2264 finally:. 2265 if bbox_inches and restore_bbox:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs). 515 . 516 def print_png(self, filename_or_obj, *args, **kwargs):. --> 517 FigureCanvasAgg.draw(self). 518 renderer = self.get_renderer(). 519 original_dpi = renderer.dpi. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw(self). 435 # if toolbar:. 436 # toolbar.set_cursor(cursors.WAIT). --> 437 self.figure.draw(self.renderer). 438 # A GUI class may be need to update a window using this draw, so. 439 # don't forget to call the superclass. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs). 53 renderer.start_filter(). 54 . ---> 55 return draw(artist, renderer, *args, **kwargs). 56 finally:. 57 if artist.get_agg_filter() is not None:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/figure.py in draw(self, renderer). 1491 . 1492 mimage._draw_list_compositing_images(. -> 1493 renderer, self, artists, self.suppressComposite). 1494 . 1495 renderer.close_group('figure'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite). 139 if not_composite or not has_ima",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:6736,usability,tool,toolbar,6736,"kwargs). 123 . 124 bytes_io = BytesIO(). --> 125 fig.canvas.print_figure(bytes_io, **kw). 126 data = bytes_io.getvalue(). 127 if fmt == 'svg':. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs). 2261 orientation=orientation,. 2262 bbox_inches_restore=_bbox_inches_restore,. -> 2263 **kwargs). 2264 finally:. 2265 if bbox_inches and restore_bbox:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs). 515 . 516 def print_png(self, filename_or_obj, *args, **kwargs):. --> 517 FigureCanvasAgg.draw(self). 518 renderer = self.get_renderer(). 519 original_dpi = renderer.dpi. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw(self). 435 # if toolbar:. 436 # toolbar.set_cursor(cursors.WAIT). --> 437 self.figure.draw(self.renderer). 438 # A GUI class may be need to update a window using this draw, so. 439 # don't forget to call the superclass. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs). 53 renderer.start_filter(). 54 . ---> 55 return draw(artist, renderer, *args, **kwargs). 56 finally:. 57 if artist.get_agg_filter() is not None:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/figure.py in draw(self, renderer). 1491 . 1492 mimage._draw_list_compositing_images(. -> 1493 renderer, self, artists, self.suppressComposite). 1494 . 1495 renderer.close_group('figure'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite). 139 if not_composite or not has_images:. 140 for a ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/264:6755,usability,cursor,cursors,6755,"bytes_io = BytesIO(). --> 125 fig.canvas.print_figure(bytes_io, **kw). 126 data = bytes_io.getvalue(). 127 if fmt == 'svg':. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs). 2261 orientation=orientation,. 2262 bbox_inches_restore=_bbox_inches_restore,. -> 2263 **kwargs). 2264 finally:. 2265 if bbox_inches and restore_bbox:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs). 515 . 516 def print_png(self, filename_or_obj, *args, **kwargs):. --> 517 FigureCanvasAgg.draw(self). 518 renderer = self.get_renderer(). 519 original_dpi = renderer.dpi. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw(self). 435 # if toolbar:. 436 # toolbar.set_cursor(cursors.WAIT). --> 437 self.figure.draw(self.renderer). 438 # A GUI class may be need to update a window using this draw, so. 439 # don't forget to call the superclass. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs). 53 renderer.start_filter(). 54 . ---> 55 return draw(artist, renderer, *args, **kwargs). 56 finally:. 57 if artist.get_agg_filter() is not None:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/figure.py in draw(self, renderer). 1491 . 1492 mimage._draw_list_compositing_images(. -> 1493 renderer, self, artists, self.suppressComposite). 1494 . 1495 renderer.close_group('figure'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite). 139 if not_composite or not has_images:. 140 for a in artists:. --> 14",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264
https://github.com/scverse/scanpy/issues/265:305,availability,cluster,clustering,305,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:0,deployability,integr,integrate,0,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:59,deployability,integr,integrate,59,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:305,deployability,cluster,clustering,305,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:0,integrability,integr,integrate,0,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:59,integrability,integr,integrate,59,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:171,integrability,batch,batch,171,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:0,interoperability,integr,integrate,0,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:59,interoperability,integr,integrate,59,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:0,modifiability,integr,integrate,0,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:59,modifiability,integr,integrate,59,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:171,performance,batch,batch,171,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:283,performance,network,network,283,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:0,reliability,integr,integrate,0,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:59,reliability,integr,integrate,59,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:0,security,integr,integrate,0,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:59,security,integr,integrate,59,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:283,security,network,network,283,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:0,testability,integr,integrate,0,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/issues/265:59,testability,integr,integrate,59,"integrate with CCA and pyscenic; Dear, . Is it possible to integrate scanpy with CCA and pyscenic? CCA (canonical correlation analysis to alignment different datasets and batch effect correction):. https://satijalab.org/seurat/immune_alignment.html. pyscenic (single-cell regulatory network inference and clustering):. https://github.com/aertslab/pySCENIC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265
https://github.com/scverse/scanpy/pull/266:8,availability,error,error,8,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:8,performance,error,error,8,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:85,reliability,doe,doesn,85,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:0,safety,Prevent,Prevent,0,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:8,safety,error,error,8,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:0,security,Preven,Prevent,0,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:199,testability,simpl,simply,199,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:8,usability,error,error,8,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:132,usability,tip,tips,132,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:148,usability,tip,tips,148,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/pull/266:199,usability,simpl,simply,199,"Prevent error when no third point is found; Else `argmax([])` is called later, which doesnt make sense. This happens because `Dseg[tips[0]] + Dseg[tips[1]]` are all `inf` for some datasets. Is that simply a consequence of my data or is that a bug? This PR assumes the former and results in such segments being skipped. In case of my data, this means that I end up with a single DPT group instead of multiple ones.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266
https://github.com/scverse/scanpy/issues/267:220,reliability,doe,does,220,"Read multiple 10X files; Hi,. Maybe this is somewhere in the manual and I just don't see it. But is there a way to read multiple 10X samples (either multiple .h5 or the matrix/genes/barcodes) in the same way that Seurat does with its Read10X() function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267
https://github.com/scverse/scanpy/issues/268:51,usability,user,user-images,51,is it not suitable for python2.7; ![image](https://user-images.githubusercontent.com/25199946/45993589-2878e480-c0c2-11e8-86de-683c7d103218.png).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/268
https://github.com/scverse/scanpy/issues/269:536,integrability,sub,sub-populations,536,"Request: add PR-AUC metric ; Similar to [my request](https://github.com/satijalab/seurat/issues/800) at the Seurat package, it would just be really nice if the precision-recall area under curve (PR-AUC) could be added alongside the AUC metric in the [""top_genes.py""](https://github.com/theislab/scanpy/blob/master/scanpy/tools/top_genes.py) and [""top_genes_visual.py""](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/top_genes_visual.py) files. PR-AUC is especially handy when dealing with imbalanced datasets (e.g. most sub-populations in a scRNA-seq experiment).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/269
https://github.com/scverse/scanpy/issues/269:115,modifiability,pac,package,115,"Request: add PR-AUC metric ; Similar to [my request](https://github.com/satijalab/seurat/issues/800) at the Seurat package, it would just be really nice if the precision-recall area under curve (PR-AUC) could be added alongside the AUC metric in the [""top_genes.py""](https://github.com/theislab/scanpy/blob/master/scanpy/tools/top_genes.py) and [""top_genes_visual.py""](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/top_genes_visual.py) files. PR-AUC is especially handy when dealing with imbalanced datasets (e.g. most sub-populations in a scRNA-seq experiment).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/269
https://github.com/scverse/scanpy/issues/269:321,usability,tool,tools,321,"Request: add PR-AUC metric ; Similar to [my request](https://github.com/satijalab/seurat/issues/800) at the Seurat package, it would just be really nice if the precision-recall area under curve (PR-AUC) could be added alongside the AUC metric in the [""top_genes.py""](https://github.com/theislab/scanpy/blob/master/scanpy/tools/top_genes.py) and [""top_genes_visual.py""](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/top_genes_visual.py) files. PR-AUC is especially handy when dealing with imbalanced datasets (e.g. most sub-populations in a scRNA-seq experiment).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/269
https://github.com/scverse/scanpy/pull/270:47,deployability,updat,updated,47,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:700,energy efficiency,optim,optimized,700,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:790,interoperability,standard,standard,790,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:700,performance,optimiz,optimized,700,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:20,safety,test,tests,20,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:39,safety,test,test,39,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:47,safety,updat,updated,47,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:111,safety,test,tests,111,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:143,safety,test,test,143,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:230,safety,test,test,230,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:271,safety,test,test,271,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:345,safety,test,test,345,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:452,safety,test,test,452,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:640,safety,test,tested,640,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:979,safety,avoid,avoid,979,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:47,security,updat,updated,47,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:20,testability,test,tests,20,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:39,testability,test,test,39,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:111,testability,test,tests,111,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:143,testability,test,test,143,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:230,testability,test,test,230,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:271,testability,test,test,271,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:345,testability,test,test,345,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:452,testability,test,test,452,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:517,testability,simpl,simplify,517,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:640,testability,test,tested,640,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:517,usability,simpl,simplify,517,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/pull/270:1048,usability,help,helpful,1048,"P-values added to t-tests and wilcoxon test; I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. . The changes are outlined below:. - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). . - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets. - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction. - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful! Andrs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270
https://github.com/scverse/scanpy/issues/271:382,deployability,modul,module,382,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:429,deployability,modul,module,429,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:473,deployability,modul,module,473,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:480,deployability,instal,installed,480,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:715,deployability,modul,module,715,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1041,deployability,build,builders,1041,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1057,deployability,automat,automatically,1057,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1251,deployability,modul,modules,1251,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1071,integrability,discover,discovered,1071,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:911,interoperability,plug,plugins,911,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1071,interoperability,discover,discovered,1071,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:10,modifiability,extens,extension,10,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:340,modifiability,extens,extensions,340,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:372,modifiability,extens,extension,372,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:382,modifiability,modul,module,382,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:429,modifiability,modul,module,429,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:458,modifiability,extens,extension,458,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:473,modifiability,modul,module,473,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:586,modifiability,pac,packages,586,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:694,modifiability,extens,extensions,694,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:715,modifiability,modul,module,715,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1096,modifiability,extens,extensions,1096,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1221,modifiability,extens,extensiondev,1221,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1251,modifiability,modul,modules,1251,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:382,safety,modul,module,382,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:429,safety,modul,module,429,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:473,safety,modul,module,473,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:715,safety,modul,module,715,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1251,safety,modul,modules,1251,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1057,testability,automat,automatically,1057,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:784,usability,user,user,784,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/issues/271:1071,usability,discov,discovered,1071,"Define an extension mechanism; We should have a discussion about this separate from #265. Theres three options how to implement them. 1. Python has a built-in way of registering entry points which might be suitable. [A tutorial](https://amir.rachum.com/blog/2017/07/28/python-entry-points/). ```py. setup(. # ... entry_points={. 'scanpy.extensions': ['myextension = my.extension.module'],. },. ). ```. 2. Some projects have a module like `scanpy.ext`. An extension is a module installed into there (which is possible in python):. ```py. setup(. name='scanpy-ext-myextension',. # ... packages=['scanpy.ext.myextension'],. ). ```. 3. Some projects provide a config value like `scanpy.settings.extensions` to which module names can be `append`ed. Unlike the first two, this means the user has to enable them explicitly. Pytest uses [both 1 and 3](https://docs.pytest.org/en/latest/writing_plugins.html) for its plugins. Sphinx uses [both 1 and 3](http://www.sphinx-doc.org/en/master/extdev/index.html) for different things: they want their builders to be automatically discovered and the other extensions to be explicitly enabled. ---. Another option for 2. is to use [flasks approach](http://flask.pocoo.org/docs/1.0/extensiondev/) of just naming modules `scanpy_*` which is too cute and magic to me. Veto.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271
https://github.com/scverse/scanpy/pull/272:11,usability,document,documentation,11,correcting documentation of sc.datasets.blobs;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/272
https://github.com/scverse/scanpy/issues/273:89,deployability,log,logreg,89,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:291,deployability,log,logreg,291,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:575,deployability,api,api,575,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:693,deployability,log,logreg,693,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:575,integrability,api,api,575,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:575,interoperability,api,api,575,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:89,safety,log,logreg,89,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:291,safety,log,logreg,291,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:330,safety,test,test,330,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:693,safety,log,logreg,693,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:89,security,log,logreg,89,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:291,security,log,logreg,291,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:693,security,log,logreg,693,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:89,testability,log,logreg,89,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:291,testability,log,logreg,291,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:330,testability,test,test,330,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:693,testability,log,logreg,693,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:433,usability,help,helpful,433,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/273:517,usability,minim,minimal,517,"Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`; Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```. import pandas as pd. import scanpy.api as sc. adata = sc.datasets.blobs(640, 3). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method). print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). ```. The result looks like this:. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 570 63 126. ```. The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):. ```python. 0 1 2. 0 570 63 126. 2 1 0. 0 126 63 570. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273
https://github.com/scverse/scanpy/issues/274:79,deployability,api,api,79,"sc.pl.paga_path: n_avg>1 messes up legend ; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.louvain(adata). sc.tl.paga(adata). adata.uns['iroot'] = 0. sc.tl.dpt(adata). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=1, as_heatmap=False). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=2, as_heatmap=False). ```. Output:. ![image](https://user-images.githubusercontent.com/7300030/46211863-e4414a80-c334-11e8-9d99-18c877bf7d74.png). ![image](https://user-images.githubusercontent.com/7300030/46211867-e7d4d180-c334-11e8-8317-8d6e06ce3a86.png). I would expect that the legend in both plots stays the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/274
https://github.com/scverse/scanpy/issues/274:79,integrability,api,api,79,"sc.pl.paga_path: n_avg>1 messes up legend ; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.louvain(adata). sc.tl.paga(adata). adata.uns['iroot'] = 0. sc.tl.dpt(adata). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=1, as_heatmap=False). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=2, as_heatmap=False). ```. Output:. ![image](https://user-images.githubusercontent.com/7300030/46211863-e4414a80-c334-11e8-9d99-18c877bf7d74.png). ![image](https://user-images.githubusercontent.com/7300030/46211867-e7d4d180-c334-11e8-8317-8d6e06ce3a86.png). I would expect that the legend in both plots stays the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/274
https://github.com/scverse/scanpy/issues/274:79,interoperability,api,api,79,"sc.pl.paga_path: n_avg>1 messes up legend ; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.louvain(adata). sc.tl.paga(adata). adata.uns['iroot'] = 0. sc.tl.dpt(adata). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=1, as_heatmap=False). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=2, as_heatmap=False). ```. Output:. ![image](https://user-images.githubusercontent.com/7300030/46211863-e4414a80-c334-11e8-9d99-18c877bf7d74.png). ![image](https://user-images.githubusercontent.com/7300030/46211867-e7d4d180-c334-11e8-8317-8d6e06ce3a86.png). I would expect that the legend in both plots stays the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/274
https://github.com/scverse/scanpy/issues/274:429,usability,user,user-images,429,"sc.pl.paga_path: n_avg>1 messes up legend ; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.louvain(adata). sc.tl.paga(adata). adata.uns['iroot'] = 0. sc.tl.dpt(adata). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=1, as_heatmap=False). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=2, as_heatmap=False). ```. Output:. ![image](https://user-images.githubusercontent.com/7300030/46211863-e4414a80-c334-11e8-9d99-18c877bf7d74.png). ![image](https://user-images.githubusercontent.com/7300030/46211867-e7d4d180-c334-11e8-8317-8d6e06ce3a86.png). I would expect that the legend in both plots stays the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/274
https://github.com/scverse/scanpy/issues/274:540,usability,user,user-images,540,"sc.pl.paga_path: n_avg>1 messes up legend ; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.louvain(adata). sc.tl.paga(adata). adata.uns['iroot'] = 0. sc.tl.dpt(adata). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=1, as_heatmap=False). sc.pl.paga_path(adata, nodes=['1', '2'], keys=['1', '2'], n_avg=2, as_heatmap=False). ```. Output:. ![image](https://user-images.githubusercontent.com/7300030/46211863-e4414a80-c334-11e8-9d99-18c877bf7d74.png). ![image](https://user-images.githubusercontent.com/7300030/46211867-e7d4d180-c334-11e8-8317-8d6e06ce3a86.png). I would expect that the legend in both plots stays the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/274
https://github.com/scverse/scanpy/issues/275:16,availability,Cluster,Clustering,16,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:104,availability,Cluster,Clustering,104,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:16,deployability,Cluster,Clustering,16,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:104,deployability,Cluster,Clustering,104,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:316,energy efficiency,current,currently,316,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:694,modifiability,variab,variables,694,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:1004,modifiability,variab,variables,1004,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:1457,modifiability,variab,variables,1457,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:493,performance,cach,cache,493,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:1026,reliability,doe,does,1026,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:1483,reliability,doe,does,1483,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/275:348,usability,learn,learn,348,"Tutorial bug at Clustering 3k PBMCs following a Seurat Tutorial; I found a minor bug in this tutorial. [Clustering 3k PBMCs following a Seurat Tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I hope this is the correct venue to post to regarding this. I'm currently going through this to learn how to use scanpy. In the first section. ```. path = './data/pbmc3k_filtered_gene_bc_matrices/hg19/'. adata = sc.read(path + 'matrix.mtx', cache=True).T # transpose the data. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. adata.obs_names = pd.read_csv(path + 'barcodes.tsv', header=None)[0]. ```. Due to how pandas dataframes indexes this part. ```. genes = pd.read_csv(path + 'genes.tsv', header=None, sep='\t'). adata.var_names = genes[1]. adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ```. does not yield the expected results. As `var_names` becomes the index of `var` adding `genes[0]` will try to merge a data frame with unmatching index resulting in a `NaN` column in `var` for `'gene_ids'`. The solution should be either. ```. genes = genes.set_index(1). adata.var = genes. ```. or. ```. adata.var_names = genes[1]. genes = genes.set_index(1). adata.var['gene_ids'] = genes[0] # add the gene ids as annotation of the variables/genes. ``` . It does probably not have any effect on the tutorial but I thought I'd mention it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/275
https://github.com/scverse/scanpy/issues/276:364,availability,error,errors,364,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:413,availability,error,errors,413,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:490,availability,error,errors,490,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:548,availability,error,errors,548,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:10,deployability,instal,install,10,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:125,deployability,instal,installing,125,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:158,deployability,log,login-,158,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:303,deployability,instal,install,303,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:395,deployability,version,versioneer,395,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:468,deployability,instal,install,468,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:72,energy efficiency,power,powerful,72,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:395,integrability,version,versioneer,395,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:140,interoperability,platform,platform,140,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:50,modifiability,pac,package,50,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:395,modifiability,version,versioneer,395,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:440,modifiability,pac,package,440,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:364,performance,error,errors,364,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:413,performance,error,errors,413,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:490,performance,error,errors,490,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:548,performance,error,errors,548,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:582,performance,time,time,582,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:158,safety,log,login-,158,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:364,safety,error,errors,364,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:413,safety,error,errors,413,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:490,safety,error,errors,490,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:548,safety,error,errors,548,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:158,security,log,login-,158,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:158,testability,log,login-,158,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:364,usability,error,errors,364,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:413,usability,error,errors,413,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:490,usability,error,errors,490,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:532,usability,clear,clearly,532,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:548,usability,error,errors,548,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:624,usability,user,user-images,624,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/276:736,usability,user,user-images,736,"unable to install scanpy; . Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing. My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10. I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,. but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors. Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276
https://github.com/scverse/scanpy/issues/277:535,availability,cluster,cluster,535,"scanpy neighbours; Dear,. Seurat embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar gene expression patterns, and then attempt to partition this graph into highly interconnected quasi-cliques or communities. A KNN graph is first constructed based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). . Does Scanpy uses Jaccard similarity to cluster too?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277
https://github.com/scverse/scanpy/issues/277:535,deployability,cluster,cluster,535,"scanpy neighbours; Dear,. Seurat embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar gene expression patterns, and then attempt to partition this graph into highly interconnected quasi-cliques or communities. A KNN graph is first constructed based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). . Does Scanpy uses Jaccard similarity to cluster too?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277
https://github.com/scverse/scanpy/issues/277:125,energy efficiency,draw,drawn,125,"scanpy neighbours; Dear,. Seurat embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar gene expression patterns, and then attempt to partition this graph into highly interconnected quasi-cliques or communities. A KNN graph is first constructed based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). . Does Scanpy uses Jaccard similarity to cluster too?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277
https://github.com/scverse/scanpy/issues/277:428,interoperability,share,shared,428,"scanpy neighbours; Dear,. Seurat embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar gene expression patterns, and then attempt to partition this graph into highly interconnected quasi-cliques or communities. A KNN graph is first constructed based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). . Does Scanpy uses Jaccard similarity to cluster too?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277
https://github.com/scverse/scanpy/issues/277:496,reliability,Doe,Does,496,"scanpy neighbours; Dear,. Seurat embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar gene expression patterns, and then attempt to partition this graph into highly interconnected quasi-cliques or communities. A KNN graph is first constructed based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). . Does Scanpy uses Jaccard similarity to cluster too?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277
https://github.com/scverse/scanpy/issues/278:246,deployability,observ,observation,246,"groups and reference in sc.tl.rank_genes_groups; I'm afraid, I do not fully understand the documentation of `sc.tl.rank_genes_groups` when using the `groups` and `reference` arguments. Suppose that I have the categories `'1'`, `'2'`, `'3'` in my observation grouping `louvain`. Now, I run . ```python. sc.tl.rank_genes_groups(adata, 'louvain', groups=['1', '2'], reference='rest'). ```. Would the reference now include cells from category `'3'`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278
https://github.com/scverse/scanpy/issues/278:76,testability,understand,understand,76,"groups and reference in sc.tl.rank_genes_groups; I'm afraid, I do not fully understand the documentation of `sc.tl.rank_genes_groups` when using the `groups` and `reference` arguments. Suppose that I have the categories `'1'`, `'2'`, `'3'` in my observation grouping `louvain`. Now, I run . ```python. sc.tl.rank_genes_groups(adata, 'louvain', groups=['1', '2'], reference='rest'). ```. Would the reference now include cells from category `'3'`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278
https://github.com/scverse/scanpy/issues/278:246,testability,observ,observation,246,"groups and reference in sc.tl.rank_genes_groups; I'm afraid, I do not fully understand the documentation of `sc.tl.rank_genes_groups` when using the `groups` and `reference` arguments. Suppose that I have the categories `'1'`, `'2'`, `'3'` in my observation grouping `louvain`. Now, I run . ```python. sc.tl.rank_genes_groups(adata, 'louvain', groups=['1', '2'], reference='rest'). ```. Would the reference now include cells from category `'3'`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278
https://github.com/scverse/scanpy/issues/278:91,usability,document,documentation,91,"groups and reference in sc.tl.rank_genes_groups; I'm afraid, I do not fully understand the documentation of `sc.tl.rank_genes_groups` when using the `groups` and `reference` arguments. Suppose that I have the categories `'1'`, `'2'`, `'3'` in my observation grouping `louvain`. Now, I run . ```python. sc.tl.rank_genes_groups(adata, 'louvain', groups=['1', '2'], reference='rest'). ```. Would the reference now include cells from category `'3'`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278
https://github.com/scverse/scanpy/issues/279:33,availability,cluster,clusters,33,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:148,availability,cluster,clustering,148,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:182,availability,cluster,clusters,182,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:312,availability,cluster,clusters,312,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:33,deployability,cluster,clusters,33,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:148,deployability,cluster,clustering,148,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:182,deployability,cluster,clusters,182,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:312,deployability,cluster,clusters,312,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:239,interoperability,specif,specific,239,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/279:355,usability,behavi,behavior,355,"Is Louvain supposed to find more clusters with increasing resolution?; Hi,. I was making the assumption that, giving more resolution to the louvain clustering, it would provide more clusters. It always worked like that, but today I find a specific dataset in which, with an increase of resolution, I found fewer clusters (figure attached). Is it a normal behavior, or an issue? Thanks,. Francesco. [tsne.louvain.resolution.pdf](https://github.com/theislab/scanpy/files/2439685/tsne.louvain.resolution.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/279
https://github.com/scverse/scanpy/issues/280:223,availability,error,error,223,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:267,deployability,version,version,267,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:334,deployability,fail,failed,334,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:267,integrability,version,version,267,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:267,modifiability,version,version,267,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:223,performance,error,error,223,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:334,reliability,fail,failed,334,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:14,safety,detect,detected,14,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:223,safety,error,error,223,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:245,safety,detect,detected,245,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:14,security,detect,detected,14,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:245,security,detect,detected,245,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:307,testability,Assert,Assertion,307,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:223,usability,error,error,223,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:449,usability,learn,learn,449,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/280:528,usability,help,help,528,"Inconsistency detected by ld.so; Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed! Ubuntu 18.04. Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280
https://github.com/scverse/scanpy/issues/281:1040,deployability,instal,installed,1040,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:1331,energy efficiency,Current,Current,1331,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:1024,interoperability,distribut,distributed,1024,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:398,modifiability,layer,layer,398,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:735,modifiability,pac,package,735,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:79,usability,tool,tool,79,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:245,usability,tool,tools,245,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:271,usability,workflow,workflow,271,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:298,usability,tool,tools,298,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:534,usability,workflow,workflow,534,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:764,usability,tool,tool,764,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:995,usability,tool,tool,995,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/issues/281:1308,usability,tool,tools-iuc,1308,"Contribution of scripts to scanpy main repo; Hi there! Thanks for such a great tool. We are working with a group of people at EBI, Sanger, U. of Freiburg, Earlham (Norwich), the US and Australia in trying to bring different single cell analysis tools to Galaxy and other workflow environments. For tools like Seurat, SC3 or Scanpy, which are normally used as libraries, we are writing an scripting layer for each of these to facilitate their use directly from the shell for well defined functionality (to be called then from whatever workflow environment people want to use). You can get an idea based on what we have here for Seurat for instance https://github.com/ebi-gene-expression-group/r-seurat-scripts. We normally make a conda package out of this called \<tool\>-scripts. This probably fits well in the initial development phase where we want to be agile in the generation of these, but in the mid and definitely longer term, we would really like to contribute those scripts to the main tool repos, so that they are distributed and installed with them. Would you welcome such contribution (a set of scripts for high level functionality that can be used as executables from a shell) in this git repo? This is where we are discussing things a bit with this community:. https://github.com/galaxyproject/tools-iuc/issues/2057. Current WIP for scanpy scripts (see feature branches):. https://github.com/ebi-gene-expression-group/scanpy-scripts/tree/feature/read10x .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281
https://github.com/scverse/scanpy/pull/282:135,integrability,wrap,wrapper,135,"Fix the parameter explanation for filter_genes; Hi,. I corrected these small mistakes while checking the documentation to write Galaxy wrapper. Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/282
https://github.com/scverse/scanpy/pull/282:135,interoperability,wrapper,wrapper,135,"Fix the parameter explanation for filter_genes; Hi,. I corrected these small mistakes while checking the documentation to write Galaxy wrapper. Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/282
https://github.com/scverse/scanpy/pull/282:8,modifiability,paramet,parameter,8,"Fix the parameter explanation for filter_genes; Hi,. I corrected these small mistakes while checking the documentation to write Galaxy wrapper. Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/282
https://github.com/scverse/scanpy/pull/282:105,usability,document,documentation,105,"Fix the parameter explanation for filter_genes; Hi,. I corrected these small mistakes while checking the documentation to write Galaxy wrapper. Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/282
https://github.com/scverse/scanpy/pull/283:198,deployability,integr,integration,198,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:287,deployability,version,version,287,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:198,integrability,integr,integration,198,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:287,integrability,version,version,287,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:19,interoperability,distribut,distributed,19,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:142,interoperability,distribut,distributed,142,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:198,interoperability,integr,integration,198,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:275,interoperability,distribut,distributed,275,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:500,interoperability,distribut,distributed,500,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:198,modifiability,integr,integration,198,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:287,modifiability,version,version,287,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:429,modifiability,interm,intermediate,429,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:198,reliability,integr,integration,198,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:198,security,integr,integration,198,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:198,testability,integr,integration,198,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/283:0,usability,Support,Support,0,"Support running on distributed compute engines like Dask, and Spark via Zap; These changes enable Scanpy's pre-processing functions to run on distributed engines including Dask and Spark. The Spark integration itself relies on [Zap](https://github.com/lasersonlab/zap) for a distributed version of NumPy. . The main change is the `materialize_as_ndarray` function that is used at certain points of the computation to materialize intermediate results (not the full matrix). This is a no-op in the non-distributed case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/283
https://github.com/scverse/scanpy/pull/284:98,modifiability,variab,variable,98,add key_added to store bool array of hvg; add option to keep genes and store bool array of highly variable genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/284
https://github.com/scverse/scanpy/issues/285:79,deployability,instal,install,79,"only for python3?; I tried seveal times in both win and linux python2 can not install scany, si there a solution for python2, thanks a lot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/285
https://github.com/scverse/scanpy/issues/285:34,performance,time,times,34,"only for python3?; I tried seveal times in both win and linux python2 can not install scany, si there a solution for python2, thanks a lot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/285
https://github.com/scverse/scanpy/issues/286:568,availability,cluster,clusters,568,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1831,availability,cluster,clusters,1831,"8, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:55,deployability,Updat,Update,55,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:214,deployability,Log,Log,214,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:318,deployability,depend,depends,318,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:568,deployability,cluster,clusters,568,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1797,deployability,modul,module,1797,"ages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1831,deployability,cluster,clusters,1831,"8, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:318,integrability,depend,depends,318,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1597,interoperability,format,format,1597,"ing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2429,interoperability,format,format,2429,"ha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#9ECAE1', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'limegreen', 'grey80', 'grey80', '#9ECAE1', 'grey80', '#4292C6', 'grey80', '#4292C6', 'grey80', 'limegreen', 'grey80', 'grey80', 'grey80', 'grey80', 'violetred', 'grey80', '#4292C6', '#9ECAE1', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'gre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:318,modifiability,depend,depends,318,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:666,modifiability,pac,package,666,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:796,modifiability,pac,packages,796,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1068,modifiability,pac,packages,1068,"e if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1206,modifiability,pac,packages,1206,"ng? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1342,modifiability,pac,packages,1342,"re huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1481,modifiability,pac,packages,1481,"scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1797,modifiability,modul,module,1797,"ages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1942,modifiability,pac,packages,1942,"e exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2105,modifiability,pac,packages,2105,"4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodger",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2236,modifiability,pac,packages,2236,"ne 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#9ECAE1', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'limegreen', 'grey80', 'grey80', '#9ECAE1', 'gr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2369,modifiability,pac,packages,2369," line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#9ECAE1', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'limegreen', 'grey80', 'grey80', '#9ECAE1', 'grey80', '#4292C6', 'grey80', '#4292C6', 'grey80', 'limegreen', 'grey80', 'grey80', 'grey80', 'grey80', 'violetred', 'grey80', '#4292C6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:874,performance,cach,cache,874,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:367,reliability,pra,pragati,367,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:764,reliability,pra,pragati,764,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1036,reliability,pra,pragati,1036," matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1174,reliability,pra,pragati,1174,"et us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1310,reliability,pra,pragati,1310," it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1449,reliability,pra,pragati,1449,"a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1910,reliability,pra,pragati,1910,"ne). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2073,reliability,pra,pragati,2073,"matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2204,reliability,pra,pragati,2204,"ckages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#9ECAE1', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'limegreen', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2337,reliability,pra,pragati,2337,"-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#9ECAE1', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'limegreen', 'grey80', 'grey80', '#9ECAE1', 'grey80', '#4292C6', 'grey80', '#4292C6', 'grey80', 'limegreen', 'grey80', 'grey80', 'grey80', 'grey80',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:55,safety,Updat,Update,55,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:214,safety,Log,Log,214,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:318,safety,depend,depends,318,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:948,safety,except,exception,948,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:967,safety,except,exception,967,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1688,safety,except,exception,1688,"finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'gr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1707,safety,except,exception,1707,"5). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1797,safety,modul,module,1797,"ages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2480,safety,valid,valid,2480,"ckages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#9ECAE1', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'limegreen', 'grey80', 'grey80', '#9ECAE1', 'grey80', '#4292C6', 'grey80', '#4292C6', 'grey80', 'limegreen', 'grey80', 'grey80', 'grey80', 'grey80', 'violetred', 'grey80', '#4292C6', '#9ECAE1', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#9ECAE1', '#2171B5', 'grey80', 'grey80', 'gr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:3491,safety,hot,hotpink,3491,", in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#9ECAE1', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'limegreen', 'grey80', 'grey80', '#9ECAE1', 'grey80', '#4292C6', 'grey80', '#4292C6', 'grey80', 'limegreen', 'grey80', 'grey80', 'grey80', 'grey80', 'violetred', 'grey80', '#4292C6', '#9ECAE1', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#9ECAE1', '#2171B5', 'grey80', 'grey80', 'grey80', 'hotpink', 'grey80' ..... . ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:55,security,Updat,Update,55,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:214,security,Log,Log,214,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:214,testability,Log,Log,214,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:318,testability,depend,depends,318,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:416,testability,plan,planaria,416,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:716,testability,Trace,Traceback,716,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:988,testability,Trace,Traceback,988,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1728,testability,Trace,Traceback,1728,"ecent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1770,testability,plan,planaria,1770,"36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:520,usability,learn,learn,520,"Function `plot_scatter` is breaking with matplotlib; **Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning? Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```. (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py . scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 . ... storing 'clusters' as categorical. computing tSNE. using data matrix X directly. using the 'MulticoreTSNE' package by Ulyanov (2017). finished (0:02:39.15). Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba. rgba = _colors_full_map.cache[c, alpha]. KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:1967,usability,tool,tools,1967,"eption occurred:. Traceback (most recent call last):. File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter. colors = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/286:2130,usability,tool,tools,2130," = mcolors.to_rgba_array(c). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array. result[i] = to_rgba(cc, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba. rgba = _to_rgba_no_colorcycle(c, alpha). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle. raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)). ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""planaria.py"", line 47, in <module>. sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne. return plot_scatter(adata, basis='tsne', **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 301, in plot_scatter. **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1785, in inner. return func(ax, *args, **kwargs). File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4231, in scatter. .format(c). ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors. Here c = ['orange', 'orange', 'orange', 'deeppink', '#6BAED6', 'deeppink', 'grey80', 'grey80', 'firebrick', '#6BAED6', '#9ECAE1', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#CBC9E2', 'grey80', 'grey80', '#2171B5', 'grey80', 'grey80', 'grey80', 'grey80', 'grey80', '#9ECAE1', 'grey80', 'grey80', 'mediumorchid1', 'grey80', '#2171B5', 'grey80', 'orange', 'grey80', '#9ECAE1', 'firebrick', 'grey80', 'grey80', 'grey80', 'grey80', 'firebrick', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#6BAED6', 'grey80', 'grey80', 'grey80', '#4292C6', '#2171B5', 'dodgerblue', 'forestgreen', '#",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286
https://github.com/scverse/scanpy/issues/287:587,integrability,pub,publication-grade,587,"Export figures in full vector mode; Hello,. Is it possible to save/export figures in full vector graphic mode ? For now it is possible to save figures by adding:. `sc.pl.tsne(..., save='_myfigure.svg')`. but it gives only partial vector graphic outputs, with only titles and axis in vector graphics, and cells or other graph elements (dots) being incorporated as compressed images (not filled vector circles). Exporting to .pdf extension doesn't works either. Full vector graphics figures are much easier to post-process (eg. if one wants to unify the color codes of several outputs for publication-grade purposes without having to recode 'manually' them within scripts). Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/287
https://github.com/scverse/scanpy/issues/287:428,modifiability,extens,extension,428,"Export figures in full vector mode; Hello,. Is it possible to save/export figures in full vector graphic mode ? For now it is possible to save figures by adding:. `sc.pl.tsne(..., save='_myfigure.svg')`. but it gives only partial vector graphic outputs, with only titles and axis in vector graphics, and cells or other graph elements (dots) being incorporated as compressed images (not filled vector circles). Exporting to .pdf extension doesn't works either. Full vector graphics figures are much easier to post-process (eg. if one wants to unify the color codes of several outputs for publication-grade purposes without having to recode 'manually' them within scripts). Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/287
https://github.com/scverse/scanpy/issues/287:438,reliability,doe,doesn,438,"Export figures in full vector mode; Hello,. Is it possible to save/export figures in full vector graphic mode ? For now it is possible to save figures by adding:. `sc.pl.tsne(..., save='_myfigure.svg')`. but it gives only partial vector graphic outputs, with only titles and axis in vector graphics, and cells or other graph elements (dots) being incorporated as compressed images (not filled vector circles). Exporting to .pdf extension doesn't works either. Full vector graphics figures are much easier to post-process (eg. if one wants to unify the color codes of several outputs for publication-grade purposes without having to recode 'manually' them within scripts). Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/287
https://github.com/scverse/scanpy/pull/289:225,deployability,log,log,225,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:309,performance,time,time,309,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:489,performance,time,time,489,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:62,safety,test,tests,62,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:157,safety,test,test,157,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:225,safety,log,log,225,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:703,safety,test,test,703,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:948,safety,test,test,948,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:225,security,log,log,225,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:62,testability,test,tests,62,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:157,testability,test,test,157,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:225,testability,log,log,225,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:703,testability,test,test,703,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:948,testability,test,test,948,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:389,usability,user,user-images,389,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:569,usability,user,user-images,569,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:886,usability,efficien,efficient,886,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/pull/289:1023,usability,help,helps,1023,"Added p-values to Wilcoxon; Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:. Original time:. <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:. <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289
https://github.com/scverse/scanpy/issues/290:13,availability,cluster,cluster,13,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:107,availability,cluster,clusters,107,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:403,availability,robust,robust,403,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:13,deployability,cluster,cluster,13,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:107,deployability,cluster,clusters,107,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:403,reliability,robust,robust,403,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:469,reliability,Doe,Does,469,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:403,safety,robust,robust,403,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:98,security,ident,identify,98,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:193,security,ident,identify,193,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:262,security,ident,identified,262,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:347,security,ident,identify,347,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/issues/290:490,usability,experien,experience,490,"How to score cluster for presence of marker genes?; A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290
https://github.com/scverse/scanpy/pull/291:72,safety,valid,valid,72,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:101,safety,test,test,101,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:180,safety,test,tests,180,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:232,safety,test,tests,232,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:160,security,modif,modify,160,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:101,testability,test,test,101,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:180,testability,test,tests,180,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:232,testability,test,tests,232,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/291:4,usability,custom,custom,4,Fix custom R colors; This PR addresses #286 and adds an extra check for valid color names. I added a test for the new functionality and took the opportunity to modify the plotting tests to mimic the way they are done for the pbmc3k tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/291
https://github.com/scverse/scanpy/pull/292:11,availability,cluster,clustering,11,"Phenograph clustering; Hi @falexwolf . Added a small wrapper for phenograph clustering, similar to phate.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/292
https://github.com/scverse/scanpy/pull/292:76,availability,cluster,clustering,76,"Phenograph clustering; Hi @falexwolf . Added a small wrapper for phenograph clustering, similar to phate.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/292
https://github.com/scverse/scanpy/pull/292:11,deployability,cluster,clustering,11,"Phenograph clustering; Hi @falexwolf . Added a small wrapper for phenograph clustering, similar to phate.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/292
https://github.com/scverse/scanpy/pull/292:76,deployability,cluster,clustering,76,"Phenograph clustering; Hi @falexwolf . Added a small wrapper for phenograph clustering, similar to phate.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/292
https://github.com/scverse/scanpy/pull/292:53,integrability,wrap,wrapper,53,"Phenograph clustering; Hi @falexwolf . Added a small wrapper for phenograph clustering, similar to phate.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/292
https://github.com/scverse/scanpy/pull/292:53,interoperability,wrapper,wrapper,53,"Phenograph clustering; Hi @falexwolf . Added a small wrapper for phenograph clustering, similar to phate.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/292
https://github.com/scverse/scanpy/issues/293:63,deployability,automat,automatic,63,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:331,deployability,version,versions,331,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:929,deployability,version,version,929,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:506,energy efficiency,Current,Current,506,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:921,energy efficiency,current,current,921,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:331,integrability,version,versions,331,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:929,integrability,version,version,929,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:331,modifiability,version,versions,331,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:929,modifiability,version,version,929,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:63,testability,automat,automatic,63,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:125,usability,Person,Personally,125,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:268,usability,command,command,268,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:412,usability,user,user-images,412,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:560,usability,user,user-images,560,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:893,usability,close,close,893,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:1059,usability,user,user-images,1059,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/293:1227,usability,user,user-images,1227,"Scatter plot default point size; @fidelram . It looks like the automatic point size selection for scatter plots has changed. Personally, I found the previous method more useful as I'm now getting more overplotting issues. For example, here are two plots made with the command `sc.pl.umap(bm, color=""biological_sex"")`, in different versions of scanpy:. Old result (at or before 1ec7af2):. ![old_plotting](https://user-images.githubusercontent.com/8238804/46785114-85d88b00-cd7c-11e8-9eec-38b912cbff92.png). Current result (at 94c3dc5):. ![new_plotting](https://user-images.githubusercontent.com/8238804/46785127-8a9d3f00-cd7c-11e8-9b9a-4a4d77dffa87.png). I suspect difference in marker used is related to this. While scatter points were previously points, it seems like they are circles now. Setting the size just seems to make the width of line for each circle decrease. For example, here's a close up of a plot from the current version with `size=0.01` and `size=0.001` respectively:. <img width=""373"" alt=""screen shot 2018-10-11 at 5 52 39 pm"" src=""https://user-images.githubusercontent.com/8238804/46785904-ef599900-cd7e-11e8-8a5c-0f7335750a18.png"">. <img width=""413"" alt=""screen shot 2018-10-11 at 5 53 02 pm"" src=""https://user-images.githubusercontent.com/8238804/46785905-f1235c80-cd7e-11e8-8eff-723a63a75c47.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293
https://github.com/scverse/scanpy/issues/296:302,deployability,automat,automatically,302,"scvelo neighbors; Dear,. I am trying to get RNA velocity with scvelo and I find that scvelo will search neighbors by default. Now I have an anndata object, of which the neighbors are made by a customized method. I wanna keep these neighbors, are there any methods to stop scvelo re-searching neighbors automatically ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/296
https://github.com/scverse/scanpy/issues/296:302,testability,automat,automatically,302,"scvelo neighbors; Dear,. I am trying to get RNA velocity with scvelo and I find that scvelo will search neighbors by default. Now I have an anndata object, of which the neighbors are made by a customized method. I wanna keep these neighbors, are there any methods to stop scvelo re-searching neighbors automatically ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/296
https://github.com/scverse/scanpy/issues/296:193,usability,custom,customized,193,"scvelo neighbors; Dear,. I am trying to get RNA velocity with scvelo and I find that scvelo will search neighbors by default. Now I have an anndata object, of which the neighbors are made by a customized method. I wanna keep these neighbors, are there any methods to stop scvelo re-searching neighbors automatically ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/296
https://github.com/scverse/scanpy/issues/296:267,usability,stop,stop,267,"scvelo neighbors; Dear,. I am trying to get RNA velocity with scvelo and I find that scvelo will search neighbors by default. Now I have an anndata object, of which the neighbors are made by a customized method. I wanna keep these neighbors, are there any methods to stop scvelo re-searching neighbors automatically ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/296
https://github.com/scverse/scanpy/issues/298:193,deployability,api,api,193,"`title` is no longer acting like ""vectorized"" argument for scatter plots; As an example, the following code produces different outputs in scanpy `v1.3.1` and 80e635d:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=[""1"",""2"",""3""], title=[""a"", ""b"", ""c""]). ```. In `v1.3.1` this shows:. ![pca_scatterprevious_titles](https://user-images.githubusercontent.com/8238804/46931190-e0802880-d095-11e8-8f94-78e3cc71f2d4.png). In 80e635d this shows:. ![pcacurrent_titles](https://user-images.githubusercontent.com/8238804/46931205-f261cb80-d095-11e8-8160-50997c16d35a.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/298
https://github.com/scverse/scanpy/issues/298:193,integrability,api,api,193,"`title` is no longer acting like ""vectorized"" argument for scatter plots; As an example, the following code produces different outputs in scanpy `v1.3.1` and 80e635d:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=[""1"",""2"",""3""], title=[""a"", ""b"", ""c""]). ```. In `v1.3.1` this shows:. ![pca_scatterprevious_titles](https://user-images.githubusercontent.com/8238804/46931190-e0802880-d095-11e8-8f94-78e3cc71f2d4.png). In 80e635d this shows:. ![pcacurrent_titles](https://user-images.githubusercontent.com/8238804/46931205-f261cb80-d095-11e8-8160-50997c16d35a.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/298
https://github.com/scverse/scanpy/issues/298:193,interoperability,api,api,193,"`title` is no longer acting like ""vectorized"" argument for scatter plots; As an example, the following code produces different outputs in scanpy `v1.3.1` and 80e635d:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=[""1"",""2"",""3""], title=[""a"", ""b"", ""c""]). ```. In `v1.3.1` this shows:. ![pca_scatterprevious_titles](https://user-images.githubusercontent.com/8238804/46931190-e0802880-d095-11e8-8f94-78e3cc71f2d4.png). In 80e635d this shows:. ![pcacurrent_titles](https://user-images.githubusercontent.com/8238804/46931205-f261cb80-d095-11e8-8160-50997c16d35a.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/298
https://github.com/scverse/scanpy/issues/298:447,usability,user,user-images,447,"`title` is no longer acting like ""vectorized"" argument for scatter plots; As an example, the following code produces different outputs in scanpy `v1.3.1` and 80e635d:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=[""1"",""2"",""3""], title=[""a"", ""b"", ""c""]). ```. In `v1.3.1` this shows:. ![pca_scatterprevious_titles](https://user-images.githubusercontent.com/8238804/46931190-e0802880-d095-11e8-8f94-78e3cc71f2d4.png). In 80e635d this shows:. ![pcacurrent_titles](https://user-images.githubusercontent.com/8238804/46931205-f261cb80-d095-11e8-8160-50997c16d35a.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/298
https://github.com/scverse/scanpy/issues/298:594,usability,user,user-images,594,"`title` is no longer acting like ""vectorized"" argument for scatter plots; As an example, the following code produces different outputs in scanpy `v1.3.1` and 80e635d:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=[""1"",""2"",""3""], title=[""a"", ""b"", ""c""]). ```. In `v1.3.1` this shows:. ![pca_scatterprevious_titles](https://user-images.githubusercontent.com/8238804/46931190-e0802880-d095-11e8-8f94-78e3cc71f2d4.png). In 80e635d this shows:. ![pcacurrent_titles](https://user-images.githubusercontent.com/8238804/46931205-f261cb80-d095-11e8-8160-50997c16d35a.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/298
https://github.com/scverse/scanpy/issues/299:156,deployability,api,api,156,"Scatter plots no longer like np.arrays for color argument; Comparing `v1.3.1` and 80e635d (current master) on the following code:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=np.array([""1"",""2"",""3""])). ```. In `v1.3.1` this shows:. ![pca_scatter_prev_colorarray](https://user-images.githubusercontent.com/8238804/46932091-ce07ee00-d099-11e8-8002-f4921e30849c.png). In 80e635d this shows:. ![pca_cur_colorarray](https://user-images.githubusercontent.com/8238804/46932109-e1b35480-d099-11e8-9baa-a8fcf67496f7.png). If the argument to color is a `list`, they show similar plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/299
https://github.com/scverse/scanpy/issues/299:91,energy efficiency,current,current,91,"Scatter plots no longer like np.arrays for color argument; Comparing `v1.3.1` and 80e635d (current master) on the following code:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=np.array([""1"",""2"",""3""])). ```. In `v1.3.1` this shows:. ![pca_scatter_prev_colorarray](https://user-images.githubusercontent.com/8238804/46932091-ce07ee00-d099-11e8-8002-f4921e30849c.png). In 80e635d this shows:. ![pca_cur_colorarray](https://user-images.githubusercontent.com/8238804/46932109-e1b35480-d099-11e8-9baa-a8fcf67496f7.png). If the argument to color is a `list`, they show similar plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/299
https://github.com/scverse/scanpy/issues/299:156,integrability,api,api,156,"Scatter plots no longer like np.arrays for color argument; Comparing `v1.3.1` and 80e635d (current master) on the following code:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=np.array([""1"",""2"",""3""])). ```. In `v1.3.1` this shows:. ![pca_scatter_prev_colorarray](https://user-images.githubusercontent.com/8238804/46932091-ce07ee00-d099-11e8-8002-f4921e30849c.png). In 80e635d this shows:. ![pca_cur_colorarray](https://user-images.githubusercontent.com/8238804/46932109-e1b35480-d099-11e8-9baa-a8fcf67496f7.png). If the argument to color is a `list`, they show similar plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/299
https://github.com/scverse/scanpy/issues/299:156,interoperability,api,api,156,"Scatter plots no longer like np.arrays for color argument; Comparing `v1.3.1` and 80e635d (current master) on the following code:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=np.array([""1"",""2"",""3""])). ```. In `v1.3.1` this shows:. ![pca_scatter_prev_colorarray](https://user-images.githubusercontent.com/8238804/46932091-ce07ee00-d099-11e8-8002-f4921e30849c.png). In 80e635d this shows:. ![pca_cur_colorarray](https://user-images.githubusercontent.com/8238804/46932109-e1b35480-d099-11e8-9baa-a8fcf67496f7.png). If the argument to color is a `list`, they show similar plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/299
https://github.com/scverse/scanpy/issues/299:398,usability,user,user-images,398,"Scatter plots no longer like np.arrays for color argument; Comparing `v1.3.1` and 80e635d (current master) on the following code:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=np.array([""1"",""2"",""3""])). ```. In `v1.3.1` this shows:. ![pca_scatter_prev_colorarray](https://user-images.githubusercontent.com/8238804/46932091-ce07ee00-d099-11e8-8002-f4921e30849c.png). In 80e635d this shows:. ![pca_cur_colorarray](https://user-images.githubusercontent.com/8238804/46932109-e1b35480-d099-11e8-9baa-a8fcf67496f7.png). If the argument to color is a `list`, they show similar plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/299
https://github.com/scverse/scanpy/issues/299:546,usability,user,user-images,546,"Scatter plots no longer like np.arrays for color argument; Comparing `v1.3.1` and 80e635d (current master) on the following code:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). sc.pl.pca(adata, color=np.array([""1"",""2"",""3""])). ```. In `v1.3.1` this shows:. ![pca_scatter_prev_colorarray](https://user-images.githubusercontent.com/8238804/46932091-ce07ee00-d099-11e8-8002-f4921e30849c.png). In 80e635d this shows:. ![pca_cur_colorarray](https://user-images.githubusercontent.com/8238804/46932109-e1b35480-d099-11e8-9baa-a8fcf67496f7.png). If the argument to color is a `list`, they show similar plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/299
https://github.com/scverse/scanpy/issues/300:250,deployability,log,logarithmized,250,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:401,deployability,log,log,401,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:365,energy efficiency,current,current,365,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:459,integrability,transform,transform,459,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:541,integrability,filter,filtering,541,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:583,integrability,sub,subset,583,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:621,integrability,sub,subset,621,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:459,interoperability,transform,transform,459,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:700,interoperability,compatib,compatibility,700,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:390,modifiability,paramet,parameter,390,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:529,performance,perform,perform,529,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:442,reliability,doe,doesn,442,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:512,reliability,doe,doesn,512,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:250,safety,log,logarithmized,250,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:401,safety,log,log,401,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:250,security,log,logarithmized,250,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:401,security,log,log,401,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:250,testability,log,logarithmized,250,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:401,testability,log,log,401,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:555,testability,simpl,simply,555,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:529,usability,perform,perform,529,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/300:555,usability,simpl,simply,555,"Write highly_variable_genes function; Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the Seurat method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesnt properly transform back using `expm`). Also, the new function doesnt actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300
https://github.com/scverse/scanpy/issues/301:366,availability,backup,backup,366,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:133,deployability,version,versions,133,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:373,deployability,version,version,373,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:432,energy efficiency,current,currently,432,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:133,integrability,version,versions,133,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:373,integrability,version,version,373,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:482,integrability,wrap,wraps,482,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:572,integrability,wrap,wrap,572,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:461,interoperability,compatib,compatibility,461,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:133,modifiability,version,versions,133,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:373,modifiability,version,version,373,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:366,reliability,backup,backup,366,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:442,reliability,doe,does,442,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/301:366,safety,backup,backup,366,"Normalization in scanpy.preprocessing; Need a file `normalization.py` in `scanpy.preprocessing`. In that, there should be cleaned-up versions of `normalize_per_cell` and `normalize_per_cell_weinreib17` without any recursive calls and no calls to `filter_cells`. The new names of these function should be `normalize_total` and `normalize_quantile`. There should be a backup version of `normalize_per_cell` that behaves exactly as it currently does for backwards compatibility, which wraps `filter_cells` and `normalize_per_cell`. In the ideal case, `normalize_total` would wrap `normalize_quantile(quantile=1)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/301
https://github.com/scverse/scanpy/issues/302:49,deployability,automat,automatically,49,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:266,deployability,integr,integrated,266,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:266,integrability,integr,integrated,266,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:293,integrability,repositor,repository,293,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:266,interoperability,integr,integrated,266,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:293,interoperability,repositor,repository,293,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:266,modifiability,integr,integrated,266,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:266,reliability,integr,integrated,266,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:483,safety,test,test,483,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:543,safety,test,tests,543,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:266,security,integr,integrated,266,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:49,testability,automat,automatically,49,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:266,testability,integr,integrated,266,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:483,testability,test,test,483,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:543,testability,test,tests,543,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/302:354,usability,clear,cleared,354,"Notebooks on readthedocs; We want notebooks that automatically run through on readthedocs: https://nbsphinx.readthedocs.io/en/0.3.5. So that the basic tutorial (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) can be integrated into the scanpy repository in `docs/tutorials` as a notebook with all output cleared (no images etc.). It is run on the readthedocs server and will produce exactly the same output, as is guaranteed by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/pbmc3k.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/302
https://github.com/scverse/scanpy/issues/303:50,performance,memor,memory,50,Improve sc.read efficiency; Improve sc.read\write memory usage and runtime.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303
https://github.com/scverse/scanpy/issues/303:16,usability,efficien,efficiency,16,Improve sc.read efficiency; Improve sc.read\write memory usage and runtime.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303
https://github.com/scverse/scanpy/issues/303:50,usability,memor,memory,50,Improve sc.read efficiency; Improve sc.read\write memory usage and runtime.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303
https://github.com/scverse/scanpy/pull/304:31,deployability,updat,updated,31,Fix scatter issues; Tests were updated to include instances of the requirements.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/304
https://github.com/scverse/scanpy/pull/304:20,safety,Test,Tests,20,Fix scatter issues; Tests were updated to include instances of the requirements.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/304
https://github.com/scverse/scanpy/pull/304:31,safety,updat,updated,31,Fix scatter issues; Tests were updated to include instances of the requirements.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/304
https://github.com/scverse/scanpy/pull/304:31,security,updat,updated,31,Fix scatter issues; Tests were updated to include instances of the requirements.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/304
https://github.com/scverse/scanpy/pull/304:20,testability,Test,Tests,20,Fix scatter issues; Tests were updated to include instances of the requirements.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/304
https://github.com/scverse/scanpy/pull/305:42,safety,test,testing,42,"Add some missing requirements; Hi,. I was testing the different functions and found out that some requirements were missing and so in the `requirements.txt`. I tried to add the one I could find on Pypi. Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/305
https://github.com/scverse/scanpy/pull/305:42,testability,test,testing,42,"Add some missing requirements; Hi,. I was testing the different functions and found out that some requirements were missing and so in the `requirements.txt`. I tried to add the one I could find on Pypi. Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/305
https://github.com/scverse/scanpy/issues/306:154,integrability,compon,components,154,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:298,integrability,compon,components,298,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:88,interoperability,standard,standard,88,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:154,interoperability,compon,components,154,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:167,interoperability,specif,specified,167,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:298,interoperability,compon,components,298,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:154,modifiability,compon,components,154,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:298,modifiability,compon,components,298,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/306:378,testability,understand,understand,378,"UMAP ignores n_components when initial position is paga; When I run sc.tl.umap with the standard setting, init_pos = 'spectral', I get whatever number of components I specified via n_components. However, when I use init_pos = 'paga' for a paga representation I computed before, I always only get 2 components, no matter how I set n_components. From looking at the code, I don't understand why this is happening. Is there a principal reason for this, or is this a bug? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306
https://github.com/scverse/scanpy/issues/307:71,deployability,observ,observation,71,"umap dot size; Hi, . I am trying to separate my umap according to some observation. I'm sure I've have missed it but is there a parameter in sc.pl.umap() to control the dot size? Thank you,. Justine :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/307
https://github.com/scverse/scanpy/issues/307:128,modifiability,paramet,parameter,128,"umap dot size; Hi, . I am trying to separate my umap according to some observation. I'm sure I've have missed it but is there a parameter in sc.pl.umap() to control the dot size? Thank you,. Justine :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/307
https://github.com/scverse/scanpy/issues/307:157,security,control,control,157,"umap dot size; Hi, . I am trying to separate my umap according to some observation. I'm sure I've have missed it but is there a parameter in sc.pl.umap() to control the dot size? Thank you,. Justine :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/307
https://github.com/scverse/scanpy/issues/307:71,testability,observ,observation,71,"umap dot size; Hi, . I am trying to separate my umap according to some observation. I'm sure I've have missed it but is there a parameter in sc.pl.umap() to control the dot size? Thank you,. Justine :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/307
https://github.com/scverse/scanpy/issues/307:157,testability,control,control,157,"umap dot size; Hi, . I am trying to separate my umap according to some observation. I'm sure I've have missed it but is there a parameter in sc.pl.umap() to control the dot size? Thank you,. Justine :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/307
https://github.com/scverse/scanpy/pull/308:116,availability,cluster,clustering,116,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:1107,availability,avail,available,1107,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:116,deployability,cluster,clustering,116,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:29,energy efficiency,heat,heatmap,29,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:131,energy efficiency,draw,draws,131,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:628,energy efficiency,Current,Currently,628,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:773,energy efficiency,heat,heatmap,773,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:849,modifiability,paramet,parameter,849,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:1107,reliability,availab,available,1107,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:1107,safety,avail,available,1107,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:1107,security,availab,available,1107,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:423,usability,user,user-images,423,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:534,usability,user,user-images,534,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/pull/308:996,usability,user,user-images,996,"This PR adds a dendrogram to heatmap, matrixplot, dotplot and staked_violins plots; This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON. pbmc = sc.datasets.pbmc68k_reduced(). ```. ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON. sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True). ```. ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308
https://github.com/scverse/scanpy/issues/309:167,deployability,api,api,167,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/309:167,integrability,api,api,167,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/309:167,interoperability,api,api,167,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/309:16,usability,behavi,behavior,16,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/309:88,usability,behavi,behavior,88,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/309:468,usability,user,user-images,468,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/309:691,usability,user,user-images,691,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/309:920,usability,user,user-images,920,"Plotting layout behavior at repl; As mentioned in #299, I'm getting some strange layout behavior when plotting at the repl. Using the setup:. ```python. import scanpy.api as sc. import numpy as np. N = 1000. M = 2000. adata = sc.AnnData(X=np.random.random_sample((N, M))). sc.pp.pca(adata). ```. I get outputs that look like the following . ```python. sc.pl.pca(adata, color=list(""123"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 46 46 pm"" src=""https://user-images.githubusercontent.com/8238804/47133668-72d23780-d2f5-11e8-9630-f6e676a146ca.png"">. ```python. sc.pl.pca(adata, color=list(""1234"")). ```. <img width=""1552"" alt=""screen shot 2018-10-18 at 4 47 37 pm"" src=""https://user-images.githubusercontent.com/8238804/47133696-909f9c80-d2f5-11e8-8482-eab30e84fe46.png"">. ```python. sc.pl.pca(adata, color=list(""12""), ncols=1). ```. <img width=""839"" alt=""screen shot 2018-10-18 at 4 50 11 pm"" src=""https://user-images.githubusercontent.com/8238804/47133806-17547980-d2f6-11e8-97ad-6d9528ea280b.png"">. I get similar results with the MacOSX and GR backends (haven't checked others). I think the issue is due to the implicit `bbox_inches=""tight""` occurring with the matplotlib inline backend, and its explicit usage for `scanpy.plotting.utils.savefig`. In the cases here, the bounding box is not being trimmed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/309
https://github.com/scverse/scanpy/issues/310:178,availability,error,error,178,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:59,deployability,api,api,59,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:87,deployability,api,api,87,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:120,deployability,instal,installing,120,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:142,deployability,version,version,142,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:198,deployability,modul,module,198,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:59,integrability,api,api,59,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:87,integrability,api,api,87,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:142,integrability,version,version,142,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:59,interoperability,api,api,59,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:87,interoperability,api,api,87,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:142,modifiability,version,version,142,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:198,modifiability,modul,module,198,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:178,performance,error,error,178,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:39,safety,test,testing,39,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:178,safety,error,error,178,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:198,safety,modul,module,198,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:39,testability,test,testing,39,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/310:178,usability,error,error,178,"Bugs with pypairs functions; Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function. 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Brnice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310
https://github.com/scverse/scanpy/issues/311:173,availability,error,error,173,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:144,integrability,compon,components,144,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:144,interoperability,compon,components,144,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:144,modifiability,compon,components,144,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:173,performance,error,error,173,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:26,safety,test,testing,26,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:173,safety,error,error,173,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:26,testability,test,testing,26,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:116,usability,document,documentation,116,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/issues/311:173,usability,error,error,173,"`pl.scatter`: ; Hi,. I am testing `pl.scatter` and it seems that:. - `color` cannot be a list (contrary to what the documentation mentions). - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311
https://github.com/scverse/scanpy/pull/312:87,modifiability,paramet,parameters,87,To fix issue #310 with pypairs; Fix issue #310 . - Import sandbag and cyclone. - Align parameters to the one in `pypairs`. - Add documentation for the parameters. I wanted to add some tests but I was not sure which dataset makes sense. Any idea? Brnice,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/312
https://github.com/scverse/scanpy/pull/312:151,modifiability,paramet,parameters,151,To fix issue #310 with pypairs; Fix issue #310 . - Import sandbag and cyclone. - Align parameters to the one in `pypairs`. - Add documentation for the parameters. I wanted to add some tests but I was not sure which dataset makes sense. Any idea? Brnice,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/312
https://github.com/scverse/scanpy/pull/312:184,safety,test,tests,184,To fix issue #310 with pypairs; Fix issue #310 . - Import sandbag and cyclone. - Align parameters to the one in `pypairs`. - Add documentation for the parameters. I wanted to add some tests but I was not sure which dataset makes sense. Any idea? Brnice,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/312
https://github.com/scverse/scanpy/pull/312:184,testability,test,tests,184,To fix issue #310 with pypairs; Fix issue #310 . - Import sandbag and cyclone. - Align parameters to the one in `pypairs`. - Add documentation for the parameters. I wanted to add some tests but I was not sure which dataset makes sense. Any idea? Brnice,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/312
https://github.com/scverse/scanpy/pull/312:129,usability,document,documentation,129,To fix issue #310 with pypairs; Fix issue #310 . - Import sandbag and cyclone. - Align parameters to the one in `pypairs`. - Add documentation for the parameters. I wanted to add some tests but I was not sure which dataset makes sense. Any idea? Brnice,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/312
https://github.com/scverse/scanpy/issues/313:317,availability,cluster,clustering,317,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:434,availability,cluster,clusters,434,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:49,deployability,pipelin,pipeline,49,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:236,deployability,pipelin,pipeline,236,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:317,deployability,cluster,clustering,317,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:434,deployability,cluster,clusters,434,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:49,integrability,pipelin,pipeline,49,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:61,integrability,filter,filtered,61,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:236,integrability,pipelin,pipeline,236,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:504,integrability,filter,filtering,504,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:83,modifiability,variab,variable,83,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:173,performance,time,time,173,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/313:107,testability,regress,regress,107,"score_genes reproducibility; In my preprocessing pipeline, I filtered for the most variable genes and also regress out n_counts and cell cycle. However, it seems like every time I restart my Jupyter notebook and rerun the preprocessing pipeline, I get a different neighborhood graph and UMAP, and therefore different clustering. If I use the same preprocessed data, I can reproduce the same PCA (using svd_solver='arpack'), UMAP, and clusters. So I was wondering if there is randomness introduced during filtering process or regress_out methods? What should I do to ensure reproducibility?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313
https://github.com/scverse/scanpy/issues/314:254,reliability,doe,doesnt,254,"expression table; Hi,. Is it possible to generate a gene expression table with scanpy and save as a csv file? I can make it with cellranger and seurat but not with scanpy. cell1 . cell2 . cell3 . etc.. gene1 . gene2 . gene3. The cmd adata.write.csvs(..) doesnt give such table. I also understand this can be huge data if many cells were used. Thank you very much for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/314
https://github.com/scverse/scanpy/issues/314:285,testability,understand,understand,285,"expression table; Hi,. Is it possible to generate a gene expression table with scanpy and save as a csv file? I can make it with cellranger and seurat but not with scanpy. cell1 . cell2 . cell3 . etc.. gene1 . gene2 . gene3. The cmd adata.write.csvs(..) doesnt give such table. I also understand this can be huge data if many cells were used. Thank you very much for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/314
https://github.com/scverse/scanpy/issues/314:372,usability,help,help,372,"expression table; Hi,. Is it possible to generate a gene expression table with scanpy and save as a csv file? I can make it with cellranger and seurat but not with scanpy. cell1 . cell2 . cell3 . etc.. gene1 . gene2 . gene3. The cmd adata.write.csvs(..) doesnt give such table. I also understand this can be huge data if many cells were used. Thank you very much for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/314
https://github.com/scverse/scanpy/issues/315:16,deployability,fail,fails,16,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:251,deployability,api,api,251,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:26,integrability,sub,subset,26,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:251,integrability,api,api,251,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:419,integrability,sub,subset,419,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:489,integrability,sub,subset,489,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:251,interoperability,api,api,251,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:62,modifiability,variab,variables,62,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:97,modifiability,variab,variable,97,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/issues/315:16,reliability,fail,fails,16,"pl.pca_loadings fails if `subset=False` when computing highly variables genes.; After the highly variable genes information was added to .var `pl.pca_loadings` no longer works. This is an example that reproduces the problem:. ```PYTHON. import scanpy.api as sc. import numpy as np. import pandas as pd. N = 1000. M = 2000. adata = sc.AnnData(. X=np.random.random_sample((N, M)). ). sc.pp.filter_genes_dispersion(adata, subset=False). sc.tl.pca(adata). sc.pl.pca_loadings(adata). ```. If ` subset=True` then the pca_loadings works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/315
https://github.com/scverse/scanpy/pull/316:128,deployability,releas,release,128,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:196,deployability,version,version,196,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:196,integrability,version,version,196,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:324,integrability,interfac,interface,324,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:420,integrability,filter,filtering,420,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:324,interoperability,interfac,interface,324,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:119,modifiability,pac,packages,119,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:196,modifiability,version,version,196,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:324,modifiability,interfac,interface,324,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:370,performance,memor,memory,370,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:602,safety,test,tests,602,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:602,testability,test,tests,602,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:370,usability,memor,memory,370,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:377,usability,efficien,efficient,377,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/pull/316:622,usability,document,documentation,622,"Add `calculate_qc_metrics` function; I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy? I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix. - [x] Add `feature_control` argument, possibly `variable_control`. - [x] Clean up and expand tests. - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that. * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316
https://github.com/scverse/scanpy/issues/317:19,deployability,fail,failing,19,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:76,deployability,fail,failing,76,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:157,deployability,fail,failed-diff,157,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:360,deployability,fail,failed-diff,360,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:19,reliability,fail,failing,19,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:76,reliability,fail,failing,76,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:157,reliability,fail,failed-diff,157,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:360,reliability,fail,failed-diff,360,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:13,safety,test,tests,13,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:66,safety,test,tests,66,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:517,safety,test,tests,517,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:13,testability,test,tests,13,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:66,testability,test,tests,66,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:517,testability,test,tests,517,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:178,usability,user,user-images,178,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/317:381,usability,user,user-images,381,"All plotting tests failing, mostly trivially; All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317
https://github.com/scverse/scanpy/issues/318:687,availability,error,error,687,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:231,deployability,api,api,231,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:439,deployability,api,api,439,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:800,deployability,modul,module,800,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:944,deployability,scale,scale,944,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:950,deployability,scale,scale,950,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1498,deployability,version,versions,1498,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1524,deployability,instal,installed,1524,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:944,energy efficiency,scale,scale,944,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:950,energy efficiency,scale,scale,950,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:231,integrability,api,api,231,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:439,integrability,api,api,439,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1498,integrability,version,versions,1498,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:231,interoperability,api,api,231,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:439,interoperability,api,api,439,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:140,modifiability,variab,variable,140,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:800,modifiability,modul,module,800,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:858,modifiability,pac,packages,858,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:944,modifiability,scal,scale,944,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:950,modifiability,scal,scale,950,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1022,modifiability,pac,packages,1022,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1160,modifiability,pac,packages,1160,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1335,modifiability,pac,packages,1335,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1465,modifiability,variab,variable,1465,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1498,modifiability,version,versions,1498,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:687,performance,error,error,687,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:944,performance,scale,scale,944,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:950,performance,scale,scale,950,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:60,safety,test,testing,60,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:687,safety,error,error,687,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:800,safety,modul,module,800,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1458,safety,input,input,1458,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1483,safety,test,tested,1483,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:60,testability,test,testing,60,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:700,testability,Trace,Traceback,700,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:736,testability,Trace,Traceback,736,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1483,testability,test,tested,1483,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:687,usability,error,error,687,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/318:1458,usability,input,input,1458,"sc.pl.stacked_violin: issue using imported adata; Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. No problem, but if I run:. ```. >>> import scanpy.api as sc. >>> adata = sc.datasets.krumsiek11(). >>> adata.write('anndata.h5ad'). >>> adata = sc.read_h5ad('anndata.h5ad'). >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False). ```. then I got the error:. ```. Traceback (most recent call last):. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin. orient='vertical', scale=scale, ax=ax, **kwds). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot. color, palette, saturation). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'variable'. ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318
https://github.com/scverse/scanpy/issues/319:60,safety,test,test,60,"Occasional dramatic differences between tSNE and UMAP; On a test dataset I compute neighbors and then immediately compute/plot both tSNE and UMAP and show them next to each other. Sometimes, we get pretty dramatic differences such as the one attached. Is this an algorithmic difference or something wrong with my approach? ```. sc.pp.neighbors(adata, n_pcs=n_pcs, n_neighbors=n_neighbors). sc.tl.tsne(adata, n_pcs=n_pcs, random_state=random_state). sc.tl.umap(adata). sc.pl.tsne(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""). sc.pl.umap(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""). ```. ![screenshot from 2018-10-22 11-57-49](https://user-images.githubusercontent.com/330899/47306454-25561300-d5f2-11e8-98e9-939703dcf61b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/319
https://github.com/scverse/scanpy/issues/319:60,testability,test,test,60,"Occasional dramatic differences between tSNE and UMAP; On a test dataset I compute neighbors and then immediately compute/plot both tSNE and UMAP and show them next to each other. Sometimes, we get pretty dramatic differences such as the one attached. Is this an algorithmic difference or something wrong with my approach? ```. sc.pp.neighbors(adata, n_pcs=n_pcs, n_neighbors=n_neighbors). sc.tl.tsne(adata, n_pcs=n_pcs, random_state=random_state). sc.tl.umap(adata). sc.pl.tsne(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""). sc.pl.umap(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""). ```. ![screenshot from 2018-10-22 11-57-49](https://user-images.githubusercontent.com/330899/47306454-25561300-d5f2-11e8-98e9-939703dcf61b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/319
https://github.com/scverse/scanpy/issues/319:698,usability,user,user-images,698,"Occasional dramatic differences between tSNE and UMAP; On a test dataset I compute neighbors and then immediately compute/plot both tSNE and UMAP and show them next to each other. Sometimes, we get pretty dramatic differences such as the one attached. Is this an algorithmic difference or something wrong with my approach? ```. sc.pp.neighbors(adata, n_pcs=n_pcs, n_neighbors=n_neighbors). sc.tl.tsne(adata, n_pcs=n_pcs, random_state=random_state). sc.tl.umap(adata). sc.pl.tsne(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""). sc.pl.umap(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""). ```. ![screenshot from 2018-10-22 11-57-49](https://user-images.githubusercontent.com/330899/47306454-25561300-d5f2-11e8-98e9-939703dcf61b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/319
https://github.com/scverse/scanpy/issues/320:509,availability,error,error,509,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1875,availability,error,errors,1875,"rt scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:12120,availability,Cluster,ClusterName,12120,")', 'u1'), ('FOXM1_extended_(14g)', 'u1'), ('NKX2-1_extended_(14g)', 'u1'), ('NR1D2_extended_(13g)', 'u1'), ('POU2F1_extended_(13g)', 'u1'), ('CLOCK_(13g)', 'u1'), ('CTCF_(13g)', 'u1'), ('MAFF_(13g)', 'u1'), ('POU2F1_(12g)', 'u1'), ('RUNX2_(12g)', 'u1'), ('SMAD3_(13g)', 'u1'), ('ETV5_extended_(12g)', 'u1'), ('FOXJ3_extended_(12g)', 'u1'), ('FOXN3_extended_(12g)', 'u1'), ('NFATC1_extended_(13g)', 'u1'), ('ELF4_(12g)', 'u1'), ('ETV1_(11g)', 'u1'), ('FOXP4_(11g)', 'u1'), ('SP2_(11g)', 'u1'), ('TCF3_(12g)', 'u1'), ('ZBTB41_(12g)', 'u1'), ('ZNF503_(12g)', 'u1'), ('HIVEP1_extended_(11g)', 'u1'), ('NPDC1_extended_(12g)', 'u1'), ('RXRB_extended_(11g)', 'u1'), ('FOXK2_(11g)', 'u1'), ('FOXM1_(11g)', 'u1'), ('HDAC1_(10g)', 'u1'), ('MELK_(11g)', 'u1'), ('RARA_(10g)', 'u1'), ('RXRB_(11g)', 'u1'), ('TP53_(10g)', 'u1'), ('ZNF260_(11g)', 'u1'), ('MEF2D_extended_(10g)', 'u1'), ('MLXIP_extended_(11g)', 'u1')] is not allowed. Column attribute 'CellID' dtype object is not allowed. Column attribute 'ClusterName' dtype object is not allowed. Column attribute 'Clusterings' dtype [('0', '<i4')] is not allowed. Column attribute 'Embedding' dtype [('_X', '<f8'), ('_Y', '<f8')] is not allowed. Column attribute 'Embeddings_X' dtype [('0', '<f8')] is not allowed. Column attribute 'Embeddings_Y' dtype [('0', '<f8')] is not allowed. Column attribute 'RegulonsAUC' dtype [('TBX21_extended (69g)', '<f8'), ('TBX21 (58g)', '<f8'), ('ELF1_extended (987g)', '<f8'), ('ELF1 (753g)', '<f8'), ('EOMES_extended (223g)', '<f8'), ('EOMES (168g)', '<f8'), ('RUNX3_extended (532g)', '<f8'), ('RUNX3 (414g)', '<f8'), ('PRDM1_extended (538g)', '<f8'), ('ETS1_extended (647g)', '<f8'), ('ETS1 (577g)', '<f8'), ('ZNF683_extended (75g)', '<f8'), ('IRF1_extended (662g)', '<f8'), ('IRF1 (617g)', '<f8'), ('JUN_extended (62g)', '<f8'), ('JUN (26g)', '<f8'), ('IRF7_extended (688g)', '<f8'), ('IRF7 (616g)', '<f8'), ('IRF9_extended (358g)', '<f8'), ('IRF9 (302g)', '<f8'), ('MAFB_extended (39g)', '<f8'), ('NR1H3_extended (208g)',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:12180,availability,Cluster,Clusterings,12180,"_(14g)', 'u1'), ('NR1D2_extended_(13g)', 'u1'), ('POU2F1_extended_(13g)', 'u1'), ('CLOCK_(13g)', 'u1'), ('CTCF_(13g)', 'u1'), ('MAFF_(13g)', 'u1'), ('POU2F1_(12g)', 'u1'), ('RUNX2_(12g)', 'u1'), ('SMAD3_(13g)', 'u1'), ('ETV5_extended_(12g)', 'u1'), ('FOXJ3_extended_(12g)', 'u1'), ('FOXN3_extended_(12g)', 'u1'), ('NFATC1_extended_(13g)', 'u1'), ('ELF4_(12g)', 'u1'), ('ETV1_(11g)', 'u1'), ('FOXP4_(11g)', 'u1'), ('SP2_(11g)', 'u1'), ('TCF3_(12g)', 'u1'), ('ZBTB41_(12g)', 'u1'), ('ZNF503_(12g)', 'u1'), ('HIVEP1_extended_(11g)', 'u1'), ('NPDC1_extended_(12g)', 'u1'), ('RXRB_extended_(11g)', 'u1'), ('FOXK2_(11g)', 'u1'), ('FOXM1_(11g)', 'u1'), ('HDAC1_(10g)', 'u1'), ('MELK_(11g)', 'u1'), ('RARA_(10g)', 'u1'), ('RXRB_(11g)', 'u1'), ('TP53_(10g)', 'u1'), ('ZNF260_(11g)', 'u1'), ('MEF2D_extended_(10g)', 'u1'), ('MLXIP_extended_(11g)', 'u1')] is not allowed. Column attribute 'CellID' dtype object is not allowed. Column attribute 'ClusterName' dtype object is not allowed. Column attribute 'Clusterings' dtype [('0', '<i4')] is not allowed. Column attribute 'Embedding' dtype [('_X', '<f8'), ('_Y', '<f8')] is not allowed. Column attribute 'Embeddings_X' dtype [('0', '<f8')] is not allowed. Column attribute 'Embeddings_Y' dtype [('0', '<f8')] is not allowed. Column attribute 'RegulonsAUC' dtype [('TBX21_extended (69g)', '<f8'), ('TBX21 (58g)', '<f8'), ('ELF1_extended (987g)', '<f8'), ('ELF1 (753g)', '<f8'), ('EOMES_extended (223g)', '<f8'), ('EOMES (168g)', '<f8'), ('RUNX3_extended (532g)', '<f8'), ('RUNX3 (414g)', '<f8'), ('PRDM1_extended (538g)', '<f8'), ('ETS1_extended (647g)', '<f8'), ('ETS1 (577g)', '<f8'), ('ZNF683_extended (75g)', '<f8'), ('IRF1_extended (662g)', '<f8'), ('IRF1 (617g)', '<f8'), ('JUN_extended (62g)', '<f8'), ('JUN (26g)', '<f8'), ('IRF7_extended (688g)', '<f8'), ('IRF7 (616g)', '<f8'), ('IRF9_extended (358g)', '<f8'), ('IRF9 (302g)', '<f8'), ('MAFB_extended (39g)', '<f8'), ('NR1H3_extended (208g)', '<f8'), ('NR1H3 (207g)', '<f8'), ('CEBPB_extended (1162g)',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:578,deployability,version,version,578,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:641,deployability,api,api,641,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:863,deployability,modul,module,863,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:888,deployability,api,api,888,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1511,deployability,fail,fails,1511," below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1780,deployability,version,version,1780,"lueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1963,deployability,version,version,1963,"nda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ('ETS1_(577g)', 'u1'), ('UQCRB_(573g)', 'u1'), ('PRDM1_extended_(538g)', 'u1'), ('RUNX3_e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:12120,deployability,Cluster,ClusterName,12120,")', 'u1'), ('FOXM1_extended_(14g)', 'u1'), ('NKX2-1_extended_(14g)', 'u1'), ('NR1D2_extended_(13g)', 'u1'), ('POU2F1_extended_(13g)', 'u1'), ('CLOCK_(13g)', 'u1'), ('CTCF_(13g)', 'u1'), ('MAFF_(13g)', 'u1'), ('POU2F1_(12g)', 'u1'), ('RUNX2_(12g)', 'u1'), ('SMAD3_(13g)', 'u1'), ('ETV5_extended_(12g)', 'u1'), ('FOXJ3_extended_(12g)', 'u1'), ('FOXN3_extended_(12g)', 'u1'), ('NFATC1_extended_(13g)', 'u1'), ('ELF4_(12g)', 'u1'), ('ETV1_(11g)', 'u1'), ('FOXP4_(11g)', 'u1'), ('SP2_(11g)', 'u1'), ('TCF3_(12g)', 'u1'), ('ZBTB41_(12g)', 'u1'), ('ZNF503_(12g)', 'u1'), ('HIVEP1_extended_(11g)', 'u1'), ('NPDC1_extended_(12g)', 'u1'), ('RXRB_extended_(11g)', 'u1'), ('FOXK2_(11g)', 'u1'), ('FOXM1_(11g)', 'u1'), ('HDAC1_(10g)', 'u1'), ('MELK_(11g)', 'u1'), ('RARA_(10g)', 'u1'), ('RXRB_(11g)', 'u1'), ('TP53_(10g)', 'u1'), ('ZNF260_(11g)', 'u1'), ('MEF2D_extended_(10g)', 'u1'), ('MLXIP_extended_(11g)', 'u1')] is not allowed. Column attribute 'CellID' dtype object is not allowed. Column attribute 'ClusterName' dtype object is not allowed. Column attribute 'Clusterings' dtype [('0', '<i4')] is not allowed. Column attribute 'Embedding' dtype [('_X', '<f8'), ('_Y', '<f8')] is not allowed. Column attribute 'Embeddings_X' dtype [('0', '<f8')] is not allowed. Column attribute 'Embeddings_Y' dtype [('0', '<f8')] is not allowed. Column attribute 'RegulonsAUC' dtype [('TBX21_extended (69g)', '<f8'), ('TBX21 (58g)', '<f8'), ('ELF1_extended (987g)', '<f8'), ('ELF1 (753g)', '<f8'), ('EOMES_extended (223g)', '<f8'), ('EOMES (168g)', '<f8'), ('RUNX3_extended (532g)', '<f8'), ('RUNX3 (414g)', '<f8'), ('PRDM1_extended (538g)', '<f8'), ('ETS1_extended (647g)', '<f8'), ('ETS1 (577g)', '<f8'), ('ZNF683_extended (75g)', '<f8'), ('IRF1_extended (662g)', '<f8'), ('IRF1 (617g)', '<f8'), ('JUN_extended (62g)', '<f8'), ('JUN (26g)', '<f8'), ('IRF7_extended (688g)', '<f8'), ('IRF7 (616g)', '<f8'), ('IRF9_extended (358g)', '<f8'), ('IRF9 (302g)', '<f8'), ('MAFB_extended (39g)', '<f8'), ('NR1H3_extended (208g)',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:12180,deployability,Cluster,Clusterings,12180,"_(14g)', 'u1'), ('NR1D2_extended_(13g)', 'u1'), ('POU2F1_extended_(13g)', 'u1'), ('CLOCK_(13g)', 'u1'), ('CTCF_(13g)', 'u1'), ('MAFF_(13g)', 'u1'), ('POU2F1_(12g)', 'u1'), ('RUNX2_(12g)', 'u1'), ('SMAD3_(13g)', 'u1'), ('ETV5_extended_(12g)', 'u1'), ('FOXJ3_extended_(12g)', 'u1'), ('FOXN3_extended_(12g)', 'u1'), ('NFATC1_extended_(13g)', 'u1'), ('ELF4_(12g)', 'u1'), ('ETV1_(11g)', 'u1'), ('FOXP4_(11g)', 'u1'), ('SP2_(11g)', 'u1'), ('TCF3_(12g)', 'u1'), ('ZBTB41_(12g)', 'u1'), ('ZNF503_(12g)', 'u1'), ('HIVEP1_extended_(11g)', 'u1'), ('NPDC1_extended_(12g)', 'u1'), ('RXRB_extended_(11g)', 'u1'), ('FOXK2_(11g)', 'u1'), ('FOXM1_(11g)', 'u1'), ('HDAC1_(10g)', 'u1'), ('MELK_(11g)', 'u1'), ('RARA_(10g)', 'u1'), ('RXRB_(11g)', 'u1'), ('TP53_(10g)', 'u1'), ('ZNF260_(11g)', 'u1'), ('MEF2D_extended_(10g)', 'u1'), ('MLXIP_extended_(11g)', 'u1')] is not allowed. Column attribute 'CellID' dtype object is not allowed. Column attribute 'ClusterName' dtype object is not allowed. Column attribute 'Clusterings' dtype [('0', '<i4')] is not allowed. Column attribute 'Embedding' dtype [('_X', '<f8'), ('_Y', '<f8')] is not allowed. Column attribute 'Embeddings_X' dtype [('0', '<f8')] is not allowed. Column attribute 'Embeddings_Y' dtype [('0', '<f8')] is not allowed. Column attribute 'RegulonsAUC' dtype [('TBX21_extended (69g)', '<f8'), ('TBX21 (58g)', '<f8'), ('ELF1_extended (987g)', '<f8'), ('ELF1 (753g)', '<f8'), ('EOMES_extended (223g)', '<f8'), ('EOMES (168g)', '<f8'), ('RUNX3_extended (532g)', '<f8'), ('RUNX3 (414g)', '<f8'), ('PRDM1_extended (538g)', '<f8'), ('ETS1_extended (647g)', '<f8'), ('ETS1 (577g)', '<f8'), ('ZNF683_extended (75g)', '<f8'), ('IRF1_extended (662g)', '<f8'), ('IRF1 (617g)', '<f8'), ('JUN_extended (62g)', '<f8'), ('JUN (26g)', '<f8'), ('IRF7_extended (688g)', '<f8'), ('IRF7 (616g)', '<f8'), ('IRF9_extended (358g)', '<f8'), ('IRF9 (302g)', '<f8'), ('MAFB_extended (39g)', '<f8'), ('NR1H3_extended (208g)', '<f8'), ('NR1H3 (207g)', '<f8'), ('CEBPB_extended (1162g)',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:22916,deployability,version,version,22916,", '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('SMAD3 (13g)', '<f8'), ('CENPB (29g)', '<f8'), ('NFE2L3_extended (15g)', '<f8'), ('ZNF664 (18g)', '<f8'), ('TBX3_extended (32g)', '<f8'), ('MEF2D_extended (10g)', '<f8'), ('BATF3_extended (45g)', '<f8'), ('TCF7L2 (27g)', '<f8'), ('FOXJ3_extended (12g)', '<f8'), ('ATF6_extended (47g)', '<f8'), ('ZNF254 (15g)', '<f8'), ('E2F6_extended (37g)', '<f8'), ('ZBTB33 (19g)', '<f8'), ('MYEF2_extended (32g)', '<f8'), ('THAP1_extended (19g)', '<f8'), ('IRF5_extended (27g)', '<f8'), ('STAT5A_extended (24g)', '<f8'), ('NR1D2_extended (13g)', '<f8'), ('HIVEP1_extended (11g)', '<f8'), ('TCF3 (12g)', '<f8'), ('MELK (11g)', '<f8'), ('TP53 (10g)', '<f8'), ('ETV6_extended (56g)', '<f8'), ('POLE3_extended (54g)', '<f8'), ('ZBTB7B_extended (26g)', '<f8'), ('MAZ_extended (96g)', '<f8'), ('ARNTL2_extended (33g)', '<f8'), ('KLF16_extended (36g)', '<f8'), ('FOXK2 (11g)', '<f8'), ('TFEB_extended (128g)', '<f8'), ('TFEB (92g)', '<f8'), ('POU2AF1_extended (64g)', '<f8'), ('POU2AF1 (14g)', '<f8'), ('POU2F2_extended (78g)', '<f8'), ('POU2F2 (66g)', '<f8'), ('BCL11A_extended (207g)', '<f8'), ('BCL11A (142g)', '<f8'), ('ETV7_extended (90g)', '<f8'), ('ETV7 (63g)', '<f8'), ('STAT1_extended (1443g)', '<f8'), ('STAT1 (1212g)', '<f8'), ('IRF2_extended (196g)', '<f8'), ('IRF2 (179g)', '<f8'), ('STAT2_extended (287g)', '<f8'), ('STAT2 (234g)', '<f8')] is not allowed. For help, see http://linnarssonlab.org/loompy/format/. ./Thienpont_T-cell_v4_R_fixed.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:20411,energy efficiency,CLOCK,CLOCK,20411,"ded (38g)', '<f8'), ('TGIF2 (36g)', '<f8'), ('ESRRA_extended (34g)', '<f8'), ('ESRRA (27g)', '<f8'), ('POU2F1_extended (13g)', '<f8'), ('POU2F1 (12g)', '<f8'), ('RXRA_extended (107g)', '<f8'), ('RXRA (78g)', '<f8'), ('MAFG_extended (64g)', '<f8'), ('MAFG (25g)', '<f8'), ('SRF_extended (14g)', '<f8'), ('SRF (13g)', '<f8'), ('HIVEP2_extended (40g)', '<f8'), ('HIVEP2 (28g)', '<f8'), ('ZBTB41 (12g)', '<f8'), ('SETDB1_extended (46g)', '<f8'), ('SETDB1 (41g)', '<f8'), ('ETV3_extended (50g)', '<f8'), ('ETV3 (35g)', '<f8'), ('HSF1_extended (47g)', '<f8'), ('HSF1 (14g)', '<f8'), ('E2F3_extended (42g)', '<f8'), ('E2F3 (34g)', '<f8'), ('USF2_extended (41g)', '<f8'), ('USF2 (33g)', '<f8'), ('MYB_extended (68g)', '<f8'), ('MYB (63g)', '<f8'), ('CREB1_extended (81g)', '<f8'), ('CREB1 (61g)', '<f8'), ('MAX_extended (83g)', '<f8'), ('MAX (80g)', '<f8'), ('KLF12_extended (36g)', '<f8'), ('KLF12 (31g)', '<f8'), ('RFX5_extended (14g)', '<f8'), ('RFX5 (13g)', '<f8'), ('CLOCK_extended (52g)', '<f8'), ('CLOCK (13g)', '<f8'), ('SREBF2_extended (39g)', '<f8'), ('SREBF2 (38g)', '<f8'), ('ARNT_extended (52g)', '<f8'), ('ARNT (16g)', '<f8'), ('MLX_extended (53g)', '<f8'), ('MLX (21g)', '<f8'), ('SP2 (11g)', '<f8'), ('BACH1_extended (63g)', '<f8'), ('BACH1 (14g)', '<f8'), ('BHLHE40_extended (77g)', '<f8'), ('BHLHE40 (16g)', '<f8'), ('NFATC1_extended (13g)', '<f8'), ('NPDC1_extended (12g)', '<f8'), ('CREBZF (15g)', '<f8'), ('ZNF100 (15g)', '<f8'), ('PPARD_extended (52g)', '<f8'), ('PPARD (20g)', '<f8'), ('ELF4_extended (49g)', '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:578,integrability,version,version,578,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:641,integrability,api,api,641,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:888,integrability,api,api,888,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1780,integrability,version,version,1780,"lueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1963,integrability,version,version,1963,"nda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ('ETS1_(577g)', 'u1'), ('UQCRB_(573g)', 'u1'), ('PRDM1_extended_(538g)', 'u1'), ('RUNX3_e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:22916,integrability,version,version,22916,", '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('SMAD3 (13g)', '<f8'), ('CENPB (29g)', '<f8'), ('NFE2L3_extended (15g)', '<f8'), ('ZNF664 (18g)', '<f8'), ('TBX3_extended (32g)', '<f8'), ('MEF2D_extended (10g)', '<f8'), ('BATF3_extended (45g)', '<f8'), ('TCF7L2 (27g)', '<f8'), ('FOXJ3_extended (12g)', '<f8'), ('ATF6_extended (47g)', '<f8'), ('ZNF254 (15g)', '<f8'), ('E2F6_extended (37g)', '<f8'), ('ZBTB33 (19g)', '<f8'), ('MYEF2_extended (32g)', '<f8'), ('THAP1_extended (19g)', '<f8'), ('IRF5_extended (27g)', '<f8'), ('STAT5A_extended (24g)', '<f8'), ('NR1D2_extended (13g)', '<f8'), ('HIVEP1_extended (11g)', '<f8'), ('TCF3 (12g)', '<f8'), ('MELK (11g)', '<f8'), ('TP53 (10g)', '<f8'), ('ETV6_extended (56g)', '<f8'), ('POLE3_extended (54g)', '<f8'), ('ZBTB7B_extended (26g)', '<f8'), ('MAZ_extended (96g)', '<f8'), ('ARNTL2_extended (33g)', '<f8'), ('KLF16_extended (36g)', '<f8'), ('FOXK2 (11g)', '<f8'), ('TFEB_extended (128g)', '<f8'), ('TFEB (92g)', '<f8'), ('POU2AF1_extended (64g)', '<f8'), ('POU2AF1 (14g)', '<f8'), ('POU2F2_extended (78g)', '<f8'), ('POU2F2 (66g)', '<f8'), ('BCL11A_extended (207g)', '<f8'), ('BCL11A (142g)', '<f8'), ('ETV7_extended (90g)', '<f8'), ('ETV7 (63g)', '<f8'), ('STAT1_extended (1443g)', '<f8'), ('STAT1 (1212g)', '<f8'), ('IRF2_extended (196g)', '<f8'), ('IRF2 (179g)', '<f8'), ('STAT2_extended (287g)', '<f8'), ('STAT2 (234g)', '<f8')] is not allowed. For help, see http://linnarssonlab.org/loompy/format/. ./Thienpont_T-cell_v4_R_fixed.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:641,interoperability,api,api,641,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:888,interoperability,api,api,888,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:22809,interoperability,format,format,22809,", '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('SMAD3 (13g)', '<f8'), ('CENPB (29g)', '<f8'), ('NFE2L3_extended (15g)', '<f8'), ('ZNF664 (18g)', '<f8'), ('TBX3_extended (32g)', '<f8'), ('MEF2D_extended (10g)', '<f8'), ('BATF3_extended (45g)', '<f8'), ('TCF7L2 (27g)', '<f8'), ('FOXJ3_extended (12g)', '<f8'), ('ATF6_extended (47g)', '<f8'), ('ZNF254 (15g)', '<f8'), ('E2F6_extended (37g)', '<f8'), ('ZBTB33 (19g)', '<f8'), ('MYEF2_extended (32g)', '<f8'), ('THAP1_extended (19g)', '<f8'), ('IRF5_extended (27g)', '<f8'), ('STAT5A_extended (24g)', '<f8'), ('NR1D2_extended (13g)', '<f8'), ('HIVEP1_extended (11g)', '<f8'), ('TCF3 (12g)', '<f8'), ('MELK (11g)', '<f8'), ('TP53 (10g)', '<f8'), ('ETV6_extended (56g)', '<f8'), ('POLE3_extended (54g)', '<f8'), ('ZBTB7B_extended (26g)', '<f8'), ('MAZ_extended (96g)', '<f8'), ('ARNTL2_extended (33g)', '<f8'), ('KLF16_extended (36g)', '<f8'), ('FOXK2 (11g)', '<f8'), ('TFEB_extended (128g)', '<f8'), ('TFEB (92g)', '<f8'), ('POU2AF1_extended (64g)', '<f8'), ('POU2AF1 (14g)', '<f8'), ('POU2F2_extended (78g)', '<f8'), ('POU2F2 (66g)', '<f8'), ('BCL11A_extended (207g)', '<f8'), ('BCL11A (142g)', '<f8'), ('ETV7_extended (90g)', '<f8'), ('ETV7 (63g)', '<f8'), ('STAT1_extended (1443g)', '<f8'), ('STAT1 (1212g)', '<f8'), ('IRF2_extended (196g)', '<f8'), ('IRF2 (179g)', '<f8'), ('STAT2_extended (287g)', '<f8'), ('STAT2 (234g)', '<f8')] is not allowed. For help, see http://linnarssonlab.org/loompy/format/. ./Thienpont_T-cell_v4_R_fixed.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:578,modifiability,version,version,578,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:863,modifiability,modul,module,863,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1003,modifiability,pac,packages,1003," connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1285,modifiability,layer,layers,1285,"rized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'),",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1357,modifiability,pac,packages,1357," of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extend",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1666,modifiability,pac,packages,1666,"hienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_exten",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1780,modifiability,version,version,1780,"lueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1963,modifiability,version,version,1963,"nda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ('ETS1_(577g)', 'u1'), ('UQCRB_(573g)', 'u1'), ('PRDM1_extended_(538g)', 'u1'), ('RUNX3_e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:22916,modifiability,version,version,22916,", '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('SMAD3 (13g)', '<f8'), ('CENPB (29g)', '<f8'), ('NFE2L3_extended (15g)', '<f8'), ('ZNF664 (18g)', '<f8'), ('TBX3_extended (32g)', '<f8'), ('MEF2D_extended (10g)', '<f8'), ('BATF3_extended (45g)', '<f8'), ('TCF7L2 (27g)', '<f8'), ('FOXJ3_extended (12g)', '<f8'), ('ATF6_extended (47g)', '<f8'), ('ZNF254 (15g)', '<f8'), ('E2F6_extended (37g)', '<f8'), ('ZBTB33 (19g)', '<f8'), ('MYEF2_extended (32g)', '<f8'), ('THAP1_extended (19g)', '<f8'), ('IRF5_extended (27g)', '<f8'), ('STAT5A_extended (24g)', '<f8'), ('NR1D2_extended (13g)', '<f8'), ('HIVEP1_extended (11g)', '<f8'), ('TCF3 (12g)', '<f8'), ('MELK (11g)', '<f8'), ('TP53 (10g)', '<f8'), ('ETV6_extended (56g)', '<f8'), ('POLE3_extended (54g)', '<f8'), ('ZBTB7B_extended (26g)', '<f8'), ('MAZ_extended (96g)', '<f8'), ('ARNTL2_extended (33g)', '<f8'), ('KLF16_extended (36g)', '<f8'), ('FOXK2 (11g)', '<f8'), ('TFEB_extended (128g)', '<f8'), ('TFEB (92g)', '<f8'), ('POU2AF1_extended (64g)', '<f8'), ('POU2AF1 (14g)', '<f8'), ('POU2F2_extended (78g)', '<f8'), ('POU2F2 (66g)', '<f8'), ('BCL11A_extended (207g)', '<f8'), ('BCL11A (142g)', '<f8'), ('ETV7_extended (90g)', '<f8'), ('ETV7 (63g)', '<f8'), ('STAT1_extended (1443g)', '<f8'), ('STAT1 (1212g)', '<f8'), ('IRF2_extended (196g)', '<f8'), ('IRF2 (179g)', '<f8'), ('STAT2_extended (287g)', '<f8'), ('STAT2 (234g)', '<f8')] is not allowed. For help, see http://linnarssonlab.org/loompy/format/. ./Thienpont_T-cell_v4_R_fixed.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:509,performance,error,error,509,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1875,performance,error,errors,1875,"rt scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1511,reliability,fail,fails,1511," below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1900,reliability,doe,does,1900,"-> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ('ETS1_(577g)', 'u1'), (",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:22853,reliability,doe,does,22853,", '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('SMAD3 (13g)', '<f8'), ('CENPB (29g)', '<f8'), ('NFE2L3_extended (15g)', '<f8'), ('ZNF664 (18g)', '<f8'), ('TBX3_extended (32g)', '<f8'), ('MEF2D_extended (10g)', '<f8'), ('BATF3_extended (45g)', '<f8'), ('TCF7L2 (27g)', '<f8'), ('FOXJ3_extended (12g)', '<f8'), ('ATF6_extended (47g)', '<f8'), ('ZNF254 (15g)', '<f8'), ('E2F6_extended (37g)', '<f8'), ('ZBTB33 (19g)', '<f8'), ('MYEF2_extended (32g)', '<f8'), ('THAP1_extended (19g)', '<f8'), ('IRF5_extended (27g)', '<f8'), ('STAT5A_extended (24g)', '<f8'), ('NR1D2_extended (13g)', '<f8'), ('HIVEP1_extended (11g)', '<f8'), ('TCF3 (12g)', '<f8'), ('MELK (11g)', '<f8'), ('TP53 (10g)', '<f8'), ('ETV6_extended (56g)', '<f8'), ('POLE3_extended (54g)', '<f8'), ('ZBTB7B_extended (26g)', '<f8'), ('MAZ_extended (96g)', '<f8'), ('ARNTL2_extended (33g)', '<f8'), ('KLF16_extended (36g)', '<f8'), ('FOXK2 (11g)', '<f8'), ('TFEB_extended (128g)', '<f8'), ('TFEB (92g)', '<f8'), ('POU2AF1_extended (64g)', '<f8'), ('POU2AF1 (14g)', '<f8'), ('POU2F2_extended (78g)', '<f8'), ('POU2F2 (66g)', '<f8'), ('BCL11A_extended (207g)', '<f8'), ('BCL11A (142g)', '<f8'), ('ETV7_extended (90g)', '<f8'), ('ETV7 (63g)', '<f8'), ('STAT1_extended (1443g)', '<f8'), ('STAT1 (1212g)', '<f8'), ('IRF2_extended (196g)', '<f8'), ('IRF2 (179g)', '<f8'), ('STAT2_extended (287g)', '<f8'), ('STAT2 (234g)', '<f8')] is not allowed. For help, see http://linnarssonlab.org/loompy/format/. ./Thienpont_T-cell_v4_R_fixed.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:509,safety,error,error,509,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:837,safety,input,input-,837,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:863,safety,modul,module,863,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1410,safety,valid,validate,1410,"ython 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1449,safety,valid,validation,1449,"ata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1477,safety,except,exception,1477,".2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1500,safety,valid,validation,1500,"the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_exte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1575,safety,valid,validate,1575,"ersion? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'),",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1584,safety,valid,validate,1584,"hanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1726,safety,valid,validate,1726,"--------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1816,safety,valid,validate,1816," last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1875,safety,error,errors,1875,"rt scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1924,safety,valid,valid,1924,"npont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ('ETS1_(577g)', 'u1'), ('UQCRB_(573g)', 'u1'), ('",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:22877,safety,valid,valid,22877,", '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('SMAD3 (13g)', '<f8'), ('CENPB (29g)', '<f8'), ('NFE2L3_extended (15g)', '<f8'), ('ZNF664 (18g)', '<f8'), ('TBX3_extended (32g)', '<f8'), ('MEF2D_extended (10g)', '<f8'), ('BATF3_extended (45g)', '<f8'), ('TCF7L2 (27g)', '<f8'), ('FOXJ3_extended (12g)', '<f8'), ('ATF6_extended (47g)', '<f8'), ('ZNF254 (15g)', '<f8'), ('E2F6_extended (37g)', '<f8'), ('ZBTB33 (19g)', '<f8'), ('MYEF2_extended (32g)', '<f8'), ('THAP1_extended (19g)', '<f8'), ('IRF5_extended (27g)', '<f8'), ('STAT5A_extended (24g)', '<f8'), ('NR1D2_extended (13g)', '<f8'), ('HIVEP1_extended (11g)', '<f8'), ('TCF3 (12g)', '<f8'), ('MELK (11g)', '<f8'), ('TP53 (10g)', '<f8'), ('ETV6_extended (56g)', '<f8'), ('POLE3_extended (54g)', '<f8'), ('ZBTB7B_extended (26g)', '<f8'), ('MAZ_extended (96g)', '<f8'), ('ARNTL2_extended (33g)', '<f8'), ('KLF16_extended (36g)', '<f8'), ('FOXK2 (11g)', '<f8'), ('TFEB_extended (128g)', '<f8'), ('TFEB (92g)', '<f8'), ('POU2AF1_extended (64g)', '<f8'), ('POU2AF1 (14g)', '<f8'), ('POU2F2_extended (78g)', '<f8'), ('POU2F2 (66g)', '<f8'), ('BCL11A_extended (207g)', '<f8'), ('BCL11A (142g)', '<f8'), ('ETV7_extended (90g)', '<f8'), ('ETV7 (63g)', '<f8'), ('STAT1_extended (1443g)', '<f8'), ('STAT1 (1212g)', '<f8'), ('IRF2_extended (196g)', '<f8'), ('IRF2 (179g)', '<f8'), ('STAT2_extended (287g)', '<f8'), ('STAT2 (234g)', '<f8')] is not allowed. For help, see http://linnarssonlab.org/loompy/format/. ./Thienpont_T-cell_v4_R_fixed.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:43,security,team,team,43,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:136,security,session,session,136,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1410,security,validat,validate,1410,"ython 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1449,security,validat,validation,1449,"ata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1500,security,validat,validation,1500,"the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_exte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1575,security,validat,validate,1575,"ersion? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'),",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1584,security,validat,validate,1584,"hanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1726,security,validat,validate,1726,"--------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1816,security,validat,validate,1816," last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:793,testability,Trace,Traceback,793,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:263,usability,User,User,263,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:509,usability,error,error,509,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:610,usability,help,help,610,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:837,usability,input,input-,837,"trouble connecting to loom file; Hi scanpy team,. I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment. ```. loompy 2.0.15 <pip>. python 3.6.6 h5001a0f_0 conda-forge. anndata 0.6.11 <pip>. scanpy 1.3.2 <pip>. ```. Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr. ```. import scanpy.api as sc . sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-2-3e86e297513a> in <module>. 1 import scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:1875,usability,error,errors,1875,"rt scanpy.api as sc. ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names). 142 filename = fspath(filename) # allow passing pathlib.Path objects. 143 from loompy import connect. --> 144 with connect(filename, 'r') as lc:. 145 . 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version). 1151 Note: if validation is requested, an exception is raised if validation fails. 1152 	"""""". -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version). 82 lv = loompy.LoomValidator(version=spec_version). 83 if not lv.validate(filename):. ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""). 85 . 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed. Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/320:22767,usability,help,help,22767,", '<f8'), ('ELF4 (12g)', '<f8'), ('TEAD4 (33g)', '<f8'), ('NFIC (31g)', '<f8'), ('HDAC1 (10g)', '<f8'), ('CTCF (13g)', '<f8'), ('SMC3_extended (50g)', '<f8'), ('RAD21 (26g)', '<f8'), ('BRF1 (35g)', '<f8'), ('HINFP (16g)', '<f8'), ('MLXIP_extended (11g)', '<f8'), ('ATF6B_extended (61g)', '<f8'), ('ZNF260 (11g)', '<f8'), ('MEF2A (16g)', '<f8'), ('FOXK1_extended (22g)', '<f8'), ('FOXN3_extended (12g)', '<f8'), ('ASCL2_extended (16g)', '<f8'), ('MXI1_extended (23g)', '<f8'), ('SMAD3 (13g)', '<f8'), ('CENPB (29g)', '<f8'), ('NFE2L3_extended (15g)', '<f8'), ('ZNF664 (18g)', '<f8'), ('TBX3_extended (32g)', '<f8'), ('MEF2D_extended (10g)', '<f8'), ('BATF3_extended (45g)', '<f8'), ('TCF7L2 (27g)', '<f8'), ('FOXJ3_extended (12g)', '<f8'), ('ATF6_extended (47g)', '<f8'), ('ZNF254 (15g)', '<f8'), ('E2F6_extended (37g)', '<f8'), ('ZBTB33 (19g)', '<f8'), ('MYEF2_extended (32g)', '<f8'), ('THAP1_extended (19g)', '<f8'), ('IRF5_extended (27g)', '<f8'), ('STAT5A_extended (24g)', '<f8'), ('NR1D2_extended (13g)', '<f8'), ('HIVEP1_extended (11g)', '<f8'), ('TCF3 (12g)', '<f8'), ('MELK (11g)', '<f8'), ('TP53 (10g)', '<f8'), ('ETV6_extended (56g)', '<f8'), ('POLE3_extended (54g)', '<f8'), ('ZBTB7B_extended (26g)', '<f8'), ('MAZ_extended (96g)', '<f8'), ('ARNTL2_extended (33g)', '<f8'), ('KLF16_extended (36g)', '<f8'), ('FOXK2 (11g)', '<f8'), ('TFEB_extended (128g)', '<f8'), ('TFEB (92g)', '<f8'), ('POU2AF1_extended (64g)', '<f8'), ('POU2AF1 (14g)', '<f8'), ('POU2F2_extended (78g)', '<f8'), ('POU2F2 (66g)', '<f8'), ('BCL11A_extended (207g)', '<f8'), ('BCL11A (142g)', '<f8'), ('ETV7_extended (90g)', '<f8'), ('ETV7 (63g)', '<f8'), ('STAT1_extended (1443g)', '<f8'), ('STAT1 (1212g)', '<f8'), ('IRF2_extended (196g)', '<f8'), ('IRF2 (179g)', '<f8'), ('STAT2_extended (287g)', '<f8'), ('STAT2 (234g)', '<f8')] is not allowed. For help, see http://linnarssonlab.org/loompy/format/. ./Thienpont_T-cell_v4_R_fixed.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320
https://github.com/scverse/scanpy/issues/322:101,deployability,api,api,101,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:28,integrability,compon,components,28,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:101,integrability,api,api,101,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:208,integrability,compon,components,208,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:28,interoperability,compon,components,28,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:101,interoperability,api,api,101,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:208,interoperability,compon,components,208,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:28,modifiability,compon,components,28,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:208,modifiability,compon,components,208,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/322:268,usability,user,user-images,268,"Wrong axis label when using components argument in sc.pl.diffmap; Example:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.pp.neighbors(adata). sc.tl.diffmap(adata). sc.pl.diffmap(adata, components='1,2'). ```. gives the output:. ![image](https://user-images.githubusercontent.com/7300030/47364845-8c4ef700-d6da-11e8-81f2-47ff0eb6d38e.png). The axis labels should be DC1 and DC2. If running `sc.pl.diffmap(adata)` the axis labels are correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/322
https://github.com/scverse/scanpy/issues/323:214,availability,error,error,214,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:239,availability,error,error,239,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:21,deployability,fail,fails,21,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:410,deployability,modul,module,410,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:1142,deployability,Observ,Observations,1142,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:1424,deployability,Observ,Observations,1424,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:1243,interoperability,format,format,1243,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:48,modifiability,variab,variable,48,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:410,modifiability,modul,module,410,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:531,modifiability,pac,packages,531,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:785,modifiability,pac,packages,785,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:1061,modifiability,pac,packages,1061,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:1366,modifiability,Variab,Variables,1366,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:214,performance,error,error,214,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:239,performance,error,error,239,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:21,reliability,fail,fails,21,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:65,safety,test,test,65,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:214,safety,error,error,214,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:239,safety,error,error,239,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:383,safety,input,input-,383,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:410,safety,modul,module,410,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:58,testability,Simpl,Simple,58,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:65,testability,test,test,65,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:339,testability,Trace,Traceback,339,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:1142,testability,Observ,Observations,1142,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:1424,testability,Observ,Observations,1424,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:58,usability,Simpl,Simple,58,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:214,usability,error,error,214,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:239,usability,error,error,239,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/323:383,usability,input,input-,383,"Adding uns to a view fails if there is only one variable; Simple test case. ```. data = sc.read(""pbmc3k.h5ad""). logical_ar = data.var[""name""] == ""RER1"". df = data[:, logical_ar]. df.uns = data.uns # this causes an error . ```. Causes this error. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-8b2cadedfe9b> in <module>(). 1 l = data.var[""name""] == ""RER1"". 2 df = data[:, l]. ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value). 987 # here, we directly generate the copy. 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)). --> 989 self._init_as_actual(adata). 990 self._uns = value. 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode). 816 self._varm = BoundRecArr(varm, self, 'varm'). 817 . --> 818 self._check_dimensions(). 819 self._check_uniqueness(). 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key). 1692 raise ValueError('Observations annot. `obs` must have number of '. 1693 'rows of `X` ({}), but has {} rows.'. -> 1694 .format(self._n_obs, self._obs.shape[0])). 1695 if 'var' in key and len(self._var) != self._n_vars:. 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323
https://github.com/scverse/scanpy/issues/324:1239,availability,consist,consistent,1239,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:413,deployability,log,log,413,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:582,deployability,log,log,582,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:99,integrability,sub,subsetted,99,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:265,integrability,sub,subsetting,265,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:593,integrability,sub,subset,593,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:219,reliability,doe,does,219,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:413,safety,log,log,413,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:582,safety,log,log,582,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:413,security,log,log,413,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:582,security,log,log,582,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:413,testability,log,log,413,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:582,testability,log,log,582,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:1014,usability,user,user-images,1014,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:1118,usability,clear,clearly,1118,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:1202,usability,visual,visualisations,1202,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/324:1239,usability,consist,consistent,1239,"Differences between umap representations for `sc.pp.pca(adata, use_highly_variable=True)`, and HVG subsetted data; To elaborate a bit on my comment on pull request #284 that `sc.pp.pca(adata, use_highly_variable=True)` does not reproduce the same umap embedding as subsetting the genes. I have done the following:. ```. disp_filter = sc.pp.filter_genes_dispersion(adata.X, flavor='cell_ranger', n_top_genes=4000, log=False). adata_hvg = adata.copy(). adata_hvg = adata_hvg[:, disp_filter['gene_subset']]. sc.pp.filter_genes_dispersion(adata, flavor='cell_ranger', n_top_genes=4000, log=False, subset=False). sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pp.pca(adata_hvg, n_comps=50, svd_solver='arpack'). sc.pp.neighbors(adata_hvg). sc.tl.umap(adata_hvg). sc.pl.umap(adata, color='n_counts', use_raw=False). sc.pl.umap(adata_hvg, color='n_counts', use_raw=False). ```. The umap output is:. ![screen shot 2018-10-25 at 10 37 36](https://user-images.githubusercontent.com/13019956/47487680-29c53a80-d843-11e8-8535-de3c84f3a3b3.png). There is clearly a difference between the two cases also in the tsne, draw_graph and diffmap visualisations. Only pca seems to be consistent judging by eye.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324
https://github.com/scverse/scanpy/issues/325:12,availability,cluster,clustering,12,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:68,availability,cluster,clustering,68,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:126,availability,cluster,clustering,126,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:292,availability,cluster,cluster,292,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:551,availability,cluster,clustering-scanpy,551,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:611,availability,cluster,clustering,611,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:706,availability,cluster,clustering,706,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:800,availability,cluster,clustering,800,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1388,availability,avail,available,1388,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:12,deployability,cluster,clustering,12,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:68,deployability,cluster,clustering,68,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:126,deployability,cluster,clustering,126,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:292,deployability,cluster,cluster,292,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:335,deployability,api,api,335,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:551,deployability,cluster,clustering-scanpy,551,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:611,deployability,cluster,clustering,611,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:706,deployability,cluster,clustering,706,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:800,deployability,cluster,clustering,800,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:335,integrability,api,api,335,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1277,integrability,pub,published,1277,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1379,integrability,pub,publicly,1379,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:335,interoperability,api,api,335,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1770,interoperability,platform,platforms,1770,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:747,performance,time,time,747,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:967,performance,time,time,967,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1388,reliability,availab,available,1388,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1388,safety,avail,available,1388,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1047,security,modif,modify,1047,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1113,security,modif,modify,1113,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1388,security,availab,available,1388,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:651,usability,visual,visualized,651,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:832,usability,visual,visualisation,832,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/325:1682,usability,learn,learn,1682,"Reproducing clustering results for the 1.3 mln dataset; Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```. import scanpy.api as sc. sc.settings.verbosity = 2. adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') . sc.pp.recipe_zheng17(adata) . sc.pp.neighbors(adata) . sc.tl.louvain(adata) . adata.obs['louvain'].to_csv('clustering-scanpy.csv'). ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:. 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way? 2. If yes, how can one modify the code to ensure reproducibility? 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper? 4. If the answer to the previous question is no, could you make those results publicly available somewhere? I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325
https://github.com/scverse/scanpy/issues/326:39,energy efficiency,Current,Currently,39,"[Suggestion] Speed up test collection; Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326
https://github.com/scverse/scanpy/issues/326:22,safety,test,test,22,"[Suggestion] Speed up test collection; Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326
https://github.com/scverse/scanpy/issues/326:50,safety,test,test,50,"[Suggestion] Speed up test collection; Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326
https://github.com/scverse/scanpy/issues/326:179,safety,test,test,179,"[Suggestion] Speed up test collection; Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326
https://github.com/scverse/scanpy/issues/326:22,testability,test,test,22,"[Suggestion] Speed up test collection; Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326
https://github.com/scverse/scanpy/issues/326:50,testability,test,test,50,"[Suggestion] Speed up test collection; Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326
https://github.com/scverse/scanpy/issues/326:179,testability,test,test,179,"[Suggestion] Speed up test collection; Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326
https://github.com/scverse/scanpy/pull/327:148,deployability,depend,dependent,148,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:148,integrability,depend,dependent,148,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:233,interoperability,specif,specific,233,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:148,modifiability,depend,dependent,148,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:200,modifiability,paramet,parameter,200,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:83,performance,time,time,83,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:265,reliability,doe,doesn,265,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:9,safety,test,test,9,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:26,safety,Test,Test,26,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:126,safety,test,test,126,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:148,safety,depend,dependent,148,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:254,safety,test,testpaths,254,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:9,testability,test,test,9,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:26,testability,Test,Test,26,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:126,testability,test,test,126,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:148,testability,depend,dependent,148,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:254,testability,test,testpaths,254,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:292,testability,simpl,simpler,292,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:292,usability,simpl,simpler,292,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/pull/327:315,usability,close,close,315,"Speed up test collection; Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't  which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327
https://github.com/scverse/scanpy/issues/328:309,availability,error,error,309,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:51,deployability,integr,integration,51,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:734,energy efficiency,core,core,734,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:944,energy efficiency,core,core,944,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:1158,energy efficiency,core,core,1158,"her than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:1371,energy efficiency,core,core,1371,"a3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:1575,energy efficiency,core,core,1575,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2144,energy efficiency,adapt,adapted,2144,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:51,integrability,integr,integration,51,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2144,integrability,adapt,adapted,2144,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:51,interoperability,integr,integration,51,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2144,interoperability,adapt,adapted,2144,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:51,modifiability,integr,integration,51,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:475,modifiability,pac,packages,475,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:718,modifiability,pac,packages,718,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:928,modifiability,pac,packages,928,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:1142,modifiability,pac,packages,1142,"annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:1355,modifiability,pac,packages,1355,"ile ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:1559,modifiability,pac,packages,1559,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2144,modifiability,adapt,adapted,2144,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:309,performance,error,error,309,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:51,reliability,integr,integration,51,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:14,safety,input,input,14,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:219,safety,test,tested,219,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:309,safety,error,error,309,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2111,safety,test,test,2111,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2176,safety,test,test,2176,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2248,safety,input,input,2248,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:51,security,integr,integration,51,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:1924,security,hash,hashtable,1924,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2037,security,hash,hashtable,2037,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:51,testability,integr,integration,51,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:109,testability,understand,understand,109,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:219,testability,test,tested,219,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:322,testability,Trace,Traceback,322,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2111,testability,test,test,2111,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2176,testability,test,test,2176,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:14,usability,input,input,14,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:92,usability,document,documentation,92,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:309,usability,error,error,309,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:500,usability,tool,tools,500,"pl.paga_path: input?; Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`. I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```. Traceback (most recent call last):. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_hel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2217,usability,behavi,behavior,2217,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2248,usability,input,input,2248,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2346,usability,document,documentation,2346,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/328:2382,usability,help,help,2382,"a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path. idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[. File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__. return self._getitem_column(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column. return self._get_item_cache(key). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache. values = self._data.get(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get. loc = self.items.get_loc(item). File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'dpt_pseudotime'. ```. My test dataset was probably not an adapted one (I did not find any test to reproduce) but is it an expected behavior? Should we provide as input always a `adata` with `dpt_pseudotime`? Maybe it would be interesting to detail that in the documentation. Anything I can do to help there? Brnice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328
https://github.com/scverse/scanpy/issues/331:914,availability,error,error,914,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:135,deployability,fail,fails,135,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:466,interoperability,format,format,466,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:218,modifiability,pac,packages,218,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:914,performance,error,error,914,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:135,reliability,fail,fails,135,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:774,safety,input,input,774,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:780,safety,test,test,780,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:914,safety,error,error,914,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:780,testability,test,test,780,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:907,testability,simpl,simple,907,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:774,usability,input,input,774,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:907,usability,simpl,simple,907,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/331:914,usability,error,error,914,"ValueError: k must be between 1 and min(A.shape); I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```. /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors). 1768 . 1769 if k <= 0 or k >= min(n, m):. -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)). 1771 . 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066). ```. Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331
https://github.com/scverse/scanpy/issues/332:21,availability,error,error,21,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:32,availability,sli,slicing,32,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:41,availability,Sli,Slicing,41,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:69,availability,state,state,69,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:124,availability,sli,slice,124,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:152,availability,sli,sliced,152,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:469,availability,sli,slice,469,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:493,availability,sli,slice,493,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:506,availability,sli,slice,506,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:521,availability,sli,slice,521,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:574,availability,sli,slice,574,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1378,availability,sli,slice,1378,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:320,deployability,api,api,320,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:651,deployability,modul,module,651,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1452,deployability,modul,module,1452,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:69,integrability,state,state,69,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:320,integrability,api,api,320,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:320,interoperability,api,api,320,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:651,modifiability,modul,module,651,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:701,modifiability,pac,packages,701,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:830,modifiability,pac,packages,830,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:984,modifiability,pac,packages,984,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1110,modifiability,pac,packages,1110,"ting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1230,modifiability,pac,packages,1230,"nd X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1452,modifiability,modul,module,1452,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1502,modifiability,pac,packages,1502,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1631,modifiability,pac,packages,1631,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1785,modifiability,pac,packages,1785,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1911,modifiability,pac,packages,1911,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:2031,modifiability,pac,packages,2031,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:21,performance,error,error,21,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:32,reliability,sli,slicing,32,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:41,reliability,Sli,Slicing,41,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:124,reliability,sli,slice,124,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:152,reliability,sli,sliced,152,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:469,reliability,sli,slice,469,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:493,reliability,sli,slice,493,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:506,reliability,sli,slice,506,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:521,reliability,sli,slice,521,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:574,reliability,sli,slice,574,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1378,reliability,sli,slice,1378,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:21,safety,error,error,21,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:289,safety,Test,Test,289,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:651,safety,modul,module,651,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1452,safety,modul,module,1452,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:289,testability,Test,Test,289,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:587,testability,Trace,Traceback,587,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:1388,testability,Trace,Traceback,1388,"bject. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. ```. Should base.py, line 741 be a reference to _X rather than X?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/332:21,usability,error,error,21,"dimension flattening error when slicing; Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:. ```. import scanpy.api as sc. data = sc.read('example-dataset/data.h5ad'). >>> data.shape, data.X.shape, data._X.shape. ((2638, 1838), (2638, 1838), (2638, 1838)). >>> slice = data[0, :]. >>> slice.shape, slice.X.shape, slice._X.shape. ((1, 1838), (1838,), (1, 1838)). >>> slice[:, 0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view. X = self._adata_ref.X[self._oidx, self._vidx]. IndexError: too many indices for array. >>> slice[0]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__. return self._getitem_view(index). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view. return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__. self._init_as_view(X, oidx, vidx). File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view. self._init_X_as_view(). File ""/cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332
https://github.com/scverse/scanpy/issues/333:96,availability,error,error,96,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1949,availability,sli,sliced,1949,"raceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:54,deployability,updat,updating,54,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1021,deployability,modul,module,1021,"bplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 13",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:22,integrability,sub,subplots,22,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:117,integrability,sub,subplots,117,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:193,integrability,sub,subplots,193,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:709,interoperability,format,format,709,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:797,interoperability,format,format,797,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1051,interoperability,format,format,1051,"updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1153,interoperability,format,format,1153,"sis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1021,modifiability,modul,module,1021,"bplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 13",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1233,modifiability,pac,packages,1233,"_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 13",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1841,modifiability,pac,packages,1841,".png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_vi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:2088,modifiability,pac,packages,2088,"> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 751 shape = (. 752 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 753 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:2379,modifiability,pac,packages,2379,"ations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 751 shape = (. 752 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 753 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 754 ). 755 if np.isscalar(X):. ~\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 141 return 1. 142 else:. --> 143 return len(idx). TypeError: object of type 'numpy.int64' has no len().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:2452,modifiability,layer,layers,2452,"ations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 751 shape = (. 752 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 753 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 754 ). 755 if np.isscalar(X):. ~\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 141 return 1. 142 else:. --> 143 return len(idx). TypeError: object of type 'numpy.int64' has no len().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:2716,modifiability,pac,packages,2716,"ations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 751 shape = (. 752 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 753 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 754 ). 755 if np.isscalar(X):. ~\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 141 return 1. 142 else:. --> 143 return len(idx). TypeError: object of type 'numpy.int64' has no len().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:2961,modifiability,pac,packages,2961,"ations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 751 shape = (. 752 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 753 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 754 ). 755 if np.isscalar(X):. ~\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 141 return 1. 142 else:. --> 143 return len(idx). TypeError: object of type 'numpy.int64' has no len().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:3197,modifiability,pac,packages,3197,"ations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 751 shape = (. 752 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 753 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 754 ). 755 if np.isscalar(X):. ~\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 141 return 1. 142 else:. --> 143 return len(idx). TypeError: object of type 'numpy.int64' has no len().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:96,performance,error,error,96,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1949,reliability,sli,sliced,1949,"raceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1308 . 1309 # this is used in the setter for uns, if a view. ~\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 667 if not isinstance(X, AnnData):. 668 raise ValueError('`X` has to be an AnnData object.'). --> 669 self._init_as_view(X, oidx, vidx). 670 else:. 671 self._init_as_actual(. ~\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 724 self._X = None. 725 else:. --> 726 self._init_X_as_view(). 727 . 728 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\Anaconda3\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:54,safety,updat,updating,54,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:96,safety,error,error,96,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:995,safety,input,input-,995,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1021,safety,modul,module,1021,"bplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 13",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:54,security,updat,updating,54,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:951,testability,Trace,Traceback,951,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:96,usability,error,error,96,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:163,usability,mous,mouse,163,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:995,usability,input,input-,995,"Issue with paga paths subplots in scanpy 1.3.2; After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:. _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/issues/333:1258,usability,tool,tools,1258,"ft': 0.12}). pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2). for ipath, (descr, path) in enumerate(paths):. _, data = sc.pl.paga_path(. adata, path, gene_names_3, . show_node_names=False,. ax=axs[ipath],. ytick_fontsize=12,. left_margin=0.15,. n_avg=50,. annotations=['distance'],. show_yticks=True if ipath==0 else False,. show_colorbar=False,. color_map='Greys',. color_maps_annotations={'distance': 'viridis'},. title='{} path'.format(descr),. return_data=True,. show=False). #data.to_csv('./write/paga_path_{}.csv'.format(descr)). #pl.savefig('./figures/paga_path.png'). pl.show(). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-8-c59dfbccf885> in <module>(). 16 title='{} path'.format(descr),. 17 return_data=True,. ---> 18 show=False). 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)). 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 932 idcs = idcs[idcs_group]. 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]). --> 934 else: x += list(adata_X[:, key].X[idcs]). 935 if ikey == 0:. 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1301 def __getitem__(self, index):. 1302 """"""Returns a sliced view of the object."""""". -> 1303 return self._getitem_view(index). 1304 . 1305 def _getitem_view(self, index):. ~\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1305 def _getitem_view(self, index):. 1306 oidx, vidx = self._normalize_indices(index). -> 1307 return AnnData(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333
https://github.com/scverse/scanpy/pull/334:69,deployability,releas,releasing,69,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:85,deployability,version,version,85,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:206,deployability,version,version,206,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:263,deployability,Updat,Updated,263,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:460,deployability,version,version,460,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:831,deployability,Updat,Updated,831,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1033,deployability,version,version,1033,"outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:85,integrability,version,version,85,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:206,integrability,version,version,206,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:460,integrability,version,version,460,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:521,integrability,wrap,wraps,521,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:602,integrability,filter,filters,602,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1033,integrability,version,version,1033,"outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1128,integrability,wrap,wraps,1128,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1209,integrability,filter,filters,1209,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:135,interoperability,format,format,135,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:182,interoperability,compatib,compatible,182,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:412,interoperability,format,format,412,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:984,interoperability,format,format,984,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1670,interoperability,specif,specified,1670,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1948,interoperability,specif,specify,1948,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:85,modifiability,version,version,85,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:206,modifiability,version,version,206,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:460,modifiability,version,version,460,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1033,modifiability,version,version,1033,"outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1805,performance,time,time,1805,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:263,safety,Updat,Updated,263,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:476,safety,input,input,476,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:831,safety,Updat,Updated,831,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1051,safety,input,input,1051,"xwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1107,safety,input,input,1107,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1439,safety,test,test,1439,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1695,safety,input,input,1695,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:263,security,Updat,Updated,263,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:831,security,Updat,Updated,831,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1439,testability,test,test,1439,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1491,testability,verif,verify,1491,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:476,usability,input,input,476,"Let Scanpy read from Cell Ranger 3.0 outputs; Hi @falexwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1051,usability,input,input,1051,"xwolf,. 10X is releasing a new version of CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1107,usability,input,input,1107,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1511,usability,behavi,behavior,1511,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/pull/334:1695,usability,input,input,1695,"f CellRanger that is changing the output format. This pull request makes Scanpy forward compatible with the new version. In particular, the following changes are made:. Updated `read_10x_h5`:. - Renamed the original `read_10x_h5` as `_read_legacy_10x_h5`;. - Added `_read_v3_10x_h5` to read the new Cell Ranger output format;. - The new `read_10x_h5` determines the version of HDF5 input by the presence of the matrix key, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is True (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` and `genome` were added into the outcome object as new attributes. Updated `read_10x_mtx`:. - Renamed the original `read_10x_mtx` as `_read_legacy_10x_mtx`;. - Added `_read_v3_10x_mtx` to read the new Cell Ranger output format;. - The new `read_10x_mtx` determines the version of matrix input by the presence of the `genes.tsv` file under the input directory, and wraps the above two functions. In addition, it takes a `gex_only` argument which filters out feature barcoding counts from the outcome object when it is `True` (default). Otherwise, the full matrix will be retained. - For CR-v3, `feature_types` was added into the outcome object as a new attribute. Added small test datasets and code for the revised functions to verify the expected behavior. Note for the `genome` argument:. - There is a genome argument in Scanpy's `read_10x_h5` function but not in `read_10x_mtx` as the genome was already specified by the path of input directory. The outcome object of the two functions should be the same which always take one genome at a time. - In this PR, when there are multiple genomes (e.g. Barnyard), `read_10x_mtx` always read them all, whereas `read_10x_h5` always need to specify one of them (mm10 by default). However, when `gex_only == False`, the `genome` argument will be ignored and the whole matrix will be read.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/334
https://github.com/scverse/scanpy/issues/335:184,performance,cach,cached,184,legend position export; The previous `sc.pl.umap` etc. had an option to export legend positions via 'on data export'. We need a solution in the docs... Presumably just by exposing the cached positions to the user.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/335
https://github.com/scverse/scanpy/issues/335:171,security,expos,exposing,171,legend position export; The previous `sc.pl.umap` etc. had an option to export legend positions via 'on data export'. We need a solution in the docs... Presumably just by exposing the cached positions to the user.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/335
https://github.com/scverse/scanpy/issues/335:208,usability,user,user,208,legend position export; The previous `sc.pl.umap` etc. had an option to export legend positions via 'on data export'. We need a solution in the docs... Presumably just by exposing the cached positions to the user.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/335
https://github.com/scverse/scanpy/issues/336:121,availability,cluster,cluster,121,"mean expression and percentage; Dear,. Is there a function that returns mean expression and percentage of each gene in a cluster ? scanpy.api.pl.dotplot() includes these information implicitly, so perhaps it's the easiest way to return a table, not only the plot. By the way, can the plots generated by scanpy be saved as vector graph ? Now the cell points on the plot are not in vector graph format and will be mosaic when amplified, though the letters and axes are in vector format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336
https://github.com/scverse/scanpy/issues/336:121,deployability,cluster,cluster,121,"mean expression and percentage; Dear,. Is there a function that returns mean expression and percentage of each gene in a cluster ? scanpy.api.pl.dotplot() includes these information implicitly, so perhaps it's the easiest way to return a table, not only the plot. By the way, can the plots generated by scanpy be saved as vector graph ? Now the cell points on the plot are not in vector graph format and will be mosaic when amplified, though the letters and axes are in vector format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336
https://github.com/scverse/scanpy/issues/336:138,deployability,api,api,138,"mean expression and percentage; Dear,. Is there a function that returns mean expression and percentage of each gene in a cluster ? scanpy.api.pl.dotplot() includes these information implicitly, so perhaps it's the easiest way to return a table, not only the plot. By the way, can the plots generated by scanpy be saved as vector graph ? Now the cell points on the plot are not in vector graph format and will be mosaic when amplified, though the letters and axes are in vector format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336
https://github.com/scverse/scanpy/issues/336:138,integrability,api,api,138,"mean expression and percentage; Dear,. Is there a function that returns mean expression and percentage of each gene in a cluster ? scanpy.api.pl.dotplot() includes these information implicitly, so perhaps it's the easiest way to return a table, not only the plot. By the way, can the plots generated by scanpy be saved as vector graph ? Now the cell points on the plot are not in vector graph format and will be mosaic when amplified, though the letters and axes are in vector format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336
https://github.com/scverse/scanpy/issues/336:138,interoperability,api,api,138,"mean expression and percentage; Dear,. Is there a function that returns mean expression and percentage of each gene in a cluster ? scanpy.api.pl.dotplot() includes these information implicitly, so perhaps it's the easiest way to return a table, not only the plot. By the way, can the plots generated by scanpy be saved as vector graph ? Now the cell points on the plot are not in vector graph format and will be mosaic when amplified, though the letters and axes are in vector format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336
https://github.com/scverse/scanpy/issues/336:393,interoperability,format,format,393,"mean expression and percentage; Dear,. Is there a function that returns mean expression and percentage of each gene in a cluster ? scanpy.api.pl.dotplot() includes these information implicitly, so perhaps it's the easiest way to return a table, not only the plot. By the way, can the plots generated by scanpy be saved as vector graph ? Now the cell points on the plot are not in vector graph format and will be mosaic when amplified, though the letters and axes are in vector format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336
https://github.com/scverse/scanpy/issues/336:477,interoperability,format,format,477,"mean expression and percentage; Dear,. Is there a function that returns mean expression and percentage of each gene in a cluster ? scanpy.api.pl.dotplot() includes these information implicitly, so perhaps it's the easiest way to return a table, not only the plot. By the way, can the plots generated by scanpy be saved as vector graph ? Now the cell points on the plot are not in vector graph format and will be mosaic when amplified, though the letters and axes are in vector format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336
https://github.com/scverse/scanpy/issues/338:464,testability,context,context,464,"Getting rankinged genes in list, e.g. from sc.pl.rankings; I'm looking in to sc.pl.pca_loadings and sc.pl.rankings. I want to retrieve the list of highest scoring genes for my pcs. However both these methods are designed for plotting and rankings is a bit hard to interpret. Is there or could there be a nice way to retrieve list of rankings in the same way as sc.pl.rankings is doing it but get the list rather than a figure? How would I go about this within the context of scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/338
https://github.com/scverse/scanpy/issues/339:295,deployability,api,api,295,"Aspect ratio of scatter plots; Is there a way to set the aspect ratio of scatter plots in scanpy? For me, the aspect ratio changes in ways that I cannot fully control. For instance, in the following example the aspect ratio of a PCA plot is changed when I set the dpi:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.tl.pca(adata, svd_solver='arpack'). ```. ```python. sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845493-808fbe80-ddc5-11e8-8e69-30bf9b37803a.png). ```python. sc.set_figure_params(dpi=80). sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845511-8c7b8080-ddc5-11e8-81a5-90ac2af77cba.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/339
https://github.com/scverse/scanpy/issues/339:295,integrability,api,api,295,"Aspect ratio of scatter plots; Is there a way to set the aspect ratio of scatter plots in scanpy? For me, the aspect ratio changes in ways that I cannot fully control. For instance, in the following example the aspect ratio of a PCA plot is changed when I set the dpi:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.tl.pca(adata, svd_solver='arpack'). ```. ```python. sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845493-808fbe80-ddc5-11e8-8e69-30bf9b37803a.png). ```python. sc.set_figure_params(dpi=80). sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845511-8c7b8080-ddc5-11e8-81a5-90ac2af77cba.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/339
https://github.com/scverse/scanpy/issues/339:295,interoperability,api,api,295,"Aspect ratio of scatter plots; Is there a way to set the aspect ratio of scatter plots in scanpy? For me, the aspect ratio changes in ways that I cannot fully control. For instance, in the following example the aspect ratio of a PCA plot is changed when I set the dpi:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.tl.pca(adata, svd_solver='arpack'). ```. ```python. sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845493-808fbe80-ddc5-11e8-8e69-30bf9b37803a.png). ```python. sc.set_figure_params(dpi=80). sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845511-8c7b8080-ddc5-11e8-81a5-90ac2af77cba.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/339
https://github.com/scverse/scanpy/issues/339:159,security,control,control,159,"Aspect ratio of scatter plots; Is there a way to set the aspect ratio of scatter plots in scanpy? For me, the aspect ratio changes in ways that I cannot fully control. For instance, in the following example the aspect ratio of a PCA plot is changed when I set the dpi:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.tl.pca(adata, svd_solver='arpack'). ```. ```python. sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845493-808fbe80-ddc5-11e8-8e69-30bf9b37803a.png). ```python. sc.set_figure_params(dpi=80). sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845511-8c7b8080-ddc5-11e8-81a5-90ac2af77cba.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/339
https://github.com/scverse/scanpy/issues/339:159,testability,control,control,159,"Aspect ratio of scatter plots; Is there a way to set the aspect ratio of scatter plots in scanpy? For me, the aspect ratio changes in ways that I cannot fully control. For instance, in the following example the aspect ratio of a PCA plot is changed when I set the dpi:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.tl.pca(adata, svd_solver='arpack'). ```. ```python. sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845493-808fbe80-ddc5-11e8-8e69-30bf9b37803a.png). ```python. sc.set_figure_params(dpi=80). sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845511-8c7b8080-ddc5-11e8-81a5-90ac2af77cba.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/339
https://github.com/scverse/scanpy/issues/339:431,usability,user,user-images,431,"Aspect ratio of scatter plots; Is there a way to set the aspect ratio of scatter plots in scanpy? For me, the aspect ratio changes in ways that I cannot fully control. For instance, in the following example the aspect ratio of a PCA plot is changed when I set the dpi:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.tl.pca(adata, svd_solver='arpack'). ```. ```python. sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845493-808fbe80-ddc5-11e8-8e69-30bf9b37803a.png). ```python. sc.set_figure_params(dpi=80). sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845511-8c7b8080-ddc5-11e8-81a5-90ac2af77cba.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/339
https://github.com/scverse/scanpy/issues/339:606,usability,user,user-images,606,"Aspect ratio of scatter plots; Is there a way to set the aspect ratio of scatter plots in scanpy? For me, the aspect ratio changes in ways that I cannot fully control. For instance, in the following example the aspect ratio of a PCA plot is changed when I set the dpi:. ```python. import scanpy.api as sc. adata = sc.datasets.blobs(). sc.tl.pca(adata, svd_solver='arpack'). ```. ```python. sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845493-808fbe80-ddc5-11e8-8e69-30bf9b37803a.png). ```python. sc.set_figure_params(dpi=80). sc.pl.pca(adata). ```. ![image](https://user-images.githubusercontent.com/7300030/47845511-8c7b8080-ddc5-11e8-81a5-90ac2af77cba.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/339
https://github.com/scverse/scanpy/pull/340:156,deployability,api,api,156,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:291,deployability,version,version,291,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:955,deployability,scale,scale,955,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:281,energy efficiency,optim,optimized,281,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:388,energy efficiency,CPU,CPU,388,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:544,energy efficiency,alloc,allocations,544,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:819,energy efficiency,profil,profiles,819,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:901,energy efficiency,current,current,901,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:955,energy efficiency,scale,scale,955,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:156,integrability,api,api,156,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:291,integrability,version,version,291,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:642,integrability,sub,subsampling,642,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:156,interoperability,api,api,156,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:1076,interoperability,distribut,distribution,1076,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:291,modifiability,version,version,291,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:955,modifiability,scal,scale,955,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:211,performance,time,time,211,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:281,performance,optimiz,optimized,281,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:344,performance,time,time,344,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:388,performance,CPU,CPU,388,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:392,performance,time,times,392,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:446,performance,time,time,446,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:819,performance,profil,profiles,819,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:955,performance,scale,scale,955,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:567,safety,test,test,567,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:567,testability,test,test,567,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:399,usability,user,user,399,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:624,usability,indicat,indicates,624,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/pull/340:909,usability,behavi,behavior,909,"Speed up `downsample_counts`; On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python. import scanpy.api as sc. adata = sc.read(""./data/pbmc3k_raw.h5ad""). %time sc.pp.downsample_counts(adata, 1500). ```. This PR implements an optimized version of the same thing, which gives:. ```python. %time sc.pp.downsample_counts(adata, 1500) . CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s. Wall time: 2.32 s. ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations. * Added a test for the function. * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340
https://github.com/scverse/scanpy/issues/341:31,integrability,compon,components,31,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/341:115,integrability,compon,components,115,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/341:31,interoperability,compon,components,31,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/341:115,interoperability,compon,components,115,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/341:31,modifiability,compon,components,31,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/341:115,modifiability,compon,components,115,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/341:0,testability,regress,regress,0,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/341:192,testability,regress,regress-out,192,regress out unwanted principal components.; I'm preprocessing a dataset and want to regress_out selected principal components. Is there a built in way in scanpy for this task. Some way to use regress-out to accomplish this?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/341
https://github.com/scverse/scanpy/issues/342:214,availability,error,error,214,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:460,availability,error,error,460,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:642,deployability,version,version,642,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:719,deployability,contain,contain,719,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:624,energy efficiency,Current,Currently,624,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:642,integrability,version,version,642,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:17,modifiability,layer,layers,17,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:307,modifiability,layer,layers,307,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:510,modifiability,layer,layers,510,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:642,modifiability,version,version,642,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:733,modifiability,layer,layers,733,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:214,performance,error,error,214,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:460,performance,error,error,460,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:315,reliability,doe,doesn,315,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:703,reliability,doe,doesn,703,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:179,safety,input,input,179,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:214,safety,error,error,214,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:460,safety,error,error,460,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:179,usability,input,input,179,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:214,usability,error,error,214,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/issues/342:460,usability,error,error,460,"How to add adata.layers information for running scvelo?; Hi,. I'm attempting to run scvelo on my scanpy processed 10x data. Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file. I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'. I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo). My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342
https://github.com/scverse/scanpy/pull/343:45,deployability,updat,updated,45,"Hvg; Added test for filter_genes_dispersion, updated docs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343
https://github.com/scverse/scanpy/pull/343:11,safety,test,test,11,"Hvg; Added test for filter_genes_dispersion, updated docs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343
https://github.com/scverse/scanpy/pull/343:45,safety,updat,updated,45,"Hvg; Added test for filter_genes_dispersion, updated docs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343
https://github.com/scverse/scanpy/pull/343:45,security,updat,updated,45,"Hvg; Added test for filter_genes_dispersion, updated docs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343
https://github.com/scverse/scanpy/pull/343:11,testability,test,test,11,"Hvg; Added test for filter_genes_dispersion, updated docs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343
https://github.com/scverse/scanpy/issues/344:270,availability,error,error,270,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:154,deployability,API,API,154,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:174,deployability,updat,updating,174,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:394,deployability,version,versions,394,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:585,deployability,releas,releasing,585,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:633,deployability,version,version,633,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:323,energy efficiency,heat,heatmap,323,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:641,energy efficiency,current,currently,641,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:154,integrability,API,API,154,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:394,integrability,version,versions,394,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:633,integrability,version,version,633,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:154,interoperability,API,API,154,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:394,modifiability,version,versions,394,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:625,modifiability,pac,package,625,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:633,modifiability,version,version,633,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:270,performance,error,error,270,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:174,safety,updat,updating,174,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:270,safety,error,error,270,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:174,security,updat,updating,174,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:218,security,access,access,218,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:577,testability,plan,plan,577,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:136,usability,document,documented,136,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:270,usability,error,error,270,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/344:500,usability,learn,learn,500,"Dendrogram feature; It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:. `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:. scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344
https://github.com/scverse/scanpy/issues/345:90,integrability,sub,subtle,90,"Reproducibility of tSNE; I am having issues with the reproducibility of tSNE but they are subtle. This might be a duplicate of #203. . Here is an example notebook: http://nbviewer.jupyter.org/gist/fabianrost84/5839b9d913de7560339d9251d1a49dae. In the notebook, the first tSNE plot is different from the second. Interestingly, the second and the third tSNE plot are exactly the same. To reproduce the behaviour it is important to restart the kernel and then run all cells. If you run all cells again without restarting the kernel, all tSNE plot look the same for me. I only have this issue if I use the MulticoreTSNE package.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/345
https://github.com/scverse/scanpy/issues/345:616,modifiability,pac,package,616,"Reproducibility of tSNE; I am having issues with the reproducibility of tSNE but they are subtle. This might be a duplicate of #203. . Here is an example notebook: http://nbviewer.jupyter.org/gist/fabianrost84/5839b9d913de7560339d9251d1a49dae. In the notebook, the first tSNE plot is different from the second. Interestingly, the second and the third tSNE plot are exactly the same. To reproduce the behaviour it is important to restart the kernel and then run all cells. If you run all cells again without restarting the kernel, all tSNE plot look the same for me. I only have this issue if I use the MulticoreTSNE package.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/345
https://github.com/scverse/scanpy/issues/345:400,usability,behavi,behaviour,400,"Reproducibility of tSNE; I am having issues with the reproducibility of tSNE but they are subtle. This might be a duplicate of #203. . Here is an example notebook: http://nbviewer.jupyter.org/gist/fabianrost84/5839b9d913de7560339d9251d1a49dae. In the notebook, the first tSNE plot is different from the second. Interestingly, the second and the third tSNE plot are exactly the same. To reproduce the behaviour it is important to restart the kernel and then run all cells. If you run all cells again without restarting the kernel, all tSNE plot look the same for me. I only have this issue if I use the MulticoreTSNE package.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/345
https://github.com/scverse/scanpy/issues/346:164,availability,error,error,164,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:653,availability,error,error,653,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:164,performance,error,error,164,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:653,performance,error,error,653,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:145,safety,test,testing,145,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:164,safety,error,error,164,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:653,safety,error,error,653,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:145,testability,test,testing,145,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:164,usability,error,error,164,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/346:653,usability,error,error,653,"Differential Expression with a fixed reference; When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb. 91 groups_order = [str(n) for n in groups_order]. 92 if reference != 'rest' and reference not in set(groups_order):. ---> 93 groups_order += [reference]. 94 if (reference != 'rest'. 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list. ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346
https://github.com/scverse/scanpy/issues/347:11,availability,cluster,cluster,11,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:39,availability,cluster,clustering,39,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:92,availability,cluster,clustering,92,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:142,availability,cluster,clustering,142,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:174,availability,cluster,cluster,174,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:249,availability,cluster,cluster,249,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:418,availability,cluster,clustering,418,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:11,deployability,cluster,cluster,11,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:39,deployability,cluster,clustering,39,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:92,deployability,cluster,clustering,92,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:142,deployability,cluster,clustering,142,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:174,deployability,cluster,cluster,174,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:249,deployability,cluster,cluster,249,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:418,deployability,cluster,clustering,418,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:7,integrability,sub,sub-cluster,7,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:158,interoperability,specif,specific,158,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:560,reliability,Doe,Doesn,560,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/347:201,security,ident,identified,201,"Adding sub-cluster to original Louvain clustering; Hi there,. I tried to refine the Louvain clustering results and in particular I re-ran the clustering on a specific bigger cluster that was initially identified. . After this analysis, the original cluster was split in two and this makes sense considering the biological system we are studying. What is the easiest way to add this information to the original Louvain clustering results? . My naive approach of using something like:. ```adata.obs.louvain[adata.obs.index.isin(adata_sub.obs.index)] = '10' ```. Doesn't seem to be the correct one? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/347
https://github.com/scverse/scanpy/issues/348:120,availability,error,errors,120,"sc.pl.violin not making multipanels; Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348
https://github.com/scverse/scanpy/issues/348:333,interoperability,specif,specific,333,"sc.pl.violin not making multipanels; Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348
https://github.com/scverse/scanpy/issues/348:120,performance,error,errors,120,"sc.pl.violin not making multipanels; Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348
https://github.com/scverse/scanpy/issues/348:120,safety,error,errors,120,"sc.pl.violin not making multipanels; Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348
https://github.com/scverse/scanpy/issues/348:99,usability,command,command,99,"sc.pl.violin not making multipanels; Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348
https://github.com/scverse/scanpy/issues/348:120,usability,error,errors,120,"sc.pl.violin not making multipanels; Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348
https://github.com/scverse/scanpy/issues/349:325,deployability,scale,scale,325,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:32,energy efficiency,heat,heatmap,32,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:325,energy efficiency,scale,scale,325,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:517,energy efficiency,heat,heatmap,517,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:813,energy efficiency,heat,heatmap,813,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:495,interoperability,format,format,495,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:325,modifiability,scal,scale,325,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:325,performance,scale,scale,325,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:234,security,rotat,rotated,234,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/349:99,usability,visual,visualization,99,Figures related to rankings and heatmap could be transposed.; These are some suggestions regarding visualization defaults. Working with the ranknings plot i realized that it would be much easier to read if the figure where transposed/rotated so that gene names could be read per line rather than per columns. This would also scale better if one wishes to plot more than 10-30 genes. There is no inherent information on the y axis that could not be layed out on the x axis. I also ran in to this format when using the heatmap plotting. Gene names are on the columns rather than rows resulting in a thin matrix and hard to read gene names. As the figure is constructed by using several axis one could transpose the figure having the gene names to the right colorbar on the right and groupings below or ontop of the heatmap. As one is most interested in a dendrogram on the cells (I think?) it could get a nice space on top.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349
https://github.com/scverse/scanpy/issues/350:0,availability,Cluster,Clustering,0,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1766,availability,cluster,clustering,1766,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:0,deployability,Cluster,Clustering,0,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1745,deployability,fail,fails,1745,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1766,deployability,cluster,clustering,1766,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1576,modifiability,paramet,parameter,1576,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:373,performance,network,network,373,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1704,performance,perform,performed,1704,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1745,reliability,fail,fails,1745,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:571,safety,test,testing,571,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:126,security,auth,author,126,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:310,security,modif,modification,310,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:373,security,network,network,373,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:469,security,ident,identical,469,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1659,security,control,control,1659,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:571,testability,test,testing,571,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1659,testability,control,control,1659,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:419,usability,support,support,419,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:544,usability,minim,minimal,544,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1539,usability,support,support,1539,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/350:1704,usability,perform,performed,1704,"Clustering with leidenalg; Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py. import leidenalg. import numpy as np. import pandas as pd. from scanpy import utils. from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):. 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True). 	weights = None. 	if use_weights:. 		weights = np.array(g.es[""weight""]).astype(np.float64). 	part = leidenalg.find_partition(. 		g, leidenalg.RBConfigurationVertexPartition, . 		resolution_parameter = resolution, weights = weights, . 		n_iterations = iterations,. 	). 	groups = np.array(part.membership). 	adata.obs['louvain'] = pd.Categorical(. 		values=groups.astype('U'),. 		categories=natsorted(np.unique(groups).astype('U')),. 	). ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350
https://github.com/scverse/scanpy/issues/351:92,performance,multiplex,multiplexed,92,Interest in HTO/ADT demultiplexing and analysis?; I'm starting to regularly analyze samples multiplexed with HTOs a la [Stoeckius et al](https://www.biorxiv.org/content/early/2017/12/21/237693) and multimodal CITE-seq ADTs. I have some rough ports of Seurat's `HTODemux` and some other functionality. . Is anyone else analyzing these kinds of experiments using scanpy and is there interest to bring functionality to do so into the main scanpy branch?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351
https://github.com/scverse/scanpy/issues/351:161,performance,content,content,161,Interest in HTO/ADT demultiplexing and analysis?; I'm starting to regularly analyze samples multiplexed with HTOs a la [Stoeckius et al](https://www.biorxiv.org/content/early/2017/12/21/237693) and multimodal CITE-seq ADTs. I have some rough ports of Seurat's `HTODemux` and some other functionality. . Is anyone else analyzing these kinds of experiments using scanpy and is there interest to bring functionality to do so into the main scanpy branch?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351
https://github.com/scverse/scanpy/issues/352:345,reliability,doe,doesn,345,"Rearranging adata.obs; The indices of adata.obs are the barcodes to the cells. I've calculated adata.obsm['X_umap'], but I want to rearrange the barcodes so that the adata.obsm['X_umap'] array will still correspond to the barcodes afterward. However, after sorting the indices based on sort_value or sort_indices, the adata.obsm['X_umap'] array doesn't change along with it. . Any thoughts on how to properly go about this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/352
https://github.com/scverse/scanpy/issues/353:249,availability,down,downstream,249,"Removing specific genes from the data before normalization; I want to remove mitochondrial genes from the data before normalization. I already have used mitochondrial genes to calculate ""pct_counts_mito"", but I don't want them to be in the data for downstream analysis. Is there a function to achieve this in scanpy.api? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/353
https://github.com/scverse/scanpy/issues/353:316,deployability,api,api,316,"Removing specific genes from the data before normalization; I want to remove mitochondrial genes from the data before normalization. I already have used mitochondrial genes to calculate ""pct_counts_mito"", but I don't want them to be in the data for downstream analysis. Is there a function to achieve this in scanpy.api? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/353
https://github.com/scverse/scanpy/issues/353:316,integrability,api,api,316,"Removing specific genes from the data before normalization; I want to remove mitochondrial genes from the data before normalization. I already have used mitochondrial genes to calculate ""pct_counts_mito"", but I don't want them to be in the data for downstream analysis. Is there a function to achieve this in scanpy.api? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/353
https://github.com/scverse/scanpy/issues/353:9,interoperability,specif,specific,9,"Removing specific genes from the data before normalization; I want to remove mitochondrial genes from the data before normalization. I already have used mitochondrial genes to calculate ""pct_counts_mito"", but I don't want them to be in the data for downstream analysis. Is there a function to achieve this in scanpy.api? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/353
https://github.com/scverse/scanpy/issues/353:316,interoperability,api,api,316,"Removing specific genes from the data before normalization; I want to remove mitochondrial genes from the data before normalization. I already have used mitochondrial genes to calculate ""pct_counts_mito"", but I don't want them to be in the data for downstream analysis. Is there a function to achieve this in scanpy.api? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/353
https://github.com/scverse/scanpy/issues/355:372,availability,down,downloaded,372,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3473,availability,error,error,3473,"src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11863,availability,error,error,11863,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11969,availability,avail,available,11969,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12065,availability,error,error,12065,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6,deployability,instal,install,6,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:120,deployability,contain,container,120,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:202,deployability,updat,update,202,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:220,deployability,instal,install,220,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:289,deployability,instal,install,289,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:355,deployability,depend,dependencies,355,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:660,deployability,modul,module,660,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:684,deployability,build,build-,684,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:730,deployability,modul,module,730,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1155,deployability,build,build,1155,"buntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1403,deployability,build,build,1403,"st_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1671,deployability,build,build-,1671,"""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str impl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1693,deployability,version,versioneer,1693,"/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . --------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2726,deployability,Fail,Failed,2726,"build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2733,deployability,build,building,2733,".run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3147,deployability,Fail,Failed,3147,"et_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3157,deployability,build,build,3157,"les(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3171,deployability,Instal,Installing,3171,"r/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3450,deployability,instal,install,3450,"d_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3580,deployability,build,build-,3580,". + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3717,deployability,instal,install,3717,"---. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> bui",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3759,deployability,instal,install-record,3759,"g setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3787,deployability,version,version-externally-managed,3787,"ng setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3957,deployability,instal,install,3957,"etup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/prepro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3974,deployability,build,build,3974,"eel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4008,deployability,build,build,4008,"in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py ->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4024,deployability,build,build,4024,"oot/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4044,deployability,build,build,4044,"s/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. cre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4092,deployability,build,build,4092,"4897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4141,deployability,build,build,4141,"x. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4189,deployability,build,build,4189,"packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4237,deployability,build,build,4237,"das, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4282,deployability,build,build,4282,", cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4315,deployability,log,logging,4315,"seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4329,deployability,build,build,4329,"xpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4378,deployability,build,build,4378,"corator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4405,deployability,build,build,4405,"llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4480,deployability,build,build,4480,"plete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/ap",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4569,deployability,build,build,4569,"tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4645,deployability,build,build,4645,"', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/querie",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4718,deployability,build,build,4718,all --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4789,deployability,build,build,4789,on-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4868,deployability,build,build,4868,rWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4938,deployability,build,build,4938,n(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5012,deployability,build,build,5012,creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_g,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5053,deployability,build,build,5053,anpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copyin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5119,deployability,build,build,5119,py/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5197,deployability,build,build,5197,canpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5233,deployability,build,build,5233, build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5297,deployability,build,build,5297,copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5332,deployability,build,build,5332,lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5349,deployability,api,api,5349,ing scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. cop,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5369,deployability,api,api,5369,.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/pa,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5388,deployability,build,build,5388,npy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5405,deployability,api,api,5405,ild/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. cop,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5425,deployability,api,api,5425,ocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5444,deployability,build,build,5444,anpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/li,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5461,deployability,api,api,5461,ng/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5481,deployability,api,api,5481,ld/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5501,deployability,build,build,5501,essing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5518,deployability,api,api,5518,scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5538,deployability,api,api,5538,/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5551,deployability,build,build,5551,le_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5568,deployability,api,api,5568,uild/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5588,deployability,api,api,5588,rocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5601,deployability,build,build,5601,ying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5618,deployability,api,api,5618,rocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5638,deployability,api,api,5638,y -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5656,deployability,build,build,5656,py/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5673,deployability,api,api,5673,. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5693,deployability,api,api,5693,processing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5697,deployability,log,logging,5697,sing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5711,deployability,build,build,5711, -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5728,deployability,api,api,5728,anpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5748,deployability,api,api,5748,copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5761,deployability,build,build,5761,/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5778,deployability,api,api,5778,ca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5792,deployability,build,build,5792,lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py ->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5847,deployability,build,build,5847,mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5904,deployability,build,build,5904, scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5963,deployability,build,build,5963,ng. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6026,deployability,build,build,6026,preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6084,deployability,build,build,6084, scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6144,deployability,build,build,6144,opying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_model,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6200,deployability,build,build,6200,lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/pl,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6269,deployability,build,build,6269,y/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6324,deployability,build,build,6324,ting build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6380,deployability,build,build,6380,y -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copyin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6439,deployability,build,build,6439,> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6495,deployability,build,build,6495,-> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/li,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6554,deployability,build,build,6554,lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> buil,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6615,deployability,build,build,6615,api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6677,deployability,build,build,6677,pying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6732,deployability,build,build,6732,pying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6796,deployability,build,build,6796,ib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6857,deployability,build,build,6857,npy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/l,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6890,deployability,build,build,6890,hate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating bui,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6952,deployability,build,build,6952,p.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/prepro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7017,deployability,build,build,7017,py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7051,deployability,build,build,7051,ing scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7121,deployability,build,build,7121,ools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/prep,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7159,deployability,build,build,7159,ools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7221,deployability,build,build,7221,copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7287,deployability,build,build,7287,s. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7350,deployability,build,build,7350,ng scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7416,deployability,build,build,7416,tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/too,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7490,deployability,build,build,7490,> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/uma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7553,deployability,build,build,7553,ild/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7624,deployability,build,build,7624,anpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copyi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7684,deployability,build,build,7684,scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7749,deployability,build,build,7749,ls. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7785,deployability,build,build,7785,y.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7853,deployability,build,build,7853, build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7890,deployability,build,build,7890,ld/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8003,deployability,build,build,8003,rect.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-in,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8103,deployability,build,build,8103,__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: sta,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8156,deployability,build,build,8156,build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8238,deployability,build,build,8238,tting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing mani,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8316,deployability,build,build,8316,ng scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. F,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8390,deployability,build,build,8390,"lotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8432,deployability,build,build,8432,"otting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic ::",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8511,deployability,build,build,8511,"g. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8589,deployability,build,build,8589,"py/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8664,deployability,build,build,8664,"lotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8740,deployability,build,build,8740,"py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8815,deployability,build,build,8815,"ng scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", lin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9347,deployability,modul,module,9347,"opying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.ru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9371,deployability,build,build-,9371,"ools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9417,deployability,modul,module,9417,"s. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9802,deployability,instal,install,9802,"ls.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9844,deployability,instal,install,9844,"running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9906,deployability,instal,install,9906,"dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9955,deployability,build,build,9955,"G-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10203,deployability,build,build,10203,"emplate 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10471,deployability,build,build-,10471,"n',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str impl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10493,deployability,version,versioneer,10493,"on3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . --------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11606,deployability,build,build-,11606,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11743,deployability,instal,install,11743,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11785,deployability,instal,install-record,11785,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11813,deployability,version,version-externally-managed,11813,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11851,deployability,fail,failed,11851,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11888,deployability,build,build-,11888,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11930,deployability,version,version,11930,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11953,deployability,version,version,11953,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12000,deployability,upgrad,upgrading,12000,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12023,deployability,instal,install,12023,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12033,deployability,upgrad,upgrade,12033,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12085,deployability,upgrad,upgrading,12085,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:827,energy efficiency,core,core,827,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3806,energy efficiency,manag,managed,3806,"y bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/prep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9514,energy efficiency,core,core,9514,"/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11832,energy efficiency,manag,managed,11832,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:355,integrability,depend,dependencies,355,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:740,integrability,Topic,Topic,740,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1693,integrability,version,versioneer,1693,"/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . --------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3787,integrability,version,version-externally-managed,3787,"ng setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5349,integrability,api,api,5349,ing scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. cop,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5369,integrability,api,api,5369,.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/pa,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5405,integrability,api,api,5405,ild/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. cop,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5425,integrability,api,api,5425,ocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5461,integrability,api,api,5461,ng/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5481,integrability,api,api,5481,ld/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5518,integrability,api,api,5518,scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5538,integrability,api,api,5538,/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5568,integrability,api,api,5568,uild/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5588,integrability,api,api,5588,rocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5618,integrability,api,api,5618,rocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5638,integrability,api,api,5638,y -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5673,integrability,api,api,5673,. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5693,integrability,api,api,5693,processing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5728,integrability,api,api,5728,anpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5748,integrability,api,api,5748,copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5778,integrability,api,api,5778,ca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9427,integrability,Topic,Topic,9427,"g build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in ru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10493,integrability,version,versioneer,10493,"on3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . --------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11813,integrability,version,version-externally-managed,11813,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11930,integrability,version,version,11930,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11953,integrability,version,version,11953,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12071,integrability,messag,message,12071,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:416,interoperability,standard,standard,416,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1239,interoperability,distribut,distribution,1239," \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1535,interoperability,distribut,distribution,1535," writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3889,interoperability,distribut,distribution,3889,"0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5349,interoperability,api,api,5349,ing scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. cop,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5369,interoperability,api,api,5369,.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/pa,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5405,interoperability,api,api,5405,ild/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. cop,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5425,interoperability,api,api,5425,ocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5461,interoperability,api,api,5461,ng/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5481,interoperability,api,api,5481,ld/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5518,interoperability,api,api,5518,scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5538,interoperability,api,api,5538,/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5568,interoperability,api,api,5568,uild/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5588,interoperability,api,api,5588,rocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5618,interoperability,api,api,5618,rocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5638,interoperability,api,api,5638,y -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5673,interoperability,api,api,5673,. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5693,interoperability,api,api,5693,processing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5728,interoperability,api,api,5728,anpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5748,interoperability,api,api,5748,copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5778,interoperability,api,api,5778,ca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9103,interoperability,standard,standard,9103,"d/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10039,interoperability,distribut,distribution,10039,"to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10335,interoperability,distribut,distribution,10335,", in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12071,interoperability,messag,message,12071,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:355,modifiability,depend,dependencies,355,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:660,modifiability,modul,module,660,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:730,modifiability,modul,module,730,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1087,modifiability,pac,packages,1087,"s in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1693,modifiability,version,versioneer,1693,"/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . --------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1777,modifiability,pac,packages,1777,"ization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1891,modifiability,pac,packages,1891,"thon3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1970,modifiability,pac,package,1970,"ile ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2058,modifiability,pac,packages,2058,"e ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b533",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2195,modifiability,pac,packages,2195,"cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2313,modifiability,pac,packages,2313,", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2359,modifiability,pac,packages,2359,"e ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, pats",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2467,modifiability,pac,package,2467,"lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2514,modifiability,pac,packages,2514,"un_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2609,modifiability,pac,package,2609,", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3192,modifiability,pac,packages,3192,"ackages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3379,modifiability,deco,decorator,3379,"nd/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3787,modifiability,version,version-externally-managed,3787,"ng setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9347,modifiability,modul,module,9347,"opying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.ru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9417,modifiability,modul,module,9417,"s. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9774,modifiability,pac,packages,9774,"ng scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10493,modifiability,version,versioneer,10493,"on3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . --------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10577,modifiability,pac,packages,10577,"ython3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tok",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10691,modifiability,pac,packages,10691,"dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10770,modifiability,pac,package,10770,"packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8z",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10858,modifiability,pac,packages,10858," File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10995,modifiability,pac,packages,10995,"cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11113,modifiability,pac,packages,11113,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11159,modifiability,pac,packages,11159,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11267,modifiability,pac,package,11267,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11314,modifiability,pac,packages,11314,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11409,modifiability,pac,package,11409,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11813,modifiability,version,version-externally-managed,11813,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11930,modifiability,version,version,11930,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11953,modifiability,version,version,11953,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12000,modifiability,upgrad,upgrading,12000,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12033,modifiability,upgrad,upgrade,12033,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12085,modifiability,upgrad,upgrading,12085,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2874,performance,cach,cache,2874,"/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2985,performance,network,networkx,2985,"uild_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3032,performance,cach,cache,3032,"""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3137,performance,network,networkx,3137,"= self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3390,performance,network,networkx,3390,"y.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3473,performance,error,error,3473,"src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11863,performance,error,error,11863,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12065,performance,error,error,12065,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2726,reliability,Fail,Failed,2726,"build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3147,reliability,Fail,Failed,3147,"et_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6907,reliability,rto,rtools,6907,lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/pre,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6930,reliability,rto,rtools,6930,ng scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6969,reliability,rto,rtools,6969,/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6992,reliability,rto,rtools,6992,scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_gene,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:7034,reliability,rto,rtools,7034,canpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_de,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11851,reliability,fail,failed,11851,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11969,reliability,availab,available,11969,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:202,safety,updat,update,202,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:355,safety,depend,dependencies,355,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:660,safety,modul,module,660,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:730,safety,modul,module,730,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3473,safety,error,error,3473,"src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3480,safety,Compl,Complete,3480,". File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> buil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3806,safety,manag,managed,3806,"y bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/prep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4315,safety,log,logging,4315,"seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5697,safety,log,logging,5697,sing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9347,safety,modul,module,9347,"opying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.ru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9417,safety,modul,module,9417,"s. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11832,safety,manag,managed,11832,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11863,safety,error,error,11863,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11969,safety,avail,available,11969,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12065,safety,error,error,12065,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:194,security,apt,apt-get,194,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:202,security,updat,update,202,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:212,security,apt,apt-get,212,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2985,security,network,networkx,2985,"uild_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3137,security,network,networkx,3137,"= self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3390,security,network,networkx,3390,"y.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3480,security,Compl,Complete,3480,". File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> buil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3552,security,token,tokenize,3552,"line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3633,security,token,tokenize,3633,"n't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4315,security,log,logging,4315,"seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5697,security,log,logging,5697,sing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11578,security,token,tokenize,11578,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11659,security,token,tokenize,11659,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11969,security,availab,available,11969,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:355,testability,depend,dependencies,355,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:595,testability,Trace,Traceback,595,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4315,testability,log,logging,4315,"seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4999,testability,simpl,simple,4999,ating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5697,testability,log,logging,5697,sing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
