id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/pull/3079:284,safety,review,review,284,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:373,safety,test,tests,373,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:568,safety,Test,Tests,568,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:284,testability,review,review,284,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:373,testability,test,tests,373,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:568,testability,Test,Tests,568,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:135,usability,guid,guidelines,135,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:166,usability,guid,guide,166,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:262,usability,workflow,workflow,262,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:547,usability,Close,Closes,547,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/issues/3080:612,availability,Error,Error,612,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:43,deployability,scale,scale,43,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:261,deployability,version,version,261,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:422,deployability,scale,scale,422,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:555,deployability,scale,scaled,555,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:645,deployability,Version,Versions,645,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:43,energy efficiency,scale,scale,43,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:422,energy efficiency,scale,scale,422,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:555,energy efficiency,scale,scaled,555,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:261,integrability,version,version,261,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:645,integrability,Version,Versions,645,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:43,modifiability,scal,scale,43,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:261,modifiability,version,version,261,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:422,modifiability,scal,scale,422,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:547,modifiability,layer,layers,547,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:555,modifiability,scal,scaled,555,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:645,modifiability,Version,Versions,645,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:43,performance,scale,scale,43,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:422,performance,scale,scale,422,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:555,performance,scale,scaled,555,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:612,performance,Error,Error,612,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:612,safety,Error,Error,612,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:221,usability,confirm,confirmed,221,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:304,usability,confirm,confirmed,304,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:475,usability,Minim,Minimal,475,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3080:612,usability,Error,Error,612,"I have always had a question: do I need to scale my adata before running sc.tl.score_genes?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I have always had a question: do I need to scale my adata before running sc.tl.score_genes? ### Minimal code sample. ```python. sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080
https://github.com/scverse/scanpy/issues/3081:41,availability,Error,Error,41,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1021,availability,Error,Error,1021,"/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=Tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1417,availability,Error,Error,1417,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:2142,availability,Error,Error,2142,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:337,deployability,version,version,337,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:2301,deployability,Version,Versions,2301,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:337,integrability,version,version,337,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:2301,integrability,Version,Versions,2301,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:111,modifiability,variab,variable,111,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:337,modifiability,version,version,337,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1464,modifiability,paramet,parameter,1464,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:2301,modifiability,Version,Versions,2301,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:41,performance,Error,Error,41,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:121,performance,memor,memory,121,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1021,performance,Error,Error,1021,"/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=Tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1417,performance,Error,Error,1417,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:2142,performance,Error,Error,2142,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:41,safety,Error,Error,41,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:519,safety,safe,safe,519,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1021,safety,Error,Error,1021,"/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=Tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1417,safety,Error,Error,1417,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:2142,safety,Error,Error,2142,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:41,usability,Error,Error,41,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:121,usability,memor,memory,121,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:297,usability,confirm,confirmed,297,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:380,usability,confirm,confirmed,380,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1021,usability,Error,Error,1021,"/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=Tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1417,usability,Error,Error,1417,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1537,usability,help,help,1537,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:1783,usability,Minim,Minimal,1783,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3081:2142,usability,Error,Error,2142,"n of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure. The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error. Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,. then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`. It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python. adata: any anndata. markers: gene list include in var_names. group: obs key. celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(. 	adata, markers, group, show=False, swap_axes=True,. 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,. ). ```. ### Error output. ```pytb. KeyError: ""['veryvery.'] not in index"". # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ). ```. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081
https://github.com/scverse/scanpy/issues/3083:1794,availability,Error,Error,1794, FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:4,deployability,releas,release,4,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:17,deployability,fail,fail,17,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:240,deployability,version,version,240,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:366,deployability,releas,release,366,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:388,deployability,fail,failing,388,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:402,deployability,FAIL,FAILED,402,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:520,deployability,FAIL,FAILED,520,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:660,deployability,FAIL,FAILED,660,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:798,deployability,FAIL,FAILED,798,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:943,deployability,FAIL,FAILED,943,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1086,deployability,FAIL,FAILED,1086,ure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1195,deployability,FAIL,FAILED,1195,e confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1316,deployability,FAIL,FAILED,1316,n branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-m,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1450,deployability,FAIL,FAILED,1450,pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1576,deployability,FAIL,FAILED,1576,p_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1751,deployability,instal,install,1751, 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1827,deployability,Version,Versions,1827,ariable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2016,deployability,api,api-compat,2016,-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:240,integrability,version,version,240,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1827,integrability,Version,Versions,1827,ariable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2016,integrability,api,api-compat,2016,-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:3173,integrability,wrap,wrapt,3173,:test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==2024.1. + uc-micro-py==1.0.3. + umap-learn==0.5.6. + urllib3==2.2.1. + virtualenv==20.26.2. + wrapt==1.16.0. + zarr==2.18.2. + zict==3.0.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2016,interoperability,api,api-compat,2016,-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2055,interoperability,platform,platformdirs,2055,ct has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2078,interoperability,plug,pluggy,2078,'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==20,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:240,modifiability,version,version,240,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1827,modifiability,Version,Versions,1827,ariable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:3049,modifiability,extens,extensions,3049,:test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==2024.1. + uc-micro-py==1.0.3. + umap-learn==0.5.6. + urllib3==2.2.1. + virtualenv==20.26.2. + wrapt==1.16.0. + zarr==2.18.2. + zict==3.0.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1794,performance,Error,Error,1794, FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:17,reliability,fail,fail,17,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:388,reliability,fail,failing,388,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:402,reliability,FAIL,FAILED,402,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:520,reliability,FAIL,FAILED,520,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:660,reliability,FAIL,FAILED,660,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:798,reliability,FAIL,FAILED,798,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:943,reliability,FAIL,FAILED,943,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1086,reliability,FAIL,FAILED,1086,ure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1195,reliability,FAIL,FAILED,1195,e confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1316,reliability,FAIL,FAILED,1316,n branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-m,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1450,reliability,FAIL,FAILED,1450,pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1576,reliability,FAIL,FAILED,1576,p_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:374,safety,test,tests,374,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:416,safety,test,tests,416,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:534,safety,test,tests,534,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:674,safety,test,tests,674,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:812,safety,test,tests,812,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:957,safety,test,tests,957,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1100,safety,test,tests,1100,itions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-comm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1209,safety,test,tests,1209,is bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynnde,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1330,safety,test,tests,1330,anpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. +,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1464,safety,test,tests,1464,buteError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1590,safety,test,tests,1590,-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1794,safety,Error,Error,1794, FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2674,security,session,session-info,2674,:test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==2024.1. + uc-micro-py==1.0.3. + umap-learn==0.5.6. + urllib3==2.2.1. + virtualenv==20.26.2. + wrapt==1.16.0. + zarr==2.18.2. + zict==3.0.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:374,testability,test,tests,374,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:416,testability,test,tests,416,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:534,testability,test,tests,534,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:674,testability,test,tests,674,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:812,testability,test,tests,812,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:957,testability,test,tests,957,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1100,testability,test,tests,1100,itions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-comm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1209,testability,test,tests,1209,is bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynnde,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1330,testability,test,tests,1330,anpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. +,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1464,testability,test,tests,1464,buteError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1590,testability,test,tests,1590,-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2318,testability,mock,mock,2318,:test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==2024.1. + uc-micro-py==1.0.3. + umap-learn==0.5.6. + urllib3==2.2.1. + virtualenv==20.26.2. + wrapt==1.16.0. + zarr==2.18.2. + zict==3.0.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:200,usability,confirm,confirmed,200,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:283,usability,confirm,confirmed,283,Pre-release jobs fail because scipy removed `.A` from csr/csc matrices; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Our pre-release tests started failing. ```. FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1715,usability,Minim,Minimal,1715,p_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:1794,usability,Error,Error,1794, FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2580,usability,learn,learn,2580,:test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==2024.1. + uc-micro-py==1.0.3. + umap-learn==0.5.6. + urllib3==2.2.1. + virtualenv==20.26.2. + wrapt==1.16.0. + zarr==2.18.2. + zict==3.0.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:2993,usability,tool,toolz,2993,:test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==2024.1. + uc-micro-py==1.0.3. + umap-learn==0.5.6. + urllib3==2.2.1. + virtualenv==20.26.2. + wrapt==1.16.0. + zarr==2.18.2. + zict==3.0.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/issues/3083:3116,usability,learn,learn,3116,:test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'. FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'. ```. ### Minimal code sample. ```python. pip install scipy==1.14.0rc1. pytest. ```. ### Error output. _No response_. ### Versions. <details>. ```. + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba). + annoy==1.17.3. + anyio==4.4.0. + array-api-compat==1.7.1. + pillow==10.3.0. + platformdirs==4.2.2. + pluggy==1.5.0. + pre-commit==3.7.1. + profimp==0.1.0. + psutil==5.9.8. + pyarrow==16.1.0. + pygments==2.18.0. + pygsp==0.5.1. + pynndescent==0.5.12. + pyparsing==3.1.2. + pytest==8.2.1. + pytest-cov==5.0.0. + pytest-memray==1.6.0. + pytest-mock==3.14.0. + pytest-nunit==1.0.7. + pytest-xdist==3.6.1. + python-dateutil==2.9.0.post0. + pytz==2024.1. + pyyaml==6.0.1. + rich==13.7.1. + scanorama==1.7.4. + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s). + scikit-image==0.23.2. + scikit-learn==1.5.0. + scikit-misc==0.3.1. + scipy==1.14.0rc1. + scprep==1.1.0. + seaborn==0.13.2. + session-info==1.0.0. + setuptools==70.0.0. + setuptools-scm==8.1.0. + six==1.16.0. + sniffio==1.3.1. + sortedcontainers==2.4.0. + sparse==0.16.0a7. + statsmodels==0.14.2. + stdlib-list==0.10.0. + tasklogger==1.2.0. + tblib==3.0.0. + texttable==1.7.0. + textual==0.63.6. + threadpoolctl==3.5.0. + tifffile==2024.5.22. + toolz==0.12.1. + tornado==6.4. + tqdm==4.66.4. + typing-extensions==4.12.0. + tzdata==2024.1. + uc-micro-py==1.0.3. + umap-learn==0.5.6. + urllib3==2.2.1. + virtualenv==20.26.2. + wrapt==1.16.0. + zarr==2.18.2. + zict==3.0.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083
https://github.com/scverse/scanpy/pull/3084:439,deployability,releas,release,439,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:464,deployability,Releas,Release,464,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:237,safety,review,review,237,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:341,safety,Test,Tests,341,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:237,testability,review,review,237,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:341,testability,Test,Tests,341,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:88,usability,guid,guidelines,88,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:119,usability,guid,guide,119,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:215,usability,workflow,workflow,215,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:321,usability,Close,Closes,321,fix `.A` removal; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3083. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Two different fixes:. 1. The `np.asarray` cases are when we e.g. had `spmat.sum(axis=1).A` (i.e. a dense matrix). I could also leave these as `.A`. 2. the `.toarray()` cases are when we converted a sparse matrix to dense directly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/issues/3085:1120,availability,Error,Error,1120,"have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:236,deployability,version,version,236,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:713,deployability,contain,contains,713,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1790,deployability,log,logg,1790," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:2208,deployability,Version,Versions,2208," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:236,integrability,version,version,236,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:2208,integrability,Version,Versions,2208," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:490,interoperability,share,shared,490,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1383,interoperability,share,shared,1383," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:2079,interoperability,share,shared,2079," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:236,modifiability,version,version,236,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1666,modifiability,pac,packages,1666," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:2208,modifiability,Version,Versions,2208," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1120,performance,Error,Error,1120,"have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1120,safety,Error,Error,1120,"have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1790,safety,log,logg,1790," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1790,security,log,logg,1790," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1151,testability,Trace,Traceback,1151,"not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-794",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1790,testability,log,logg,1790," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:196,usability,confirm,confirmed,196,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:279,usability,confirm,confirmed,279,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:985,usability,Minim,Minimal,985,"OSError between tissue_positions_list.csv and tissue_positions.csv; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1120,usability,Error,Error,1120,"have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:1592,usability,Person,Personal,1592," ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python. adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). Cell In[2], line 6. 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'. 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'. ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path). 387 logg.warning(. 388 f""You seem to be missing an image file.\n"". 389 f""Could not find '{f}'."". 390 ). 391 else:. --> 392 raise OSError(f""Could not find '{f}'""). 394 adata.uns[""spatial""][library_id][""images""] = dict(). 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3086:11,availability,error,error,11,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:435,availability,error,error,435,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:586,availability,Error,Error,586,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:600,availability,Error,Error,600,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2698,availability,Error,Error,2698," high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:236,deployability,version,version,236,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6305,deployability,Version,Versions,6305,"ies._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:9009,deployability,updat,updated,9009,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1754,energy efficiency,heat,heatmap,1754,"-------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4586,energy efficiency,core,core,4586,"np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4821,energy efficiency,core,core,4821,"t.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5282,energy efficiency,core,core,5282,"yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5770,energy efficiency,core,core,5770,"ta\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6647,energy efficiency,cloud,cloudpickle,6647,"esult. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:8448,energy efficiency,cpu,cpu,8448,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:236,integrability,version,version,236,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1220,integrability,wrap,wrapper,1220," the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1273,integrability,wrap,wraps,1273,"ve confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2383,integrability,sub,subplots,2383,"-> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2938,integrability,wrap,wrapper,2938,".uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2991,integrability,wrap,wraps,2991," 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:3452,integrability,sub,subplots,3452,"y(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6305,integrability,Version,Versions,6305,"ies._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:8677,integrability,wrap,wrapt,8677,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1220,interoperability,wrapper,wrapper,1220," the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2938,interoperability,wrapper,wrapper,2938,".uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:7652,interoperability,platform,platformdirs,7652, 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:236,modifiability,version,version,236,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:727,modifiability,variab,variable,727,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1156,modifiability,pac,packages,1156,"already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1543,modifiability,pac,packages,1543,"1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2226,modifiability,pac,packages,2226,"ocals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positiona",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2874,modifiability,pac,packages,2874,"values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:3261,modifiability,pac,packages,3261," in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4165,modifiability,pac,packages,4165,"os, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4570,modifiability,pac,packages,4570,"s,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.as",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4805,modifiability,pac,packages,4805,"pt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5135,modifiability,scal,scalars,5135,"File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before index",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5266,modifiability,pac,packages,5266,"abel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5754,modifiability,pac,packages,5754,". File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6305,modifiability,Version,Versions,6305,"ies._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvml",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6790,modifiability,deco,decorator,6790,"1, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pyc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:7559,modifiability,pac,packaging,7559,otli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:8867,modifiability,pac,packaged,8867,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:11,performance,error,error,11,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:435,performance,error,error,435,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:586,performance,Error,Error,586,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:600,performance,Error,Error,600,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1739,performance,time,time,1739,", for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2024,performance,time,time,2024,":. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2058,performance,time,time,2058,"nt call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) ->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2068,performance,time,timeseries,2068,". Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if le",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2698,performance,Error,Error,2698," high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:3541,performance,time,time,3541,"r_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4000,performance,time,time,4000,"78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4230,performance,time,time,4230,"]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4378,performance,time,time,4378,"). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4396,performance,time,time,4396,"ups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""].cat.categories), dtype=int). 284 if len(adata.obs[""dpt_groups""].cat.categories) < 5. 285 else None. 286 ),. 287 palette=palette,. 288 ax=ax_grp,. 289 marker=marker,. 290 ). 291 timeseries_subplot(. 292 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5454,performance,time,timeseries,5454,"pe[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6544,performance,bottleneck,bottleneck,6544,"rray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. nump",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:8448,performance,cpu,cpu,8448,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:11,safety,error,error,11,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:435,safety,error,error,435,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:586,safety,Error,Error,586,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:600,safety,Error,Error,600,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:969,safety,except,exception,969,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1017,safety,except,exception,1017,".pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2698,safety,Error,Error,2698," high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5441,safety,test,tests,5441,"]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autogr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5519,safety,avoid,avoid,5519,"]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:9009,safety,updat,updated,9009,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6573,security,certif,certifi,6573,"ay(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:8257,security,soc,socks,8257,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:8989,security,Session,Session,8989,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:9009,security,updat,updated,9009,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:843,testability,Trace,Traceback,843,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:1040,testability,Trace,Traceback,1040,"dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2751,testability,Trace,Traceback,2751,"atmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. 282 yticks=(. 283 np.arange(len(adata.obs[""dpt_groups""]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5441,testability,test,tests,5441,"]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autogr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:11,usability,error,error,11,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:196,usability,confirm,confirmed,196,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:279,usability,confirm,confirmed,279,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:435,usability,error,error,435,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:456,usability,Minim,Minimal,456,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:586,usability,Error,Error,586,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:600,usability,Error,Error,600,"unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python. sc.tl.dpt(a1,n_branchings=2). sc.pl.dpt_groups_pseudotime(a1). sc.pl.dpt_timeseries(a1). ```. ### Error output. Error in dpt_timeseries:. ```pytb. WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last). Cell In[85], line 1. ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker). 242 # only if number of genes is not too high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:2698,usability,Error,Error,2698," high. 243 if as_heatmap:. 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d. --> 245 timeseries_as_heatmap(. 246 adata.X[adata.obs[""dpt_order_indices""].values],. 247 var_names=adata.var_names,. 248 highlights_x=adata.uns[""dpt_changepoints""],. 249 color_map=color_map,. 250 ). 251 else:. 252 # plot time series as gene expression vs time. 253 timeseries(. 254 adata.X[adata.obs[""dpt_order_indices""].values],. 255 var_names=adata.var_names,. (...). 258 marker=marker,. 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map). 223 x_new[:, _hold:] = X[:, hold:]. 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)). 226 img = ax.imshow(. --> 227 np.array(X, dtype=np.float_),. 228 aspect=""auto"",. 229 interpolation=""nearest"",. 230 cmap=color_map,. 231 ). 232 plt.colorbar(img, shrink=0.5). 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence. ```. Error in dpt_groups_pseudotime:. ```pytb. ValueError Traceback (most recent call last). Cell In[91], line 1. ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker). 274 """"""Plot groups and pseudotime."""""". 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1). --> 276 timeseries_subplot(. 277 adata.obs[""dpt_groups""].cat.codes,. 278 time=adata.obs[""dpt_order""].values,. 279 color=np.asarray(adata.obs[""dpt_groups""]),. 280 highlights_x=adata.uns[""dpt_changepoints""],. 281 ylabel=""dpt groups"",. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:4952,usability,support,supported,4952,"2 adata.obs[""dpt_pseudotime""].values,. 293 time=adata.obs[""dpt_order""].values,. (...). 301 marker=marker,. 302 ). 303 savefig_or_show(""dpt_groups_pseudotime"", save=save, show=show). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:140, in timeseries_subplot(X, time, color, var_names, highlights_x, xlabel, ylabel, yticks, xlim, legend, palette, color_map, ax, marker). 138 x_range = np.arange(X.shape[0]) if time is None else time. 139 if X.ndim == 1:. --> 140 X = X[:, None]. 141 if X.shape[1] > 1:. 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key). 1150 key = np.asarray(key, dtype=bool). 1151 return self._get_rows_with_mask(key). -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """"",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:5846,usability,Help,Helper,5846,"es._get_with(self, key). 1158 raise TypeError(. 1159 ""Indexing a Series with DataFrame is not "". 1160 ""supported, use the appropriate DataFrame column"". 1161 ). 1162 elif isinstance(key, tuple):. -> 1163 return self._get_values_tuple(key). 1165 elif not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6091,usability,support,supported,6091,"if not is_list_like(key):. 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684. 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. je",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:6235,usability,support,supported,6235,"ing\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key). 1198 if com.any_none(*key):. 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];. 1200 # see tests.series.timeseries.test_mpl_compat_hack. 1201 # the asarray is needed to avoid returning a 2D DatetimeArray. 1202 result = np.asarray(self._values[key]). -> 1203 disallow_ndim_indexing(result). 1204 return result. 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result). 333 """""". 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index. 335 . (...). 338 in GH#30588. 339 """""". 340 if np.ndim(result) > 1:. --> 341 raise ValueError(. 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer "". 343 ""supported. Convert to a numpy array before indexing instead."". 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead. ```. ### Versions. <details>. ```-----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. annoy NA. anyio NA. asttokens NA. attr 22.1.0. autograd NA. autograd_gamma NA. babel 2.11.0. backcall 0.2.0. bbknn 1.6.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. brotli NA. certifi 2024.02.02. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. entrypoints 0.4. executing 0.8.3. fastjsonschema NA. formulaic 1.0.1. future 0.18.3. gseapy 1.1.2. h5py 3.9.0. hypergeom_ufunc NA. idna 3.4. igraph 0.11.5. interface_meta 1.3.0. invgauss_ufunc NA. ipykernel 6.25.0. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:8422,usability,tool,toolz,8422,"ython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.1. jsonschema 4.17.3. jupyter_server 1.23.4. jupyterlab_server 2.22.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. lifelines 0.28.0. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.59.1. numexpr 2.8.4. numpy 1.26.4. packaging 23.1. pandas 2.2.2. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotly 5.9.0. prometheus_client NA. prompt_toolkit 3.0.36. psutil 5.9.0. pure_eval 0.2.2. pvectorc NA. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.11. pyparsing 3.0.9. pyrsistent NA. pythoncom NA. pytz 2023.3.post1. pywintypes NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. ruamel NA. scipy 1.11.1. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setuptools 69.5.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.3.0. sniffio 1.2.0. socks 1.7.1. sparse 0.15.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.7.0. threadpoolctl 2.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.2.1+cpu. torchgen NA. tornado 6.3.2. tqdm 4.65.0. traitlets 5.7.1. typing_extensions NA. umap 0.5.5. urllib3 1.26.16. wcwidth 0.2.5. websocket 0.58.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. winpty 2.0.10. wrapt 1.14.1. xxhash 2.0.2. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 8.15.0. jupyter_client 7.4.9. jupyter_core 5.3.0. jupyterlab 3.6.3. notebook 6.5.4. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-06-02 17:20. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3087:623,availability,Error,Error,623,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:188,deployability,version,version,188,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:544,deployability,instal,install,544,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3536,deployability,Version,Versions,3536,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:4406,deployability,updat,updated,4406,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3652,energy efficiency,cloud,cloudpickle,3652,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:188,integrability,version,version,188,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:2010,integrability,wrap,wrapper,2010,"s', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3536,integrability,Version,Versions,3536,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1579,interoperability,share,share,1579,"t_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function true",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:2010,interoperability,wrapper,wrapper,2010,"s', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3391,interoperability,format,format,3391,"ZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3471,interoperability,format,format,3471,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:188,modifiability,version,version,188,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1657,modifiability,pac,packages,1657,"_____________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1864,modifiability,layer,layer,1864,"_________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1870,modifiability,layer,layer,1870,"___________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:2998,modifiability,scal,scaling,2998,"909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3536,modifiability,Version,Versions,3536,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3987,modifiability,pac,packaging,3987,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:623,performance,Error,Error,623,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:13,safety,test,tests,13,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:332,safety,test,tests,332,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:573,safety,test,tests,573,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:623,safety,Error,Error,623,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1219,safety,test,tests,1219,") I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1625,safety,test,test,1625,"r output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truedi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:4406,safety,updat,updated,4406,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:4386,security,Session,Session,4386,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:4406,security,updat,updated,4406,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:13,testability,test,tests,13,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:332,testability,test,tests,332,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:573,testability,test,tests,573,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1219,testability,test,tests,1219,") I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:1625,testability,test,test,1625,"r output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truedi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:3671,testability,coverag,coverage,3671,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:148,usability,confirm,confirmed,148,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:231,usability,confirm,confirmed,231,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:508,usability,Minim,Minimal,508,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:623,usability,Error,Error,623,"Broken zappy tests; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python. pip install zappy. pytest scanpy/tests/test_preprocessing_distributed.py. ```. ### Error output. ```pytb. ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000. var: 'gene_ids'. uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):. > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible. return fn(*args_all, **kw). scanpy/preprocessing/_normalization.py:240: in normalize_total. adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer. scanpy/preprocessing/_normalization.py:49: in _normalize_data. return axis_mul_or_truediv(. /usr/lib/python3.12/functools.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:2954,usability,behavi,behavior,2954,"_truediv(. /usr/lib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:2970,usability,support,supported,2970,"ib/python3.12/functools.py:909: in wrapper. return dispatch(args[0].__class__)(*args, **kw). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . X = <zappy.direct.array.DirectZappyArray object at 0x7f06eb607a40>, scaling_array = array([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/issues/3087:4210,usability,tool,toolz,4210,"ay([0.9270073, 0.4379562, 1.5985402, ..., 0.8540146, 1.5109489,. 0.8978102], dtype=float32), axis = 0, op = <built-in function truediv>. @singledispatch. def axis_mul_or_truediv(. X: sparse.spmatrix,. scaling_array,. axis: Literal[0, 1],. op: Callable[[Any, Any], Any],. *,. allow_divide_by_zero: bool = True,. out: sparse.spmatrix | None = None,. ) -> sparse.spmatrix:. check_op(op). if out is not None:. if X.data is not out.data:. raise ValueError(. ""`out` argument provided but not equal to X. This behavior is not supported for sparse matrix scaling."". ). if not allow_divide_by_zero and op is truediv:. scaling_array = scaling_array.copy() + (scaling_array == 0). . row_scale = axis == 0. column_scale = axis == 1. if row_scale:. . def new_data_op(x):. return op(x.data, np.repeat(scaling_array, np.diff(x.indptr))). . elif column_scale:. . def new_data_op(x):. return op(x.data, scaling_array.take(x.indices, mode=""clip"")). . > if X.format == ""csr"":. E AttributeError: 'DirectZappyArray' object has no attribute 'format'. scanpy/_utils/__init__.py:612: AttributeError. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev61+g874d99b3. -----. PIL 10.3.0. asciitree NA. cloudpickle 3.0.0. coverage 7.5.3. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. distutils 3.12.3. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. yaml 6.0.1. zappy NA. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 23 2024, 09:16:07) [GCC 13.2.1 20240417]. Linux-6.9.3-zen1-1-zen-x86_64-with-glibc2.39. -----. Session information updated at 2024-06-03 11:27. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087
https://github.com/scverse/scanpy/pull/3089:449,deployability,releas,release,449,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:474,deployability,Releas,Release,474,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:8,safety,test,test,8,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:247,safety,review,review,247,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:351,safety,Test,Tests,351,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:8,testability,test,test,8,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:247,testability,review,review,247,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:351,testability,Test,Tests,351,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:19,usability,support,support,19,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:98,usability,guid,guidelines,98,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:129,usability,guid,guide,129,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:225,usability,workflow,workflow,225,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3089:331,usability,Close,Closes,331,Fix and test zappy support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3087. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089
https://github.com/scverse/scanpy/pull/3090:44,safety,test,test,44,Backport PR #3089 on branch 1.10.x (Fix and test zappy support); Backport PR #3089: Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090
https://github.com/scverse/scanpy/pull/3090:92,safety,test,test,92,Backport PR #3089 on branch 1.10.x (Fix and test zappy support); Backport PR #3089: Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090
https://github.com/scverse/scanpy/pull/3090:44,testability,test,test,44,Backport PR #3089 on branch 1.10.x (Fix and test zappy support); Backport PR #3089: Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090
https://github.com/scverse/scanpy/pull/3090:92,testability,test,test,92,Backport PR #3089 on branch 1.10.x (Fix and test zappy support); Backport PR #3089: Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090
https://github.com/scverse/scanpy/pull/3090:55,usability,support,support,55,Backport PR #3089 on branch 1.10.x (Fix and test zappy support); Backport PR #3089: Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090
https://github.com/scverse/scanpy/pull/3090:103,usability,support,support,103,Backport PR #3089 on branch 1.10.x (Fix and test zappy support); Backport PR #3089: Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090
https://github.com/scverse/scanpy/pull/3091:36,deployability,Updat,Updated,36,Backport PR #2888 on branch 1.10.x (Updated missing params in docstrings); Backport PR #2888: Updated missing params in docstrings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091
https://github.com/scverse/scanpy/pull/3091:94,deployability,Updat,Updated,94,Backport PR #2888 on branch 1.10.x (Updated missing params in docstrings); Backport PR #2888: Updated missing params in docstrings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091
https://github.com/scverse/scanpy/pull/3091:36,safety,Updat,Updated,36,Backport PR #2888 on branch 1.10.x (Updated missing params in docstrings); Backport PR #2888: Updated missing params in docstrings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091
https://github.com/scverse/scanpy/pull/3091:94,safety,Updat,Updated,94,Backport PR #2888 on branch 1.10.x (Updated missing params in docstrings); Backport PR #2888: Updated missing params in docstrings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091
https://github.com/scverse/scanpy/pull/3091:36,security,Updat,Updated,36,Backport PR #2888 on branch 1.10.x (Updated missing params in docstrings); Backport PR #2888: Updated missing params in docstrings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091
https://github.com/scverse/scanpy/pull/3091:94,security,Updat,Updated,94,Backport PR #2888 on branch 1.10.x (Updated missing params in docstrings); Backport PR #2888: Updated missing params in docstrings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3091
https://github.com/scverse/scanpy/pull/3092:174,modifiability,interm,intermediate,174,Move to src / tests layout; Changes exactly as in. - https://github.com/scverse/anndata/pull/1151 and. - https://github.com/scverse/anndata/pull/1459. but without adding the intermediate cruft,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3092
https://github.com/scverse/scanpy/pull/3092:14,safety,test,tests,14,Move to src / tests layout; Changes exactly as in. - https://github.com/scverse/anndata/pull/1151 and. - https://github.com/scverse/anndata/pull/1459. but without adding the intermediate cruft,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3092
https://github.com/scverse/scanpy/pull/3092:14,testability,test,tests,14,Move to src / tests layout; Changes exactly as in. - https://github.com/scverse/anndata/pull/1151 and. - https://github.com/scverse/anndata/pull/1459. but without adding the intermediate cruft,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3092
https://github.com/scverse/scanpy/pull/3094:36,usability,Document,Document,36,Backport PR #3060 on branch 1.10.x (Document datasets); Backport PR #3060: Document datasets,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3094
https://github.com/scverse/scanpy/pull/3094:75,usability,Document,Document,75,Backport PR #3060 on branch 1.10.x (Document datasets); Backport PR #3060: Document datasets,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3094
https://github.com/scverse/scanpy/issues/3095:421,availability,cluster,clustering-,421,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:524,availability,cluster,clustering,524,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:773,availability,Error,Error,773,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:35,deployability,scale,scale,35,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:210,deployability,version,version,210,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:421,deployability,cluster,clustering-,421,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:459,deployability,scale,scale,459,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:524,deployability,cluster,clustering,524,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:607,deployability,scale,scale,607,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:712,deployability,scale,scale,712,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:806,deployability,Version,Versions,806,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:35,energy efficiency,scale,scale,35,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:459,energy efficiency,scale,scale,459,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:607,energy efficiency,scale,scale,607,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:712,energy efficiency,scale,scale,712,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:210,integrability,version,version,210,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:806,integrability,Version,Versions,806,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:35,modifiability,scal,scale,35,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:210,modifiability,version,version,210,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:459,modifiability,scal,scale,459,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:607,modifiability,scal,scale,607,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:712,modifiability,scal,scale,712,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:806,modifiability,Version,Versions,806,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:35,performance,scale,scale,35,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:459,performance,scale,scale,459,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:607,performance,scale,scale,607,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:712,performance,scale,scale,712,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:773,performance,Error,Error,773,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:618,reliability,doe,does,618,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:773,safety,Error,Error,773,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:170,usability,confirm,confirmed,170,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:253,usability,confirm,confirmed,253,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:579,usability,visual,visualization,579,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:723,usability,Minim,Minimal,723,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:773,usability,Error,Error,773,"scanpy legacy and not legacy about scale; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Thanks a lot. when I read docs in . https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale). https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python. no code. ```. ### Error output. _No response_. ### Versions. <details>. ```. [. <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">. ](url). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3096:114,modifiability,paramet,parameters,114,"scanpy.pl.spatial plotting square pixels; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello! I wonder if there is a way to plot pixels as squares (now they are rounds) with scanpy.pl.spatial. Thanks! Best,. Haikuo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3096
https://github.com/scverse/scanpy/pull/3097:0,testability,Simpl,Simplify,0,Simplify score_genes; Extract simplifications from https://github.com/scverse/scanpy/pull/2921 because they can be backported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3097
https://github.com/scverse/scanpy/pull/3097:30,testability,simpl,simplifications,30,Simplify score_genes; Extract simplifications from https://github.com/scverse/scanpy/pull/2921 because they can be backported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3097
https://github.com/scverse/scanpy/pull/3097:0,usability,Simpl,Simplify,0,Simplify score_genes; Extract simplifications from https://github.com/scverse/scanpy/pull/2921 because they can be backported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3097
https://github.com/scverse/scanpy/pull/3097:30,usability,simpl,simplifications,30,Simplify score_genes; Extract simplifications from https://github.com/scverse/scanpy/pull/2921 because they can be backported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3097
https://github.com/scverse/scanpy/pull/3098:19,testability,Simpl,Simplify,19,Backport PR #3097: Simplify score_genes; Backport PR #3097: Simplify score_genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3098
https://github.com/scverse/scanpy/pull/3098:60,testability,Simpl,Simplify,60,Backport PR #3097: Simplify score_genes; Backport PR #3097: Simplify score_genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3098
https://github.com/scverse/scanpy/pull/3098:19,usability,Simpl,Simplify,19,Backport PR #3097: Simplify score_genes; Backport PR #3097: Simplify score_genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3098
https://github.com/scverse/scanpy/pull/3098:60,usability,Simpl,Simplify,60,Backport PR #3097: Simplify score_genes; Backport PR #3097: Simplify score_genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3098
https://github.com/scverse/scanpy/pull/3099:620,availability,cluster,cluster,620,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:857,availability,Down,Downloading,857,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:892,availability,down,download,892,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1691,availability,cluster,clusters,1691,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1805,availability,cluster,cluster,1805,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:0,deployability,scale,scale,0,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:30,deployability,updat,updated,30,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:444,deployability,Updat,Updated,444,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:620,deployability,cluster,cluster,620,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1691,deployability,cluster,clusters,1691,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1805,deployability,cluster,cluster,1805,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2510,deployability,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3333,deployability,scale,scale,3333,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3362,deployability,scale,scale,3362,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3389,deployability,scale,scale,3389,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3694,deployability,scale,scale,3694,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:0,energy efficiency,scale,scale,0,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2071,energy efficiency,reduc,reduce,2071,"ial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3333,energy efficiency,scale,scale,3333,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3362,energy efficiency,scale,scale,3362,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3389,energy efficiency,scale,scale,3389,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3694,energy efficiency,scale,scale,3694,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:320,integrability,sub,submitting,320,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:693,integrability,filter,filterwarnings,693,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1173,integrability,filter,filtering,1173,"uide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1217,integrability,Filter,Filter,1217,"est/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1300,integrability,Filter,Filter,1300,"-->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1356,integrability,filter,filtering,1356,"an_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1398,integrability,Filter,Filter,1398,"--------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1562,integrability,compon,components,1562,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1632,integrability,compon,components,1632,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2408,integrability,filter,filter,2408,"nes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (ti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2808,integrability,Filter,Filter,2808,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1562,interoperability,compon,components,1562,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1632,interoperability,compon,components,1632,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:0,modifiability,scal,scale,0,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1489,modifiability,variab,variable,1489,"iment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1562,modifiability,compon,components,1562,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1632,modifiability,compon,components,1632,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2562,modifiability,variab,variable,2562,"onents to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preproces",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2830,modifiability,variab,variable,2830,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3333,modifiability,scal,scale,3333,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3362,modifiability,scal,scale,3362,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3389,modifiability,scal,scale,3389,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3694,modifiability,scal,scale,3694,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:0,performance,scale,scale,0,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:384,performance,Time,Time,384,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:539,performance,time,time,539,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1826,performance,parallel,parallel,1826,"xists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1898,performance,time,time,1898,"('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1903,performance,time,time,1903,"ps://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1914,performance,time,time,1914,"-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1919,performance,time,time,1919,"le-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2018,performance,time,time,2018,"enes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2032,performance,time,time,2032,"E_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2037,performance,time,time,2037,"FIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2053,performance,time,time,2053,"efix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2058,performance,time,time,2058,"for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_coun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2429,performance,time,time,2429,"er cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2443,performance,time,time,2443,"this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer aro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2448,performance,time,time,2448," n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2464,performance,time,time,2464,"000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var cal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2469,performance,time,time,2469," Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2514,performance,time,time,2514," PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2528,performance,time,time,2528,"ents = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2533,performance,time,time,2533,"= 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2894,performance,time,time,2894,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2899,performance,time,time,2899,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3300,performance,time,time,3300,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3314,performance,time,time,3314,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3319,performance,time,time,3319,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3333,performance,scale,scale,3333,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3343,performance,time,time,3343,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3348,performance,time,time,3348,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3362,performance,scale,scale,3362,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3389,performance,scale,scale,3389,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3395,performance,time,time,3395,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3409,performance,time,time,3409,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3414,performance,time,time,3414,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3436,performance,time,timer,3436,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3694,performance,scale,scale,3694,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:30,safety,updat,updated,30,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:295,safety,review,review,295,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:444,safety,Updat,Updated,444,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2510,safety,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:30,security,updat,updated,30,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:444,security,Updat,Updated,444,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2510,security,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:295,testability,review,review,295,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:741,testability,simpl,simplefilter,741,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1087,testability,regress,regress,1087,"r opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2510,testability,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:2908,testability,Regress,Regress,2908,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:3288,testability,regress,regress,3288,"ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata). print(""Total scale time : %s"" % (time.time()-ts)). ```. add timer around _get_mean_var call . https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L167. we can also create _get_mean_var_std function that return std as well so we don't require to compute it in scale function(L168-L169).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:146,usability,guid,guidelines,146,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:177,usability,guid,guide,177,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:273,usability,workflow,workflow,273,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:741,usability,simpl,simplefilter,741,"scale function(_get_mean_var) updated for dense array, speedup upto ~4.65x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:1156,usability,visual,visualization,1156," contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi,. We are submitting PR for speed up of the _get_mean_var function. . | | Time(sec)|. | -----------| ----- |. | Original | 18.49 |. | Updated | 3.97 |. | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3100:869,availability,cluster,cluster,869,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1106,availability,Down,Downloading,1106,"sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyCon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1141,availability,down,download,1141,"our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). star",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1940,availability,cluster,clusters,1940,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2054,availability,cluster,cluster,2054,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:478,deployability,releas,release,478,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:503,deployability,Releas,Release,503,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:688,deployability,Updat,Updated,688,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:869,deployability,cluster,cluster,869,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1940,deployability,cluster,clusters,1940,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2054,deployability,cluster,cluster,2054,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2759,deployability,log,log,2759,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3582,deployability,scale,scale,3582," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3611,deployability,scale,scale,3611," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3651,deployability,scale,scale,3651," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2320,energy efficiency,reduc,reduce,2320,"ial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3582,energy efficiency,scale,scale,3582," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3611,energy efficiency,scale,scale,3611," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3651,energy efficiency,scale,scale,3651," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:553,integrability,sub,submitting,553,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:942,integrability,filter,filterwarnings,942,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1422,integrability,filter,filtering,1422,"nly check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1466,integrability,Filter,Filter,1466," include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1549,integrability,Filter,Filter,1549," submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1605,integrability,filter,filtering,1605,"g function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1647,integrability,Filter,Filter,1647,"---| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1811,integrability,compon,components,1811,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1881,integrability,compon,components,1881,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2657,integrability,filter,filter,2657,"nes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale tim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3057,integrability,Filter,Filter,3057," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1811,interoperability,compon,components,1811,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1881,interoperability,compon,components,1881,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:42,modifiability,scal,scaling,42,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:604,modifiability,scal,scaling,604,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1738,modifiability,variab,variable,1738,"t setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1811,modifiability,compon,components,1811,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1881,modifiability,compon,components,1881,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2811,modifiability,variab,variable,2811," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3079,modifiability,variab,variable,3079," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3582,modifiability,scal,scale,3582," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3611,modifiability,scal,scale,3611," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3651,modifiability,scal,scale,3651," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:628,performance,Time,Time,628,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:788,performance,time,time,788,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2075,performance,parallel,parallel,2075,"xists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2147,performance,time,time,2147,"('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2152,performance,time,time,2152,"ps://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2163,performance,time,time,2163,"-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2168,performance,time,time,2168,"le-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2267,performance,time,time,2267,"enes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2281,performance,time,time,2281,"E_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2286,performance,time,time,2286,"FIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2302,performance,time,time,2302,"efix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2307,performance,time,time,2307,"for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_coun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2678,performance,time,time,2678,"er cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2692,performance,time,time,2692,"this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2697,performance,time,time,2697," n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2713,performance,time,time,2713,"000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2718,performance,time,time,2718," Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2763,performance,time,time,2763," PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65db",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2777,performance,time,time,2777,"ents = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2782,performance,time,time,2782,"= 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/pre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3143,performance,time,time,3143," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3148,performance,time,time,3148," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3549,performance,time,time,3549," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3563,performance,time,time,3563," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3568,performance,time,time,3568," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3582,performance,scale,scale,3582," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3592,performance,time,time,3592," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3597,performance,time,time,3597," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3611,performance,scale,scale,3611," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3651,performance,scale,scale,3651," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3657,performance,time,time,3657," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3671,performance,time,time,3671," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3676,performance,time,time,3676," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:280,safety,review,review,280,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:380,safety,Test,Tests,380,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:688,safety,Updat,Updated,688,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2759,safety,log,log,2759,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:688,security,Updat,Updated,688,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2759,security,log,log,2759,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:280,testability,review,review,280,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:380,testability,Test,Tests,380,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:990,testability,simpl,simplefilter,990,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1336,testability,regress,regress,1336,"lowing boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:2759,testability,log,log,2759,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3157,testability,Regress,Regress,3157," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:3537,testability,regress,regress,3537," components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata,max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). ```. https://github.com/scverse/scanpy/blob/706d4ef65e5d65e04b788831e7fd65dbe6b2a61f/scanpy/preprocessing/_scale.py#L202.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:131,usability,guid,guidelines,131,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:162,usability,guid,guide,162,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:258,usability,workflow,workflow,258,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:364,usability,Close,Closes,364,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:990,usability,simpl,simplefilter,990,"speedup(~7x) of the clipping array inside scaling function ; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:1405,usability,visual,visualization,1405,"ecause:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the clipping part of scaling function. . | | Time(sec)|. | -----------| ----- |. | Original | 11.82 |. | Updated | 1.59 |. | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3101:456,deployability,releas,release,456,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:481,deployability,Releas,Release,481,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:254,safety,review,review,254,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:358,safety,Test,Tests,358,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:254,testability,review,review,254,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:358,testability,Test,Tests,358,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:105,usability,guid,guidelines,105,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:136,usability,guid,guide,136,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:232,usability,workflow,workflow,232,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/pull/3101:338,usability,Close,Closes,338,Fix dotplot totals for pandas 1.x; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3062. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3101
https://github.com/scverse/scanpy/issues/3102:63,availability,error,error,63,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:842,availability,Error,Error,842,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:251,deployability,version,version,251,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:526,deployability,continu,continuous,526,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3174,deployability,Version,Versions,3174,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3916,deployability,updat,updated,3916,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3066,energy efficiency,draw,draw,3066,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:251,integrability,version,version,251,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1254,integrability,wrap,wrapper,1254," of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1307,integrability,wrap,wraps,1307,"ug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1751,integrability,compon,components,1751,"ata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:2670,integrability,compon,components,2670,"tter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3174,integrability,Version,Versions,3174,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1254,interoperability,wrapper,wrapper,1254," of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1751,interoperability,compon,components,1751,"ata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:2670,interoperability,compon,components,2670,"tter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:251,modifiability,version,version,251,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1190,modifiability,pac,packages,1190,"ed. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1627,modifiability,pac,packages,1627,"om/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, lay",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1709,modifiability,layer,layers,1709,"mal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:1751,modifiability,compon,components,1751,"ata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:2541,modifiability,pac,packages,2541,"al:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:2628,modifiability,layer,layers,2628,"ages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:2670,modifiability,compon,components,2670,"tter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3174,modifiability,Version,Versions,3174,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3532,modifiability,pac,packaging,3532,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:63,performance,error,error,63,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:842,performance,Error,Error,842,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:478,reliability,doe,does,478,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:63,safety,error,error,63,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:842,safety,Error,Error,842,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3916,safety,updat,updated,3916,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3896,security,Session,Session,3896,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:3916,security,updat,updated,3916,"ther provide a `basis` or `x` and `y`.""). 161 if (. 162 (x in adata.obs.keys() or x in var_index). 163 and (y in adata.obs.keys() or y in var_index). 164 and (color is None or color in adata.obs.keys() or color in var_index). 165 ):. --> 166 return _scatter_obs(**args). 167 if (. 168 (x in adata.var.keys() or x in adata.obs.index). 169 and (y in adata.var.keys() or y in adata.obs.index). 170 and (color is None or color in adata.var.keys() or color in adata.obs.index). 171 ):. 172 adata_T = adata.T. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:521, in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 517 legend = axs[ikey].legend(. 518 frameon=False, loc=legend_loc, fontsize=legend_fontsize. 519 ). 520 if legend is not None:. --> 521 for handle in legend.legendHandles:. 522 handle.set_sizes([300.0]). 524 # draw a frame around the scatter. AttributeError: 'Legend' object has no attribute 'legendHandles'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. cffi 1.16.0. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. defusedxml 0.7.1. dill 0.3.8. h5py 3.11.0. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. packaging 24.0. pandas 2.2.2. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. threadpoolctl 3.5.0. torch 2.3.1+cu121. torchgen NA. tqdm 4.66.4. typing_extensions NA. yaml 6.0.1. -----. Python 3.11.7 (main, Jan 17 2024, 16:00:28) [GCC 8.5.0]. Linux-3.10.0-1160.114.2.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-06-06 11:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:957,testability,Trace,Traceback,957,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:63,usability,error,error,63,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:211,usability,confirm,confirmed,211,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:294,usability,confirm,confirmed,294,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:708,usability,Minim,Minimal,708,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:842,usability,Error,Error,842,"Scatterplot with color for categorical value outputs attribute error about legend; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks! ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python. sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[37], line 1. ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax). 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3103:69,availability,error,error,69,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:590,availability,error,error,590,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:970,availability,error,error,970,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1044,availability,Error,Error,1044," a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:286,deployability,version,version,286,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:474,deployability,contain,contains,474,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:553,deployability,fail,failed,553,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:746,deployability,contain,contains,746,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:3004,deployability,Version,Versions,3004,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:2860,energy efficiency,estimat,estimator,2860,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:90,integrability,batch,batch,90,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:286,integrability,version,version,286,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:483,integrability,batch,batch,483,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:526,integrability,filter,filtering,526,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:639,integrability,batch,batch,639,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:727,integrability,batch,batch,727,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:738,integrability,Batch,Batch,738,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:834,integrability,batch,batch,834,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1026,integrability,batch,batch,1026,"tch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1692,integrability,sub,subset,1692,"hon. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small valu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:2148,integrability,filter,filtered,2148,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:3004,integrability,Version,Versions,3004,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:286,modifiability,version,version,286,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1517,modifiability,pac,packages,1517,"lier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1610,modifiability,layer,layer,1610,"ehavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1922,modifiability,layer,layer,1922,"nes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1928,modifiability,layer,layer,1928,"st_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:2305,modifiability,pac,packages,2305,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:2412,modifiability,layer,layer,2412,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:2725,modifiability,pac,packages,2725,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:3004,modifiability,Version,Versions,3004,"------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:206, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor). 203 else:. 204 X = np.expm1(X). --> 206 mean, var = materialize_as_ndarray(_get_mean_var(X)). 207 # now actually compute the dispersion. 208 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. File ~/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:14, in _get_mean_var(X, axis). 12 var = mean_sq - mean**2. 13 # enforce R convention (unbiased estimator) for variance. ---> 14 var *= X.shape[axis] / (X.shape[axis] - 1). 15 return mean, var. ZeroDivisionError: division by zero. ```. ### Versions. <details>. ```. anndata 0.10.3. scanpy 1.9.6. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:69,performance,error,error,69,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:90,performance,batch,batch,90,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:483,performance,batch,batch,483,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:590,performance,error,error,590,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:639,performance,batch,batch,639,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:727,performance,batch,batch,727,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:738,performance,Batch,Batch,738,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:834,performance,batch,batch,834,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:970,performance,error,error,970,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1026,performance,batch,batch,1026,"tch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1044,performance,Error,Error,1044," a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:553,reliability,fail,failed,553,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:69,safety,error,error,69,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:454,safety,input,input,454,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:590,safety,error,error,590,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:970,safety,error,error,970,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1044,safety,Error,Error,1044," a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1162,testability,Trace,Traceback,1162,"[X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1300,testability,simpl,simplefilter,1300," [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:69,usability,error,error,69,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:246,usability,confirm,confirmed,246,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:329,usability,confirm,confirmed,329,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:454,usability,input,input,454,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:590,usability,error,error,590,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:612,usability,behavi,behavior,612,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:668,usability,Minim,Minimal,668,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:970,usability,error,error,970,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1044,usability,Error,Error,1044," a ""division by zero"" error, if there is a batch with a single sample; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:1300,usability,simpl,simplefilter,1300," [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. . The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python. #Create dummy anndata with batch key. Batch 3 contains 1 sample. test_ad = ad.AnnData(X=np.random.randn(10,100), . obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})). #This works fine. sc.pp.highly_variable_genes(test_ad). #This returns division by zero error. #sc.pp.highly_variable_genes(test_ad, batch_key='batch'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ZeroDivisionError Traceback (most recent call last). Cell In[41], line 11. 9 with warnings.catch_warnings(): #ignore future_warning in groupby. 10 warnings.simplefilter(action='ignore', category=FutureWarning). ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count). 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]. 467 adata_subset = adata_subset[:, filt]. --> 469 hvg = _highly_variable_genes_single_batch(. 470 adata_subset,. 471 layer=layer,. 472 min_disp=min_disp,. 473 max_disp=max_disp,. 474 min_mean=min_mean,. 475 max_mean=max_mean,. 476 n_top_genes=n_top_genes,. 477 n_bins=n_bins,. 478 flavor=flavor,. 479 ). 481 # Add 0 values for genes that were filtered out. 482 missing_hvg = pd.DataFrame(. 483 np.zeros((np.sum(~filt), len(hvg.columns))),. 484 columns=hvg.columns,. 485 ). File ~/lib/python3.10/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/pull/3105:50,safety,test,tests,50,Backport PR #3092 on branch 1.10.x (Move to src / tests layout); Backport PR #3092: Move to src / tests layout,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3105
https://github.com/scverse/scanpy/pull/3105:98,safety,test,tests,98,Backport PR #3092 on branch 1.10.x (Move to src / tests layout); Backport PR #3092: Move to src / tests layout,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3105
https://github.com/scverse/scanpy/pull/3105:50,testability,test,tests,50,Backport PR #3092 on branch 1.10.x (Move to src / tests layout); Backport PR #3092: Move to src / tests layout,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3105
https://github.com/scverse/scanpy/pull/3105:98,testability,test,tests,98,Backport PR #3092 on branch 1.10.x (Move to src / tests layout); Backport PR #3092: Move to src / tests layout,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3105
https://github.com/scverse/scanpy/issues/3106:1125,availability,Error,Error,1125,"ssue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:217,deployability,version,version,217,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1391,deployability,version,versions,1391,"ffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1739,deployability,Version,Versions,1739,"ps_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:4437,deployability,updat,updated,4437,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:2047,energy efficiency,cloud,cloudpickle,2047,"s_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:217,integrability,version,version,217,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1391,integrability,version,versions,1391,"ffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1739,integrability,Version,Versions,1739,"ps_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:3058,interoperability,platform,platformdirs,3058,. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. x,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:217,modifiability,version,version,217,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:658,modifiability,layer,layer,658,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:974,modifiability,layer,layer,974,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1391,modifiability,version,versions,1391,"ffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1739,modifiability,Version,Versions,1739,"ps_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:2191,modifiability,deco,decorator,2191,"he same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:2950,modifiability,pac,packaging,2950,NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. uma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:4282,modifiability,pac,packaged,4282,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1125,performance,Error,Error,1125,"ssue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1125,safety,Error,Error,1125,"ssue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:2243,safety,except,exceptiongroup,2243,", the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:4437,safety,updat,updated,4437,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:770,security,aPT,aPT,770,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1086,security,aPT,aPT,1086,"re met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1973,security,certif,certifi,1973,"er = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:2411,security,iso,isoduration,2411,"ssue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.2. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. episcanpy 0.4.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.3. intervaltree NA. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:3702,security,soc,socks,3702,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:4417,security,Session,Session,4417,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:4437,security,updat,updated,4437,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:3641,testability,simpl,simplejson,3641,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:177,usability,confirm,confirmed,177,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:260,usability,confirm,confirmed,260,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:511,usability,Minim,Minimal,511,"Shuffled gene names for differential expression; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:1125,usability,Error,Error,1125,"ssue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python. import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],. ascending = False ). sc.tl.rank_genes_groups( rna_ann, . 'celltypes',. key_added = 'wilcoxon2',. reference = 'PT',. layer = 'data',. method='wilcoxon',. pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, . group = 'aPT', . key = 'wilcoxon2', ). ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.10.1. -----. PIL 9.2.0. anyio NA. argcomplete NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. bamnostic NA. brotli 1.0.9. certifi 2024.06.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.0. cloudpickle 3.0.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:3641,usability,simpl,simplejson,3641,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/issues/3106:3871,usability,tool,toolz,3871,"pointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.8.0. jupyter_server 2.8.0. jupyterlab_server 2.25.0. kiwisolver 1.4.5. kneed 0.8.5. legacy_api_wrap NA. leidenalg 0.9.1. llvmlite 0.40.1. louvain 0.8.0. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.2. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.6. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numcodecs 0.12.1. numexpr 2.8.7. numpy 1.24.4. overrides NA. packaging 23.2. pandas 2.2.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pysam 0.20.0. pythonjsonlogger NA. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sortedcontainers 2.4.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 2.0.0. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.2. tomli 2.0.1. toolz 0.12.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.4. upsetplot 0.8.0. uri_template NA. urllib3 1.26.18. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. xxhash NA. yaml 6.0.1. zarr 2.17.2. zipp NA. zmq 25.1.1. zoneinfo NA. zope NA. zstandard 0.21.0. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.1.4. notebook 7.1.1. -----. Python 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:23:14) [GCC 10.4.0]. Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2024-06-13 10:40. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/pull/3110:986,availability,cluster,cluster,986,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1223,availability,Down,Downloading,1223,"st/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyCon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1258,availability,down,download,1258," yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). star",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2057,availability,cluster,clusters,2057,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2171,availability,cluster,cluster,2171,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:501,deployability,releas,release,501,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:526,deployability,Releas,Release,526,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:810,deployability,Updat,Updated,810,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:986,deployability,cluster,cluster,986,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2057,deployability,cluster,clusters,2057,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2171,deployability,cluster,cluster,2171,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2876,deployability,log,log,2876,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2437,energy efficiency,reduc,reduce,2437,"ial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:576,integrability,sub,submitting,576,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1059,integrability,filter,filterwarnings,1059,"t Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1539,integrability,filter,filtering,1539,"necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1583,integrability,Filter,Filter,1583," PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1666,integrability,Filter,Filter,1666,"ear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1722,integrability,filter,filtering,1722,"non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1764,integrability,Filter,Filter,1764,"-----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1928,integrability,compon,components,1928,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1998,integrability,compon,components,1998,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2774,integrability,filter,filter,2774,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3174,integrability,Filter,Filter,3174,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1928,interoperability,compon,components,1928,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1998,interoperability,compon,components,1998,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1855,modifiability,variab,variable,1855,"t setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1928,modifiability,compon,components,1928,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1998,modifiability,compon,components,1998,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2928,modifiability,variab,variable,2928,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3196,modifiability,variab,variable,3196,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:753,performance,Time,Time,753,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:905,performance,time,time,905,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2192,performance,parallel,parallel,2192,"xists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2264,performance,time,time,2264,"('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2269,performance,time,time,2269,"ps://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2280,performance,time,time,2280,"-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2285,performance,time,time,2285,"le-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding facto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2384,performance,time,time,2384,"enes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(M",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2398,performance,time,time,2398,"E_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFI",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2403,performance,time,time,2403,"FIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2419,performance,time,time,2419,"efix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.arr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2424,performance,time,time,2424,"for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2795,performance,time,time,2795,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2809,performance,time,time,2809,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2814,performance,time,time,2814,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2830,performance,time,time,2830,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2835,performance,time,time,2835,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2880,performance,time,time,2880,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2894,performance,time,time,2894,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2899,performance,time,time,2899,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3572,performance,time,time,3572,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3577,performance,time,time,3577,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3666,performance,time,time,3666,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3680,performance,time,time,3680,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3685,performance,time,time,3685,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:303,safety,review,review,303,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:403,safety,Test,Tests,403,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:810,safety,Updat,Updated,810,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2876,safety,log,log,2876,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:810,security,Updat,Updated,810,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2876,security,log,log,2876,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:303,testability,review,review,303,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:403,testability,Test,Tests,403,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:673,testability,regress,regression,673,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1107,testability,simpl,simplefilter,1107," to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_gene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1453,testability,regress,regress,1453,"ck the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:2876,testability,log,log,2876,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3258,testability,Regress,Regress,3258,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:3654,testability,regress,regress,3654,"an this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. ts=time.time(). sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:154,usability,guid,guidelines,154,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:185,usability,guid,guide,185,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:281,usability,workflow,workflow,281,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:387,usability,Close,Closes,387,"Speedup (~20x) of scanpy.pp.regress_out function using Linear Least Square method.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1107,usability,simpl,simplefilter,1107," to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_gene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:1522,usability,visual,visualization,1522,"ease notes not necessary because:. Hi,. We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|. | -----------| ----- |. | Original | 297|. | Updated | 14.91 |. | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3112:61,modifiability,scal,scaling,61,Backport PR #3100: speedup(~7x) of the clipping array inside scaling function; Backport PR #3100: speedup(~7x) of the clipping array inside scaling function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3112
https://github.com/scverse/scanpy/pull/3112:140,modifiability,scal,scaling,140,Backport PR #3100: speedup(~7x) of the clipping array inside scaling function; Backport PR #3100: speedup(~7x) of the clipping array inside scaling function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3112
https://github.com/scverse/scanpy/issues/3113:1214,availability,Error,Error,1214,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:213,deployability,version,version,213,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:1575,deployability,Version,Versions,1575,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:213,integrability,version,version,213,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:1575,integrability,Version,Versions,1575,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:213,modifiability,version,version,213,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:1575,modifiability,Version,Versions,1575,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:1214,performance,Error,Error,1214,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:1214,safety,Error,Error,1214,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:1086,testability,Verif,Verify,1086,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:173,usability,confirm,confirmed,173,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:256,usability,confirm,confirmed,256,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:510,usability,document,documentation,510,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:750,usability,Minim,Minimal,750,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:1214,usability,Error,Error,1214,"Can't read in protein antibody capture data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python. print(key). adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ). print(adata). . # Separate RNA and protein data. rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']. protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']. . # Verify the separated data. print(""RNA data shape:"", rna_data.shape). print(""Protein data shape:"", protein_data.shape). ```. ### Error output. ```pytb. MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085. obs: 'in_tissue', 'array_row', 'array_col'. var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'. uns: 'spatial'. obsm: 'spatial'. RNA data shape: (2256, 18085). Protein data shape: (2256, 0). ```. ### Versions. <details>. ```. 1.10.1. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3114:169,deployability,releas,released,169,"Numpy 2 support (unpin); ### What kind of feature would you like to request? Other? ### Please describe your wishes. https://github.com/lmcinnes/pynndescent/pull/242 is released in [0.5.13](https://github.com/lmcinnes/pynndescent/releases/tag/release-0.5.13), so we can do that now",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3114
https://github.com/scverse/scanpy/issues/3114:230,deployability,releas,releases,230,"Numpy 2 support (unpin); ### What kind of feature would you like to request? Other? ### Please describe your wishes. https://github.com/lmcinnes/pynndescent/pull/242 is released in [0.5.13](https://github.com/lmcinnes/pynndescent/releases/tag/release-0.5.13), so we can do that now",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3114
https://github.com/scverse/scanpy/issues/3114:243,deployability,releas,release-,243,"Numpy 2 support (unpin); ### What kind of feature would you like to request? Other? ### Please describe your wishes. https://github.com/lmcinnes/pynndescent/pull/242 is released in [0.5.13](https://github.com/lmcinnes/pynndescent/releases/tag/release-0.5.13), so we can do that now",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3114
https://github.com/scverse/scanpy/issues/3114:8,usability,support,support,8,"Numpy 2 support (unpin); ### What kind of feature would you like to request? Other? ### Please describe your wishes. https://github.com/lmcinnes/pynndescent/pull/242 is released in [0.5.13](https://github.com/lmcinnes/pynndescent/releases/tag/release-0.5.13), so we can do that now",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3114
https://github.com/scverse/scanpy/pull/3115:436,deployability,releas,release,436,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:461,deployability,Releas,Release,461,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:806,deployability,version,versions,806,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:806,integrability,version,versions,806,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:533,modifiability,variab,variables,533,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:806,modifiability,version,versions,806,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:234,safety,review,review,234,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:338,safety,Test,Tests,338,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:651,safety,test,tests,651,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:776,safety,test,tests,776,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:815,safety,test,test,815,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:234,testability,review,review,234,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:338,testability,Test,Tests,338,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:651,testability,test,tests,651,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:776,testability,test,tests,776,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:815,testability,test,test,815,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:85,usability,guid,guidelines,85,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:116,usability,guid,guide,116,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:212,usability,workflow,workflow,212,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:318,usability,Close,Closes,318,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:600,usability,minim,minimal,600,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:798,usability,minim,minimum,798,"Unpin numpy 2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #3114. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Other things done:. - Rename some variables and reorder functions so the diff between the metrics is minimal for a future unification. - Skip seurat v3 tests with numpy 2 because skmisc isn’t ready: https://github.com/has2k1/scikit-misc/issues/34. This will skip the seurat v3 tests for all but the minimum versions test job for now, but I think that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/issues/3116:15579,availability,Error,Error,15579,".2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:201,deployability,version,version,201,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:394,deployability,version,version,394,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1995,deployability,Automat,Automatically,1995,"var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2294,deployability,depend,dependency,2294,"on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2359,deployability,pipelin,pipeline,2359," code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2426,deployability,pipelin,pipeline,2426,"t finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2447,deployability,updat,updated,2447," of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2466,deployability,version,version,2466,"g Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2574,deployability,fail,failed,2574,"nished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2665,deployability,depend,dependencies,2665,"iable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2843,deployability,api,api-compat,2843,"per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - htt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:4557,deployability,api,api-wrap,4557, - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.1.3. - libblas=3.9.0. - libbrotlicommon=1.1.0. - libbrotlidec=1.1.0. - libbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6764,deployability,log,logger,6764,yncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - uma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8693,deployability,depend,dependencies,8693,yping_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8910,deployability,api,api-compat,8910,0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:11000,deployability,api,api-wrap,11000,reetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-lsp=2.2.0. - jupyter_client=8.3.0. - jupyter_core=5.3.1. - jupyter_events=0.7.0. - jupyter_server=2.7.1. - jupyter_server_terminals=0.4.4. - jupyterlab=4.0.5. - jupyterlab_pygments=0.2.2. - jupyterlab_server=2.24.0. - kaleido-core=0.2.1. - kiwisolver=1.4.4. - krb5=1.21.2. - lame=3.100. - lcms2=2.15. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.0.6. - libass=0.17.1. - libblas=3.9.0. - libbrotlicommon=1.0.9. - libbrotlidec=1.0.9. - libbrotlienc=1.0.9. - libcblas=3.9.0. - libcurl=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13361,deployability,log,logger,13361,m=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webco,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:14971,deployability,loader,loader,14971,4.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlit,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15144,deployability,modul,modules,15144, tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15612,deployability,Version,Versions,15612,". - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16569,deployability,updat,updated,16569,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16600,deployability,Fail,Failed,16600,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:17497,deployability,updat,updated,17497,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1311,energy efficiency,core,core,1311,"ened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2078,energy efficiency,Estimat,Estimated,2078," 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2166,energy efficiency,Estimat,Estimated,2166,"00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:4487,energy efficiency,core,core,4487,on=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.1.3. - libblas=3.9.0. - libbrotlicommon=1.1.0. - libbrotlidec=1.1.0. - libbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:5711,energy efficiency,core,core,5711,bbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonsc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6421,energy efficiency,cpu,cpuinfo,6421,otlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6556,energy efficiency,core,core,6556,.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - to,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:10916,energy efficiency,core,core,10916, fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-lsp=2.2.0. - jupyter_client=8.3.0. - jupyter_core=5.3.1. - jupyter_events=0.7.0. - jupyter_server=2.7.1. - jupyter_server_terminals=0.4.4. - jupyterlab=4.0.5. - jupyterlab_pygments=0.2.2. - jupyterlab_server=2.24.0. - kaleido-core=0.2.1. - kiwisolver=1.4.4. - krb5=1.21.2. - lame=3.100. - lcms2=2.15. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.0.6. - libass=0.17.1. - libblas=3.9.0. - libbrotlicommon=1.0.9. - libbrotlidec=1.0.9. - libbrotlienc=1.0.9. - libcblas=3.9.0. - libcurl=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12216,energy efficiency,core,core,12216,=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13006,energy efficiency,cpu,cpuinfo,13006, - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13155,energy efficiency,core,core,13155,muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:14971,energy efficiency,load,loader,14971,4.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlit,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15316,energy efficiency,estimat,estimator,15316,ri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:201,integrability,version,version,201,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:394,integrability,version,version,394,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:783,integrability,filter,filtered,783,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1482,integrability,filter,filtered,1482,"`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2294,integrability,depend,dependency,2294,"on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2359,integrability,pipelin,pipeline,2359," code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2426,integrability,pipelin,pipeline,2426,"t finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2466,integrability,version,version,2466,"g Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2665,integrability,depend,dependencies,2665,"iable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2843,integrability,api,api-compat,2843,"per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - htt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:4557,integrability,api,api-wrap,4557, - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.1.3. - libblas=3.9.0. - libbrotlicommon=1.1.0. - libbrotlidec=1.1.0. - libbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8562,integrability,wrap,wrapt,8562,on=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8693,integrability,depend,dependencies,8693,yping_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8910,integrability,api,api-compat,8910,0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:11000,integrability,api,api-wrap,11000,reetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-lsp=2.2.0. - jupyter_client=8.3.0. - jupyter_core=5.3.1. - jupyter_events=0.7.0. - jupyter_server=2.7.1. - jupyter_server_terminals=0.4.4. - jupyterlab=4.0.5. - jupyterlab_pygments=0.2.2. - jupyterlab_server=2.24.0. - kaleido-core=0.2.1. - kiwisolver=1.4.4. - krb5=1.21.2. - lame=3.100. - lcms2=2.15. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.0.6. - libass=0.17.1. - libblas=3.9.0. - libbrotlicommon=1.0.9. - libbrotlidec=1.0.9. - libbrotlienc=1.0.9. - libcblas=3.9.0. - libcurl=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15491,integrability,wrap,wrapt,15491,"xau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15612,integrability,Version,Versions,15612,". - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2802,interoperability,bind,bindings,2802,"at vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2843,interoperability,api,api-compat,2843,"per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - htt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:4183,interoperability,specif,specifications,4183,2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.1.3. - libblas=3.9.0. - libbrotlicommon=1.1.0. - libbrotlidec=1.1.0. - libbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:4227,interoperability,format,format-nongpl,4227,y=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.1.3. - libblas=3.9.0. - libbrotlicommon=1.1.0. - libbrotlidec=1.1.0. - libbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:4557,interoperability,api,api-wrap,4557, - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.1.3. - libblas=3.9.0. - libbrotlicommon=1.1.0. - libbrotlidec=1.1.0. - libbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6146,interoperability,platform,platformdirs,6146,=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seabor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6366,interoperability,stub,stubs,6366,safe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8869,interoperability,bind,bindings,8869,=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8910,interoperability,api,api-compat,8910,0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:10615,interoperability,specif,specifications,10615, - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-lsp=2.2.0. - jupyter_client=8.3.0. - jupyter_core=5.3.1. - jupyter_events=0.7.0. - jupyter_server=2.7.1. - jupyter_server_terminals=0.4.4. - jupyterlab=4.0.5. - jupyterlab_pygments=0.2.2. - jupyterlab_server=2.24.0. - kaleido-core=0.2.1. - kiwisolver=1.4.4. - krb5=1.21.2. - lame=3.100. - lcms2=2.15. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.0.6. - libass=0.17.1. - libblas=3.9.0. - libbrotlicommon=1.0.9. - libbrotlidec=1.0.9. - libbrotlienc=1.0.9. - libcblas=3.9.0. - libcurl=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:10658,interoperability,format,format-nongpl,10658,_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-lsp=2.2.0. - jupyter_client=8.3.0. - jupyter_core=5.3.1. - jupyter_events=0.7.0. - jupyter_server=2.7.1. - jupyter_server_terminals=0.4.4. - jupyterlab=4.0.5. - jupyterlab_pygments=0.2.2. - jupyterlab_server=2.24.0. - kaleido-core=0.2.1. - kiwisolver=1.4.4. - krb5=1.21.2. - lame=3.100. - lcms2=2.15. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.0.6. - libass=0.17.1. - libblas=3.9.0. - libbrotlicommon=1.0.9. - libbrotlidec=1.0.9. - libbrotlienc=1.0.9. - libcblas=3.9.0. - libcurl=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:11000,interoperability,api,api-wrap,11000,reetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-lsp=2.2.0. - jupyter_client=8.3.0. - jupyter_core=5.3.1. - jupyter_events=0.7.0. - jupyter_server=2.7.1. - jupyter_server_terminals=0.4.4. - jupyterlab=4.0.5. - jupyterlab_pygments=0.2.2. - jupyterlab_server=2.24.0. - kaleido-core=0.2.1. - kiwisolver=1.4.4. - krb5=1.21.2. - lame=3.100. - lcms2=2.15. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.0.6. - libass=0.17.1. - libblas=3.9.0. - libbrotlicommon=1.0.9. - libbrotlidec=1.0.9. - libbrotlienc=1.0.9. - libcblas=3.9.0. - libcurl=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12749,interoperability,platform,platformdirs,12749,ing=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12951,interoperability,stub,stubs,12951,hjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:201,modifiability,version,version,201,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:394,modifiability,version,version,394,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:914,modifiability,variab,variable,914,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1613,modifiability,variab,variable,1613,"a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2294,modifiability,depend,dependency,2294,"on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2382,modifiability,pac,package,2382,"virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2466,modifiability,version,version,2466,"g Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2503,modifiability,pac,packages,2503,"hat are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entryp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2665,modifiability,depend,dependencies,2665,"iable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2802,modifiability,bind,bindings,2802,"at vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:3429,modifiability,deco,decorator,3429, needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:5961,modifiability,pac,packaging,5961,rbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - read,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7677,modifiability,extens,extensions,7677,util=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - co,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8693,modifiability,depend,dependencies,8693,yping_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8869,modifiability,bind,bindings,8869,=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:9572,modifiability,deco,decorator,9572,```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12516,modifiability,pac,packaging,12516,g=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15144,modifiability,modul,modules,15144, tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15431,modifiability,extens,extensions,15431,2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15612,modifiability,Version,Versions,15612,". - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16125,modifiability,pac,packaging,16125,"5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16441,modifiability,pac,packaged,16441,"5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:17047,modifiability,pac,packaging,17047,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:17365,modifiability,pac,packaged,17365,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1455,performance,time,time,1455,"ng the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2333,performance,perform,performing,2333,"en I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:3195,performance,cach,cached-property,3195,"0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:5782,performance,network,networkx,5782,ibdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6421,performance,cpu,cpuinfo,6421,otlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:9284,performance,cach,cached-property,9284,0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperfram,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12301,performance,network,networkx,12301,expat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastj,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13006,performance,cpu,cpuinfo,13006, - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:14720,performance,cach,cachetools,14720,scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:14971,performance,load,loader,14971,4.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlit,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15579,performance,Error,Error,15579,".2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2574,reliability,fail,failed,2574,"nished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16600,reliability,Fail,Failed,16600,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:816,safety,detect,detected,816,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1515,safety,detect,detected,1515,"m was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2048,safety,Detect,Detected,2048,"ons', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2088,safety,detect,detectable,2088,"ons_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2294,safety,depend,dependency,2294,"on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2447,safety,updat,updated,2447," of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2665,safety,depend,dependencies,2665,"iable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:3540,safety,except,exceptiongroup,3540,an the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6764,safety,log,logger,6764,yncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - uma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7027,safety,valid,validator,7027, patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7054,safety,valid,validator,7054,.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - z,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8693,safety,depend,dependencies,8693,yping_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:9683,safety,except,exceptiongroup,9683,e. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13361,safety,log,logger,13361,m=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webco,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13623,safety,valid,validator,13623,3. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13650,safety,valid,validator,13650,eshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15144,safety,modul,modules,15144, tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15579,safety,Error,Error,15579,".2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16569,safety,updat,updated,16569,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:17497,safety,updat,updated,17497,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:816,security,detect,detected,816,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1515,security,detect,detected,1515,"m was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2048,security,Detect,Detected,2048,"ons', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2088,security,detect,detectable,2088,"ons_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2447,security,updat,updated,2447," of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:3170,security,certif,certificates,3170,"= 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - json",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:3245,security,certif,certifi,3245,"y caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:3482,security,dns,dnspython,3482, details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:4046,security,iso,isoduration,4046,5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=0.1.2. - gffpandas=1.2.2. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.5. - h11=0.14.0. - h2=4.1.0. - h5py=3.11.0. - hdf5=1.14.3. - hpack=4.0.0. - httpcore=1.0.5. - httpx=0.27.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.7. - igraph=0.10.12. - importlib-metadata=7.1.0. - importlib_metadata=7.1.0. - importlib_resources=6.4.0. - ipykernel=6.29.4. - ipython=8.25.0. - isoduration=20.11.0. - jedi=0.19.1. - jinja2=3.1.4. - joblib=1.4.2. - json5=0.9.25. - jsonpointer=2.4. - jsonschema=4.22.0. - jsonschema-specifications=2023.12.1. - jsonschema-with-format-nongpl=4.22.0. - jupyter-lsp=2.2.5. - jupyter_client=8.6.2. - jupyter_core=5.7.2. - jupyter_events=0.10.0. - jupyter_server=2.14.1. - jupyter_server_terminals=0.5.3. - jupyterlab=4.2.2. - jupyterlab_pygments=0.3.0. - jupyterlab_server=2.27.2. - kaleido-core=0.2.1. - kiwisolver=1.4.5. - krb5=1.21.2. - lcms2=2.16. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.1.3. - libblas=3.9.0. - libbrotlicommon=1.1.0. - libbrotlidec=1.1.0. - libbrotlienc=1.1.0. - libcblas=3.9.0. - libcurl=8.8.0. - libcxx=17.0.6. - libdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:5782,security,network,networkx,5782,ibdeflate=1.20. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.6.2. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=13.2.0. - libhwloc=2.10.0. - libiconv=1.17. - libjpeg-turbo=3.0.0. - liblapack=3.9.0. - liblapacke=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.58.0. - libopenblas=0.3.27. - libpng=1.6.43. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.46.0. - libssh2=1.11.0. - libtiff=4.6.0. - libwebp-base=1.4.0. - libxcb=1.15. - libxml2=2.12.7. - libzlib=1.3.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6764,security,log,logger,6764,yncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - uma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7027,security,validat,validator,7027, patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7054,security,validat,validator,7054,.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - z,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7207,security,session,session-info,7207,.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:9259,security,certif,certificates,9259,3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - h,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:9350,security,certif,certifi,9350,insum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:9500,security,cryptograph,cryptography,9500,ystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - j,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:9625,security,dns,dnspython,9625, case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:10467,security,iso,isoduration,10467,.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.1.3. - executing=1.2.0. - expat=2.5.0. - ffmpeg=6.0.0. - filelock=3.12.2. - font-ttf-dejavu-sans-mono=2.37. - font-ttf-inconsolata=3.000. - font-ttf-source-code-pro=2.038. - font-ttf-ubuntu=0.83. - fontconfig=2.14.2. - fonts-conda-ecosystem=1. - fonts-conda-forge=1. - fonttools=4.42.1. - fqdn=1.5.1. - freetype=2.12.1. - fribidi=1.0.10. - get-annotations=0.1.2. - gettext=0.21.1. - gffutils=0.13. - glpk=5.0. - gmp=6.3.0. - gmpy2=2.1.2. - gnutls=3.7.8. - graphite2=1.3.13. - h11=0.14.0. - h2=4.1.0. - h5py=3.9.0. - harfbuzz=7.3.0. - hdf5=1.14.1. - hpack=4.0.0. - httpcore=0.18.0. - hyperframe=6.0.1. - icu=73.2. - idna=3.4. - igraph=0.10.8. - importlib-metadata=6.8.0. - importlib_metadata=6.8.0. - importlib_resources=6.0.1. - ipykernel=6.25.1. - ipython=8.14.0. - isoduration=20.11.0. - jedi=0.19.0. - jinja2=3.1.2. - joblib=1.3.2. - jpeg=9e. - json5=0.9.14. - jsonpointer=2.0. - jsonschema=4.19.0. - jsonschema-specifications=2023.7.1. - jsonschema-with-format-nongpl=4.19.0. - jupyter-lsp=2.2.0. - jupyter_client=8.3.0. - jupyter_core=5.3.1. - jupyter_events=0.7.0. - jupyter_server=2.7.1. - jupyter_server_terminals=0.4.4. - jupyterlab=4.0.5. - jupyterlab_pygments=0.2.2. - jupyterlab_server=2.24.0. - kaleido-core=0.2.1. - kiwisolver=1.4.4. - krb5=1.21.2. - lame=3.100. - lcms2=2.15. - legacy-api-wrap=1.4. - leidenalg=0.10.2. - lerc=4.0.0. - libabseil=20240116.2. - libaec=1.0.6. - libass=0.17.1. - libblas=3.9.0. - libbrotlicommon=1.0.9. - libbrotlidec=1.0.9. - libbrotlienc=1.0.9. - libcblas=3.9.0. - libcurl=8.2.1. - libcxx=16.0.6. - libdeflate=1.17. - libedit=3.1.20191231. - libev=4.33. - libexpat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12301,security,network,networkx,12301,expat=2.5.0. - libffi=3.4.2. - libgfortran=5.0.0. - libgfortran5=12.3.0. - libglib=2.80.0. - libhwloc=2.9.3. - libiconv=1.17. - libidn2=2.3.4. - libintl=0.22.5. - libjpeg-turbo=2.1.4. - liblapack=3.9.0. - libleidenalg=0.11.1. - libllvm14=14.0.6. - libnghttp2=1.52.0. - libopenblas=0.3.23. - libopus=1.3.1. - libpng=1.6.39. - libprotobuf=4.25.3. - libsodium=1.0.18. - libsqlite=3.42.0. - libssh2=1.11.0. - libtasn1=4.19.0. - libtiff=4.5.0. - libunistring=0.9.10. - libuv=1.48.0. - libvpx=1.13.0. - libwebp-base=1.3.1. - libxcb=1.13. - libxml2=2.11.6. - libzlib=1.2.13. - llvm-openmp=16.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastj,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13361,security,log,logger,13361,m=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webco,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13623,security,validat,validator,13623,3. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13650,security,validat,validator,13650,eshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13802,security,session,session-info,13802,- pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:14842,security,auth,auth,14842, simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:14865,security,auth,auth-oauthlib,14865,16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15190,security,rsa,rsa,15190,5.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psut,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16549,security,Session,Session,16549,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:16569,security,updat,updated,16569,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:17477,security,Session,Session,17477,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:17497,security,updat,updated,17497,"hon. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 2024-06-22 00:24. # Failed case. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. astunparse 1.6.3. cffi 1.16.0. colorama 0.4.6. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. defusedxml 0.7.1. dill 0.3.8. google NA. h5py 3.11.0. igraph 0.11.5. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numexpr 2.10.0. numpy 1.26.4. optree 0.11.0. packaging 24.0. pandas 2.2.2. pkg_resources NA. plotly 5.22.0. psutil 5.9.8. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. six 1.16.0. sklearn 1.5.0. texttable 1.7.0. threadpoolctl 3.5.0. torch 2.2.2. torchgen NA. tqdm 4.66.4. typing_extensions NA. wcwidth 0.2.13. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:10:28) [Clang 15.0.7 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-06-22 00:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:1995,testability,Automat,Automatically,1995,"var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2294,testability,depend,dependency,2294,"on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2665,testability,depend,dependencies,2665,"iable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1.0. - colorful=0.5.6. - comm=0.2.2. - contourpy=1.2.1. - cycler=0.12.1. - debugpy=1.8.1. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.8. - dnspython=2.6.1. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1.2.0. - executing=2.0.1. - filelock=3.14.0. - fonttools=4.53.0. - fqdn=1.5.1. - freetype=2.12.1. - get-annotations=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6366,testability,stub,stubs,6366,safe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6764,testability,log,logger,6764,yncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - uma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7250,testability,simpl,simplejson,7250,_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:8693,testability,depend,dependencies,8693,yping_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom=3.5.0. - appnope=0.1.3. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.4.1. - arrow=1.2.3. - asttokens=2.2.1. - async-lru=2.0.4. - attrs=23.1.0. - babel=2.12.1. - backcall=0.2.0. - backports=1.0. - backports.functools_lru_cache=1.6.5. - beautifulsoup4=4.12.2. - bleach=6.0.0. - blosc=1.21.4. - brotli=1.0.9. - brotli-bin=1.0.9. - brotli-python=1.0.9. - bzip2=1.0.8. - c-ares=1.19.1. - c-blosc2=2.10.2. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - cairo=1.18.0. - certifi=2024.6.2. - cffi=1.15.1. - charset-normalizer=3.2.0. - colorama=0.4.6. - colorcet=3.0.1. - colorful=0.5.4. - comm=0.1.4. - contourpy=1.1.0. - cryptography=41.0.4. - cycler=0.11.0. - dav1d=1.2.1. - debugpy=1.6.8. - decorator=5.1.1. - defusedxml=0.7.1. - dill=0.3.7. - dnspython=2.4.2. - entrypoints=0.4. - et_xmlfile=1.1.0. - exceptiongroup=1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12951,testability,stub,stubs,12951,hjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13361,testability,log,logger,13361,m=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webco,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13845,testability,simpl,simplejson,13845,rometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:161,usability,confirm,confirmed,161,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:244,usability,confirm,confirmed,244,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:441,usability,paus,pause,441,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:733,usability,paus,paused,733,"Unable to run Scrublet in v1.10; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Dear `scanpy` developers, . I was exploring the new features in the latest version of Scanpy, but encountered a prolonged pause when running the `sc.pp.scrublet(adata)`. Initially I thought the problem was due to the large size (~100k cells) of the dataset I was exploring (I let it run for almost a whole week and nothing changed). However, even if I switched to my own dataset (unpublished, around 5k celIs), it paused at the same step. . ```. Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... ```. I was running this analysis on my Intel-core iMac. Surprisingly, when I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Autom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:2333,usability,perform,performing,2333,"en I ran the same line of code (under a similar virtual environment) on my M2-chip laptop, it finished in a flash of time. ```Running Scrublet. filtered out 1419 genes that are detected in less than 3 cells. normalizing counts per cell. finished (0:00:00). extracting highly variable genes. finished (0:00:00). --> added. 'highly_variable', boolean vector (adata.var). 'means', float vector (adata.var). 'dispersions', float vector (adata.var). 'dispersions_norm', float vector (adata.var). normalizing counts per cell. finished (0:00:00). normalizing counts per cell. finished (0:00:00). Embedding transcriptomes using PCA... using data matrix X directly. Automatically set threshold at doublet score = 0.42. Detected doublet rate = 0.3%. Estimated detectable doublet fraction = 5.2%. Overall doublet rate:. 	Expected = 5.0%. 	Estimated = 6.6%. Scrublet finished (0:00:14). ```. I'm still not sure what actually caused the problem, but it seems that some dependency inconsistency occurred when performing PCA within the pipeline. Perhaps some package required for the `sc.pp.scrublet()` pipeline needs to be updated to a newer version? Here are the details of the packages in the virtual environment when I ran the code on my desktop (failed case):. ```. channels:. - pytorch. - plotly. - conda-forge. - bioconda. - defaults. dependencies:. - anndata=0.10.7. - anyio=4.4.0. - appnope=0.1.4. - argcomplete=3.3.0. - argh=0.31.2. - argon2-cffi=23.1.0. - argon2-cffi-bindings=21.2.0. - arpack=3.8.0. - array-api-compat=1.7.1. - arrow=1.3.0. - asttokens=2.4.1. - async-lru=2.0.4. - attrs=23.2.0. - babel=2.14.0. - beautifulsoup4=4.12.3. - biopython=1.83. - blas=2.120. - blas-devel=3.9.0. - bleach=6.1.0. - blosc=1.21.5. - brotli=1.1.0. - brotli-bin=1.1.0. - brotli-python=1.1.0. - bzip2=1.0.8. - c-ares=1.28.1. - c-blosc2=2.14.4. - ca-certificates=2024.6.2. - cached-property=1.5.2. - cached_property=1.5.2. - certifi=2024.6.2. - cffi=1.16.0. - charset-normalizer=3.3.2. - colorama=0.4.6. - colorcet=3.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:6280,usability,tool,toolkit,6280,.1. - llvm-openmp=18.1.7. - llvmlite=0.42.0. - louvain=0.8.2. - lz4-c=1.9.4. - markupsafe=2.1.5. - mathjax=2.7.7. - matplotlib=3.8.4. - matplotlib-base=3.8.4. - matplotlib-inline=0.1.7. - mistune=3.0.2. - mkl=2023.2.0. - mkl-devel=2023.2.0. - mkl-include=2023.2.0. - mpc=1.3.1. - mpfr=4.2.1. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.16. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.10.0. - nbconvert-core=7.16.4. - nbformat=5.10.4. - ncurses=6.5. - nest-asyncio=1.6.0. - networkx=3.3. - notebook=7.2.1. - notebook-shim=0.2.4. - numba=0.59.1. - numexpr=2.10.0. - numpy=1.26.4. - openjpeg=2.5.2. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.7.0. - packaging=24.0. - pandas=2.2.2. - pandocfilters=1.5.0. - parso=0.8.4. - patsy=0.5.6. - pexpect=4.9.0. - pickleshare=0.7.5. - pillow=10.3.0. - pip=24.0. - pkgutil-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7115,usability,learn,learn,7115,util-resolve-name=1.3.10. - platformdirs=4.2.2. - plotly=5.22.0. - plotly-orca=1.3.1. - pooch=1.8.2. - prettyprinter=0.18.0. - prometheus_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7250,usability,simpl,simplejson,7250,_client=0.20.0. - prompt-toolkit=3.0.47. - prompt_toolkit=3.0.47. - protobuf=4.25.3. - psutil=5.9.8. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.22. - pyfaidx=0.8.1.1. - pygments=2.18.0. - pymde=0.1.18. - pymongo=4.7.3. - pynndescent=0.5.12. - pyobjc-core=10.2. - pyobjc-framework-cocoa=10.2. - pyparsing=3.1.2. - pysocks=1.7.1. - pytables=3.9.2. - python=3.11.4. - python-dateutil=2.9.0. - python-fastjsonschema=2.19.1. - python-igraph=0.11.5. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:7769,usability,learn,learn,7769,.0.7. - python-kaleido=0.2.1. - python-tzdata=2024.1. - python_abi=3.11. - pytorch=2.2.2. - pytz=2024.1. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=26.0.3. - radian=0.6.12. - rchitect=0.4.6. - readline=8.2. - referencing=0.35.1. - requests=2.32.3. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.18.1. - scanpy=1.10.1. - scikit-learn=1.5.0. - scipy=1.13.1. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.3. - session-info=1.0.0. - setuptools=70.0.0. - simplejson=3.19.2. - six=1.16.0. - snappy=1.2.0. - sniffio=1.3.1. - soupsieve=2.5. - stack_data=0.6.2. - statsmodels=0.14.2. - stdlib-list=0.10.0. - sympy=1.12. - tbb=2021.12.0. - tenacity=8.3.0. - terminado=0.18.1. - texttable=1.7.0. - threadpoolctl=3.5.0. - tinycss2=1.3.0. - tk=8.6.13. - tomli=2.0.1. - torchvision=0.17.2. - tornado=6.4.1. - tqdm=4.66.4. - traitlets=5.14.3. - types-python-dateutil=2.9.0.20240316. - typing-extensions=4.12.2. - typing_extensions=4.12.2. - typing_utils=0.1.0. - tzdata=2024a. - umap-learn=0.5.5. - uri-template=1.3.0. - urllib3=2.2.1. - wcwidth=0.2.13. - webcolors=24.6.0. - webencodings=0.5.1. - websocket-client=1.8.0. - wheel=0.43.0. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.5. - zipp=3.19.2. - zlib-ng=2.0.7. - zstd=1.5.6. - pip:. - absl-py==2.1.0. - astunparse==1.6.3. - bcbio-gff==0.7.1. - flatbuffers==24.3.25. - gast==0.5.4. - google-pasta==0.2.0. - grpcio==1.64.1. - keras==3.3.3. - libclang==18.1.1. - markdown==3.6. - markdown-it-py==3.0.0. - mdurl==0.1.2. - ml-dtypes==0.3.2. - namex==0.0.8. - opt-einsum==3.3.0. - optree==0.11.0. - rich==13.7.1. - tensorboard==2.16.2. - tensorboard-data-server==0.7.2. - tensorflow==2.16.1. - tensorflow-io-gcs-filesystem==0.37.0. - termcolor==2.4.0. - werkzeug==3.0.3. - wrapt==1.16.0. ```. The virtual environment on my laptop (successful case):. ```. channels:. - pytorch. - bioconda. - conda-forge. dependencies:. - adjusttext=1.0.4. - anndata=0.10.5.post1. - anyio=3.7.1. - aom,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:12884,usability,tool,toolkit,12884,6.0.6. - llvmlite=0.40.1. - lz4-c=1.9.4. - markupsafe=2.1.3. - mathjax=2.7.7. - matplotlib=3.7.2. - matplotlib-base=3.7.2. - matplotlib-inline=0.1.6. - mistune=3.0.1. - mpc=1.3.1. - mpfr=4.2.0. - mpmath=1.3.0. - mudata=0.2.3. - multiprocess=0.70.15. - munkres=1.1.4. - muon=0.1.6. - natsort=8.4.0. - nbclient=0.8.0. - nbconvert-core=7.7.4. - nbformat=5.9.2. - ncurses=6.4. - nest-asyncio=1.5.6. - nettle=3.8.1. - networkx=3.1. - nodejs=20.9.0. - notebook=7.0.2. - notebook-shim=0.2.3. - numba=0.57.1. - numexpr=2.8.4. - openh264=2.3.1. - openjpeg=2.5.0. - openpyxl=3.1.2. - openssl=3.3.1. - overrides=7.4.0. - p11-kit=0.24.1. - packaging=23.1. - pandas=2.0.3. - pandocfilters=1.5.0. - param=2.0.2. - parso=0.8.3. - patsy=0.5.3. - pcre2=10.43. - pexpect=4.8.0. - pickleshare=0.7.5. - pillow=9.4.0. - pip=23.2.1. - pixman=0.43.4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13710,usability,learn,learn,13710,4. - pkgutil-resolve-name=1.3.10. - platformdirs=3.10.0. - plotly=5.16.1. - plotly-orca=3.4.2. - pooch=1.7.0. - prettyprinter=0.18.0. - prometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:13845,usability,simpl,simplejson,13845,rometheus_client=0.17.1. - prompt-toolkit=3.0.39. - prompt_toolkit=3.0.39. - psutil=5.9.5. - pthread-stubs=0.4. - ptyprocess=0.7.0. - pure_eval=0.2.2. - py-cpuinfo=9.0.0. - pycparser=2.21. - pyct=0.5.0. - pyfaidx=0.8.1.1. - pygments=2.16.1. - pymde=0.1.18. - pymongo=4.5.0. - pynndescent=0.5.11. - pyobjc-core=9.2. - pyobjc-framework-cocoa=9.2. - pyparsing=3.0.9. - pysocks=1.7.1. - pytables=3.8.0. - python=3.11.4. - python-dateutil=2.8.2. - python-fastjsonschema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:14305,usability,learn,learn,14305,schema=2.18.0. - python-igraph=0.11.3. - python-json-logger=2.0.7. - python-kaleido=0.2.1. - python-tzdata=2023.3. - python_abi=3.11. - pytorch=2.0.1. - pytz=2023.3. - pyvcf3=1.0.3. - pyyaml=6.0.1. - pyzmq=25.1.1. - radian=0.6.7. - rchitect=0.4.1. - readline=8.2. - referencing=0.30.2. - requests=2.31.0. - rfc3339-validator=0.1.4. - rfc3986-validator=0.1.1. - rpds-py=0.9.2. - scanpy=1.10.1. - scikit-learn=1.3.0. - scipy=1.11.2. - seaborn=0.13.2. - seaborn-base=0.13.2. - send2trash=1.8.2. - session-info=1.0.0. - setuptools=68.1.2. - simplejson=3.19.2. - six=1.16.0. - snappy=1.1.10. - sniffio=1.3.0. - soupsieve=2.3.2.post1. - stack_data=0.6.2. - statsmodels=0.14.0. - stdlib-list=0.10.0. - svt-av1=1.6.0. - sympy=1.12. - tbb=2021.11.0. - tenacity=8.2.3. - terminado=0.17.1. - texttable=1.7.0. - threadpoolctl=3.2.0. - tinycss2=1.2.1. - tk=8.6.12. - tomli=2.0.1. - torchvision=0.15.2. - tornado=6.3.3. - traitlets=5.9.0. - typing_extensions=4.8.0. - typing_utils=0.1.0. - tzdata=2023c. - umap-learn=0.5.5. - uri-template=1.3.0. - wcwidth=0.2.6. - webcolors=1.13. - webencodings=0.5.1. - websocket-client=1.6.2. - wheel=0.41.2. - x264=1!164.3095. - x265=3.5. - xlrd=1.2.0. - xorg-libxau=1.0.11. - xorg-libxdmcp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - ten,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15515,usability,Minim,Minimal,15515,"cp=1.1.3. - xz=5.2.6. - yaml=0.2.5. - zeromq=4.3.4. - zipp=3.16.2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:15579,usability,Error,Error,15579,".2. - zlib=1.2.13. - zlib-ng=2.0.7. - zstd=1.5.2. - pip:. - absl-py==1.4.0. - astunparse==1.6.3. - bcbio-gff==0.7.0. - biopython==1.81. - cachetools==5.3.1. - click==8.1.7. - flatbuffers==23.5.26. - gast==0.4.0. - geoparse==2.0.3. - gffpandas==1.2.0. - google-auth==2.22.0. - google-auth-oauthlib==1.0.0. - google-pasta==0.2.0. - grpcio==1.57.0. - imageio==2.34.1. - keras==2.13.1. - lazy-loader==0.4. - libclang==16.0.6. - louvain==0.8.2. - markdown==3.4.4. - numpy==1.24.3. - oauthlib==3.2.2. - opt-einsum==3.3.0. - protobuf==4.24.1. - pyasn1==0.5.0. - pyasn1-modules==0.3.0. - requests-oauthlib==1.3.1. - rsa==4.9. - scikit-image==0.24.0. - tensorboard==2.13.0. - tensorboard-data-server==0.7.1. - tensorflow==2.13.0. - tensorflow-estimator==2.13.0. - tensorflow-macos==2.13.0. - termcolor==2.3.0. - tifffile==2024.6.18. - tqdm==4.66.1. - typing-extensions==4.5.0. - urllib3==1.26.16. - werkzeug==2.3.7. - wrapt==1.15.0. ```. ### Minimal code sample. ```python. sc.pp.scrublet(adata). ```. ### Error output. _No response_. ### Versions. <details>. ```. # Successful case. -----. anndata 0.10.5.post1. scanpy 1.10.1. -----. PIL 9.4.0. astunparse 1.6.3. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. dill 0.3.7. gmpy2 2.1.2. google NA. h5py 3.9.0. igraph 0.11.3. joblib 1.3.2. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.1. louvain 0.8.2. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. pkg_resources NA. plotly 5.16.1. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.1. tqdm 4.66.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]. macOS-14.3-arm64-arm-64bit. -----. Session information updated at 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3117:489,integrability,batch,batch,489,"FindConservedMarkers implementaion in Scanpy; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hi, thanks for your efforts for maintaining this wonderful framework! I was wondering if there is an implementaion of Seurat FindConservedMarkers function in Scanpy, which can perform DGE analysis per group(e.g datasets) then combine them. It could be extreme useful especially when batch effects exist. Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3117
https://github.com/scverse/scanpy/issues/3117:118,modifiability,paramet,parameters,118,"FindConservedMarkers implementaion in Scanpy; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hi, thanks for your efforts for maintaining this wonderful framework! I was wondering if there is an implementaion of Seurat FindConservedMarkers function in Scanpy, which can perform DGE analysis per group(e.g datasets) then combine them. It could be extreme useful especially when batch effects exist. Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3117
https://github.com/scverse/scanpy/issues/3117:238,modifiability,maintain,maintaining,238,"FindConservedMarkers implementaion in Scanpy; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hi, thanks for your efforts for maintaining this wonderful framework! I was wondering if there is an implementaion of Seurat FindConservedMarkers function in Scanpy, which can perform DGE analysis per group(e.g datasets) then combine them. It could be extreme useful especially when batch effects exist. Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3117
https://github.com/scverse/scanpy/issues/3117:382,performance,perform,perform,382,"FindConservedMarkers implementaion in Scanpy; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hi, thanks for your efforts for maintaining this wonderful framework! I was wondering if there is an implementaion of Seurat FindConservedMarkers function in Scanpy, which can perform DGE analysis per group(e.g datasets) then combine them. It could be extreme useful especially when batch effects exist. Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3117
https://github.com/scverse/scanpy/issues/3117:489,performance,batch,batch,489,"FindConservedMarkers implementaion in Scanpy; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hi, thanks for your efforts for maintaining this wonderful framework! I was wondering if there is an implementaion of Seurat FindConservedMarkers function in Scanpy, which can perform DGE analysis per group(e.g datasets) then combine them. It could be extreme useful especially when batch effects exist. Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3117
https://github.com/scverse/scanpy/issues/3117:238,safety,maintain,maintaining,238,"FindConservedMarkers implementaion in Scanpy; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hi, thanks for your efforts for maintaining this wonderful framework! I was wondering if there is an implementaion of Seurat FindConservedMarkers function in Scanpy, which can perform DGE analysis per group(e.g datasets) then combine them. It could be extreme useful especially when batch effects exist. Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3117
https://github.com/scverse/scanpy/issues/3117:382,usability,perform,perform,382,"FindConservedMarkers implementaion in Scanpy; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hi, thanks for your efforts for maintaining this wonderful framework! I was wondering if there is an implementaion of Seurat FindConservedMarkers function in Scanpy, which can perform DGE analysis per group(e.g datasets) then combine them. It could be extreme useful especially when batch effects exist. Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3117
https://github.com/scverse/scanpy/issues/3118:18,availability,error,errors,18,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:214,availability,error,errors,214,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:607,availability,operat,operate,607,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:380,deployability,continu,continue,380,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:972,deployability,scale,scale,972,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:1036,deployability,observ,observations,1036,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:972,energy efficiency,scale,scale,972,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:128,integrability,filter,filter,128,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:983,integrability,repositor,repository,983,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:983,interoperability,repositor,repository,983,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:972,modifiability,scal,scale,972,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:18,performance,error,errors,18,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:214,performance,error,errors,214,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:697,performance,perform,performing,697,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:972,performance,scale,scale,972,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:1075,reliability,pra,practice,1075,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:18,safety,error,errors,18,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:214,safety,error,errors,214,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:1036,testability,observ,observations,1036,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:18,usability,error,errors,18,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:214,usability,error,errors,214,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/issues/3118:697,usability,perform,performing,697,"rank genes groups errors on less than 2 cells in a category; Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118
https://github.com/scverse/scanpy/pull/3120:433,deployability,releas,release,433,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:458,deployability,Releas,Release,458,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:235,safety,review,review,235,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:335,safety,Test,Tests,335,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:235,testability,review,review,235,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:335,testability,Test,Tests,335,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:86,usability,guid,guidelines,86,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:117,usability,guid,guide,117,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:213,usability,workflow,workflow,213,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3120:319,usability,Close,Closes,319,Prepare 1.10.2; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3120
https://github.com/scverse/scanpy/pull/3121:17,deployability,releas,release,17,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:42,deployability,releas,release,42,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:468,deployability,releas,release,468,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:493,deployability,Releas,Release,493,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:270,safety,review,review,270,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:370,safety,Test,Tests,370,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:270,testability,review,review,270,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:370,testability,Test,Tests,370,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:121,usability,guid,guidelines,121,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:152,usability,guid,guide,152,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:248,usability,workflow,workflow,248,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3121:354,usability,Close,Closes,354,(chore): prepare release notes for 0.10.2 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121
https://github.com/scverse/scanpy/pull/3122:28,deployability,releas,release,28,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:468,deployability,releas,release,468,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:493,deployability,Releas,Release,493,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:270,safety,review,review,270,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:370,safety,Test,Tests,370,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:270,testability,review,review,270,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:370,testability,Test,Tests,370,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:36,usability,document,documentation,36,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:121,usability,guid,guidelines,121,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:152,usability,guid,guide,152,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:248,usability,workflow,workflow,248,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3122:354,usability,Close,Closes,354,(chore): add preparation-of-release documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/pull/3123:53,deployability,releas,release,53,Backport PR #3121 on branch 1.10.x ((chore): prepare release notes for 0.10.2 release); Backport PR #3121: (chore): prepare release notes for 0.10.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3123
https://github.com/scverse/scanpy/pull/3123:78,deployability,releas,release,78,Backport PR #3121 on branch 1.10.x ((chore): prepare release notes for 0.10.2 release); Backport PR #3121: (chore): prepare release notes for 0.10.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3123
https://github.com/scverse/scanpy/pull/3123:124,deployability,releas,release,124,Backport PR #3121 on branch 1.10.x ((chore): prepare release notes for 0.10.2 release); Backport PR #3121: (chore): prepare release notes for 0.10.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3123
https://github.com/scverse/scanpy/pull/3123:149,deployability,releas,release,149,Backport PR #3121 on branch 1.10.x ((chore): prepare release notes for 0.10.2 release); Backport PR #3121: (chore): prepare release notes for 0.10.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3123
https://github.com/scverse/scanpy/issues/3124:25,availability,failur,failures,25,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:25,deployability,fail,failures,25,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:263,modifiability,maintain,maintain,263,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:25,performance,failur,failures,25,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:25,reliability,fail,failures,25,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:20,safety,test,test,20,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:180,safety,test,test,180,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:263,safety,maintain,maintain,263,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:20,testability,test,test,20,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:180,testability,test,test,180,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/issues/3124:213,usability,effectiv,effectively,213,Fix all the various test failures; - [x] #2866. - [ ] #3068. - [x] https://github.com/scverse/anndata/pull/1537. - [ ] Maybe also mark the frequently broken `ebi_expression_atlas` test as `xfail(strict=False)` to effectively disable it. Scanpy is getting hard to maintain due to this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124
https://github.com/scverse/scanpy/pull/3125:451,deployability,releas,release,451,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:476,deployability,Releas,Release,476,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:249,safety,review,review,249,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:353,safety,Test,Tests,353,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:249,testability,review,review,249,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:353,testability,Test,Tests,353,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:100,usability,guid,guidelines,100,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:131,usability,guid,guide,131,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:227,usability,workflow,workflow,227,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/pull/3125:333,usability,Close,Closes,333,Skip scanorama on Python 3.9; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Closes #2866. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: technical fix.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3125
https://github.com/scverse/scanpy/issues/3127:464,availability,down,downstream,464,"`elem_mul` in variance calculation should use `float64` casting; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1148,availability,down,downstream,1148,"not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1793,availability,Error,Error,1793,"in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:233,deployability,version,version,233,"`elem_mul` in variance calculation should use `float64` casting; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1238,deployability,releas,release,1238,"f scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1334,deployability,build,buildId,1334,"at happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1352,deployability,log,logs,1352,"n we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1830,deployability,Version,Versions,1830,"cverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:3048,deployability,updat,updated,3048,"t, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.0.2.5)]. macOS-13.6.1-arm64-arm-64bit. -----. Session information updated at 2024-06-26 16:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1976,energy efficiency,cloud,cloudpickle,1976,"n multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:233,integrability,version,version,233,"`elem_mul` in variance calculation should use `float64` casting; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1830,integrability,Version,Versions,1830,"cverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:233,modifiability,version,version,233,"`elem_mul` in variance calculation should use `float64` casting; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1830,modifiability,Version,Versions,1830,"cverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:2066,modifiability,deco,decorator,2066,"oing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.0.2.5)]. macOS-13.6.1-arm64-arm-64bit. -----. Session information updated at 2024-06-26 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:2422,modifiability,pac,packaging,2422,"t, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.0.2.5)]. macOS-13.6.1-arm64-arm-64bit. -----. Session information updated at 2024-06-26 16:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1793,performance,Error,Error,1793,"in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1207,safety,reme,remedy,1207,"g exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1352,safety,log,logs,1352,"n we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1793,safety,Error,Error,1793,"in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:3048,safety,updat,updated,3048,"t, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.0.2.5)]. macOS-13.6.1-arm64-arm-64bit. -----. Session information updated at 2024-06-26 16:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1352,security,log,logs,1352,"n we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:3028,security,Session,Session,3028,"t, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.0.2.5)]. macOS-13.6.1-arm64-arm-64bit. -----. Session information updated at 2024-06-26 16:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:3048,security,updat,updated,3048,"t, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.0.2.5)]. macOS-13.6.1-arm64-arm-64bit. -----. Session information updated at 2024-06-26 16:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:803,testability,context,context,803,"`elem_mul` in variance calculation should use `float64` casting; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1352,testability,log,logs,1352,"n we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:193,usability,confirm,confirmed,193,"`elem_mul` in variance calculation should use `float64` casting; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:276,usability,confirm,confirmed,276,"`elem_mul` in variance calculation should use `float64` casting; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1599,usability,Minim,Minimal,1599,"62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. sci",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:1793,usability,Error,Error,1793,"in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/issues/3127:2831,usability,tool,toolz,2831,"t, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171. <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python. import numpy as np. arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")). print(np.multiply(arr, arr)). ```. ### Error output. ```pytb. N/A. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.0rc2.dev74+g1c98fd19. -----. IPython 8.24.0. PIL 10.3.0. asciitree NA. asttokens NA. cloudpickle 3.0.0. cycler 0.12.1. cython_runtime NA. dask 2024.5.1. dateutil 2.9.0.post0. decorator 5.1.1. defusedxml 0.7.1. distutils 3.12.3. executing 2.0.1. h5py 3.11.0. igraph 0.11.5. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. louvain 0.8.2. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. msgpack 1.0.8. natsort 8.4.0. numba 0.59.1. numcodecs 0.12.1. numpy 1.26.4. packaging 24.0. pandas 2.2.2. parso 0.8.4. pkg_resources NA. prompt_toolkit 3.0.45. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pygments 2.18.0. pyparsing 3.1.2. pytz 2024.1. scipy 1.13.1. session_info 1.0.0. setuptools 70.0.0. setuptools_scm NA. sitecustomize NA. six 1.16.0. sklearn 1.5.0. sparse 0.15.4. sphinxcontrib NA. stack_data 0.6.3. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. traitlets 5.14.3. wcwidth 0.2.13. yaml 6.0.1. zarr 2.18.2. -----. Python 3.12.3 (main, Apr 9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.1.0.2.5)]. macOS-13.6.1-arm64-arm-64bit. -----. Session information updated at 2024-06-26 16:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127
https://github.com/scverse/scanpy/pull/3128:58,integrability,batch,batch,58,Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset; Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3128
https://github.com/scverse/scanpy/pull/3128:72,integrability,sub,subset,72,Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset; Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3128
https://github.com/scverse/scanpy/pull/3128:138,integrability,batch,batch,138,Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset; Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3128
https://github.com/scverse/scanpy/pull/3128:152,integrability,sub,subset,152,Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset; Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3128
https://github.com/scverse/scanpy/pull/3128:58,performance,batch,batch,58,Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset; Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3128
https://github.com/scverse/scanpy/pull/3128:138,performance,batch,batch,138,Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset; Backport PR #3042: hvg flavors seurat and cellranger with batch: bug in subset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3128
https://github.com/scverse/scanpy/issues/3129:0,availability,cluster,cluster,0,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:365,availability,cluster,clustering,365,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:490,availability,cluster,clustering,490,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:722,availability,cluster,clusters,722,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:893,availability,cluster,clustered,893,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:0,deployability,cluster,cluster,0,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:365,deployability,cluster,clustering,365,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:490,deployability,cluster,clustering,490,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:722,deployability,cluster,clusters,722,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:893,deployability,cluster,clustered,893,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:57,energy efficiency,heat,heatmap,57,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:259,energy efficiency,heat,heatmap,259,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:1109,energy efficiency,current,current,1109,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:342,interoperability,specif,specified,342,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:140,modifiability,paramet,parameters,140,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:998,performance,time,time,998,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:1022,performance,time,time,1022,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:923,security,sign,signatures,923,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:389,usability,help,helpful,389,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/issues/3129:696,usability,help,helpful,696,"cluster cells within groups when plotting with scanpy.pl.heatmap(); ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. I find the function `scanpy.pl.heatmap()` useful to see how a gene is expressed in single cells within each group specified. I think the clustering of groups is helpful as well. However, I find this function lacking one crucial functionality which is additional clustering of cells within a group. . In case of grouping per cell types it might not be that important, but imagine one was to group by samples and plot some pathway gene expression. Then it would be very helpful to be able to see clusters of cells within each group (e.g. sample) expressing some pathways and not expressing the others. Right now seeing patterns is much harder since the cells are not clustered by their expression signatures. . I suppose this would require running dendrogram twice -- one time for groups and one time for cells within each group. Not sure how to implement a way around this with the current function implementation without rewriting the internal code for `_reorder_categories_after_dendrogram()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3129
https://github.com/scverse/scanpy/pull/3132:64,deployability,releas,release,64,Backport PR #3122 on branch 1.10.x ((chore): add preparation-of-release documentation); Backport PR #3122: (chore): add preparation-of-release documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3132
https://github.com/scverse/scanpy/pull/3132:135,deployability,releas,release,135,Backport PR #3122 on branch 1.10.x ((chore): add preparation-of-release documentation); Backport PR #3122: (chore): add preparation-of-release documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3132
https://github.com/scverse/scanpy/pull/3132:72,usability,document,documentation,72,Backport PR #3122 on branch 1.10.x ((chore): add preparation-of-release documentation); Backport PR #3122: (chore): add preparation-of-release documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3132
https://github.com/scverse/scanpy/pull/3132:143,usability,document,documentation,143,Backport PR #3122 on branch 1.10.x ((chore): add preparation-of-release documentation); Backport PR #3122: (chore): add preparation-of-release documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3132
https://github.com/scverse/scanpy/issues/3136:18,deployability,API,API,18,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:218,deployability,api,api,218,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:373,deployability,api,api-dev,373,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:313,energy efficiency,CPU,CPU,313,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:317,energy efficiency,GPU,GPU,317,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:18,integrability,API,API,18,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:218,integrability,api,api,218,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:373,integrability,api,api-dev,373,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:18,interoperability,API,API,18,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:218,interoperability,api,api,218,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:282,interoperability,interoperab,interoperability,282,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:373,interoperability,api,api-dev,373,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:431,interoperability,format,format,431,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:120,modifiability,paramet,parameters,120,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:282,modifiability,interop,interoperability,282,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:313,performance,CPU,CPU,313,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3136:317,performance,GPU,GPU,317,Investigate Array API usage in scanpy codebase; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The array api is somewhat mature to the point of being using in scipy for interoperability between dense CPU/GPU functions (see https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html). It is coming with the new sparse format that may come into existence: https://github.com/pydata/sparse/discussions/618. So it would be good to start experimenting with this in scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3136
https://github.com/scverse/scanpy/issues/3137:131,testability,simpl,simple,131,Investigate SquidPy tools used in scRNAseq-only analyses; ### What kind of feature would you like to request? New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? ### Please describe your wishes. LigRec and so on. cc @Intron7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:20,usability,tool,tools,20,Investigate SquidPy tools used in scRNAseq-only analyses; ### What kind of feature would you like to request? New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? ### Please describe your wishes. LigRec and so on. cc @Intron7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:123,usability,tool,tool,123,Investigate SquidPy tools used in scRNAseq-only analyses; ### What kind of feature would you like to request? New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? ### Please describe your wishes. LigRec and so on. cc @Intron7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:131,usability,simpl,simple,131,Investigate SquidPy tools used in scRNAseq-only analyses; ### What kind of feature would you like to request? New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? ### Please describe your wishes. LigRec and so on. cc @Intron7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:147,usability,tool,tool,147,Investigate SquidPy tools used in scRNAseq-only analyses; ### What kind of feature would you like to request? New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? ### Please describe your wishes. LigRec and so on. cc @Intron7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:195,usability,tool,tools,195,Investigate SquidPy tools used in scRNAseq-only analyses; ### What kind of feature would you like to request? New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? ### Please describe your wishes. LigRec and so on. cc @Intron7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/pull/3138:655,deployability,releas,release,655,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:680,deployability,Releas,Release,680,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:4,modifiability,layer,layer,4,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:309,modifiability,layer,layer,309,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:403,modifiability,layer,layer,403,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:272,safety,review,review,272,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:557,safety,Test,Tests,557,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:272,testability,review,review,272,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:285,testability,Simpl,Simple,285,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:557,testability,Test,Tests,557,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:123,usability,guid,guidelines,123,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:154,usability,guid,guide,154,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:250,usability,workflow,workflow,250,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:285,usability,Simpl,Simple,285,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/pull/3138:541,usability,Close,Closes,541,add layer argument for sc.tl.score_genes_cell_cycle; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138
https://github.com/scverse/scanpy/issues/3139:482,availability,Error,Error,482,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:731,availability,toler,tolerance,731,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1073,availability,toler,tolerance,1073,"ecked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:184,deployability,version,version,184,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1224,deployability,Version,Versions,1224,"onfirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:2655,deployability,updat,updated,2655,"5]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:184,integrability,version,version,184,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1224,integrability,Version,Versions,1224,"onfirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1179,interoperability,coordinat,coordinates,1179,"ersion of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1940,interoperability,platform,platformdirs,1940,"5]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:184,modifiability,version,version,184,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:372,modifiability,paramet,parameter,372,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:583,modifiability,pac,packages,583,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:930,modifiability,pac,packages,930,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1224,modifiability,Version,Versions,1224,"onfirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1526,modifiability,deco,decorator,1526,"/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1832,modifiability,pac,packaging,1832,"5]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:482,performance,Error,Error,482,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:390,reliability,doe,doesn,390,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:731,reliability,toleran,tolerance,731,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1073,reliability,toleran,tolerance,1073,"ecked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:482,safety,Error,Error,482,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:2655,safety,updat,updated,2655,"5]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:1401,security,certif,certifi,1401," ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. trai",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:2281,security,soc,socks,2281,"5]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:2635,security,Session,Session,2635,"5]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:2655,security,updat,updated,2655,"5]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:144,usability,confirm,confirmed,144,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:227,usability,confirm,confirmed,227,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:410,usability,Minim,Minimal,410,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:482,usability,Error,Error,482,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:614,usability,User,UserWarning,614,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:961,usability,User,UserWarning,961,"A umap warning; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python. sc.tl.umap(adata, maxiter=50). ```. ### Error output. ```pytb. computing UMAP. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies . [0.01180801 0.01616286 0.01491355]. not reaching the requested tolerance 1e-08. Use iteration 19 instead with accuracy . 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies . [0.0114102 0.01466 0.01555016]. not reaching the requested tolerance 1e-08. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (1:07:21). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3140:420,availability,error,error,420,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:552,availability,Error,Error,552,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7826,availability,error,errors,7826,"(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:207,deployability,version,version,207,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1366,deployability,log,log,1366," and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1561,deployability,scale,scale,1561,". ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1763,deployability,Stack,StackedViolin,1763,", groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 416 ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size. 417 ). 419 # turn on axis for `ax` as this is turned off. 420 # by make_grid_spec when the axis is subdivided earlier. 421 ax.set_fra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:2405,deployability,Stack,StackedViolin,2405,"title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 416 ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size. 417 ). 419 # turn on axis for `ax` as this is turned off. 420 # by make_grid_spec when the axis is subdivided earlier. 421 ax.set_frame_on(True). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:537, in StackedViolin._make_rows_of_violinplots(self, ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size). 531 # because of the renamed matrix columns here. 532 # we need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:2888,deployability,Stack,StackedViolin,2888,"envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 416 ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size. 417 ). 419 # turn on axis for `ax` as this is turned off. 420 # by make_grid_spec when the axis is subdivided earlier. 421 ax.set_frame_on(True). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:537, in StackedViolin._make_rows_of_violinplots(self, ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size). 531 # because of the renamed matrix columns here. 532 # we need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, sp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:4059,deployability,scale,scale,4059,"e need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs). 1767 kde_kws = dict(cut=cut, gridsize=gridsize, bw_method=bw_method, bw_adjust=bw_adjust). 1768 inner_kws = {} if inner_kws is None else inner_kws.copy(). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 104",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5253,deployability,observ,observation,5253,"). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5290,deployability,observ,observations,5290,"h=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6545,deployability,updat,update,6545,"ta is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7751,deployability,Updat,Update,7751,"12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8494,deployability,Version,Versions,8494,". --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_cli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:10402,deployability,updat,updated,10402,"expected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1561,energy efficiency,scale,scale,1561,". ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:4059,energy efficiency,scale,scale,4059,"e need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs). 1767 kde_kws = dict(cut=cut, gridsize=gridsize, bw_method=bw_method, bw_adjust=bw_adjust). 1768 inner_kws = {} if inner_kws is None else inner_kws.copy(). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 104",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8769,energy efficiency,cloud,cloudpickle,8769," without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. reques",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:207,integrability,version,version,207,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:922,integrability,wrap,wrapper,922,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:975,integrability,wrap,wraps,975,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:2736,integrability,sub,subdivided,2736,". 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 416 ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size. 417 ). 419 # turn on axis for `ax` as this is turned off. 420 # by make_grid_spec when the axis is subdivided earlier. 421 ax.set_frame_on(True). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:537, in StackedViolin._make_rows_of_violinplots(self, ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size). 531 # because of the renamed matrix columns here. 532 # we need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5476,integrability,wrap,wraps,5476,"y_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 56",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8494,integrability,Version,Versions,8494,". --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_cli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:922,interoperability,wrapper,wrapper,922,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:4015,interoperability,format,formatter,4015,"f the renamed matrix columns here. 532 # we need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs). 1767 kde_kws = dict(cut=cut, gridsize=gridsize, bw_method=bw_method, bw_adjust=bw_adjust). 1768 inner_kws = {} if inner_kws is None else inner_kws.copy(). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5713,interoperability,bind,bind,5713,"env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8323,interoperability,format,format,8323,"ntialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:9464,interoperability,platform,platformdirs,9464,"expected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:207,modifiability,version,version,207,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:858,modifiability,pac,packages,858,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1272,modifiability,pac,packages,1272,"on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", le",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1529,modifiability,layer,layer,1529,"ation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1561,modifiability,scal,scale,1561,". ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1930,modifiability,pac,packages,1930,"als>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 416 ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size. 417 ). 419 # turn on axis for `ax` as this is turned off. 420 # by make_grid_spec when the axis is subdivided earlier. 421 ax.set_frame_on(True). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:537, in StackedViolin._make_rows_of_violinplots(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:2353,modifiability,pac,packages,2353,"groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 416 ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size. 417 ). 419 # turn on axis for `ax` as this is turned off. 420 # by make_grid_spec when the axis is subdivided earlier. 421 ax.set_frame_on(True). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:537, in StackedViolin._make_rows_of_violinplots(self, ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size). 531 # because of the renamed matrix columns here. 532 # we need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:2836,modifiability,pac,packages,2836,".autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 416 ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size. 417 ). 419 # turn on axis for `ax` as this is turned off. 420 # by make_grid_spec when the axis is subdivided earlier. 421 ax.set_frame_on(True). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:537, in StackedViolin._make_rows_of_violinplots(self, ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size). 531 # because of the renamed matrix columns here. 532 # we need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_ord",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:3757,modifiability,pac,packages,3757,"x.set_frame_on(True). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:537, in StackedViolin._make_rows_of_violinplots(self, ax, _matrix, colormap_array, _color_df, x_spacer_size, y_spacer_size). 531 # because of the renamed matrix columns here. 532 # we need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs). 1767 kde_kws = dict(cut=cut, gridsize=gridsize, bw_method=bw_method, bw_adjust=bw_adjust). 1768 inner_kws = {} if inner_kws is None else inner_kws.copy(). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:4059,modifiability,scal,scale,4059,"e need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs). 1767 kde_kws = dict(cut=cut, gridsize=gridsize, bw_method=bw_method, bw_adjust=bw_adjust). 1768 inner_kws = {} if inner_kws is None else inner_kws.copy(). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 104",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:4739,modifiability,pac,packages,4739,"thon3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs). 1767 kde_kws = dict(cut=cut, gridsize=gridsize, bw_method=bw_method, bw_adjust=bw_adjust). 1768 inner_kws = {} if inner_kws is None else inner_kws.copy(). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 147",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5359,modifiability,pac,packages,5359," color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5713,modifiability,bind,bind,5713,"env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5886,modifiability,pac,packages,5886,"sity_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6287,modifiability,pac,packages,6287,"bservations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6762,modifiability,pac,packages,6762,"rguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6955,modifiability,Paramet,Parameters,6955," x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7187,modifiability,pac,packages,7187,"rpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7616,modifiability,pac,packages,7616,"e, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7901,modifiability,maintain,maintain,7901,"=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8124,modifiability,pac,packages,8124,"sed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8494,modifiability,Version,Versions,8494,". --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_cli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8886,modifiability,deco,decorator,8886,"ion is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:9435,modifiability,pac,packaging,9435,"t an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:10257,modifiability,pac,packaged,10257,"expected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:420,performance,error,error,420,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:552,performance,Error,Error,552,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1561,performance,scale,scale,1561,". ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:415, in StackedViolin._mainplot(self, ax). 413 x_spacer_size = self.plot_x_padding. 414 y_spacer_size = self.plot_y_padding. --> 415 self._make_rows_of_violinplots(. 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:4059,performance,scale,scale,4059,"e need to use this instead of the 'row_label'. 533 # (in _color_df the values are not renamed as those. 534 # values will be used to label the ticks). 535 _df = df[df.genes == _matrix.columns[idx]]. --> 537 row_ax = sns.violinplot(. 538 x=x,. 539 y=""values"",. 540 data=_df,. 541 orient=""vertical"",. 542 ax=row_ax,. 543 # use a single `color`` if row_colors[idx] is defined. 544 # else use the palette. 545 hue=None if palette_colors is None else x,. 546 palette=palette_colors,. 547 color=row_colors[idx],. 548 **self.kwds,. 549 ). 551 if self.stripplot:. 552 row_ax = sns.stripplot(. 553 x=x,. 554 y=""values"",. (...). 559 ax=row_ax,. 560 ). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1770, in violinplot(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs). 1767 kde_kws = dict(cut=cut, gridsize=gridsize, bw_method=bw_method, bw_adjust=bw_adjust). 1768 inner_kws = {} if inner_kws is None else inner_kws.copy(). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 104",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6568,performance,autosc,autoscale,6568,"rn func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7826,performance,error,errors,7826,"(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:420,safety,error,error,420,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:552,safety,Error,Error,552,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1366,safety,log,log,1366," and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6545,safety,updat,update,6545,"ta is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7751,safety,Updat,Update,7751,"12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7826,safety,error,errors,7826,"(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7901,safety,maintain,maintain,7901,"=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:10402,safety,updat,updated,10402,"expected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:529,security,rotat,rotation,529,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:790,security,rotat,rotation,790,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1366,security,log,log,1366," and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6545,security,updat,update,6545,"ta is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7751,security,Updat,Update,7751,"12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8474,security,rotat,rotation,8474,"_path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:8710,security,certif,certifi,8710,"pdate(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:9022,security,iso,isoduration,9022,"keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:10382,security,Session,Session,10382,"expected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:10402,security,updat,updated,10402,"expected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:666,testability,Trace,Traceback,666,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:1366,testability,log,log,1366," and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self). 789 return_ax_dict[""gene_group_ax""] = gene_groups_ax. 791 # plot the mainplot. --> 792 normalize = self._mainplot(main_ax). 794 # code from pandas.plot in add_totals adds. 795 # minor ticks that need to be removed. 796 main_ax.yaxis.set_tick_params(which=""minor"", left=False, right=False). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5253,testability,observ,observation,5253,"). -> 1770 p.plot_violins(. 1771 width=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:5290,testability,observ,observations,5290,"h=width,. 1772 dodge=dodge,. 1773 gap=gap,. 1774 split=split,. 1775 color=color,. 1776 fill=fill,. 1777 linecolor=linecolor,. 1778 linewidth=linewidth,. 1779 inner=inner,. 1780 density_norm=density_norm,. 1781 common_norm=common_norm,. 1782 kde_kws=kde_kws,. 1783 inner_kws=inner_kws,. 1784 plot_kws=kwargs,. 1785 ). 1787 p._add_axis_labels(ax). 1788 p._adjust_cat_axis(ax, axis=p.orient). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/seaborn/categorical.py:1047, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1045 # Plot the main violin body. 1046 plot_func = {""x"": ax.fill_betweenx, ""y"": ax.fill_between}[self.orient]. -> 1047 plot_func(. 1048 inv_val(data[value_var]),. 1049 inv_pos(data[self.orient] - offsets[0]),. 1050 inv_pos(data[self.orient] + offsets[1]),. 1051 **violin[""kwargs""]. 1052 ). 1054 # Adjust the observation data. 1055 obs = violin[""observations""]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1470 @functools.wraps(func). 1471 def inner(ax, *args, data=None, **kwargs):. 1472 if data is None:. -> 1473 return func(. 1474 ax,. 1475 *map(sanitize_sequence, args),. 1476 **{k: sanitize_sequence(v) for k, v in kwargs.items()}). 1478 bound = new_sig.bind(ax, *args, **kwargs). 1479 auto_label = (bound.arguments.get(label_namer). 1480 or bound.kwargs.get(label_namer)). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:167,usability,confirm,confirmed,167,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:250,usability,confirm,confirmed,250,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:347,usability,workflow,workflow,347,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:420,usability,error,error,420,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:437,usability,Minim,Minimal,437,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:552,usability,Error,Error,552,"AttributeError (sc.pl.stacked_violin); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python. sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90). ```. ### Error output. ```pytb. --------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[51], line 1. ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds). 823 if return_fig:. 824 return vp. --> 825 vp.make_figure(). 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save). 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6850,usability,close,closed,6850,"vs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:6915,usability,close,closed,6915,"y:5662, in Axes.fill_betweenx(self, y, x1, x2, where, step, interpolate, **kwargs). 5660 def fill_betweenx(self, y, x1, x2=0, where=None,. 5661 step=None, interpolate=False, **kwargs):. -> 5662 return self._fill_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcomp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7125,usability,close,closed,7125,"l_between_x_or_y(. 5663 ""y"", y, x1, x2,. 5664 where=where, interpolate=interpolate, step=step, **kwargs). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5629, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs). 5625 pts = pts[:, ::-1]. 5627 polys.append(pts). -> 5629 collection = mcoll.PolyCollection(polys, **kwargs). 5631 # now update the datalim and autoscale. 5632 pts = np.vstack([np.hstack([ind[where, None], dep1[where, None]]),. 5633 np.hstack([ind[where, None], dep2[where, None]])]). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:7826,usability,error,errors,7826,"(self, verts, sizes, closed, **kwargs). 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):. 1179 """""". 1180 Parameters. 1181 ----------. (...). 1196 Forwarded to `.Collection`. 1197 """""". -> 1198 super().__init__(**kwargs). 1199 self.set_sizes(sizes). 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs). 203 self._offset_transform = offset_transform. 205 self._path_effects = None. --> 206 self._internal_update(kwargs). 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs). 1209 def _internal_update(self, kwargs):. 1210 """""". 1211 Update artist properties without prenormalizing them, but generating. 1212 errors as if calling `set`. 1213 . 1214 The lack of prenormalization is to maintain backcompatibility. 1215 """""". -> 1216 return self._update_props(. 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument "". 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt). 1188 func = getattr(self, f""set_{k}"", None). 1189 if not callable(func):. -> 1190 raise AttributeError(. 1191 errfmt.format(cls=type(self), prop_name=k)). 1192 ret.append(func(v)). 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:9984,usability,tool,toolz,9984,"expected keyword argument 'rotation'. ```. ### Versions. <details>. ```. numpy 1.26.4. pandas 2.2.2. scanpy 1.10.2. session_info 1.0.0. -----. PIL 10.3.0. anndata 0.10.8. anyio NA. arrow 1.3.0. asciitree NA. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.15.0. certifi 2024.06.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.5. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 2.4. jsonschema 4.22.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.1. jupyterlab_server 2.27.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.9.0. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numcodecs 0.12.1. overrides NA. packaging 24.0. parso 0.8.4. platformdirs 4.2.2. prometheus_client NA. prompt_toolkit 3.0.46. psutil 5.9.8. pure_eval 0.2.2. pyarrow 16.1.0. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.11.0. send2trash NA. six 1.16.0. sklearn 1.5.0. sniffio 1.3.1. stack_data 0.6.3. texttable 1.7.0. threadpoolctl 3.5.0. tlz 0.12.1. toolz 0.12.1. tornado 6.4.1. traitlets 5.14.3. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 24.6.0. websocket 1.8.0. yaml 6.0.1. zarr 2.18.2. zmq 26.0.3. -----. IPython 8.25.0. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.1. -----. Python 3.12.3 | packaged by Anaconda, Inc. | (main, May 6 2024, 19:46:43) [GCC 11.2.0]. Linux-5.4.0-84-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-07-03 15:12. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3141:12,availability,error,error,12,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:413,availability,Error,Error,413,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:187,deployability,version,version,187,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1254,deployability,Version,Versions,1254," the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:2685,deployability,updat,updated,2685,"irected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:187,integrability,version,version,187,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:592,integrability,Buffer,Buffer,592,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:992,integrability,Buffer,Buffer,992,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1254,integrability,Version,Versions,1254," the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:605,interoperability,mismatch,mismatch,605,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1005,interoperability,mismatch,mismatch,1005,"rs error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1970,interoperability,platform,platformdirs,1970,"irected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:187,modifiability,version,version,187,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:844,modifiability,pac,packages,844,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1254,modifiability,Version,Versions,1254," the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1556,modifiability,deco,decorator,1556,"recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1862,modifiability,pac,packaging,1862,"irected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:12,performance,error,error,12,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:413,performance,Error,Error,413,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:12,safety,error,error,12,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:413,safety,Error,Error,413,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:650,safety,Except,Exception,650,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:2685,safety,updat,updated,2685,"irected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:1431,security,certif,certifi,1431," computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. trai",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:2311,security,soc,socks,2311,"irected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:2665,security,Session,Session,2665,"irected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:2685,security,updat,updated,2685,"irected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.13.1. pooch v1.7.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pygments 2.14.0. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. requests 2.28.1. ruamel NA. scipy 1.10.1. seaborn 0.13.2. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.2. texttable 1.6.7. threadpoolctl 3.1.0. tqdm 4.64.1. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.14. wcwidth 0.2.6. yaml 6.0. zstandard 0.18.0. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-07-03 12:41. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:545,testability,Trace,Traceback,545,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:740,testability,Trace,Traceback,740,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:12,usability,error,error,12,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:147,usability,confirm,confirmed,147,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:230,usability,confirm,confirmed,230,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:348,usability,Minim,Minimal,348,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:413,usability,Error,Error,413,"A neighbors error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? i have a trouble when i run neighbors. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. computing neighbors. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'. Traceback (most recent call last):. File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__. self._connected_components = connected_components(self._connectivities). ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'. using 'X_pca' with n_pcs = 50. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:29:05). ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.10.1. -----. Cython 0.29.33. IPython 8.13.2. PIL 9.4.0. annoy NA. asttokens NA. backcall 0.2.0. bbknn 1.6.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cycler 0.10.0. cython 0.29.33. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. executing 1.2.0. fontTools 4.39.0. h5py 3.8.0. idna 3.4. igraph 0.10.5. jedi 0.18.2. joblib 1.3.1. kiwisolver 1.4.4. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.40.1. matplotlib 3.9.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numexpr 2.8.4. numpy 1.23.0. packaging 23.0. pandas 2.0.1. parso 0.8.3. patsy 0.5.6. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.8.0. plotly 5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/pull/3142:82,security,control,control,82,Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene; Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142
https://github.com/scverse/scanpy/pull/3142:178,security,control,control,178,Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene; Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142
https://github.com/scverse/scanpy/pull/3142:82,testability,control,control,82,Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene; Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142
https://github.com/scverse/scanpy/pull/3142:178,testability,control,control,178,Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene; Backport PR #2875: Bugfix: Gene score edge case where gene_list gene is chosen as control gene,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142
https://github.com/scverse/scanpy/issues/3143:16,availability,error,error,16,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:429,availability,error,error,429,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:578,availability,Error,Error,578,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:261,deployability,version,version,261,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:682,deployability,Version,Versions,682,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:699,deployability,version,version,699,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:261,integrability,version,version,261,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:682,integrability,Version,Versions,682,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:699,integrability,version,version,699,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:261,modifiability,version,version,261,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:682,modifiability,Version,Versions,682,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:699,modifiability,version,version,699,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:16,performance,error,error,16,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:429,performance,error,error,429,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:578,performance,Error,Error,578,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:16,safety,error,error,16,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:429,safety,error,error,429,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:578,safety,Error,Error,578,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:16,usability,error,error,16,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:221,usability,confirm,confirmed,221,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:304,usability,confirm,confirmed,304,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:429,usability,error,error,429,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:513,usability,Minim,Minimal,513,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3143:578,usability,Error,Error,578,"sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python. sc.pp.neighbors(adata). ```. ### Error output. ```pytb. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ```. ### Versions. Latest version of scanpy .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143
https://github.com/scverse/scanpy/issues/3144:102,availability,error,error,102,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:580,availability,error,error,580,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:766,availability,error,error,766,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1783,availability,error,error,1783,"t find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1898,availability,error,error,1898," I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4563,availability,error,error,4563,"ghly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-mis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4873,availability,avail,available,4873,"in_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-instal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5196,availability,error,error,5196," span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5321,availability,error,error,5321,"stall skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5351,availability,error,error,5351,"install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6053,availability,Error,Error,6053,"e the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:121,deployability,instal,installable,121,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:327,deployability,version,version,327,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:608,deployability,instal,install,608,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:640,deployability,instal,install,640,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:699,deployability,instal,install,699,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1082,deployability,version,version,1082,"ces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1402,deployability,instal,install,1402,"n branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. Mo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1425,deployability,instal,install,1425," What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1491,deployability,instal,install,1491,"to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, anot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2039,deployability,Modul,ModuleNotFoundError,2039,"ns worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2404,deployability,Modul,ModuleNotFoundError,2404,"ng to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2428,deployability,modul,module,2428,"l scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4322,deployability,instal,install,4322,"sp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4354,deployability,instal,install,4354,", span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4498,deployability,instal,install,4498,"(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4530,deployability,instal,install,4530,"s""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4585,deployability,instal,install,4585,"rat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a0799",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4646,deployability,instal,install,4646,"9 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4811,deployability,fail,failed,4811,"_Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5176,deployability,instal,install,5176,"_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5250,deployability,version,versions,5250,"ess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5539,deployability,instal,install-,5539,"r scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . bab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5662,deployability,instal,install-,5662,":scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5754,deployability,releas,release,5754,"metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5776,deployability,releas,release,5776,"n): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5872,deployability,instal,install-,5872,"ilable from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6086,deployability,Version,Versions,6086,"g for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6119,deployability,Version,Version,6119,"nda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6127,deployability,Build,Build,6127,". ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normalizer 2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6403,deployability,api,api-compat,6403,successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normalizer 2.0.4 pyhd3eb1b0_0 . chex 0.1.81 pyhd8ed1ab_0 conda-forge. colorama 0.4.6 pyhd8ed1ab_0 conda-forge. comm 0.2.1 py39hca03da5_0 . contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge. cycler 0.12.1 pyhd8ed1ab_0 conda-forge. cython 3.0.10 pypi_0 pypi. debugpy 1.6.7 py39h313beb8_0 . decorator ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:13605,deployability,api,api,13605,30c_2 conda-forge. optax 0.2.2 pyhd8ed1ab_0 conda-forge. overrides 7.4.0 py39hca03da5_0 . packaging 24.1 pyhd8ed1ab_0 conda-forge. pandas 2.2.2 py39h998126f_1 conda-forge. pandocfilters 1.5.0 pyhd3eb1b0_0 . parso 0.8.3 pyhd3eb1b0_0 . patsy 0.5.6 pyhd8ed1ab_0 conda-forge. pcre2 10.43 h26f9a81_0 conda-forge. pexpect 4.8.0 pyhd3eb1b0_3 . pickleshare 0.7.5 pyhd3eb1b0_1003 . pillow 10.3.0 py39h3352c98_0 conda-forge. pip 24.0 py39hca03da5_0 . platformdirs 3.10.0 py39hca03da5_0 . ply 3.11 py39hca03da5_0 . prometheus_client 0.14.1 py39hca03da5_0 . prompt-toolkit 3.0.43 py39hca03da5_0 . prompt_toolkit 3.0.43 hd3eb1b0_0 . psutil 5.9.0 py39h1a28f6b_0 . pthread-stubs 0.4 h27ca646_1001 conda-forge. ptyprocess 0.7.0 pyhd3eb1b0_2 . pure_eval 0.2.2 pyhd3eb1b0_0 . pycparser 2.22 pyhd8ed1ab_0 conda-forge. pygments 2.18.0 pyhd8ed1ab_0 conda-forge. pynndescent 0.5.13 pyhff2d567_0 conda-forge. pyparsing 3.1.2 pyhd8ed1ab_0 conda-forge. pyqt 5.15.10 py39h313beb8_0 . pyqt5-sip 12.13.0 py39h80987f9_0 . pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge. pyro-ppl 1.8.6 pyhd8ed1ab_0 conda-forge. pysocks 1.7.1 py39hca03da5_0 . python 3.9.18 hd7ebdb9_1_cpython conda-forge. python-dateutil 2.9.0 pyhd8ed1ab_0 conda-forge. python-fastjsonschema 2.16.2 py39hca03da5_0 . python-igraph 0.11.5 py39hd012b80_1 conda-forge. python-json-logger 2.0.7 py39hca03da5_0 . python-tzdata 2024.1 pyhd8ed1ab_0 conda-forge. python_abi 3.9 4_cp39 conda-forge. pytorch 1.12.1 cpu_py39h6ba7f14_0 . pytorch-lightning 1.9.4 pyhd8ed1ab_1 conda-forge. pytz 2024.1 py39hca03da5_0 . pyyaml 6.0.1 py39h0f82c59_1 conda-forge. pyzmq 25.1.2 py39h313beb8_0 . qt-main 5.15.8 hf679f28_21 conda-forge. qtconsole 5.5.1 py39hca03da5_0 . qtpy 2.4.1 py39hca03da5_0 . re2 2023.02.01 hb7217d7_0 conda-forge. readline 8.2 h1a28f6b_0 . referencing 0.30.2 py39hca03da5_0 . requests 2.32.2 py39hca03da5_0 . rfc3339-validator 0.1.4 py39hca03da5_0 . rfc3986-validator 0.1.1 py39hca03da5_0 . rich 13.7.1 pyhd8ed1ab_0 conda-forge. rpds-py 0.10.6 py39hf0e4da2_0 . scanpy 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:13914,deployability,log,logger,13914,xpect 4.8.0 pyhd3eb1b0_3 . pickleshare 0.7.5 pyhd3eb1b0_1003 . pillow 10.3.0 py39h3352c98_0 conda-forge. pip 24.0 py39hca03da5_0 . platformdirs 3.10.0 py39hca03da5_0 . ply 3.11 py39hca03da5_0 . prometheus_client 0.14.1 py39hca03da5_0 . prompt-toolkit 3.0.43 py39hca03da5_0 . prompt_toolkit 3.0.43 hd3eb1b0_0 . psutil 5.9.0 py39h1a28f6b_0 . pthread-stubs 0.4 h27ca646_1001 conda-forge. ptyprocess 0.7.0 pyhd3eb1b0_2 . pure_eval 0.2.2 pyhd3eb1b0_0 . pycparser 2.22 pyhd8ed1ab_0 conda-forge. pygments 2.18.0 pyhd8ed1ab_0 conda-forge. pynndescent 0.5.13 pyhff2d567_0 conda-forge. pyparsing 3.1.2 pyhd8ed1ab_0 conda-forge. pyqt 5.15.10 py39h313beb8_0 . pyqt5-sip 12.13.0 py39h80987f9_0 . pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge. pyro-ppl 1.8.6 pyhd8ed1ab_0 conda-forge. pysocks 1.7.1 py39hca03da5_0 . python 3.9.18 hd7ebdb9_1_cpython conda-forge. python-dateutil 2.9.0 pyhd8ed1ab_0 conda-forge. python-fastjsonschema 2.16.2 py39hca03da5_0 . python-igraph 0.11.5 py39hd012b80_1 conda-forge. python-json-logger 2.0.7 py39hca03da5_0 . python-tzdata 2024.1 pyhd8ed1ab_0 conda-forge. python_abi 3.9 4_cp39 conda-forge. pytorch 1.12.1 cpu_py39h6ba7f14_0 . pytorch-lightning 1.9.4 pyhd8ed1ab_1 conda-forge. pytz 2024.1 py39hca03da5_0 . pyyaml 6.0.1 py39h0f82c59_1 conda-forge. pyzmq 25.1.2 py39h313beb8_0 . qt-main 5.15.8 hf679f28_21 conda-forge. qtconsole 5.5.1 py39hca03da5_0 . qtpy 2.4.1 py39hca03da5_0 . re2 2023.02.01 hb7217d7_0 conda-forge. readline 8.2 h1a28f6b_0 . referencing 0.30.2 py39hca03da5_0 . requests 2.32.2 py39hca03da5_0 . rfc3339-validator 0.1.4 py39hca03da5_0 . rfc3986-validator 0.1.1 py39hca03da5_0 . rich 13.7.1 pyhd8ed1ab_0 conda-forge. rpds-py 0.10.6 py39hf0e4da2_0 . scanpy 1.8.1 pypi_0 pypi. scikit-learn 1.1.2 py39h598ef33_0 conda-forge. scikit-misc 0.3.1 pypi_0 pypi. scipy 1.13.1 py39h3d5391c_0 conda-forge. scvi-tools 0.20.3 pyhd8ed1ab_0 conda-forge. seaborn 0.12.2 hd8ed1ab_0 conda-forge. seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge. send2trash 1.8.2 py39hca03da5_0 . session-in,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:16489,deployability,log,logging,16489,hf0e4da2_0 . scanpy 1.8.1 pypi_0 pypi. scikit-learn 1.1.2 py39h598ef33_0 conda-forge. scikit-misc 0.3.1 pypi_0 pypi. scipy 1.13.1 py39h3d5391c_0 conda-forge. scvi-tools 0.20.3 pyhd8ed1ab_0 conda-forge. seaborn 0.12.2 hd8ed1ab_0 conda-forge. seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge. send2trash 1.8.2 py39hca03da5_0 . session-info 1.0.0 pyhd8ed1ab_0 conda-forge. setuptools 69.5.1 py39hca03da5_0 . sinfo 0.3.4 pypi_0 pypi. sip 6.7.12 py39h313beb8_0 . six 1.16.0 pyh6c4a22f_0 conda-forge. sniffio 1.3.0 py39hca03da5_0 . soupsieve 2.5 py39hca03da5_0 . sqlite 3.45.3 h80987f9_0 . stack_data 0.2.0 pyhd3eb1b0_0 . statsmodels 0.14.2 py39h161d348_0 conda-forge. stdlib-list 0.10.0 pyhd8ed1ab_0 conda-forge. tbb 2021.8.0 h48ca7d4_0 . terminado 0.17.1 py39hca03da5_0 . texttable 1.7.0 pyhd8ed1ab_0 conda-forge. threadpoolctl 3.5.0 pyhc1e730c_0 conda-forge. tinycss2 1.2.1 py39hca03da5_0 . tk 8.6.14 h6ba3021_0 . tomli 2.0.1 py39hca03da5_0 . toolz 0.12.1 pyhd8ed1ab_0 conda-forge. torchmetrics 1.0.3 pyhd8ed1ab_0 conda-forge. tornado 6.4.1 py39h80987f9_0 . tqdm 4.66.4 pyhd8ed1ab_0 conda-forge. traitlets 5.14.3 py39hca03da5_0 . typing-extensions 4.12.2 hd8ed1ab_0 conda-forge. typing_extensions 4.12.2 pyha770c72_0 conda-forge. tzdata 2024a h04d1e81_0 . umap-learn 0.5.6 pypi_0 pypi. unicodedata2 15.1.0 py39h0f82c59_0 conda-forge. urllib3 2.2.2 py39hca03da5_0 . wcwidth 0.2.5 pyhd3eb1b0_0 . webencodings 0.5.1 py39hca03da5_1 . websocket-client 1.8.0 py39hca03da5_0 . wheel 0.43.0 py39hca03da5_0 . widgetsnbextension 4.0.10 py39hca03da5_0 . xlrd 1.2.0 pyh9f0ad1d_1 conda-forge. xorg-libxau 1.0.11 hb547adb_0 conda-forge. xorg-libxdmcp 1.1.3 h27ca646_0 conda-forge. xz 5.4.6 h80987f9_1 . yaml 0.2.5 h3422bc3_2 conda-forge. zeromq 4.3.5 h313beb8_0 . zipp 3.19.2 pyhd8ed1ab_0 conda-forge. zlib 1.2.13 hfb2fe0b_6 conda-forge. zstd 1.5.6 hb46c0d2_0 conda-forge. ```. Im so sorry somethine else is wrong so scanpy.logging.print_versions() doesn't work at the moment. I'll fix it and update the post. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:16558,deployability,updat,update,16558,hf0e4da2_0 . scanpy 1.8.1 pypi_0 pypi. scikit-learn 1.1.2 py39h598ef33_0 conda-forge. scikit-misc 0.3.1 pypi_0 pypi. scipy 1.13.1 py39h3d5391c_0 conda-forge. scvi-tools 0.20.3 pyhd8ed1ab_0 conda-forge. seaborn 0.12.2 hd8ed1ab_0 conda-forge. seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge. send2trash 1.8.2 py39hca03da5_0 . session-info 1.0.0 pyhd8ed1ab_0 conda-forge. setuptools 69.5.1 py39hca03da5_0 . sinfo 0.3.4 pypi_0 pypi. sip 6.7.12 py39h313beb8_0 . six 1.16.0 pyh6c4a22f_0 conda-forge. sniffio 1.3.0 py39hca03da5_0 . soupsieve 2.5 py39hca03da5_0 . sqlite 3.45.3 h80987f9_0 . stack_data 0.2.0 pyhd3eb1b0_0 . statsmodels 0.14.2 py39h161d348_0 conda-forge. stdlib-list 0.10.0 pyhd8ed1ab_0 conda-forge. tbb 2021.8.0 h48ca7d4_0 . terminado 0.17.1 py39hca03da5_0 . texttable 1.7.0 pyhd8ed1ab_0 conda-forge. threadpoolctl 3.5.0 pyhc1e730c_0 conda-forge. tinycss2 1.2.1 py39hca03da5_0 . tk 8.6.14 h6ba3021_0 . tomli 2.0.1 py39hca03da5_0 . toolz 0.12.1 pyhd8ed1ab_0 conda-forge. torchmetrics 1.0.3 pyhd8ed1ab_0 conda-forge. tornado 6.4.1 py39h80987f9_0 . tqdm 4.66.4 pyhd8ed1ab_0 conda-forge. traitlets 5.14.3 py39hca03da5_0 . typing-extensions 4.12.2 hd8ed1ab_0 conda-forge. typing_extensions 4.12.2 pyha770c72_0 conda-forge. tzdata 2024a h04d1e81_0 . umap-learn 0.5.6 pypi_0 pypi. unicodedata2 15.1.0 py39h0f82c59_0 conda-forge. urllib3 2.2.2 py39hca03da5_0 . wcwidth 0.2.5 pyhd3eb1b0_0 . webencodings 0.5.1 py39hca03da5_1 . websocket-client 1.8.0 py39hca03da5_0 . wheel 0.43.0 py39hca03da5_0 . widgetsnbextension 4.0.10 py39hca03da5_0 . xlrd 1.2.0 pyh9f0ad1d_1 conda-forge. xorg-libxau 1.0.11 hb547adb_0 conda-forge. xorg-libxdmcp 1.1.3 h27ca646_0 conda-forge. xz 5.4.6 h80987f9_1 . yaml 0.2.5 h3422bc3_2 conda-forge. zeromq 4.3.5 h313beb8_0 . zipp 3.19.2 pyhd8ed1ab_0 conda-forge. zlib 1.2.13 hfb2fe0b_6 conda-forge. zstd 1.5.6 hb46c0d2_0 conda-forge. ```. Im so sorry somethine else is wrong so scanpy.logging.print_versions() doesn't work at the moment. I'll fix it and update the post. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4888,energy efficiency,current,current,4888,"). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/sci",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4935,energy efficiency,Current,Current,4935,"isp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.meso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:327,integrability,version,version,327,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:969,integrability,sub,subject,969,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1082,integrability,version,version,1082,"ces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2313,integrability,sub,subset,2313,"e and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_gen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2673,integrability,sub,subset,2673,"/opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2853,integrability,wrap,wrapper,2853,"how?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2906,integrability,wrap,wraps,2906,"running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3382,integrability,sub,subset,3382,"cept ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3756,integrability,sub,subset,3756,"canpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3763,integrability,sub,subset,3763,"vt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4206,integrability,sub,subset,4206,"ckages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5250,integrability,version,versions,5250,"ess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5328,integrability,sub,subprocess-exited-with-error,5328,"ge via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6086,integrability,Version,Versions,6086,"g for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6119,integrability,Version,Version,6119,"nda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6403,integrability,api,api-compat,6403,successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normalizer 2.0.4 pyhd3eb1b0_0 . chex 0.1.81 pyhd8ed1ab_0 conda-forge. colorama 0.4.6 pyhd8ed1ab_0 conda-forge. comm 0.2.1 py39hca03da5_0 . contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge. cycler 0.12.1 pyhd8ed1ab_0 conda-forge. cython 3.0.10 pypi_0 pypi. debugpy 1.6.7 py39h313beb8_0 . decorator ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:13605,integrability,api,api,13605,30c_2 conda-forge. optax 0.2.2 pyhd8ed1ab_0 conda-forge. overrides 7.4.0 py39hca03da5_0 . packaging 24.1 pyhd8ed1ab_0 conda-forge. pandas 2.2.2 py39h998126f_1 conda-forge. pandocfilters 1.5.0 pyhd3eb1b0_0 . parso 0.8.3 pyhd3eb1b0_0 . patsy 0.5.6 pyhd8ed1ab_0 conda-forge. pcre2 10.43 h26f9a81_0 conda-forge. pexpect 4.8.0 pyhd3eb1b0_3 . pickleshare 0.7.5 pyhd3eb1b0_1003 . pillow 10.3.0 py39h3352c98_0 conda-forge. pip 24.0 py39hca03da5_0 . platformdirs 3.10.0 py39hca03da5_0 . ply 3.11 py39hca03da5_0 . prometheus_client 0.14.1 py39hca03da5_0 . prompt-toolkit 3.0.43 py39hca03da5_0 . prompt_toolkit 3.0.43 hd3eb1b0_0 . psutil 5.9.0 py39h1a28f6b_0 . pthread-stubs 0.4 h27ca646_1001 conda-forge. ptyprocess 0.7.0 pyhd3eb1b0_2 . pure_eval 0.2.2 pyhd3eb1b0_0 . pycparser 2.22 pyhd8ed1ab_0 conda-forge. pygments 2.18.0 pyhd8ed1ab_0 conda-forge. pynndescent 0.5.13 pyhff2d567_0 conda-forge. pyparsing 3.1.2 pyhd8ed1ab_0 conda-forge. pyqt 5.15.10 py39h313beb8_0 . pyqt5-sip 12.13.0 py39h80987f9_0 . pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge. pyro-ppl 1.8.6 pyhd8ed1ab_0 conda-forge. pysocks 1.7.1 py39hca03da5_0 . python 3.9.18 hd7ebdb9_1_cpython conda-forge. python-dateutil 2.9.0 pyhd8ed1ab_0 conda-forge. python-fastjsonschema 2.16.2 py39hca03da5_0 . python-igraph 0.11.5 py39hd012b80_1 conda-forge. python-json-logger 2.0.7 py39hca03da5_0 . python-tzdata 2024.1 pyhd8ed1ab_0 conda-forge. python_abi 3.9 4_cp39 conda-forge. pytorch 1.12.1 cpu_py39h6ba7f14_0 . pytorch-lightning 1.9.4 pyhd8ed1ab_1 conda-forge. pytz 2024.1 py39hca03da5_0 . pyyaml 6.0.1 py39h0f82c59_1 conda-forge. pyzmq 25.1.2 py39h313beb8_0 . qt-main 5.15.8 hf679f28_21 conda-forge. qtconsole 5.5.1 py39hca03da5_0 . qtpy 2.4.1 py39hca03da5_0 . re2 2023.02.01 hb7217d7_0 conda-forge. readline 8.2 h1a28f6b_0 . referencing 0.30.2 py39hca03da5_0 . requests 2.32.2 py39hca03da5_0 . rfc3339-validator 0.1.4 py39hca03da5_0 . rfc3986-validator 0.1.1 py39hca03da5_0 . rich 13.7.1 pyhd8ed1ab_0 conda-forge. rpds-py 0.10.6 py39hf0e4da2_0 . scanpy 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2853,interoperability,wrapper,wrapper,2853,"how?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4718,interoperability,Platform,Platform,4718,"heck_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6319,interoperability,bind,bindings,6319,ror: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normalizer 2.0.4 pyhd3eb1b0_0 . chex 0.1.81 pyhd8ed1ab_0 conda-forge. colorama 0.4.6 pyhd8ed1ab_0 conda-forge. comm 0.2.1 py39hca03da5_0 . contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge. cycler 0.12.1 pyhd8ed1a,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6403,interoperability,api,api-compat,6403,successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normalizer 2.0.4 pyhd3eb1b0_0 . chex 0.1.81 pyhd8ed1ab_0 conda-forge. colorama 0.4.6 pyhd8ed1ab_0 conda-forge. comm 0.2.1 py39hca03da5_0 . contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge. cycler 0.12.1 pyhd8ed1ab_0 conda-forge. cython 3.0.10 pypi_0 pypi. debugpy 1.6.7 py39h313beb8_0 . decorator ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:8128,interoperability,plug,plugins-base,8128,yhd3eb1b0_0 . chex 0.1.81 pyhd8ed1ab_0 conda-forge. colorama 0.4.6 pyhd8ed1ab_0 conda-forge. comm 0.2.1 py39hca03da5_0 . contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge. cycler 0.12.1 pyhd8ed1ab_0 conda-forge. cython 3.0.10 pypi_0 pypi. debugpy 1.6.7 py39h313beb8_0 . decorator 5.1.1 pyhd3eb1b0_0 . defusedxml 0.7.1 pyhd3eb1b0_0 . dm-tree 0.1.7 py39h2666b31_0 conda-forge. docrep 0.3.2 pyh44b312d_0 conda-forge. et_xmlfile 1.1.0 pyhd8ed1ab_0 conda-forge. etils 1.6.0 pyhd8ed1ab_0 conda-forge. exceptiongroup 1.2.1 pypi_0 pypi. executing 0.8.3 pyhd3eb1b0_0 . flax 0.6.1 pyhd8ed1ab_1 conda-forge. fonttools 4.53.0 py39hfea33bf_0 conda-forge. freetype 2.12.1 hadb7bae_2 conda-forge. fsspec 2024.6.1 pyhff2d567_0 conda-forge. future 1.0.0 pyhd8ed1ab_0 conda-forge. get-annotations 0.1.2 pyhd8ed1ab_0 conda-forge. glib 2.80.2 h535f939_0 conda-forge. glib-tools 2.80.2 h4c882b9_0 conda-forge. glpk 5.0 h6d7a090_0 conda-forge. gmp 6.3.0 h7bae524_2 conda-forge. grpc-cpp 1.46.4 hb15be72_9 conda-forge. gst-plugins-base 1.24.4 h8a8f8c8_0 conda-forge. gstreamer 1.24.4 h430e707_0 conda-forge. h5py 3.11.0 nompi_py39h534c8c8_102 conda-forge. hdf5 1.14.3 nompi_hec07895_105 conda-forge. icu 73.2 hc8870d7_0 conda-forge. idna 3.7 py39hca03da5_0 . igraph 0.10.13 h762ac30_0 conda-forge. importlib-metadata 7.0.1 py39hca03da5_0 . importlib_metadata 7.0.1 hd3eb1b0_0 . importlib_resources 6.4.0 pyhd8ed1ab_0 conda-forge. ipykernel 6.28.0 py39hca03da5_0 . ipython 8.15.0 py39hca03da5_0 . ipywidgets 8.1.2 py39hca03da5_0 . jax 0.3.15 pyhd8ed1ab_0 conda-forge. jaxlib 0.3.15 cpu_py39hb5f911d_3 conda-forge. jedi 0.18.1 py39hca03da5_1 . jinja2 3.1.4 py39hca03da5_0 . joblib 1.4.2 pyhd8ed1ab_0 conda-forge. json5 0.9.6 pyhd3eb1b0_0 . jsonschema 4.19.2 py39hca03da5_0 . jsonschema-specifications 2023.7.1 py39hca03da5_0 . jupyter 1.0.0 py39hca03da5_9 . jupyter-lsp 2.2.0 py39hca03da5_0 . jupyter_client 8.6.0 py39hca03da5_0 . jupyter_console 6.6.3 py39hca03da5_0 . jupyter_core 5.7.2 py39hca03da5_0 . jupyter_events 0.10.0 py3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:8889,interoperability,specif,specifications,8889,nnotations 0.1.2 pyhd8ed1ab_0 conda-forge. glib 2.80.2 h535f939_0 conda-forge. glib-tools 2.80.2 h4c882b9_0 conda-forge. glpk 5.0 h6d7a090_0 conda-forge. gmp 6.3.0 h7bae524_2 conda-forge. grpc-cpp 1.46.4 hb15be72_9 conda-forge. gst-plugins-base 1.24.4 h8a8f8c8_0 conda-forge. gstreamer 1.24.4 h430e707_0 conda-forge. h5py 3.11.0 nompi_py39h534c8c8_102 conda-forge. hdf5 1.14.3 nompi_hec07895_105 conda-forge. icu 73.2 hc8870d7_0 conda-forge. idna 3.7 py39hca03da5_0 . igraph 0.10.13 h762ac30_0 conda-forge. importlib-metadata 7.0.1 py39hca03da5_0 . importlib_metadata 7.0.1 hd3eb1b0_0 . importlib_resources 6.4.0 pyhd8ed1ab_0 conda-forge. ipykernel 6.28.0 py39hca03da5_0 . ipython 8.15.0 py39hca03da5_0 . ipywidgets 8.1.2 py39hca03da5_0 . jax 0.3.15 pyhd8ed1ab_0 conda-forge. jaxlib 0.3.15 cpu_py39hb5f911d_3 conda-forge. jedi 0.18.1 py39hca03da5_1 . jinja2 3.1.4 py39hca03da5_0 . joblib 1.4.2 pyhd8ed1ab_0 conda-forge. json5 0.9.6 pyhd3eb1b0_0 . jsonschema 4.19.2 py39hca03da5_0 . jsonschema-specifications 2023.7.1 py39hca03da5_0 . jupyter 1.0.0 py39hca03da5_9 . jupyter-lsp 2.2.0 py39hca03da5_0 . jupyter_client 8.6.0 py39hca03da5_0 . jupyter_console 6.6.3 py39hca03da5_0 . jupyter_core 5.7.2 py39hca03da5_0 . jupyter_events 0.10.0 py39hca03da5_0 . jupyter_server 2.14.1 py39hca03da5_0 . jupyter_server_terminals 0.4.4 py39hca03da5_1 . jupyterlab 4.0.11 py39hca03da5_0 . jupyterlab_pygments 0.1.2 py_0 . jupyterlab_server 2.25.1 py39hca03da5_0 . jupyterlab_widgets 3.0.10 py39hca03da5_0 . kiwisolver 1.4.5 py39hbd775c9_1 conda-forge. krb5 1.21.3 h237132a_0 conda-forge. lcms2 2.16 ha0e7c42_0 conda-forge. leidenalg 0.10.2 py39hf3050f2_0 conda-forge. lerc 4.0.0 h9a09cb3_0 conda-forge. libabseil 20220623.0 cxx17_h28b99d4_6 conda-forge. libaec 1.1.3 hebf3989_0 conda-forge. libblas 3.9.0 16_osxarm64_openblas conda-forge. libbrotlicommon 1.1.0 hb547adb_1 conda-forge. libbrotlidec 1.1.0 hb547adb_1 conda-forge. libbrotlienc 1.1.0 hb547adb_1 conda-forge. libcblas 3.9.0 16_osxarm64_openblas conda-fo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:13048,interoperability,platform,platformdirs,13048,bconvert 7.10.0 py39hca03da5_0 . nbformat 5.9.2 py39hca03da5_0 . ncurses 6.4 h313beb8_0 . nest-asyncio 1.6.0 py39hca03da5_0 . networkx 3.2.1 pypi_0 pypi. ninja 1.12.1 h420ef59_0 conda-forge. notebook 7.0.8 py39hca03da5_0 . notebook-shim 0.2.3 py39hca03da5_0 . nspr 4.35 h313beb8_0 . nss 3.100 hc6e9f88_0 conda-forge. numba 0.60.0 pypi_0 pypi. numpy 2.0.0 pypi_0 pypi. numpyro 0.13.2 pyhd8ed1ab_0 conda-forge. openjpeg 2.5.2 h9f1df11_0 conda-forge. openpyxl 3.1.4 py39hfb846b4_0 conda-forge. openssl 3.3.1 hfb2fe0b_1 conda-forge. opt_einsum 3.3.0 pyhc1e730c_2 conda-forge. optax 0.2.2 pyhd8ed1ab_0 conda-forge. overrides 7.4.0 py39hca03da5_0 . packaging 24.1 pyhd8ed1ab_0 conda-forge. pandas 2.2.2 py39h998126f_1 conda-forge. pandocfilters 1.5.0 pyhd3eb1b0_0 . parso 0.8.3 pyhd3eb1b0_0 . patsy 0.5.6 pyhd8ed1ab_0 conda-forge. pcre2 10.43 h26f9a81_0 conda-forge. pexpect 4.8.0 pyhd3eb1b0_3 . pickleshare 0.7.5 pyhd3eb1b0_1003 . pillow 10.3.0 py39h3352c98_0 conda-forge. pip 24.0 py39hca03da5_0 . platformdirs 3.10.0 py39hca03da5_0 . ply 3.11 py39hca03da5_0 . prometheus_client 0.14.1 py39hca03da5_0 . prompt-toolkit 3.0.43 py39hca03da5_0 . prompt_toolkit 3.0.43 hd3eb1b0_0 . psutil 5.9.0 py39h1a28f6b_0 . pthread-stubs 0.4 h27ca646_1001 conda-forge. ptyprocess 0.7.0 pyhd3eb1b0_2 . pure_eval 0.2.2 pyhd3eb1b0_0 . pycparser 2.22 pyhd8ed1ab_0 conda-forge. pygments 2.18.0 pyhd8ed1ab_0 conda-forge. pynndescent 0.5.13 pyhff2d567_0 conda-forge. pyparsing 3.1.2 pyhd8ed1ab_0 conda-forge. pyqt 5.15.10 py39h313beb8_0 . pyqt5-sip 12.13.0 py39h80987f9_0 . pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge. pyro-ppl 1.8.6 pyhd8ed1ab_0 conda-forge. pysocks 1.7.1 py39hca03da5_0 . python 3.9.18 hd7ebdb9_1_cpython conda-forge. python-dateutil 2.9.0 pyhd8ed1ab_0 conda-forge. python-fastjsonschema 2.16.2 py39hca03da5_0 . python-igraph 0.11.5 py39hd012b80_1 conda-forge. python-json-logger 2.0.7 py39hca03da5_0 . python-tzdata 2024.1 pyhd8ed1ab_0 conda-forge. python_abi 3.9 4_cp39 conda-forge. pytorch 1.12.1 cpu_py39h6ba7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:13265,interoperability,stub,stubs,13265,3da5_0 . notebook-shim 0.2.3 py39hca03da5_0 . nspr 4.35 h313beb8_0 . nss 3.100 hc6e9f88_0 conda-forge. numba 0.60.0 pypi_0 pypi. numpy 2.0.0 pypi_0 pypi. numpyro 0.13.2 pyhd8ed1ab_0 conda-forge. openjpeg 2.5.2 h9f1df11_0 conda-forge. openpyxl 3.1.4 py39hfb846b4_0 conda-forge. openssl 3.3.1 hfb2fe0b_1 conda-forge. opt_einsum 3.3.0 pyhc1e730c_2 conda-forge. optax 0.2.2 pyhd8ed1ab_0 conda-forge. overrides 7.4.0 py39hca03da5_0 . packaging 24.1 pyhd8ed1ab_0 conda-forge. pandas 2.2.2 py39h998126f_1 conda-forge. pandocfilters 1.5.0 pyhd3eb1b0_0 . parso 0.8.3 pyhd3eb1b0_0 . patsy 0.5.6 pyhd8ed1ab_0 conda-forge. pcre2 10.43 h26f9a81_0 conda-forge. pexpect 4.8.0 pyhd3eb1b0_3 . pickleshare 0.7.5 pyhd3eb1b0_1003 . pillow 10.3.0 py39h3352c98_0 conda-forge. pip 24.0 py39hca03da5_0 . platformdirs 3.10.0 py39hca03da5_0 . ply 3.11 py39hca03da5_0 . prometheus_client 0.14.1 py39hca03da5_0 . prompt-toolkit 3.0.43 py39hca03da5_0 . prompt_toolkit 3.0.43 hd3eb1b0_0 . psutil 5.9.0 py39h1a28f6b_0 . pthread-stubs 0.4 h27ca646_1001 conda-forge. ptyprocess 0.7.0 pyhd3eb1b0_2 . pure_eval 0.2.2 pyhd3eb1b0_0 . pycparser 2.22 pyhd8ed1ab_0 conda-forge. pygments 2.18.0 pyhd8ed1ab_0 conda-forge. pynndescent 0.5.13 pyhff2d567_0 conda-forge. pyparsing 3.1.2 pyhd8ed1ab_0 conda-forge. pyqt 5.15.10 py39h313beb8_0 . pyqt5-sip 12.13.0 py39h80987f9_0 . pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge. pyro-ppl 1.8.6 pyhd8ed1ab_0 conda-forge. pysocks 1.7.1 py39hca03da5_0 . python 3.9.18 hd7ebdb9_1_cpython conda-forge. python-dateutil 2.9.0 pyhd8ed1ab_0 conda-forge. python-fastjsonschema 2.16.2 py39hca03da5_0 . python-igraph 0.11.5 py39hd012b80_1 conda-forge. python-json-logger 2.0.7 py39hca03da5_0 . python-tzdata 2024.1 pyhd8ed1ab_0 conda-forge. python_abi 3.9 4_cp39 conda-forge. pytorch 1.12.1 cpu_py39h6ba7f14_0 . pytorch-lightning 1.9.4 pyhd8ed1ab_1 conda-forge. pytz 2024.1 py39hca03da5_0 . pyyaml 6.0.1 py39h0f82c59_1 conda-forge. pyzmq 25.1.2 py39h313beb8_0 . qt-main 5.15.8 hf679f28_21 conda-forge. qtconsole 5.5.1 ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:13605,interoperability,api,api,13605,30c_2 conda-forge. optax 0.2.2 pyhd8ed1ab_0 conda-forge. overrides 7.4.0 py39hca03da5_0 . packaging 24.1 pyhd8ed1ab_0 conda-forge. pandas 2.2.2 py39h998126f_1 conda-forge. pandocfilters 1.5.0 pyhd3eb1b0_0 . parso 0.8.3 pyhd3eb1b0_0 . patsy 0.5.6 pyhd8ed1ab_0 conda-forge. pcre2 10.43 h26f9a81_0 conda-forge. pexpect 4.8.0 pyhd3eb1b0_3 . pickleshare 0.7.5 pyhd3eb1b0_1003 . pillow 10.3.0 py39h3352c98_0 conda-forge. pip 24.0 py39hca03da5_0 . platformdirs 3.10.0 py39hca03da5_0 . ply 3.11 py39hca03da5_0 . prometheus_client 0.14.1 py39hca03da5_0 . prompt-toolkit 3.0.43 py39hca03da5_0 . prompt_toolkit 3.0.43 hd3eb1b0_0 . psutil 5.9.0 py39h1a28f6b_0 . pthread-stubs 0.4 h27ca646_1001 conda-forge. ptyprocess 0.7.0 pyhd3eb1b0_2 . pure_eval 0.2.2 pyhd3eb1b0_0 . pycparser 2.22 pyhd8ed1ab_0 conda-forge. pygments 2.18.0 pyhd8ed1ab_0 conda-forge. pynndescent 0.5.13 pyhff2d567_0 conda-forge. pyparsing 3.1.2 pyhd8ed1ab_0 conda-forge. pyqt 5.15.10 py39h313beb8_0 . pyqt5-sip 12.13.0 py39h80987f9_0 . pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge. pyro-ppl 1.8.6 pyhd8ed1ab_0 conda-forge. pysocks 1.7.1 py39hca03da5_0 . python 3.9.18 hd7ebdb9_1_cpython conda-forge. python-dateutil 2.9.0 pyhd8ed1ab_0 conda-forge. python-fastjsonschema 2.16.2 py39hca03da5_0 . python-igraph 0.11.5 py39hd012b80_1 conda-forge. python-json-logger 2.0.7 py39hca03da5_0 . python-tzdata 2024.1 pyhd8ed1ab_0 conda-forge. python_abi 3.9 4_cp39 conda-forge. pytorch 1.12.1 cpu_py39h6ba7f14_0 . pytorch-lightning 1.9.4 pyhd8ed1ab_1 conda-forge. pytz 2024.1 py39hca03da5_0 . pyyaml 6.0.1 py39h0f82c59_1 conda-forge. pyzmq 25.1.2 py39h313beb8_0 . qt-main 5.15.8 hf679f28_21 conda-forge. qtconsole 5.5.1 py39hca03da5_0 . qtpy 2.4.1 py39hca03da5_0 . re2 2023.02.01 hb7217d7_0 conda-forge. readline 8.2 h1a28f6b_0 . referencing 0.30.2 py39hca03da5_0 . requests 2.32.2 py39hca03da5_0 . rfc3339-validator 0.1.4 py39hca03da5_0 . rfc3986-validator 0.1.1 py39hca03da5_0 . rich 13.7.1 pyhd8ed1ab_0 conda-forge. rpds-py 0.10.6 py39hf0e4da2_0 . scanpy 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:109,modifiability,pac,package,109,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:327,modifiability,version,version,327,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:623,modifiability,pac,package,623,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:711,modifiability,pac,package,711,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:797,modifiability,pac,package,797,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1082,modifiability,version,version,1082,"ces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1109,modifiability,pac,packages,1109,"age not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1610,modifiability,pac,packages,1610,"l skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1727,modifiability,pac,packages,1727,"and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1924,modifiability,variab,variable,1924,"d there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2039,modifiability,Modul,ModuleNotFoundError,2039,"ns worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2151,modifiability,pac,packages,2151,"tioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2262,modifiability,layer,layer,2262,"rience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:65",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2404,modifiability,Modul,ModuleNotFoundError,2404,"ng to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2428,modifiability,modul,module,2428,"l scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:2789,modifiability,pac,packages,2789,"gh... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3207,modifiability,pac,packages,3207,"in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subse",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3300,modifiability,layer,layer,3300,"es, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise Import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3512,modifiability,paramet,parameters,3512,":. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3634,modifiability,layer,layer,3634,"able_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:3640,modifiability,layer,layer,3640,"enes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4044,modifiability,pac,packages,4044,"*kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4155,modifiability,layer,layer,4155,"t/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:655, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble rep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4337,modifiability,pac,package,4337,"in_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 653 sig = signature(_highly_variable_genes_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4464,modifiability,layer,layer,4464,"_seurat_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4470,modifiability,layer,layer,4470,"t_v3). 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4513,modifiability,pac,package,4513,"eters[""n_top_genes""].default). --> 655 return _highly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4750,modifiability,pac,package,4750,"3 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4819,modifiability,Pac,PackagesNotFoundError,4819,"e(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folder",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4856,modifiability,pac,packages,4856,"s,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5068,modifiability,pac,package,5068,"g/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:5250,modifiability,version,versions,5250,"ess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6086,modifiability,Version,Versions,6086,"g for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6119,modifiability,Version,Version,6119,"nda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:6319,modifiability,bind,bindings,6319,ror: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini. Preparing metadata (pyproject.toml) did not run successfully. ```. ### Error output. _No response_. ### Versions. <details>. ```. # Name Version Build Channel. absl-py 2.1.0 pyhd8ed1ab_0 conda-forge. anndata 0.10.8 pypi_0 pypi. anyio 4.2.0 py39hca03da5_0 . appnope 0.1.2 py39hca03da5_1001 . argon2-cffi 21.3.0 pyhd3eb1b0_0 . argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 . arpack 3.9.1 nompi_h593882a_101 conda-forge. array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normalizer 2.0.4 pyhd3eb1b0_0 . chex 0.1.81 pyhd8ed1ab_0 conda-forge. colorama 0.4.6 pyhd8ed1ab_0 conda-forge. comm 0.2.1 py39hca03da5_0 . contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge. cycler 0.12.1 pyhd8ed1a,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:7398,modifiability,deco,decorator,7398,api-compat 1.7.1 pyhd8ed1ab_0 conda-forge. asttokens 2.0.5 pyhd3eb1b0_0 . async-lru 2.0.4 py39hca03da5_0 . attrs 23.1.0 py39hca03da5_0 . babel 2.11.0 py39hca03da5_0 . backcall 0.2.0 pyhd3eb1b0_0 . beautifulsoup4 4.12.3 py39hca03da5_0 . blas 1.0 openblas . bleach 4.1.0 pyhd3eb1b0_0 . blosc2 2.0.0 pypi_0 pypi. brotli 1.1.0 hb547adb_1 conda-forge. brotli-bin 1.1.0 hb547adb_1 conda-forge. brotli-python 1.0.9 py39h313beb8_8 . bzip2 1.0.8 h80987f9_6 . c-ares 1.28.1 h93a5062_0 conda-forge. ca-certificates 2024.7.4 hf0a4a13_0 conda-forge. cached-property 1.5.2 hd8ed1ab_1 conda-forge. cached_property 1.5.2 pyha770c72_1 conda-forge. certifi 2024.6.2 py39hca03da5_0 . cffi 1.16.0 py39he153c15_0 conda-forge. charset-normalizer 2.0.4 pyhd3eb1b0_0 . chex 0.1.81 pyhd8ed1ab_0 conda-forge. colorama 0.4.6 pyhd8ed1ab_0 conda-forge. comm 0.2.1 py39hca03da5_0 . contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge. cycler 0.12.1 pyhd8ed1ab_0 conda-forge. cython 3.0.10 pypi_0 pypi. debugpy 1.6.7 py39h313beb8_0 . decorator 5.1.1 pyhd3eb1b0_0 . defusedxml 0.7.1 pyhd3eb1b0_0 . dm-tree 0.1.7 py39h2666b31_0 conda-forge. docrep 0.3.2 pyh44b312d_0 conda-forge. et_xmlfile 1.1.0 pyhd8ed1ab_0 conda-forge. etils 1.6.0 pyhd8ed1ab_0 conda-forge. exceptiongroup 1.2.1 pypi_0 pypi. executing 0.8.3 pyhd3eb1b0_0 . flax 0.6.1 pyhd8ed1ab_1 conda-forge. fonttools 4.53.0 py39hfea33bf_0 conda-forge. freetype 2.12.1 hadb7bae_2 conda-forge. fsspec 2024.6.1 pyhff2d567_0 conda-forge. future 1.0.0 pyhd8ed1ab_0 conda-forge. get-annotations 0.1.2 pyhd8ed1ab_0 conda-forge. glib 2.80.2 h535f939_0 conda-forge. glib-tools 2.80.2 h4c882b9_0 conda-forge. glpk 5.0 h6d7a090_0 conda-forge. gmp 6.3.0 h7bae524_2 conda-forge. grpc-cpp 1.46.4 hb15be72_9 conda-forge. gst-plugins-base 1.24.4 h8a8f8c8_0 conda-forge. gstreamer 1.24.4 h430e707_0 conda-forge. h5py 3.11.0 nompi_py39h534c8c8_102 conda-forge. hdf5 1.14.3 nompi_hec07895_105 conda-forge. icu 73.2 hc8870d7_0 conda-forge. idna 3.7 py39hca03da5_0 . igraph 0.10.13 h762ac30_0 conda-forge. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:12697,modifiability,pac,packaging,12697,pyhd8ed1ab_0 conda-forge. msgpack-python 1.0.8 py39ha1e04a5_0 conda-forge. mudata 0.2.3 pyhd8ed1ab_0 conda-forge. multipledispatch 0.6.0 py_0 conda-forge. munkres 1.1.4 pyh9f0ad1d_0 conda-forge. mysql-common 8.3.0 hd1853d3_4 conda-forge. mysql-libs 8.3.0 hf036fc4_4 conda-forge. natsort 8.4.0 pyhd8ed1ab_0 conda-forge. nbclient 0.8.0 py39hca03da5_0 . nbconvert 7.10.0 py39hca03da5_0 . nbformat 5.9.2 py39hca03da5_0 . ncurses 6.4 h313beb8_0 . nest-asyncio 1.6.0 py39hca03da5_0 . networkx 3.2.1 pypi_0 pypi. ninja 1.12.1 h420ef59_0 conda-forge. notebook 7.0.8 py39hca03da5_0 . notebook-shim 0.2.3 py39hca03da5_0 . nspr 4.35 h313beb8_0 . nss 3.100 hc6e9f88_0 conda-forge. numba 0.60.0 pypi_0 pypi. numpy 2.0.0 pypi_0 pypi. numpyro 0.13.2 pyhd8ed1ab_0 conda-forge. openjpeg 2.5.2 h9f1df11_0 conda-forge. openpyxl 3.1.4 py39hfb846b4_0 conda-forge. openssl 3.3.1 hfb2fe0b_1 conda-forge. opt_einsum 3.3.0 pyhc1e730c_2 conda-forge. optax 0.2.2 pyhd8ed1ab_0 conda-forge. overrides 7.4.0 py39hca03da5_0 . packaging 24.1 pyhd8ed1ab_0 conda-forge. pandas 2.2.2 py39h998126f_1 conda-forge. pandocfilters 1.5.0 pyhd3eb1b0_0 . parso 0.8.3 pyhd3eb1b0_0 . patsy 0.5.6 pyhd8ed1ab_0 conda-forge. pcre2 10.43 h26f9a81_0 conda-forge. pexpect 4.8.0 pyhd3eb1b0_3 . pickleshare 0.7.5 pyhd3eb1b0_1003 . pillow 10.3.0 py39h3352c98_0 conda-forge. pip 24.0 py39hca03da5_0 . platformdirs 3.10.0 py39hca03da5_0 . ply 3.11 py39hca03da5_0 . prometheus_client 0.14.1 py39hca03da5_0 . prompt-toolkit 3.0.43 py39hca03da5_0 . prompt_toolkit 3.0.43 hd3eb1b0_0 . psutil 5.9.0 py39h1a28f6b_0 . pthread-stubs 0.4 h27ca646_1001 conda-forge. ptyprocess 0.7.0 pyhd3eb1b0_2 . pure_eval 0.2.2 pyhd3eb1b0_0 . pycparser 2.22 pyhd8ed1ab_0 conda-forge. pygments 2.18.0 pyhd8ed1ab_0 conda-forge. pynndescent 0.5.13 pyhff2d567_0 conda-forge. pyparsing 3.1.2 pyhd8ed1ab_0 conda-forge. pyqt 5.15.10 py39h313beb8_0 . pyqt5-sip 12.13.0 py39h80987f9_0 . pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge. pyro-ppl 1.8.6 pyhd8ed1ab_0 conda-forge. pysocks 1.7.1 py39hc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:15716,modifiability,extens,extensions,15716,hf0e4da2_0 . scanpy 1.8.1 pypi_0 pypi. scikit-learn 1.1.2 py39h598ef33_0 conda-forge. scikit-misc 0.3.1 pypi_0 pypi. scipy 1.13.1 py39h3d5391c_0 conda-forge. scvi-tools 0.20.3 pyhd8ed1ab_0 conda-forge. seaborn 0.12.2 hd8ed1ab_0 conda-forge. seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge. send2trash 1.8.2 py39hca03da5_0 . session-info 1.0.0 pyhd8ed1ab_0 conda-forge. setuptools 69.5.1 py39hca03da5_0 . sinfo 0.3.4 pypi_0 pypi. sip 6.7.12 py39h313beb8_0 . six 1.16.0 pyh6c4a22f_0 conda-forge. sniffio 1.3.0 py39hca03da5_0 . soupsieve 2.5 py39hca03da5_0 . sqlite 3.45.3 h80987f9_0 . stack_data 0.2.0 pyhd3eb1b0_0 . statsmodels 0.14.2 py39h161d348_0 conda-forge. stdlib-list 0.10.0 pyhd8ed1ab_0 conda-forge. tbb 2021.8.0 h48ca7d4_0 . terminado 0.17.1 py39hca03da5_0 . texttable 1.7.0 pyhd8ed1ab_0 conda-forge. threadpoolctl 3.5.0 pyhc1e730c_0 conda-forge. tinycss2 1.2.1 py39hca03da5_0 . tk 8.6.14 h6ba3021_0 . tomli 2.0.1 py39hca03da5_0 . toolz 0.12.1 pyhd8ed1ab_0 conda-forge. torchmetrics 1.0.3 pyhd8ed1ab_0 conda-forge. tornado 6.4.1 py39h80987f9_0 . tqdm 4.66.4 pyhd8ed1ab_0 conda-forge. traitlets 5.14.3 py39hca03da5_0 . typing-extensions 4.12.2 hd8ed1ab_0 conda-forge. typing_extensions 4.12.2 pyha770c72_0 conda-forge. tzdata 2024a h04d1e81_0 . umap-learn 0.5.6 pypi_0 pypi. unicodedata2 15.1.0 py39h0f82c59_0 conda-forge. urllib3 2.2.2 py39hca03da5_0 . wcwidth 0.2.5 pyhd3eb1b0_0 . webencodings 0.5.1 py39hca03da5_1 . websocket-client 1.8.0 py39hca03da5_0 . wheel 0.43.0 py39hca03da5_0 . widgetsnbextension 4.0.10 py39hca03da5_0 . xlrd 1.2.0 pyh9f0ad1d_1 conda-forge. xorg-libxau 1.0.11 hb547adb_0 conda-forge. xorg-libxdmcp 1.1.3 h27ca646_0 conda-forge. xz 5.4.6 h80987f9_1 . yaml 0.2.5 h3422bc3_2 conda-forge. zeromq 4.3.5 h313beb8_0 . zipp 3.19.2 pyhd8ed1ab_0 conda-forge. zlib 1.2.13 hfb2fe0b_6 conda-forge. zstd 1.5.6 hb46c0d2_0 conda-forge. ```. Im so sorry somethine else is wrong so scanpy.logging.print_versions() doesn't work at the moment. I'll fix it and update the post. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:102,performance,error,error,102,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:465,performance,time,time,465,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:580,performance,error,error,580,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:690,performance,time,times,690,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:766,performance,error,error,766,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hello scanpy! First time, please let me know what to fix about my question asking! When running sc.pp.highly_variable_genes I get this error. ""ImportError: Please install skmisc package via `pip install --user scikit-misc "". I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. --------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1783,performance,error,error,1783,"t find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:1898,performance,error,error,1898," I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc . Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1). Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes. ```python. <details>. ---------------------------------------------------------------------------. ModuleNotFoundError Traceback (most recent call last). File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 try:. ---> 66 from skmisc.loess import loess. 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). Cell In[14], line 1. ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'). 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:4563,performance,error,error,4563,"ghly_variable_genes_seurat_v3(. 656 adata,. 657 flavor=flavor,. 658 layer=layer,. 659 n_top_genes=n_top_genes,. 660 batch_key=batch_key,. 661 check_values=check_values,. 662 span=span,. 663 subset=subset,. 664 inplace=inplace,. 665 ). 667 cutoff = _Cutoffs.validate(. 668 n_top_genes=n_top_genes,. 669 min_disp=min_disp,. (...). 672 max_mean=max_mean,. 673 ). 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 66 from skmisc.loess import loess. 67 except ImportError:. ---> 68 raise ImportError(. 69 ""Please install skmisc package via `pip install --user scikit-misc"". 70 ). 71 df = pd.DataFrame(index=adata.var_names). 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. error when attempting install w/ conda. ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc. Channels:. - defaults. - conda-forge. Platform: osx-arm64. Collecting package metadata (repodata.json): done. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults. - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're. looking for, navigate to. https://anaconda.org. ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python. error: subprocess-exited-with-error. × Preparing metadata (pyproject.toml) did not run successfully. │ exit code: 1. ╰─> [32 lines of output]. + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-mis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
